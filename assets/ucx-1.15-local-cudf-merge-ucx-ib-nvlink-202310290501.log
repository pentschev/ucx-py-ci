/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38263 instead
  warnings.warn(
[1698558774.427388] [dgx13:85404:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:85404:0:85404]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  85404) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f2f409ee07d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f2f409ebc21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f2f409ebdbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7f2f40a969f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f2f40a6dd8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f2f40aa9afd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f2f40aae9ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f2f40aaf72f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7f2f40b5d6f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55cf8006e44c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55cf800536fb]
11  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55cf8004f094]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55cf80060519]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55cf80051128]
14  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55cf8004f094]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55cf80060519]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55cf80051128]
17  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55cf80103162]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55cf80055e64]
19  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55cf80103162]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55cf80055e64]
21  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55cf80103162]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55cf80055e64]
23  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55cf80103162]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55cf80055e64]
25  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55cf80103162]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55cf80055e64]
27  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55cf80103162]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f2f53cde1e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f2f53cdeaa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55cf8005877c]
31  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55cf8000ad05]
32  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55cf800577f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55cf80055929]
34  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55cf800607c2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cf800505c6]
36  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55cf800607c2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cf800505c6]
38  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55cf800607c2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cf800505c6]
40  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55cf800607c2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cf800505c6]
42  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55cf8004f094]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55cf80060519]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55cf80051128]
45  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55cf8004f094]
46  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55cf8006dccb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55cf8006e44c]
48  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55cf8013110e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55cf8005877c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55cf800536fb]
51  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55cf800607c2]
52  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55cf8006ddac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55cf800536fb]
54  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55cf800607c2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cf800505c6]
56  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55cf8004f094]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55cf80060519]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cf800505c6]
59  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55cf800607c2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55cf80050312]
61  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55cf8004f094]
=================================
2023-10-29 05:52:56,994 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33739
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #035] ep: 0x7fcb015361c0, tag: 0x596437f64a7f49e6, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #035] ep: 0x7fcb015361c0, tag: 0x596437f64a7f49e6, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-29 05:52:56,994 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33739
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #025] ep: 0x7f70e0331400, tag: 0xaf9e6f6749b6e3d2, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #025] ep: 0x7f70e0331400, tag: 0xaf9e6f6749b6e3d2, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-29 05:52:56,994 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33739
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #025] ep: 0x7f032ce8e300, tag: 0x72409d571675d87c, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #025] ep: 0x7f032ce8e300, tag: 0x72409d571675d87c, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-29 05:52:56,994 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33739
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #033] ep: 0x7f1f7d759280, tag: 0xc3dd4d156d6ceabb, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #033] ep: 0x7f1f7d759280, tag: 0xc3dd4d156d6ceabb, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-29 05:52:56,994 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33739
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #025] ep: 0x7fcc3cc9b280, tag: 0x6c47bf94eaa0ccb7, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #025] ep: 0x7fcc3cc9b280, tag: 0x6c47bf94eaa0ccb7, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-29 05:52:56,997 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33739
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f3924f5e280, tag: 0xaef46de960e11668, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #036] ep: 0x7f3924f5e280, tag: 0xaef46de960e11668, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-10-29 05:52:56,997 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33739
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #025] ep: 0x7f7655583340, tag: 0xea337d703d0ab81e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #025] ep: 0x7f7655583340, tag: 0xea337d703d0ab81e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
[1698558777.777701] [dgx13:85401:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:85401:0:85401]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  85401) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f0341ce407d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f0341ce1c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f0341ce1dbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7f0341d8c9f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f0341d63d8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f0341d9fafd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f0341da49ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f0341da572f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7f0341e536f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x559f698ab44c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x559f698906fb]
11  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559f6988c094]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559f6989d519]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x559f6988e128]
14  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559f6988c094]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559f6989d519]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x559f6988e128]
17  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559f69940162]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x559f69892e64]
19  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559f69940162]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x559f69892e64]
21  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559f69940162]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x559f69892e64]
23  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559f69940162]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x559f69892e64]
25  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559f69940162]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x559f69892e64]
27  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559f69940162]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f03670131e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f0367013aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x559f6989577c]
31  /opt/conda/envs/gdf/bin/python(+0xead05) [0x559f69847d05]
32  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x559f698947f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x559f69892929]
34  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559f6989d7c2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559f6988d5c6]
36  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559f6989d7c2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559f6988d5c6]
38  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559f6989d7c2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559f6988d5c6]
40  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559f6989d7c2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559f6988d5c6]
42  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559f6988c094]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559f6989d519]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x559f6988e128]
45  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559f6988c094]
46  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x559f698aaccb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x559f698ab44c]
48  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x559f6996e10e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x559f6989577c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x559f698906fb]
51  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559f6989d7c2]
52  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x559f698aadac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x559f698906fb]
54  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559f6989d7c2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559f6988d5c6]
56  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559f6988c094]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559f6989d519]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559f6988d5c6]
59  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559f6989d7c2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x559f6988d312]
61  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559f6988c094]
=================================
2023-10-29 05:53:00,568 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #041] ep: 0x7f1f7d7592c0, tag: 0x95d36730eb996475, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #041] ep: 0x7f1f7d7592c0, tag: 0x95d36730eb996475, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-29 05:53:00,568 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #037] ep: 0x7fcc3cc9b200, tag: 0xc97c506be0f95fa9, nbytes: 100016960, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #037] ep: 0x7fcc3cc9b200, tag: 0xc97c506be0f95fa9, nbytes: 100016960, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-10-29 05:53:00,570 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #056] ep: 0x7fcb01536240, tag: 0x7c8cd3780a84c058, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #056] ep: 0x7fcb01536240, tag: 0x7c8cd3780a84c058, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-29 05:53:00,570 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #033] ep: 0x7f70e0331340, tag: 0xbfc94a2b6edde8a8, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #033] ep: 0x7f70e0331340, tag: 0xbfc94a2b6edde8a8, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-29 05:53:00,571 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #033] ep: 0x7f7655583280, tag: 0x98f917edd65ce83e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #033] ep: 0x7f7655583280, tag: 0x98f917edd65ce83e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-29 05:53:00,571 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #033] ep: 0x7f3924f5e180, tag: 0x94974669fa623590, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #033] ep: 0x7f3924f5e180, tag: 0x94974669fa623590, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-29 05:53:01,645 - distributed.nanny - WARNING - Restarting worker
2023-10-29 05:53:04,964 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-adccb87e3fee0e0ff9c5206a34e9fe09', 4)
Function:  subgraph_callable-604d8bd3-e9a2-4230-8b21-4cbb3140
args:      (               key   payload
shuffle                     
0           325204  73302487
0           262184  20968255
0            18865  59139714
0           281849  10894266
0           507100  14319805
...            ...       ...
7        799903262   5674405
7        799921902   1857168
7        799995384  72744992
7        799899890  76746716
7        799939754  94635352

[100023899 rows x 2 columns],                  key   payload
2296          783923  85228195
2303       860970085  54631523
52256      206953645  39275542
52282      818023411  49158307
52283      408381556   4322830
...              ...       ...
99998485  1520632855  42743201
99998488  1504858102  96996203
99998489  1513153884  14106573
99998490  1551807900  96602017
99998492   387968159  97993966

[99980499 rows x 2 columns], 'simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 'simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-10-29 05:53:05,039 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-adccb87e3fee0e0ff9c5206a34e9fe09', 5)
Function:  subgraph_callable-604d8bd3-e9a2-4230-8b21-4cbb3140
args:      (               key   payload
shuffle                     
0           284688  92900079
0            32555  50889616
0            72993  72535441
0           297610  82882809
0           255081  76044716
...            ...       ...
7        799939752  60936581
7        799963066  96238240
7        799935078  58764419
7        799851055  56032812
7        799989006  16246192

[99993166 rows x 2 columns],                  key   payload
2273       411744614  83446787
2275       606681590   2970753
2279       810801639  10507816
2283       862929432  73701496
2286       807350807  19590396
...              ...       ...
99997661  1507660825   2253766
99998471   690995302  82889664
99998474  1552468558  44078070
99998475  1563696931  66551559
99998478  1523774391  66027308

[99997899 rows x 2 columns], 'simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 'simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-10-29 05:53:05,243 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
2023-10-29 05:53:05,243 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
2023-10-29 05:53:05,355 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 6)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           261795  44037472
0            88040  62189955
0           256008   8217278
0           300750   9716200
0            29613  53532069
...            ...       ...
0        799981921  58764868
0        799876185  53331831
0        799980420   4787811
0        799891107  21206935
0        799999480  71615924

[12498811 rows x 2 columns],                key   payload
shuffle                     
1            51235  18554687
1           111871  17555288
1            29401  68539417
1           114935  81399230
1            22734  52855690
...            ...       ...
1        799896273  14345813
1        799887930  15500188
1        799952682  58723584
1        799994356  67069555
1        799825560   8537277

[12498510 rows x 2 columns],                key   payload
shuffle                     
2           562086  95070268
2           440514  94397093
2           640847  27680078
2           464061  27128447
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-10-29 05:53:05,356 - distributed.worker - ERROR - 'int' object is not subscriptable
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2861, in get_data_from_worker
    status = response["status"]
TypeError: 'int' object is not subscriptable
2023-10-29 05:53:06,565 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
