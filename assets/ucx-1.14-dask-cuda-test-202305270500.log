============================= test session starts ==============================
platform linux -- Python 3.9.16, pytest-7.3.1, pluggy-1.0.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1181 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-05-27 06:08:56,105 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:08:56,109 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37367 instead
  warnings.warn(
2023-05-27 06:08:56,113 - distributed.scheduler - INFO - State start
2023-05-27 06:08:56,318 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:08:56,319 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-05-27 06:08:56,319 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37367/status
2023-05-27 06:08:56,621 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45329'
2023-05-27 06:08:56,636 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42779'
2023-05-27 06:08:56,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38343'
2023-05-27 06:08:56,644 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36349'
2023-05-27 06:08:57,465 - distributed.scheduler - INFO - Receive client connection: Client-f585cf88-fc54-11ed-a607-d8c49764f6bb
2023-05-27 06:08:57,477 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38834
2023-05-27 06:08:58,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-flvkdv_4', purging
2023-05-27 06:08:58,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n1mif38_', purging
2023-05-27 06:08:58,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:58,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:58,258 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:58,258 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:58,261 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:58,266 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:58,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:58,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:58,292 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:58,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:58,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:58,310 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-05-27 06:08:58,322 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35937
2023-05-27 06:08:58,322 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35937
2023-05-27 06:08:58,322 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35727
2023-05-27 06:08:58,322 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-05-27 06:08:58,322 - distributed.worker - INFO - -------------------------------------------------
2023-05-27 06:08:58,322 - distributed.worker - INFO -               Threads:                          4
2023-05-27 06:08:58,322 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-05-27 06:08:58,322 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-etc82brh
2023-05-27 06:08:58,322 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-035eca58-9154-4cd5-ae57-f5286d0acb95
2023-05-27 06:08:58,323 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab64c6a9-20ae-4289-be6e-d9639279cb18
2023-05-27 06:08:58,323 - distributed.worker - INFO - Starting Worker plugin PreImport-94e9b8c7-5e40-4d72-8c08-97b234c1dac5
2023-05-27 06:08:58,323 - distributed.worker - INFO - -------------------------------------------------
2023-05-27 06:08:58,337 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35937', status: init, memory: 0, processing: 0>
2023-05-27 06:08:58,338 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35937
2023-05-27 06:08:58,338 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38846
2023-05-27 06:08:58,338 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-05-27 06:08:58,339 - distributed.worker - INFO - -------------------------------------------------
2023-05-27 06:08:58,340 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:00,297 - distributed.nanny - INFO - Worker process 26492 exited with status 127
2023-05-27 06:09:00,298 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:00,516 - distributed.nanny - INFO - Worker process 26499 exited with status 127
2023-05-27 06:09:00,517 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:01,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7_ibk6jn', purging
2023-05-27 06:09:01,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hed2s5eu', purging
2023-05-27 06:09:01,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:01,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:01,911 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:02,114 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-21j18r4b', purging
2023-05-27 06:09:02,115 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:02,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:02,122 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:02,337 - distributed.nanny - INFO - Worker process 26495 exited with status 127
2023-05-27 06:09:02,338 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:03,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:03,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:03,976 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:04,812 - distributed.nanny - INFO - Worker process 26537 exited with status 127
2023-05-27 06:09:04,813 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:04,851 - distributed.nanny - INFO - Worker process 26540 exited with status 127
2023-05-27 06:09:04,851 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:04,937 - distributed.nanny - INFO - Worker process 26551 exited with status 127
2023-05-27 06:09:04,937 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:06,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pbunv7dm', purging
2023-05-27 06:09:06,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0d_423a1', purging
2023-05-27 06:09:06,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yhbvoabr', purging
2023-05-27 06:09:06,264 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:06,264 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:06,271 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:06,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:06,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:06,402 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:06,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:06,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:06,463 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:07,529 - distributed.scheduler - INFO - Remove client Client-f585cf88-fc54-11ed-a607-d8c49764f6bb
2023-05-27 06:09:07,529 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38834; closing.
2023-05-27 06:09:07,529 - distributed.scheduler - INFO - Remove client Client-f585cf88-fc54-11ed-a607-d8c49764f6bb
2023-05-27 06:09:07,530 - distributed.scheduler - INFO - Close client connection: Client-f585cf88-fc54-11ed-a607-d8c49764f6bb
2023-05-27 06:09:07,531 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45329'. Reason: nanny-close
2023-05-27 06:09:07,531 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42779'. Reason: nanny-close
2023-05-27 06:09:07,531 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38343'. Reason: nanny-close
2023-05-27 06:09:07,532 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36349'. Reason: nanny-close
2023-05-27 06:09:07,532 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-27 06:09:07,533 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35937. Reason: nanny-close
2023-05-27 06:09:07,534 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38846; closing.
2023-05-27 06:09:07,534 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-05-27 06:09:07,535 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35937', status: closing, memory: 0, processing: 0>
2023-05-27 06:09:07,535 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35937
2023-05-27 06:09:07,535 - distributed.scheduler - INFO - Lost all workers
2023-05-27 06:09:07,536 - distributed.nanny - INFO - Worker closed
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:08,575 - distributed.nanny - INFO - Worker process 26566 exited with status 127
2023-05-27 06:09:08,612 - distributed.nanny - INFO - Worker process 26569 exited with status 127
2023-05-27 06:09:08,638 - distributed.nanny - INFO - Worker process 26573 exited with status 127
2023-05-27 06:09:37,695 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:09:37,695 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:09:37,696 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:09:37,697 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-05-27 06:09:37,697 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-05-27 06:09:39,999 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:09:40,003 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36865 instead
  warnings.warn(
2023-05-27 06:09:40,006 - distributed.scheduler - INFO - State start
2023-05-27 06:09:40,070 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:09:40,070 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:09:40,071 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:09:40,071 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-05-27 06:09:40,259 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45135'
2023-05-27 06:09:40,274 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46643'
2023-05-27 06:09:40,275 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45347'
2023-05-27 06:09:40,282 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34851'
2023-05-27 06:09:40,290 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36827'
2023-05-27 06:09:40,297 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33265'
2023-05-27 06:09:40,304 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36419'
2023-05-27 06:09:40,313 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42829'
2023-05-27 06:09:41,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:41,881 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zbdg3g8i', purging
2023-05-27 06:09:41,881 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:41,881 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1wmetu56', purging
2023-05-27 06:09:41,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tbr6s6pg', purging
2023-05-27 06:09:41,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:41,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:41,896 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:41,896 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:41,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:41,929 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:41,930 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:41,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:41,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:41,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:41,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:41,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:41,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:41,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:41,948 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:41,949 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:41,950 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:42,160 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:42,163 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:42,193 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:42,220 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:42,234 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:45,148 - distributed.nanny - INFO - Worker process 26778 exited with status 127
2023-05-27 06:09:45,149 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:45,218 - distributed.nanny - INFO - Worker process 26774 exited with status 127
2023-05-27 06:09:45,219 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:45,260 - distributed.nanny - INFO - Worker process 26791 exited with status 127
2023-05-27 06:09:45,261 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:45,303 - distributed.nanny - INFO - Worker process 26788 exited with status 127
2023-05-27 06:09:45,304 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:45,360 - distributed.nanny - INFO - Worker process 26783 exited with status 127
2023-05-27 06:09:45,361 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:45,391 - distributed.nanny - INFO - Worker process 26770 exited with status 127
2023-05-27 06:09:45,392 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:46,191 - distributed.nanny - INFO - Worker process 26785 exited with status 127
2023-05-27 06:09:46,192 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:46,574 - distributed.nanny - INFO - Worker process 26767 exited with status 127
2023-05-27 06:09:46,575 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:46,830 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n0e5ndsq', purging
2023-05-27 06:09:46,830 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bxwf68tp', purging
2023-05-27 06:09:46,830 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a_rieg83', purging
2023-05-27 06:09:46,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-05v8iyfr', purging
2023-05-27 06:09:46,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zu8dcu6m', purging
2023-05-27 06:09:46,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2dxslwig', purging
2023-05-27 06:09:46,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3g3iqsop', purging
2023-05-27 06:09:46,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k5eq9rxv', purging
2023-05-27 06:09:46,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:46,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:46,907 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:46,907 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:46,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:46,949 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:46,961 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:47,030 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:47,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:47,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:47,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:47,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:47,096 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:47,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:47,116 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:47,166 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:47,250 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:47,258 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:47,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:47,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:48,065 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:48,216 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:48,216 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:48,625 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:53,449 - distributed.nanny - INFO - Worker process 26862 exited with status 127
2023-05-27 06:09:53,450 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:53,481 - distributed.nanny - INFO - Worker process 26865 exited with status 127
2023-05-27 06:09:53,481 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:53,526 - distributed.nanny - INFO - Worker process 26852 exited with status 127
2023-05-27 06:09:53,527 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:53,551 - distributed.nanny - INFO - Worker process 26855 exited with status 127
2023-05-27 06:09:53,552 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:53,580 - distributed.nanny - INFO - Worker process 26848 exited with status 127
2023-05-27 06:09:53,581 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:53,613 - distributed.nanny - INFO - Worker process 26859 exited with status 127
2023-05-27 06:09:53,614 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:54,144 - distributed.nanny - INFO - Worker process 26874 exited with status 127
2023-05-27 06:09:54,145 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:54,324 - distributed.nanny - INFO - Worker process 26877 exited with status 127
2023-05-27 06:09:54,324 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:54,542 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45135'. Reason: nanny-close
2023-05-27 06:09:54,543 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46643'. Reason: nanny-close
2023-05-27 06:09:54,543 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45347'. Reason: nanny-close
2023-05-27 06:09:54,543 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34851'. Reason: nanny-close
2023-05-27 06:09:54,543 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36827'. Reason: nanny-close
2023-05-27 06:09:54,544 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33265'. Reason: nanny-close
2023-05-27 06:09:54,544 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36419'. Reason: nanny-close
2023-05-27 06:09:54,544 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42829'. Reason: nanny-close
2023-05-27 06:09:55,153 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-otj21k2c', purging
2023-05-27 06:09:55,153 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ifssqpg1', purging
2023-05-27 06:09:55,153 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yaj7emkz', purging
2023-05-27 06:09:55,154 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zvec69zq', purging
2023-05-27 06:09:55,154 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-piei3_xu', purging
2023-05-27 06:09:55,154 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n8_z5n0t', purging
2023-05-27 06:09:55,155 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k4d1w9i7', purging
2023-05-27 06:09:55,155 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7woc480a', purging
2023-05-27 06:09:55,155 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:55,155 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:55,166 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:55,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:55,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:55,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:55,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:55,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:55,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:55,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:55,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:55,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:55,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:55,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:55,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:55,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:56,092 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:56,106 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:56,106 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:56,116 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:56,121 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:56,122 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:56,136 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:56,168 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:59,238 - distributed.nanny - INFO - Worker process 26943 exited with status 127
2023-05-27 06:09:59,294 - distributed.nanny - INFO - Worker process 26928 exited with status 127
2023-05-27 06:09:59,372 - distributed.nanny - INFO - Worker process 26934 exited with status 127
2023-05-27 06:09:59,399 - distributed.nanny - INFO - Worker process 26940 exited with status 127
2023-05-27 06:09:59,424 - distributed.nanny - INFO - Worker process 26931 exited with status 127
2023-05-27 06:09:59,446 - distributed.nanny - INFO - Worker process 26957 exited with status 127
2023-05-27 06:09:59,470 - distributed.nanny - INFO - Worker process 26937 exited with status 127
2023-05-27 06:09:59,499 - distributed.nanny - INFO - Worker process 26950 exited with status 127
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-05-27 06:10:26,511 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:10:26,516 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38679 instead
  warnings.warn(
2023-05-27 06:10:26,519 - distributed.scheduler - INFO - State start
2023-05-27 06:10:26,810 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:10:26,811 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:10:26,811 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:10:26,812 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-05-27 06:10:26,900 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43085'
2023-05-27 06:10:26,921 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40467'
2023-05-27 06:10:26,924 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39277'
2023-05-27 06:10:26,938 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44001'
2023-05-27 06:10:26,949 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38223'
2023-05-27 06:10:26,951 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38203'
2023-05-27 06:10:26,961 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37483'
2023-05-27 06:10:26,970 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39997'
2023-05-27 06:10:28,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hkvj8ttt', purging
2023-05-27 06:10:28,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rqwxdzqs', purging
2023-05-27 06:10:28,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i6f77c__', purging
2023-05-27 06:10:28,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-333c1jqp', purging
2023-05-27 06:10:28,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_dmn42n9', purging
2023-05-27 06:10:28,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nz1kho7v', purging
2023-05-27 06:10:28,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-323uqj9k', purging
2023-05-27 06:10:28,497 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aqvbym77', purging
2023-05-27 06:10:28,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,540 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:28,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,573 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:28,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,644 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:28,674 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,674 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,690 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,690 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,882 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:28,887 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:28,889 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:28,890 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:28,891 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:29,619 - distributed.nanny - INFO - Worker process 27198 exited with status 127
2023-05-27 06:10:29,620 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:31,145 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i26v8gij', purging
2023-05-27 06:10:31,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:31,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:31,716 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:32,486 - distributed.nanny - INFO - Worker process 27177 exited with status 127
2023-05-27 06:10:32,487 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:32,954 - distributed.nanny - INFO - Worker process 27180 exited with status 127
2023-05-27 06:10:32,955 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:33,032 - distributed.nanny - INFO - Worker process 27201 exited with status 127
2023-05-27 06:10:33,033 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:33,060 - distributed.nanny - INFO - Worker process 27192 exited with status 127
2023-05-27 06:10:33,061 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:33,129 - distributed.nanny - INFO - Worker process 27188 exited with status 127
2023-05-27 06:10:33,129 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:33,154 - distributed.nanny - INFO - Worker process 27184 exited with status 127
2023-05-27 06:10:33,154 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:33,338 - distributed.nanny - INFO - Worker process 27195 exited with status 127
2023-05-27 06:10:33,340 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:34,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04r0oswt', purging
2023-05-27 06:10:34,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6xgyaesg', purging
2023-05-27 06:10:34,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m0be2bbc', purging
2023-05-27 06:10:34,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9alhgum1', purging
2023-05-27 06:10:34,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v1rwe3lv', purging
2023-05-27 06:10:34,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n8lkfd59', purging
2023-05-27 06:10:34,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9b54disb', purging
2023-05-27 06:10:34,189 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:34,189 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:34,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:34,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:34,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:34,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:34,858 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0v4q82x3', purging
2023-05-27 06:10:34,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:34,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:34,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:34,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:34,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:34,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:35,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:35,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:35,260 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,299 - distributed.nanny - INFO - Worker process 27243 exited with status 127
2023-05-27 06:10:35,300 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:35,315 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,316 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,376 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,379 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,398 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,414 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:36,950 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:36,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:37,397 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:40,455 - distributed.nanny - INFO - Worker process 27276 exited with status 127
2023-05-27 06:10:40,456 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:40,493 - distributed.nanny - INFO - Worker process 27261 exited with status 127
2023-05-27 06:10:40,493 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:40,539 - distributed.nanny - INFO - Worker process 27283 exited with status 127
2023-05-27 06:10:40,540 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:40,570 - distributed.nanny - INFO - Worker process 27280 exited with status 127
2023-05-27 06:10:40,571 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:40,603 - distributed.nanny - INFO - Worker process 27288 exited with status 127
2023-05-27 06:10:40,604 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:40,690 - distributed.nanny - INFO - Worker process 27270 exited with status 127
2023-05-27 06:10:40,691 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:40,992 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43085'. Reason: nanny-close
2023-05-27 06:10:40,992 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40467'. Reason: nanny-close
2023-05-27 06:10:40,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39277'. Reason: nanny-close
2023-05-27 06:10:40,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38223'. Reason: nanny-close
2023-05-27 06:10:40,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44001'. Reason: nanny-close
2023-05-27 06:10:40,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38203'. Reason: nanny-close
2023-05-27 06:10:40,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37483'. Reason: nanny-close
2023-05-27 06:10:40,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39997'. Reason: nanny-close
2023-05-27 06:10:41,031 - distributed.nanny - INFO - Worker process 27273 exited with status 127
2023-05-27 06:10:42,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:42,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-us0sxojv', purging
2023-05-27 06:10:42,106 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:42,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z9a94h_e', purging
2023-05-27 06:10:42,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1fluu5oh', purging
2023-05-27 06:10:42,107 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7e3_85uy', purging
2023-05-27 06:10:42,107 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p758po8g', purging
2023-05-27 06:10:42,107 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lhgb_i8k', purging
2023-05-27 06:10:42,108 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5zmopsge', purging
2023-05-27 06:10:42,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:42,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:42,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:42,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:42,159 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:42,159 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:42,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:42,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:42,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:42,304 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:42,414 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:42,421 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:42,426 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:42,429 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:42,440 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:42,442 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:43,067 - distributed.nanny - INFO - Worker process 27310 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:44,661 - distributed.nanny - INFO - Worker process 27356 exited with status 127
2023-05-27 06:10:44,718 - distributed.nanny - INFO - Worker process 27353 exited with status 127
2023-05-27 06:10:44,741 - distributed.nanny - INFO - Worker process 27364 exited with status 127
2023-05-27 06:10:44,763 - distributed.nanny - INFO - Worker process 27350 exited with status 127
2023-05-27 06:10:44,785 - distributed.nanny - INFO - Worker process 27347 exited with status 127
2023-05-27 06:10:44,809 - distributed.nanny - INFO - Worker process 27359 exited with status 127
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-05-27 06:11:13,029 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:11:13,033 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34509 instead
  warnings.warn(
2023-05-27 06:11:13,036 - distributed.scheduler - INFO - State start
2023-05-27 06:11:13,055 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:11:13,056 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:11:13,056 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:11:13,056 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-05-27 06:11:13,448 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41981'
2023-05-27 06:11:13,465 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35039'
2023-05-27 06:11:13,467 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34251'
2023-05-27 06:11:13,480 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38081'
2023-05-27 06:11:13,484 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38183'
2023-05-27 06:11:13,498 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42031'
2023-05-27 06:11:13,500 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34805'
2023-05-27 06:11:13,508 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43601'
2023-05-27 06:11:15,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ffgjrxlf', purging
2023-05-27 06:11:15,169 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:15,169 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:15,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ejlg74m4', purging
2023-05-27 06:11:15,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6qroqe41', purging
2023-05-27 06:11:15,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5w55kz6', purging
2023-05-27 06:11:15,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kypv06v8', purging
2023-05-27 06:11:15,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c2dyg7nq', purging
2023-05-27 06:11:15,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rfmsr258', purging
2023-05-27 06:11:15,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:15,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:15,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:15,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:15,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:15,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:15,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:15,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:15,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:15,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:15,278 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:15,278 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:15,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:15,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:15,612 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:15,624 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:15,626 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:15,647 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:15,647 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:15,671 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:15,673 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:15,681 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:18,726 - distributed.nanny - INFO - Worker process 27601 exited with status 127
2023-05-27 06:11:18,727 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:18,841 - distributed.nanny - INFO - Worker process 27595 exited with status 127
2023-05-27 06:11:18,842 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:18,884 - distributed.nanny - INFO - Worker process 27584 exited with status 127
2023-05-27 06:11:18,885 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:19,173 - distributed.nanny - INFO - Worker process 27577 exited with status 127
2023-05-27 06:11:19,174 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:19,207 - distributed.nanny - INFO - Worker process 27598 exited with status 127
2023-05-27 06:11:19,208 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:19,250 - distributed.nanny - INFO - Worker process 27580 exited with status 127
2023-05-27 06:11:19,251 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:19,274 - distributed.nanny - INFO - Worker process 27592 exited with status 127
2023-05-27 06:11:19,275 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:19,308 - distributed.nanny - INFO - Worker process 27588 exited with status 127
2023-05-27 06:11:19,309 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:20,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k15s7i3p', purging
2023-05-27 06:11:20,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kex4m1sz', purging
2023-05-27 06:11:20,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fe2c7bk0', purging
2023-05-27 06:11:20,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rwhvvk61', purging
2023-05-27 06:11:20,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kqtxdqz0', purging
2023-05-27 06:11:20,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qkv5xv4l', purging
2023-05-27 06:11:20,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ky3ecuaw', purging
2023-05-27 06:11:20,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_es53xvf', purging
2023-05-27 06:11:20,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:20,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:20,449 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:20,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:20,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:20,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:20,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:20,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:20,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:20,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:20,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:20,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:20,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:20,993 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:20,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:20,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:20,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:21,740 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:21,759 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:21,776 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:21,778 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:21,845 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:21,854 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:21,856 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:26,007 - distributed.nanny - INFO - Worker process 27659 exited with status 127
2023-05-27 06:11:26,008 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:26,100 - distributed.nanny - INFO - Worker process 27672 exited with status 127
2023-05-27 06:11:26,101 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:26,158 - distributed.nanny - INFO - Worker process 27669 exited with status 127
2023-05-27 06:11:26,159 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:26,205 - distributed.nanny - INFO - Worker process 27678 exited with status 127
2023-05-27 06:11:26,206 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:26,987 - distributed.nanny - INFO - Worker process 27666 exited with status 127
2023-05-27 06:11:26,988 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:27,189 - distributed.nanny - INFO - Worker process 27675 exited with status 127
2023-05-27 06:11:27,189 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:27,214 - distributed.nanny - INFO - Worker process 27681 exited with status 127
2023-05-27 06:11:27,215 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:27,396 - distributed.nanny - INFO - Worker process 27663 exited with status 127
2023-05-27 06:11:27,397 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:27,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jgexz89q', purging
2023-05-27 06:11:27,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_h_oy7sx', purging
2023-05-27 06:11:27,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6hcr7669', purging
2023-05-27 06:11:27,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z997qpvw', purging
2023-05-27 06:11:27,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5wbmrvo0', purging
2023-05-27 06:11:27,564 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-legvoxjv', purging
2023-05-27 06:11:27,564 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gocelpju', purging
2023-05-27 06:11:27,564 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w1i9b93p', purging
2023-05-27 06:11:27,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:27,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:27,603 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41981'. Reason: nanny-close
2023-05-27 06:11:27,604 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35039'. Reason: nanny-close
2023-05-27 06:11:27,604 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34251'. Reason: nanny-close
2023-05-27 06:11:27,604 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38081'. Reason: nanny-close
2023-05-27 06:11:27,604 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42031'. Reason: nanny-close
2023-05-27 06:11:27,604 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34805'. Reason: nanny-close
2023-05-27 06:11:27,605 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43601'. Reason: nanny-close
2023-05-27 06:11:27,605 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38183'. Reason: nanny-close
2023-05-27 06:11:27,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:27,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:27,703 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:27,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:27,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:27,814 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:27,843 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:27,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:27,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:27,993 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:28,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:28,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:28,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:28,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:28,940 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:28,953 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:28,953 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:28,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:28,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:29,112 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:29,439 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:29,443 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:31,956 - distributed.nanny - INFO - Worker process 27749 exited with status 127
2023-05-27 06:11:31,984 - distributed.nanny - INFO - Worker process 27743 exited with status 127
2023-05-27 06:11:32,037 - distributed.nanny - INFO - Worker process 27735 exited with status 127
2023-05-27 06:11:32,087 - distributed.nanny - INFO - Worker process 27746 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:32,468 - distributed.nanny - INFO - Worker process 27759 exited with status 127
2023-05-27 06:11:32,490 - distributed.nanny - INFO - Worker process 27756 exited with status 127
2023-05-27 06:11:32,531 - distributed.nanny - INFO - Worker process 27762 exited with status 127
2023-05-27 06:11:32,553 - distributed.nanny - INFO - Worker process 27765 exited with status 127
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-05-27 06:11:59,311 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:11:59,314 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45449 instead
  warnings.warn(
2023-05-27 06:11:59,318 - distributed.scheduler - INFO - State start
2023-05-27 06:11:59,336 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:11:59,337 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:11:59,337 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:11:59,337 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-05-27 06:11:59,503 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36731'
2023-05-27 06:11:59,513 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43473'
2023-05-27 06:11:59,526 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44355'
2023-05-27 06:11:59,528 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35117'
2023-05-27 06:11:59,535 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40963'
2023-05-27 06:11:59,543 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38571'
2023-05-27 06:11:59,550 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45613'
2023-05-27 06:11:59,558 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40493'
2023-05-27 06:12:01,097 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w0vexkwq', purging
2023-05-27 06:12:01,098 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2d1_6uf_', purging
2023-05-27 06:12:01,098 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zr0_0pr_', purging
2023-05-27 06:12:01,098 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5sfcw22s', purging
2023-05-27 06:12:01,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-88wj44ct', purging
2023-05-27 06:12:01,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yualo_7r', purging
2023-05-27 06:12:01,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bhcuebj0', purging
2023-05-27 06:12:01,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kzdb63um', purging
2023-05-27 06:12:01,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:01,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:01,123 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:01,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:01,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:01,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:01,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:01,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:01,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:01,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:01,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:01,153 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:01,178 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:01,179 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:01,180 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:01,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:01,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:01,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:01,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:01,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:01,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:01,218 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:01,222 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:01,253 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:03,141 - distributed.nanny - INFO - Worker process 27987 exited with status 127
2023-05-27 06:12:03,142 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:03,254 - distributed.nanny - INFO - Worker process 28011 exited with status 127
2023-05-27 06:12:03,255 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:03,320 - distributed.nanny - INFO - Worker process 27994 exited with status 127
2023-05-27 06:12:03,321 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:03,386 - distributed.nanny - INFO - Worker process 28008 exited with status 127
2023-05-27 06:12:03,387 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:03,413 - distributed.nanny - INFO - Worker process 27998 exited with status 127
2023-05-27 06:12:03,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:03,439 - distributed.nanny - INFO - Worker process 28002 exited with status 127
2023-05-27 06:12:03,440 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:03,467 - distributed.nanny - INFO - Worker process 27990 exited with status 127
2023-05-27 06:12:03,468 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:03,506 - distributed.nanny - INFO - Worker process 28006 exited with status 127
2023-05-27 06:12:03,507 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:04,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5b2k6iol', purging
2023-05-27 06:12:04,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_985p0a_', purging
2023-05-27 06:12:04,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-scdj8j1r', purging
2023-05-27 06:12:04,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s3xi99dl', purging
2023-05-27 06:12:04,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cureh44e', purging
2023-05-27 06:12:04,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufury69y', purging
2023-05-27 06:12:04,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xczooek_', purging
2023-05-27 06:12:04,834 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8bg80uk_', purging
2023-05-27 06:12:04,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:04,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:04,860 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:04,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:04,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:04,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:04,936 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:04,953 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:05,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:05,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:05,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:05,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:05,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:05,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:05,135 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:05,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:05,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:05,157 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:05,160 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:05,172 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:05,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:05,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:05,191 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:05,240 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:06,617 - distributed.nanny - INFO - Worker process 28064 exited with status 127
2023-05-27 06:12:06,618 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:07,289 - distributed.nanny - INFO - Worker process 28075 exited with status 127
2023-05-27 06:12:07,290 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:07,329 - distributed.nanny - INFO - Worker process 28068 exited with status 127
2023-05-27 06:12:07,330 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:07,356 - distributed.nanny - INFO - Worker process 28082 exited with status 127
2023-05-27 06:12:07,356 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:07,387 - distributed.nanny - INFO - Worker process 28079 exited with status 127
2023-05-27 06:12:07,388 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:07,445 - distributed.nanny - INFO - Worker process 28085 exited with status 127
2023-05-27 06:12:07,446 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:07,470 - distributed.nanny - INFO - Worker process 28088 exited with status 127
2023-05-27 06:12:07,471 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:07,502 - distributed.nanny - INFO - Worker process 28091 exited with status 127
2023-05-27 06:12:07,503 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:08,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-98_56g39', purging
2023-05-27 06:12:08,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6_l2jtiy', purging
2023-05-27 06:12:08,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5zbjbfu5', purging
2023-05-27 06:12:08,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xz9hy9el', purging
2023-05-27 06:12:08,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8_n6uzzo', purging
2023-05-27 06:12:08,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6_lx0pdu', purging
2023-05-27 06:12:08,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vwklpfh9', purging
2023-05-27 06:12:08,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hot0oo2e', purging
2023-05-27 06:12:08,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:08,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:08,297 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:08,717 - distributed.nanny - INFO - Worker process 28143 exited with status 127
2023-05-27 06:12:08,717 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:08,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-98huie2r', purging
2023-05-27 06:12:08,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:08,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:08,964 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:08,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:08,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:08,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:08,996 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:09,011 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:09,022 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:09,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:09,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:09,060 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:09,119 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:09,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:09,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:09,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:09,188 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:09,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:09,268 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:09,271 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:09,272 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:10,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-09u7su1u', purging
2023-05-27 06:12:10,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:10,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:10,719 - distributed.nanny - INFO - Worker process 28153 exited with status 127
2023-05-27 06:12:10,720 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:10,750 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:11,145 - distributed.nanny - INFO - Worker process 28160 exited with status 127
2023-05-27 06:12:11,146 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:11,180 - distributed.nanny - INFO - Worker process 28157 exited with status 127
2023-05-27 06:12:11,181 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:11,213 - distributed.nanny - INFO - Worker process 28163 exited with status 127
2023-05-27 06:12:11,213 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:11,288 - distributed.nanny - INFO - Worker process 28169 exited with status 127
2023-05-27 06:12:11,289 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:11,320 - distributed.nanny - INFO - Worker process 28166 exited with status 127
2023-05-27 06:12:11,321 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:11,351 - distributed.nanny - INFO - Worker process 28172 exited with status 127
2023-05-27 06:12:11,352 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:11,644 - distributed.nanny - INFO - Worker process 28188 exited with status 127
2023-05-27 06:12:11,645 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:12,370 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7yh5ctt8', purging
2023-05-27 06:12:12,371 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jp7mqjq6', purging
2023-05-27 06:12:12,371 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dsokx_v4', purging
2023-05-27 06:12:12,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i91u02gm', purging
2023-05-27 06:12:12,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g7t4kg58', purging
2023-05-27 06:12:12,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rjwiziuu', purging
2023-05-27 06:12:12,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gmsu7h86', purging
2023-05-27 06:12:12,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:12,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:12,397 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:12,695 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:12,695 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:12,701 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:12,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:12,721 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:12,725 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:12,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:12,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:12,846 - distributed.nanny - INFO - Worker process 28229 exited with status 127
2023-05-27 06:12:12,847 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:12,854 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:12,899 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mjt6xags', purging
2023-05-27 06:12:12,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:12,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:12,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:12,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:12,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:12,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:13,205 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:13,205 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:13,206 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:13,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:13,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:13,300 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:13,680 - distributed.nanny - INFO - Worker process 28245 exited with status 127
2023-05-27 06:12:13,681 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:13,711 - distributed.nanny - INFO - Worker process 28238 exited with status 127
2023-05-27 06:12:13,711 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:13,931 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35117'. Reason: nanny-close
2023-05-27 06:12:13,932 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36731'. Reason: nanny-close
2023-05-27 06:12:13,932 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43473'. Reason: nanny-close
2023-05-27 06:12:13,932 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44355'. Reason: nanny-close
2023-05-27 06:12:13,932 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40963'. Reason: nanny-close
2023-05-27 06:12:13,932 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38571'. Reason: nanny-close
2023-05-27 06:12:13,932 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45613'. Reason: nanny-close
2023-05-27 06:12:13,933 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40493'. Reason: nanny-close
2023-05-27 06:12:14,307 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iy3p8g6d', purging
2023-05-27 06:12:14,307 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l8jx69iv', purging
2023-05-27 06:12:14,308 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:14,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:14,505 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:14,722 - distributed.nanny - INFO - Worker process 28241 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:14,922 - distributed.nanny - INFO - Worker process 28249 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:14,980 - distributed.nanny - INFO - Worker process 28258 exited with status 127
2023-05-27 06:12:15,015 - distributed.nanny - INFO - Worker process 28253 exited with status 127
2023-05-27 06:12:15,057 - distributed.nanny - INFO - Worker process 28262 exited with status 127
2023-05-27 06:12:15,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-98504rfm', purging
2023-05-27 06:12:15,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d3lq6vt7', purging
2023-05-27 06:12:15,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dtuwd5d7', purging
2023-05-27 06:12:15,214 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pcph3jw9', purging
2023-05-27 06:12:15,214 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d3na79uf', purging
2023-05-27 06:12:15,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:15,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:15,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:15,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:15,261 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:15,261 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:15,447 - distributed.nanny - INFO - Worker process 28287 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:15,934 - distributed.nanny - INFO - Worker process 28314 exited with status 127
2023-05-27 06:12:15,956 - distributed.nanny - INFO - Worker process 28311 exited with status 127
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-05-27 06:12:45,853 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:12:45,857 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37693 instead
  warnings.warn(
2023-05-27 06:12:45,860 - distributed.scheduler - INFO - State start
2023-05-27 06:12:45,878 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:12:45,879 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:12:45,879 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:12:45,880 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-05-27 06:12:45,978 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43871'
2023-05-27 06:12:47,364 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pkpt2xr_', purging
2023-05-27 06:12:47,364 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2nr_skzl', purging
2023-05-27 06:12:47,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bmk7eo0d', purging
2023-05-27 06:12:47,365 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:47,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:47,637 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:48,038 - distributed.nanny - INFO - Worker process 28517 exited with status 127
2023-05-27 06:12:48,039 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:49,410 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aiiilsup', purging
2023-05-27 06:12:49,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:49,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:49,704 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:50,101 - distributed.nanny - INFO - Worker process 28527 exited with status 127
2023-05-27 06:12:50,102 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:51,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ab1jkoue', purging
2023-05-27 06:12:51,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:51,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:51,781 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:52,166 - distributed.nanny - INFO - Worker process 28537 exited with status 127
2023-05-27 06:12:52,166 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:53,517 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bnyvurho', purging
2023-05-27 06:12:53,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:53,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:53,771 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:54,139 - distributed.nanny - INFO - Worker process 28547 exited with status 127
2023-05-27 06:12:54,140 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:54,381 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43871'. Reason: nanny-close
2023-05-27 06:12:55,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zjc4jpeo', purging
2023-05-27 06:12:55,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:55,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:55,722 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:56,110 - distributed.nanny - INFO - Worker process 28557 exited with status 127
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-05-27 06:13:27,777 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:13:27,781 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45099 instead
  warnings.warn(
2023-05-27 06:13:27,784 - distributed.scheduler - INFO - State start
2023-05-27 06:13:27,802 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:13:27,803 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:13:27,803 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:13:27,804 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-05-27 06:13:27,942 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33917'
2023-05-27 06:13:29,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u5e9gy71', purging
2023-05-27 06:13:29,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:13:29,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:13:29,633 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:13:30,015 - distributed.nanny - INFO - Worker process 28815 exited with status 127
2023-05-27 06:13:30,016 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:13:31,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zgbjqqsn', purging
2023-05-27 06:13:31,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:13:31,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:13:31,646 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:13:32,031 - distributed.nanny - INFO - Worker process 28825 exited with status 127
2023-05-27 06:13:32,032 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:13:33,400 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lxnsxf8l', purging
2023-05-27 06:13:33,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:13:33,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:13:33,676 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:13:34,082 - distributed.nanny - INFO - Worker process 28835 exited with status 127
2023-05-27 06:13:34,083 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:13:35,442 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r3owdvp7', purging
2023-05-27 06:13:35,443 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:13:35,443 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:13:35,720 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:13:36,133 - distributed.nanny - INFO - Worker process 28845 exited with status 127
2023-05-27 06:13:36,133 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:13:36,406 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33917'. Reason: nanny-close
2023-05-27 06:13:37,517 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-33msycdw', purging
2023-05-27 06:13:37,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:13:37,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:13:37,801 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:13:38,196 - distributed.nanny - INFO - Worker process 28855 exited with status 127
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-05-27 06:14:08,204 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:14:08,208 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38821 instead
  warnings.warn(
2023-05-27 06:14:08,212 - distributed.scheduler - INFO - State start
2023-05-27 06:14:08,231 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:14:08,232 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:14:08,232 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:14:08,233 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-05-27 06:28:43,313 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:28:43,318 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36175 instead
  warnings.warn(
2023-05-27 06:28:43,322 - distributed.scheduler - INFO - State start
2023-05-27 06:28:43,342 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:28:43,344 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-05-27 06:28:43,344 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36175/status
2023-05-27 06:28:43,443 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43039'
2023-05-27 06:28:43,654 - distributed.scheduler - INFO - Receive client connection: Client-b92a0865-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:28:43,668 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58254
2023-05-27 06:28:44,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-klrb6r8p', purging
2023-05-27 06:28:44,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:44,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:44,840 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:46,857 - distributed.nanny - INFO - Worker process 33318 exited with status 127
2023-05-27 06:28:46,858 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:48,239 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jj3pwqd2', purging
2023-05-27 06:28:48,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:48,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:48,247 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:50,594 - distributed.nanny - INFO - Worker process 33329 exited with status 127
2023-05-27 06:28:50,595 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:52,044 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i89xlbqz', purging
2023-05-27 06:28:52,045 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:52,045 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:52,051 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:52,426 - distributed.nanny - INFO - Worker process 33339 exited with status 127
2023-05-27 06:28:52,426 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:53,733 - distributed.scheduler - INFO - Remove client Client-b92a0865-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:28:53,734 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58254; closing.
2023-05-27 06:28:53,734 - distributed.scheduler - INFO - Remove client Client-b92a0865-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:28:53,736 - distributed.scheduler - INFO - Close client connection: Client-b92a0865-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:28:53,736 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43039'. Reason: nanny-close
2023-05-27 06:28:53,813 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ednr7i_7', purging
2023-05-27 06:28:53,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:53,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:53,821 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:55,268 - distributed.nanny - INFO - Worker process 33349 exited with status 127
2023-05-27 06:29:23,800 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:29:23,800 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:29:23,801 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:29:23,802 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-05-27 06:29:23,803 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-05-27 06:29:26,135 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:29:26,140 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37809 instead
  warnings.warn(
2023-05-27 06:29:26,144 - distributed.scheduler - INFO - State start
2023-05-27 06:29:26,178 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:29:26,179 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:29:26,180 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37809/status
2023-05-27 06:29:26,504 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44347'
2023-05-27 06:29:26,523 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40155'
2023-05-27 06:29:26,525 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40633'
2023-05-27 06:29:26,532 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34229'
2023-05-27 06:29:26,540 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43261'
2023-05-27 06:29:26,548 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39121'
2023-05-27 06:29:26,556 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33969'
2023-05-27 06:29:26,564 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37121'
2023-05-27 06:29:27,107 - distributed.scheduler - INFO - Receive client connection: Client-d29e4eaf-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:29:27,120 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59584
2023-05-27 06:29:28,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7hq6wkjk', purging
2023-05-27 06:29:28,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:28,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:28,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:28,216 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,216 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:28,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:28,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:28,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:28,284 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:28,285 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:28,285 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:28,290 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:28,293 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:28,293 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:28,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:28,313 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:28,355 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:31,481 - distributed.nanny - INFO - Worker process 33544 exited with status 127
2023-05-27 06:29:31,482 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:31,581 - distributed.nanny - INFO - Worker process 33526 exited with status 127
2023-05-27 06:29:31,581 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:31,640 - distributed.nanny - INFO - Worker process 33541 exited with status 127
2023-05-27 06:29:31,641 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:31,694 - distributed.nanny - INFO - Worker process 33529 exited with status 127
2023-05-27 06:29:31,695 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:32,737 - distributed.nanny - INFO - Worker process 33547 exited with status 127
2023-05-27 06:29:32,738 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:32,782 - distributed.nanny - INFO - Worker process 33534 exited with status 127
2023-05-27 06:29:32,783 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:32,838 - distributed.nanny - INFO - Worker process 33550 exited with status 127
2023-05-27 06:29:32,839 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:32,870 - distributed.nanny - INFO - Worker process 33537 exited with status 127
2023-05-27 06:29:32,871 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:33,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0zitoy9r', purging
2023-05-27 06:29:33,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aleav6ti', purging
2023-05-27 06:29:33,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wu1te9ph', purging
2023-05-27 06:29:33,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5r6g1xv6', purging
2023-05-27 06:29:33,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-shjkuz5_', purging
2023-05-27 06:29:33,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-01cjhd13', purging
2023-05-27 06:29:33,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n5v2v647', purging
2023-05-27 06:29:33,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2a2ygug9', purging
2023-05-27 06:29:33,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:33,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:33,084 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:33,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:33,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:33,218 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:33,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:33,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:33,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:33,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:33,378 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:33,391 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:34,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u301nweq', purging
2023-05-27 06:29:34,419 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:34,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:34,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:34,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:34,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:34,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:34,526 - distributed.nanny - INFO - Worker process 33610 exited with status 127
2023-05-27 06:29:34,527 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:34,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:34,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:34,579 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:34,581 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:34,590 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:34,787 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:35,055 - distributed.nanny - INFO - Worker process 33613 exited with status 127
2023-05-27 06:29:35,056 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:35,198 - distributed.nanny - INFO - Worker process 33616 exited with status 127
2023-05-27 06:29:35,199 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:35,315 - distributed.nanny - INFO - Worker process 33619 exited with status 127
2023-05-27 06:29:35,316 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:36,178 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8qc_n5mn', purging
2023-05-27 06:29:36,178 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jhk0fwg7', purging
2023-05-27 06:29:36,179 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k7gs5k75', purging
2023-05-27 06:29:36,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:36,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:36,614 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:36,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:36,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:36,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:36,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:36,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:36,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:36,985 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:37,141 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:37,141 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:38,287 - distributed.nanny - INFO - Worker process 33632 exited with status 127
2023-05-27 06:29:38,288 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:38,382 - distributed.nanny - INFO - Worker process 33629 exited with status 127
2023-05-27 06:29:38,382 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:38,413 - distributed.nanny - INFO - Worker process 33635 exited with status 127
2023-05-27 06:29:38,413 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:39,631 - distributed.nanny - INFO - Worker process 33626 exited with status 127
2023-05-27 06:29:39,632 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:39,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e63seq_t', purging
2023-05-27 06:29:39,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3x4fdji5', purging
2023-05-27 06:29:39,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9hf6qce0', purging
2023-05-27 06:29:39,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-moyzhmj_', purging
2023-05-27 06:29:39,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zgm4zh2o', purging
2023-05-27 06:29:39,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:39,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:39,968 - distributed.nanny - INFO - Worker process 33666 exited with status 127
2023-05-27 06:29:39,969 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:40,019 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:40,025 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x6duqpo_', purging
2023-05-27 06:29:40,025 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ajf4ph0a', purging
2023-05-27 06:29:40,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:40,026 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:40,067 - distributed.nanny - INFO - Worker process 33680 exited with status 127
2023-05-27 06:29:40,068 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:40,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:40,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:40,127 - distributed.nanny - INFO - Worker process 33688 exited with status 127
2023-05-27 06:29:40,128 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:40,166 - distributed.nanny - INFO - Worker process 33685 exited with status 127
2023-05-27 06:29:40,166 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:40,176 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:40,176 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:41,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9d_fb0gf', purging
2023-05-27 06:29:41,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:41,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:41,543 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:41,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:41,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:41,691 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:41,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:41,738 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:41,755 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:41,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:41,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:41,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:41,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:41,865 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:41,869 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:42,072 - distributed.nanny - INFO - Worker process 33718 exited with status 127
2023-05-27 06:29:42,073 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:42,154 - distributed.nanny - INFO - Worker process 33724 exited with status 127
2023-05-27 06:29:42,154 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:42,221 - distributed.nanny - INFO - Worker process 33721 exited with status 127
2023-05-27 06:29:42,221 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:43,135 - distributed.scheduler - INFO - Remove client Client-d29e4eaf-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:29:43,136 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59584; closing.
2023-05-27 06:29:43,137 - distributed.scheduler - INFO - Remove client Client-d29e4eaf-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:29:43,138 - distributed.scheduler - INFO - Close client connection: Client-d29e4eaf-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:29:43,138 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34229'. Reason: nanny-close
2023-05-27 06:29:43,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44347'. Reason: nanny-close
2023-05-27 06:29:43,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40155'. Reason: nanny-close
2023-05-27 06:29:43,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40633'. Reason: nanny-close
2023-05-27 06:29:43,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43261'. Reason: nanny-close
2023-05-27 06:29:43,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39121'. Reason: nanny-close
2023-05-27 06:29:43,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33969'. Reason: nanny-close
2023-05-27 06:29:43,140 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37121'. Reason: nanny-close
2023-05-27 06:29:43,667 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l6e9m_ut', purging
2023-05-27 06:29:43,668 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lmrjpqj7', purging
2023-05-27 06:29:43,668 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xe_dtagn', purging
2023-05-27 06:29:43,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:43,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:43,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:43,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:43,802 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:43,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:44,341 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:44,359 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:29:44,380 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:45,074 - distributed.nanny - INFO - Worker process 33738 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:45,269 - distributed.nanny - INFO - Worker process 33745 exited with status 127
2023-05-27 06:29:45,302 - distributed.nanny - INFO - Worker process 33752 exited with status 127
2023-05-27 06:29:45,400 - distributed.nanny - INFO - Worker process 33756 exited with status 127
2023-05-27 06:29:46,486 - distributed.nanny - INFO - Worker process 33763 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:46,913 - distributed.nanny - INFO - Worker process 33798 exited with status 127
2023-05-27 06:29:46,941 - distributed.nanny - INFO - Worker process 33801 exited with status 127
2023-05-27 06:29:47,018 - distributed.nanny - INFO - Worker process 33795 exited with status 127
2023-05-27 06:30:13,252 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:30:13,253 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:30:13,254 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:30:13,255 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:30:13,255 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-05-27 06:30:15,515 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:30:15,519 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45571 instead
  warnings.warn(
2023-05-27 06:30:15,522 - distributed.scheduler - INFO - State start
2023-05-27 06:30:15,594 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:30:15,595 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:30:15,595 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45571/status
2023-05-27 06:30:15,625 - distributed.scheduler - INFO - Receive client connection: Client-f01aab08-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:30:15,637 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45580
2023-05-27 06:30:15,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42781'
2023-05-27 06:30:17,360 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aois4mxx', purging
2023-05-27 06:30:17,361 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-30acpya2', purging
2023-05-27 06:30:17,361 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d74cr6cm', purging
2023-05-27 06:30:17,362 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xqy_uayy', purging
2023-05-27 06:30:17,362 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1xkzqdus', purging
2023-05-27 06:30:17,362 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8tnajsgb', purging
2023-05-27 06:30:17,362 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_whdhswb', purging
2023-05-27 06:30:17,363 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mtrtg6r8', purging
2023-05-27 06:30:17,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:17,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:17,520 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:18,669 - distributed.nanny - INFO - Worker process 34008 exited with status 127
2023-05-27 06:30:18,671 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:20,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4cc41kun', purging
2023-05-27 06:30:20,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:20,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:20,190 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:21,581 - distributed.nanny - INFO - Worker process 34018 exited with status 127
2023-05-27 06:30:21,582 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:23,050 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5q66gh4n', purging
2023-05-27 06:30:23,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:23,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:23,148 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:23,860 - distributed.nanny - INFO - Worker process 34028 exited with status 127
2023-05-27 06:30:23,861 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:25,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pf0lswk7', purging
2023-05-27 06:30:25,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:25,302 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:25,677 - distributed.scheduler - INFO - Remove client Client-f01aab08-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:30:25,677 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45580; closing.
2023-05-27 06:30:25,677 - distributed.scheduler - INFO - Remove client Client-f01aab08-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:30:25,678 - distributed.scheduler - INFO - Close client connection: Client-f01aab08-fc57-11ed-a607-d8c49764f6bb
2023-05-27 06:30:25,679 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42781'. Reason: nanny-close
2023-05-27 06:30:25,687 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:26,748 - distributed.nanny - INFO - Worker process 34038 exited with status 127
2023-05-27 06:30:55,711 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:30:55,711 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:30:55,712 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:30:55,713 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:30:55,713 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-05-27 06:30:57,984 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:30:57,989 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37765 instead
  warnings.warn(
2023-05-27 06:30:57,992 - distributed.scheduler - INFO - State start
2023-05-27 06:30:58,055 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:30:58,056 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:30:58,056 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37765/status
2023-05-27 06:30:58,118 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34007'
2023-05-27 06:30:58,459 - distributed.scheduler - INFO - Receive client connection: Client-0965af48-fc58-11ed-a607-d8c49764f6bb
2023-05-27 06:30:58,473 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60500
2023-05-27 06:30:59,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wf_p_8es', purging
2023-05-27 06:30:59,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:59,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:59,624 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:00,684 - distributed.nanny - INFO - Worker process 34215 exited with status 127
2023-05-27 06:31:00,685 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:02,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p5v9krcg', purging
2023-05-27 06:31:02,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:02,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:02,217 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:02,876 - distributed.nanny - INFO - Worker process 34226 exited with status 127
2023-05-27 06:31:02,877 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:04,342 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rjc09y5g', purging
2023-05-27 06:31:04,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:04,343 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:04,397 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:05,262 - distributed.nanny - INFO - Worker process 34236 exited with status 127
2023-05-27 06:31:05,262 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:06,661 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bfg_ie7g', purging
2023-05-27 06:31:06,662 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:06,662 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:06,848 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:07,692 - distributed.nanny - INFO - Worker process 34246 exited with status 127
2023-05-27 06:31:07,693 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:08,577 - distributed.scheduler - INFO - Remove client Client-0965af48-fc58-11ed-a607-d8c49764f6bb
2023-05-27 06:31:08,578 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60500; closing.
2023-05-27 06:31:08,578 - distributed.scheduler - INFO - Remove client Client-0965af48-fc58-11ed-a607-d8c49764f6bb
2023-05-27 06:31:08,579 - distributed.scheduler - INFO - Close client connection: Client-0965af48-fc58-11ed-a607-d8c49764f6bb
2023-05-27 06:31:08,579 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34007'. Reason: nanny-close
2023-05-27 06:31:09,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8hwxrvrb', purging
2023-05-27 06:31:09,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:09,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:09,226 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:10,129 - distributed.nanny - INFO - Worker process 34256 exited with status 127
2023-05-27 06:31:38,611 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:31:38,612 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:31:38,613 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:31:38,613 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:31:38,614 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40945 instead
  warnings.warn(
2023-05-27 06:31:48,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ibhg5bpx', purging
2023-05-27 06:31:48,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:48,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:48,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:48,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:48,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:48,668 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:48,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:48,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:48,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:48,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:48,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:48,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:48,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:48,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:48,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:48,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:51,647 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:51,706 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:51,732 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:51,779 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:51,904 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:52,099 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:52,659 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:52,684 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:53,286 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ppxi4933', purging
2023-05-27 06:31:53,287 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-an41y3w5', purging
2023-05-27 06:31:53,287 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tvxqmbf1', purging
2023-05-27 06:31:53,287 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6chi5c9b', purging
2023-05-27 06:31:53,288 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4rhv30ss', purging
2023-05-27 06:31:53,288 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uujbartb', purging
2023-05-27 06:31:53,288 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qf34js__', purging
2023-05-27 06:31:53,288 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_p54fav7', purging
2023-05-27 06:31:53,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:53,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:53,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:53,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:53,368 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:53,368 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:53,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:53,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:53,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:53,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:53,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:53,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:54,134 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:54,289 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cxw8r_x3', purging
2023-05-27 06:31:54,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:54,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:54,309 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:54,309 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:54,868 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:55,150 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:55,278 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:55,495 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:55,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y4k_4exl', purging
2023-05-27 06:31:55,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2hz4m5at', purging
2023-05-27 06:31:55,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-chtnan1i', purging
2023-05-27 06:31:55,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dz_8v1nr', purging
2023-05-27 06:31:55,744 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:55,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:56,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:56,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:56,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:56,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:56,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:56,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:57,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:57,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:57,304 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:57,721 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:58,356 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:58,786 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pset7yv1', purging
2023-05-27 06:31:58,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xjjfydc6', purging
2023-05-27 06:31:58,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qkr6443g', purging
2023-05-27 06:31:58,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:58,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:59,183 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:59,230 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:59,268 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:59,303 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:59,338 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:59,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bh6i_x_t', purging
2023-05-27 06:31:59,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-410du0e3', purging
2023-05-27 06:31:59,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wcyei684', purging
2023-05-27 06:31:59,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xqyzd6dz', purging
2023-05-27 06:31:59,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z_q21hgm', purging
2023-05-27 06:31:59,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:59,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:59,911 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:59,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:59,965 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:00,822 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5861s3_n', purging
2023-05-27 06:32:00,822 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:00,822 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:00,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:00,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:00,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:00,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:00,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:00,881 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:00,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:00,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:01,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:01,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:02,119 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:03,665 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yfcib13h', purging
2023-05-27 06:32:03,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:03,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:03,702 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:03,834 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:03,895 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:03,937 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:03,962 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:03,993 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:04,020 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:05,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_hdoes6v', purging
2023-05-27 06:32:05,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iyi1frkk', purging
2023-05-27 06:32:05,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ho_d86g', purging
2023-05-27 06:32:05,329 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a2n62712', purging
2023-05-27 06:32:05,329 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sgpsrz0d', purging
2023-05-27 06:32:05,329 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9jrhwm14', purging
2023-05-27 06:32:05,330 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d9ro5_h_', purging
2023-05-27 06:32:05,330 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eki94l96', purging
2023-05-27 06:32:05,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:05,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:05,375 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:05,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:05,459 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:05,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:05,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:05,586 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:05,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:05,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:05,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:05,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:05,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:05,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:05,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:06,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:06,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:08,293 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:08,378 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:08,451 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:09,195 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:09,384 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:09,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:09,445 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:09,809 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:09,928 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bq18ksvn', purging
2023-05-27 06:32:09,928 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5kfhsokc', purging
2023-05-27 06:32:09,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ocm_e50', purging
2023-05-27 06:32:09,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ajq8c7k6', purging
2023-05-27 06:32:09,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e8muyyls', purging
2023-05-27 06:32:09,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nclwr8qx', purging
2023-05-27 06:32:09,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bjx2ycbj', purging
2023-05-27 06:32:09,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ken37x8z', purging
2023-05-27 06:32:09,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:09,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:09,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:09,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:10,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:10,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:10,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:10,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:10,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:10,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:11,023 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:11,023 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:11,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:11,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:11,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:11,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:11,748 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:11,795 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:12,759 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:13,341 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-roerp1ir', purging
2023-05-27 06:32:13,342 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ti9w7cof', purging
2023-05-27 06:32:13,342 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h5lzefws', purging
2023-05-27 06:32:13,343 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:13,343 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:13,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:13,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:13,863 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:14,057 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:14,119 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:14,166 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:14,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-50cgifiy', purging
2023-05-27 06:32:14,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fmg5wen5', purging
2023-05-27 06:32:14,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9te2bk4m', purging
2023-05-27 06:32:14,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2t78dw40', purging
2023-05-27 06:32:14,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cv_qvg7', purging
2023-05-27 06:32:14,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:14,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:14,415 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:15,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:15,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:15,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:15,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:15,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:15,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:15,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:15,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:16,024 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:16,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8uy85exz', purging
2023-05-27 06:32:16,049 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q28ekw_p', purging
2023-05-27 06:32:16,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:16,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:16,063 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:16,653 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:17,587 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:17,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5n8s1nl2', purging
2023-05-27 06:32:17,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6t1hk8vs', purging
2023-05-27 06:32:17,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:17,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:17,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:17,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:17,846 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:18,139 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:18,172 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:18,266 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:18,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rxrmp3od', purging
2023-05-27 06:32:18,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4bnuj0fl', purging
2023-05-27 06:32:18,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xx9qu32t', purging
2023-05-27 06:32:18,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-un070d_n', purging
2023-05-27 06:32:18,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:18,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:19,247 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:19,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:19,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:19,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:19,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:19,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:19,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:19,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:19,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:19,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:20,601 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:20,630 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:21,781 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:21,956 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:22,008 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:22,039 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:22,083 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:22,108 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:22,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9smm19mt', purging
2023-05-27 06:32:22,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-92iayf8s', purging
2023-05-27 06:32:22,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gpj4l00e', purging
2023-05-27 06:32:22,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:22,195 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:22,195 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yqp989m8', purging
2023-05-27 06:32:22,195 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7bch_w9r', purging
2023-05-27 06:32:22,195 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gvi5tsc6', purging
2023-05-27 06:32:22,196 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6unopxnp', purging
2023-05-27 06:32:22,196 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hq6v3_95', purging
2023-05-27 06:32:22,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:22,196 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:23,380 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:23,380 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:23,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:23,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:23,610 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:23,610 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:23,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:23,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:23,737 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:23,737 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:23,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:23,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:25,759 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:25,950 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:26,385 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:26,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:26,850 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:26,882 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:26,911 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:26,943 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:27,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eshl3s_c', purging
2023-05-27 06:32:27,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zh9zgres', purging
2023-05-27 06:32:27,453 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-88b872el', purging
2023-05-27 06:32:27,453 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g_74fbhx', purging
2023-05-27 06:32:27,453 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ybkkjamd', purging
2023-05-27 06:32:27,454 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-052_xrnz', purging
2023-05-27 06:32:27,454 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cujv7ldn', purging
2023-05-27 06:32:27,454 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wveh7pmh', purging
2023-05-27 06:32:27,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:27,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:27,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:27,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:28,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:28,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:28,125 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:28,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:28,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:28,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:28,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:28,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:28,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:28,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:28,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:28,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:29,622 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:29,694 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:31,083 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:31,116 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:31,151 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:31,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zc4e1ab6', purging
2023-05-27 06:32:31,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r4yyygcw', purging
2023-05-27 06:32:31,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3q8ojbk7', purging
2023-05-27 06:32:31,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-91e8r3zk', purging
2023-05-27 06:32:31,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3nqd734m', purging
2023-05-27 06:32:31,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fh2lvg44', purging
2023-05-27 06:32:31,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:31,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:31,346 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:31,346 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:31,383 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:31,630 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:31,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:32,717 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q6gv78ri', purging
2023-05-27 06:32:32,718 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a4db45ah', purging
2023-05-27 06:32:32,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:32,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:32,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:32,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:32,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:32,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:32,966 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:32,966 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:33,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x626_rxk', purging
2023-05-27 06:32:33,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m0giejd2', purging
2023-05-27 06:32:33,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:33,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:33,303 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:33,338 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:33,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:33,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:34,734 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:34,899 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qg7rfv79', purging
2023-05-27 06:32:34,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:34,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:34,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:34,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:35,161 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:35,208 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:35,500 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:36,156 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:36,215 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:36,368 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z49u00h_', purging
2023-05-27 06:32:36,368 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ft73r84', purging
2023-05-27 06:32:36,369 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4gdedm8e', purging
2023-05-27 06:32:36,369 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1mvx8el9', purging
2023-05-27 06:32:36,370 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_lba6z5i', purging
2023-05-27 06:32:36,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:36,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:36,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:36,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:36,797 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:36,797 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:37,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:37,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:37,436 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:37,542 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:37,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v5nbjrjw', purging
2023-05-27 06:32:37,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0kyxm6d_', purging
2023-05-27 06:32:37,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:37,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:37,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:37,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:38,685 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:39,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ud7qqyev', purging
2023-05-27 06:32:39,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x9lx0ohm', purging
2023-05-27 06:32:39,114 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5xttfdxd', purging
2023-05-27 06:32:39,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:39,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:39,146 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:39,148 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:39,173 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:39,173 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:39,328 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:40,103 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:40,274 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e67r042z', purging
2023-05-27 06:32:40,274 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0vimswmg', purging
2023-05-27 06:32:40,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:40,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:40,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fml5ka4k', purging
2023-05-27 06:32:40,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:40,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:40,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:40,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:40,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:40,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:40,908 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:41,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:41,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:42,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7rk___62', purging
2023-05-27 06:32:42,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7b9gsii', purging
2023-05-27 06:32:42,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:42,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:42,460 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:42,522 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:43,075 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:43,102 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:43,129 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:43,161 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:43,562 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:44,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yv_4_vgb', purging
2023-05-27 06:32:44,153 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qd8v6ev0', purging
2023-05-27 06:32:44,153 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y18fq8yx', purging
2023-05-27 06:32:44,153 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cqlzyf5w', purging
2023-05-27 06:32:44,154 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a4i7fuvm', purging
2023-05-27 06:32:44,154 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dwva74bd', purging
2023-05-27 06:32:44,154 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:44,154 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:44,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:44,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:44,311 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:44,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:44,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:44,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:44,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:44,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:44,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:44,911 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:44,911 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:45,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:45,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:45,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:45,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:46,780 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:46,806 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:47,335 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:47,366 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:47,397 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:47,429 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:47,677 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:48,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2jf6thdm', purging
2023-05-27 06:32:48,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5xxhw56v', purging
2023-05-27 06:32:48,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kzlxkoli', purging
2023-05-27 06:32:48,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lfxfyxtj', purging
2023-05-27 06:32:48,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-elcvvc45', purging
2023-05-27 06:32:48,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zrle3bj1', purging
2023-05-27 06:32:48,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6hf464bh', purging
2023-05-27 06:32:48,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:48,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:48,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:48,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:48,966 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jttp21dt', purging
2023-05-27 06:32:48,966 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:48,966 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:48,997 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:49,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:49,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:49,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:49,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:49,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:49,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:49,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:49,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:50,571 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:50,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:51,085 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:51,114 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:51,637 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:51,665 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:51,691 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:52,618 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1wcy9eej', purging
2023-05-27 06:32:52,619 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hhj6n0dh', purging
2023-05-27 06:32:52,619 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l64ygprq', purging
2023-05-27 06:32:52,619 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nvakwuf2', purging
2023-05-27 06:32:52,620 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o0g950t2', purging
2023-05-27 06:32:52,620 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l3pbqgoz', purging
2023-05-27 06:32:52,621 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g8t_7gjp', purging
2023-05-27 06:32:52,621 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:52,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:52,655 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:52,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:52,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:52,690 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:53,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:53,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:53,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:53,264 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:53,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:53,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:53,408 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:54,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dc3zi55f', purging
2023-05-27 06:32:54,329 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:54,329 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:54,390 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:54,390 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:54,867 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:54,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-favwnz_o', purging
2023-05-27 06:32:54,912 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:54,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psm1xeux', purging
2023-05-27 06:32:54,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:54,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:55,289 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:55,401 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:55,441 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:56,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aw8sshge', purging
2023-05-27 06:32:56,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-59l76dpd', purging
2023-05-27 06:32:56,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i9cnjn3p', purging
2023-05-27 06:32:56,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:56,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:56,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:56,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:56,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:56,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:57,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:57,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:57,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:57,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:57,336 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:57,443 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:57,472 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:58,877 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0unk4402', purging
2023-05-27 06:32:58,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xwkt4eex', purging
2023-05-27 06:32:58,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ld644kcm', purging
2023-05-27 06:32:58,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:58,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:58,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:58,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:59,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:59,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:59,507 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:59,542 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:59,598 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:59,669 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:59,696 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:01,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d9_k64on', purging
2023-05-27 06:33:01,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5hu3egcl', purging
2023-05-27 06:33:01,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yho6omly', purging
2023-05-27 06:33:01,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lkns33_a', purging
2023-05-27 06:33:01,075 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m5a9wavj', purging
2023-05-27 06:33:01,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:01,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:01,119 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:01,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:01,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:01,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:01,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:01,196 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:01,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:01,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:01,393 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:01,494 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:01,525 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:02,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yok23c6x', purging
2023-05-27 06:33:02,941 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e5sp7i06', purging
2023-05-27 06:33:02,941 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b5wc8dca', purging
2023-05-27 06:33:02,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:02,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:03,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:03,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:03,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:03,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:03,717 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:03,816 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:03,909 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:03,942 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:04,006 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:05,330 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7bb47oyf', purging
2023-05-27 06:33:05,330 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5podncvw', purging
2023-05-27 06:33:05,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-taumasp5', purging
2023-05-27 06:33:05,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w48f2vqe', purging
2023-05-27 06:33:05,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c8y_dw5t', purging
2023-05-27 06:33:05,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:05,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:05,491 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:05,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bholivfz', purging
2023-05-27 06:33:05,513 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tqb9f70c', purging
2023-05-27 06:33:05,514 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:05,514 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:05,559 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:05,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dn5c10d8', purging
2023-05-27 06:33:05,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:05,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:05,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:05,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:05,632 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:05,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:05,700 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:07,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:07,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:07,159 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:07,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:07,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:07,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:07,886 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:08,161 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:08,213 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:08,240 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:08,272 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:09,363 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4hv6cuy1', purging
2023-05-27 06:33:09,364 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kk50nxcp', purging
2023-05-27 06:33:09,364 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k93j6bny', purging
2023-05-27 06:33:09,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-beqclg23', purging
2023-05-27 06:33:09,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zm93ztwu', purging
2023-05-27 06:33:09,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:09,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:09,802 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:09,821 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-am6beorp', purging
2023-05-27 06:33:09,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:09,822 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:09,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3cfj0jg2', purging
2023-05-27 06:33:09,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j96ptx4r', purging
2023-05-27 06:33:09,903 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:09,903 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:09,903 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:09,903 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:09,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:09,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:09,979 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:10,004 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:11,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:11,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:11,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:11,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:11,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:11,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:11,951 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:12,330 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:12,456 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:12,493 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:13,591 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e8o6avi8', purging
2023-05-27 06:33:13,591 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zbbwr3kp', purging
2023-05-27 06:33:13,591 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-exsm_tne', purging
2023-05-27 06:33:13,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ty9za4g5', purging
2023-05-27 06:33:13,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f2om6dsk', purging
2023-05-27 06:33:13,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:13,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:13,621 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:13,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:13,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:14,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-00n5r5vv', purging
2023-05-27 06:33:14,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:14,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:14,092 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:14,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:14,161 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:14,237 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:14,287 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:15,311 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iwh0512w', purging
2023-05-27 06:33:15,312 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o_hm2cjx', purging
2023-05-27 06:33:15,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:15,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:15,766 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:15,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l68qp61u', purging
2023-05-27 06:33:15,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:15,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:15,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:15,806 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:15,967 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ruj7cbg4', purging
2023-05-27 06:33:15,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:15,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:16,003 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:16,247 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:16,301 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:17,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cchto7u5', purging
2023-05-27 06:33:17,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pcy11a5v', purging
2023-05-27 06:33:17,268 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:17,268 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:17,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x0eyrbrx', purging
2023-05-27 06:33:17,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:17,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:17,739 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:17,918 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:17,918 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:17,950 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:17,950 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:18,054 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:18,088 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:18,255 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:19,375 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kpepfcn0', purging
2023-05-27 06:33:19,375 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pm0m_i6v', purging
2023-05-27 06:33:19,376 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ljd_nh14', purging
2023-05-27 06:33:19,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:19,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:19,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:19,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:19,750 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:19,750 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:19,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:19,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:19,978 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:20,007 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:20,069 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:20,118 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:21,538 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:21,642 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-159ykq4s', purging
2023-05-27 06:33:21,643 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s5jh0zhv', purging
2023-05-27 06:33:21,643 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-77h6anvw', purging
2023-05-27 06:33:21,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-02jjcn_c', purging
2023-05-27 06:33:21,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5erekzrf', purging
2023-05-27 06:33:21,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:21,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:21,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:21,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:21,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:21,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:21,734 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:21,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jpvkcpd6', purging
2023-05-27 06:33:21,777 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:21,777 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:22,053 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:22,422 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:23,182 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d2fov_i6', purging
2023-05-27 06:33:23,183 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8o5yfsbh', purging
2023-05-27 06:33:23,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:23,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:23,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:23,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:23,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:23,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:24,022 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:24,052 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:24,063 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rl6bkhnf', purging
2023-05-27 06:33:24,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fa_1o1mz', purging
2023-05-27 06:33:24,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-avsvf983', purging
2023-05-27 06:33:24,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:24,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:24,080 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:24,671 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:25,598 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:25,681 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:25,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j5g1ohnd', purging
2023-05-27 06:33:25,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-435mc7o_', purging
2023-05-27 06:33:25,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kd7piciz', purging
2023-05-27 06:33:25,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:25,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:25,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:25,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:25,753 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:25,796 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gkvvonb8', purging
2023-05-27 06:33:25,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:25,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:26,221 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:26,340 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7q41b2hk', purging
2023-05-27 06:33:26,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:26,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:27,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:27,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:27,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:27,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:27,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:27,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:27,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rzn7xspk', purging
2023-05-27 06:33:27,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w6sbgfxt', purging
2023-05-27 06:33:27,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:27,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:27,905 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:27,932 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:28,009 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:29,106 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:29,583 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:29,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fdb9jkel', purging
2023-05-27 06:33:29,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-55t6jdf4', purging
2023-05-27 06:33:29,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-42ocgjgq', purging
2023-05-27 06:33:29,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:29,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:29,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:29,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:29,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:29,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:29,678 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:29,706 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:30,222 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:30,618 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lg_se8pr', purging
2023-05-27 06:33:30,619 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rowkt55o', purging
2023-05-27 06:33:30,619 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h3tudczy', purging
2023-05-27 06:33:30,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:30,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:31,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:31,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:31,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:31,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:31,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:31,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:31,626 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:31,740 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:31,766 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:31,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m16a7tnt', purging
2023-05-27 06:33:31,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2_m_2m6e', purging
2023-05-27 06:33:31,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h9efedr5', purging
2023-05-27 06:33:31,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:31,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:33,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:33,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:33,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-21lor309', purging
2023-05-27 06:33:33,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:33,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:33,523 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:33,582 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y0grskhx', purging
2023-05-27 06:33:33,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:33,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:33,605 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:33,705 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:33,786 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:35,120 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:35,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nh4nyzoa', purging
2023-05-27 06:33:35,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bg8pqpyb', purging
2023-05-27 06:33:35,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q0glu922', purging
2023-05-27 06:33:35,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:35,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:35,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:35,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:35,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:35,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:35,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:35,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:35,549 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:35,741 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:35,777 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:36,747 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zscluw9s', purging
2023-05-27 06:33:36,748 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kb9t59b6', purging
2023-05-27 06:33:36,748 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lw2riw1h', purging
2023-05-27 06:33:36,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:36,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:37,100 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:37,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ye5lisn', purging
2023-05-27 06:33:37,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:37,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:37,348 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:37,361 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ju0b7bc0', purging
2023-05-27 06:33:37,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:37,362 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:37,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:37,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:37,510 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:37,539 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:38,700 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rtn5cxiw', purging
2023-05-27 06:33:38,701 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j8msmgno', purging
2023-05-27 06:33:38,702 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:38,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:38,922 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j8asmwp2', purging
2023-05-27 06:33:38,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:38,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:39,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:39,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:39,117 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:39,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:39,164 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:39,671 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:39,721 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:39,793 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:40,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oup4vmox', purging
2023-05-27 06:33:40,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m8_ep87h', purging
2023-05-27 06:33:40,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_7de4ead', purging
2023-05-27 06:33:40,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:40,709 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:41,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5i3nxx4q', purging
2023-05-27 06:33:41,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-huv_ejnj', purging
2023-05-27 06:33:41,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:41,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:41,286 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:41,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:41,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:41,344 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:41,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o5fjkm10', purging
2023-05-27 06:33:41,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3zbobz2y', purging
2023-05-27 06:33:41,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:41,430 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:41,433 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:41,467 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:42,877 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2cax8a1', purging
2023-05-27 06:33:42,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:42,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:42,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:42,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:43,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:43,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:43,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:43,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:43,095 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:43,669 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:43,727 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:43,796 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:44,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7fixatf7', purging
2023-05-27 06:33:44,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3_zwyrti', purging
2023-05-27 06:33:44,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oply031h', purging
2023-05-27 06:33:44,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:44,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:45,278 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:45,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_rt1o79n', purging
2023-05-27 06:33:45,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dz282qyt', purging
2023-05-27 06:33:45,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r9cb9acd', purging
2023-05-27 06:33:45,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:45,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:45,360 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:45,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:45,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:45,424 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:45,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jei1lhq5', purging
2023-05-27 06:33:45,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:45,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:45,466 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:46,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xaon5qmu', purging
2023-05-27 06:33:46,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:46,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:46,921 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:46,921 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:46,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:46,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:47,041 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:47,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:47,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:47,677 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:48,634 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:48,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8h_xwzem', purging
2023-05-27 06:33:48,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-grpkkpp6', purging
2023-05-27 06:33:48,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-epwr_amu', purging
2023-05-27 06:33:48,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:48,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:48,697 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:49,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:49,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:49,261 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:49,392 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:49,412 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:49,444 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:50,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sdllndap', purging
2023-05-27 06:33:50,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vagpcwj2', purging
2023-05-27 06:33:50,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iujujhuw', purging
2023-05-27 06:33:50,245 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-05jbombg', purging
2023-05-27 06:33:50,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:50,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:50,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:50,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:50,485 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:50,748 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:50,920 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3zjen9lk', purging
2023-05-27 06:33:50,920 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c8z58tl1', purging
2023-05-27 06:33:50,921 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:50,921 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:51,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:51,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:51,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:51,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:51,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:51,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:51,670 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:52,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ie14gov', purging
2023-05-27 06:33:52,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:52,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:52,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:52,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:52,711 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:53,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5gxman8x', purging
2023-05-27 06:33:53,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:53,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:53,369 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:53,464 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:53,538 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:54,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ung4rr6l', purging
2023-05-27 06:33:54,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0y0x1prj', purging
2023-05-27 06:33:54,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hx62g7av', purging
2023-05-27 06:33:54,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qvq_hk8y', purging
2023-05-27 06:33:54,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:54,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:54,851 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:54,917 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:55,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1oj1hbc7', purging
2023-05-27 06:33:55,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d9sk74vp', purging
2023-05-27 06:33:55,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:55,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:55,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:55,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:55,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:55,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:55,512 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:56,402 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:56,474 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e5bjs48a', purging
2023-05-27 06:33:56,474 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jz356rsr', purging
2023-05-27 06:33:56,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:56,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:56,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:56,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:56,743 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:56,812 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:56,880 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:56,996 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6yczpm2e', purging
2023-05-27 06:33:56,997 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0u4lcgni', purging
2023-05-27 06:33:56,997 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6q2c_ap2', purging
2023-05-27 06:33:56,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:56,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:58,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:58,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:58,404 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i_pn_0lu', purging
2023-05-27 06:33:58,405 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:58,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:58,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:58,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:58,418 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:58,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:58,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:58,550 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:59,215 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:59,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_0deil76', purging
2023-05-27 06:33:59,926 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-01s1n66j', purging
2023-05-27 06:33:59,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:59,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:00,226 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:00,226 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:00,367 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:00,479 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:00,518 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:00,569 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:00,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zj35xerx', purging
2023-05-27 06:34:00,889 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-02bt6anh', purging
2023-05-27 06:34:00,889 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr4zw_t7', purging
2023-05-27 06:34:00,889 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ud3u93s', purging
2023-05-27 06:34:00,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:00,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:01,806 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:02,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c54u_5lf', purging
2023-05-27 06:34:02,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:02,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:02,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:02,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:02,145 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wldnz9cj', purging
2023-05-27 06:34:02,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:02,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:02,159 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:02,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:02,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:03,358 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a8owbn9r', purging
2023-05-27 06:34:03,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:03,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:03,592 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:03,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:03,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:04,060 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:04,100 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:04,176 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:04,210 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:05,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dhf04_r3', purging
2023-05-27 06:34:05,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6nsbj533', purging
2023-05-27 06:34:05,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-42jgoh7u', purging
2023-05-27 06:34:05,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-262pvjw3', purging
2023-05-27 06:34:05,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:05,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:05,496 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:05,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rb6hgrep', purging
2023-05-27 06:34:05,609 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_otjgjip', purging
2023-05-27 06:34:05,610 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:05,610 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:05,616 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:05,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:05,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:05,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:05,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:05,873 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:05,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:06,510 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:07,044 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lp_du8ya', purging
2023-05-27 06:34:07,045 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:07,045 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:07,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:07,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:07,762 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:07,836 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:07,866 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:07,939 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:08,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5pzst7wq', purging
2023-05-27 06:34:08,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zn_1hy8n', purging
2023-05-27 06:34:08,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bxg6hljf', purging
2023-05-27 06:34:08,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jhh3tp0w', purging
2023-05-27 06:34:08,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:08,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:09,204 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:09,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gzmwl3dr', purging
2023-05-27 06:34:09,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:09,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:09,513 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g7rorstq', purging
2023-05-27 06:34:09,514 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:09,514 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:09,515 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:09,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:09,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:09,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:09,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:09,928 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:10,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sat02egk', purging
2023-05-27 06:34:10,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:10,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:11,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:11,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:11,315 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:11,433 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:11,460 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:11,524 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_9g2de91', purging
2023-05-27 06:34:11,524 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hmb5lqa3', purging
2023-05-27 06:34:11,525 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u1_4_wl4', purging
2023-05-27 06:34:11,526 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:11,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:11,913 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:12,879 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ndhm8y4h', purging
2023-05-27 06:34:12,880 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3t2c_jhp', purging
2023-05-27 06:34:12,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:12,881 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:13,019 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:13,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:13,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:13,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i61ixzb9', purging
2023-05-27 06:34:13,125 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:13,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:13,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:13,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:13,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:13,593 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:14,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-adgd67_c', purging
2023-05-27 06:34:14,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:14,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:14,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:14,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:14,924 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:15,035 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:15,061 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:15,266 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s3nk5mzy', purging
2023-05-27 06:34:15,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uh9tueag', purging
2023-05-27 06:34:15,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mhogywn0', purging
2023-05-27 06:34:15,268 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:15,268 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:15,979 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:16,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pl8mo191', purging
2023-05-27 06:34:16,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-phu_mudy', purging
2023-05-27 06:34:16,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:16,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:16,472 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:16,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:16,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:16,730 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6zq3psy5', purging
2023-05-27 06:34:16,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:16,731 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:16,750 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:17,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:17,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:17,993 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:18,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c39m95nr', purging
2023-05-27 06:34:18,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:18,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:18,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:18,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:18,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:18,455 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:18,495 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:19,542 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xxaergo_', purging
2023-05-27 06:34:19,542 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0o5ly7m9', purging
2023-05-27 06:34:19,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2r2oeroo', purging
2023-05-27 06:34:19,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lyj61j1f', purging
2023-05-27 06:34:19,543 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:19,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:19,706 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:19,797 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:20,008 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-17_r991f', purging
2023-05-27 06:34:20,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:20,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:20,060 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v_587s4s', purging
2023-05-27 06:34:20,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:20,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:20,087 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:20,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:20,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:21,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:21,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:21,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:21,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:21,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:21,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:21,826 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:22,060 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:22,148 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:22,574 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:23,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wfong4xw', purging
2023-05-27 06:34:23,497 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eo51me_a', purging
2023-05-27 06:34:23,497 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i2o38v0s', purging
2023-05-27 06:34:23,498 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dtm7hmtx', purging
2023-05-27 06:34:23,498 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:23,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:23,614 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s95xslh1', purging
2023-05-27 06:34:23,615 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-24rqlant', purging
2023-05-27 06:34:23,615 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:23,615 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:23,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:23,660 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:23,709 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:23,824 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uyxz8yoh', purging
2023-05-27 06:34:23,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:23,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:24,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:24,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:25,050 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:25,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ubwjeoi8', purging
2023-05-27 06:34:25,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vkxngnmy', purging
2023-05-27 06:34:25,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:25,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:25,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:25,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:25,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:25,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:25,459 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:25,685 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:26,549 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:26,698 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6vm02296', purging
2023-05-27 06:34:26,698 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rlls36r8', purging
2023-05-27 06:34:26,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:26,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:27,118 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n2zxjjny', purging
2023-05-27 06:34:27,119 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6grejglv', purging
2023-05-27 06:34:27,119 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_pgpk0dq', purging
2023-05-27 06:34:27,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:27,120 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:27,120 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:27,180 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:27,208 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:27,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:27,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:28,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:28,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:28,709 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:28,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g9y1ni4u', purging
2023-05-27 06:34:28,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:28,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:28,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:28,753 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:28,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:28,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:29,251 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:29,269 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:30,161 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:30,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_fo0n4zp', purging
2023-05-27 06:34:30,230 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xi5mohlb', purging
2023-05-27 06:34:30,230 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_vrp3h9', purging
2023-05-27 06:34:30,230 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y1z75qb1', purging
2023-05-27 06:34:30,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:30,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:30,259 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:30,652 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:30,694 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:30,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l48zkcur', purging
2023-05-27 06:34:30,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mck52nrq', purging
2023-05-27 06:34:30,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:30,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:30,863 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:30,863 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:31,747 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zk7d_um2', purging
2023-05-27 06:34:31,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:31,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:31,827 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:31,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:31,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:32,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:32,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:32,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:32,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:32,814 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:32,837 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:33,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6a9prros', purging
2023-05-27 06:34:33,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yxrdqytt', purging
2023-05-27 06:34:33,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c8kfbwmu', purging
2023-05-27 06:34:33,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:33,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:33,424 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:33,517 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:34,026 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:34,076 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:34,412 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bwcf7ahk', purging
2023-05-27 06:34:34,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9284jhyd', purging
2023-05-27 06:34:34,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jxkmjyjs', purging
2023-05-27 06:34:34,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:34,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:34,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:34,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:34,943 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:35,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cxmvjs89', purging
2023-05-27 06:34:35,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:35,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:35,216 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:35,216 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:35,716 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:35,724 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-69hkfmor', purging
2023-05-27 06:34:35,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:35,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:35,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:35,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:36,154 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:36,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qf3dc1l2', purging
2023-05-27 06:34:36,576 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_i469p9x', purging
2023-05-27 06:34:36,576 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ws3oube2', purging
2023-05-27 06:34:36,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:36,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:36,906 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:36,925 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:37,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:37,304 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:37,467 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:37,521 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:37,748 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iam_99j7', purging
2023-05-27 06:34:37,748 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lyejafee', purging
2023-05-27 06:34:37,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:37,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:38,442 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:38,442 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:38,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:38,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:38,769 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:39,008 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:39,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ho91_pnc', purging
2023-05-27 06:34:39,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wu3z5hp4', purging
2023-05-27 06:34:39,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:39,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:39,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:39,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:39,450 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:39,821 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:40,228 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:40,367 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q7gtgo4l', purging
2023-05-27 06:34:40,368 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1f5m_i50', purging
2023-05-27 06:34:40,368 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-th65blb1', purging
2023-05-27 06:34:40,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:40,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:40,438 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:40,496 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:40,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5lrlf9ug', purging
2023-05-27 06:34:40,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cnlhmbc', purging
2023-05-27 06:34:40,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:40,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:41,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:41,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:41,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:41,419 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:41,757 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:41,820 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hgr8w8x4', purging
2023-05-27 06:34:41,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:41,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:42,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:42,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:42,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:42,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:42,540 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:42,900 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:43,390 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uht5c2ks', purging
2023-05-27 06:34:43,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ncn6bck4', purging
2023-05-27 06:34:43,391 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:43,391 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:43,555 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:43,813 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:44,068 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:44,164 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xwuckwy1', purging
2023-05-27 06:34:44,165 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2638a6m1', purging
2023-05-27 06:34:44,165 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-25pjf6gl', purging
2023-05-27 06:34:44,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g0o9bygr', purging
2023-05-27 06:34:44,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:44,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:44,286 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:44,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:44,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:45,144 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:45,146 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ebfz083', purging
2023-05-27 06:34:45,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:45,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:45,442 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:45,442 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:45,685 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:45,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e_ua4ghr', purging
2023-05-27 06:34:45,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:45,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:45,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:45,881 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:46,014 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:46,309 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:46,786 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9s5t4zt9', purging
2023-05-27 06:34:46,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8u8qqpu8', purging
2023-05-27 06:34:46,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:46,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:47,048 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:47,210 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-15g_6c4_', purging
2023-05-27 06:34:47,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ras0yshq', purging
2023-05-27 06:34:47,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:47,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:47,222 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:47,521 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-it1fonss', purging
2023-05-27 06:34:47,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:47,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:47,599 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:47,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:47,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:48,291 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:48,646 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yo3guvll', purging
2023-05-27 06:34:48,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:48,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:48,841 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:48,841 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:49,230 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:49,258 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2qzusihj', purging
2023-05-27 06:34:49,259 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:49,259 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:49,307 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:49,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y8rb25ik', purging
2023-05-27 06:34:49,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:49,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:50,226 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:50,452 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:50,762 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:50,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5nbgvxyu', purging
2023-05-27 06:34:50,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3hf1unc5', purging
2023-05-27 06:34:50,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6xuc4epi', purging
2023-05-27 06:34:50,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:50,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:50,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:50,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:51,193 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:51,470 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:51,889 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ongozcy', purging
2023-05-27 06:34:51,890 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-24j7413l', purging
2023-05-27 06:34:51,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:51,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:52,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:52,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:52,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:52,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:52,599 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:52,633 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:52,846 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pypm7v0g', purging
2023-05-27 06:34:52,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z9pqdttb', purging
2023-05-27 06:34:52,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:52,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:53,092 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:53,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:53,451 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:53,579 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:54,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-im_mhxgo', purging
2023-05-27 06:34:54,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c6s_cmxx', purging
2023-05-27 06:34:54,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:54,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:54,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:54,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:54,392 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:54,579 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:54,637 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:55,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fqn4pfr_', purging
2023-05-27 06:34:55,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qhrfubxk', purging
2023-05-27 06:34:55,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i77v04r3', purging
2023-05-27 06:34:55,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:55,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:55,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:55,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:55,915 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:55,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a6gy38ef', purging
2023-05-27 06:34:55,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tz7jjztl', purging
2023-05-27 06:34:55,977 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:55,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:56,112 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:56,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:56,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:56,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:56,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:56,661 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:56,676 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:57,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-am9l_0jk', purging
2023-05-27 06:34:57,551 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f12ze67a', purging
2023-05-27 06:34:57,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:57,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:57,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:57,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:57,807 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:57,895 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:57,922 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:58,188 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:58,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ht8wje01', purging
2023-05-27 06:34:58,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:58,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k_hvffh8', purging
2023-05-27 06:34:58,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ty5lahxv', purging
2023-05-27 06:34:58,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:58,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:58,877 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:59,450 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-99yeifxa', purging
2023-05-27 06:34:59,451 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:59,451 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:59,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:59,487 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:59,545 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:59,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r_dnhe3l', purging
2023-05-27 06:34:59,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:59,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:00,000 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:00,038 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:00,493 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6dd5wcfm', purging
2023-05-27 06:35:00,493 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7_yxj5kj', purging
2023-05-27 06:35:00,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:00,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:01,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:01,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:01,222 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:01,282 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:01,312 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:01,679 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-attz_gjt', purging
2023-05-27 06:35:01,679 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-58oj4qch', purging
2023-05-27 06:35:01,680 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ovogcquh', purging
2023-05-27 06:35:01,680 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:01,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:01,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:01,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:02,231 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:02,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4zord98m', purging
2023-05-27 06:35:02,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-epmjf9xa', purging
2023-05-27 06:35:02,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:02,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:02,841 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:02,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:02,936 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:02,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:02,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:03,155 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:03,756 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:03,886 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-men75_f1', purging
2023-05-27 06:35:03,886 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sgtznkv1', purging
2023-05-27 06:35:03,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:03,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:04,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:04,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:04,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lrkl5j5w', purging
2023-05-27 06:35:04,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:04,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:04,693 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:04,778 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:04,807 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:05,383 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:05,390 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bv1j2olz', purging
2023-05-27 06:35:05,390 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ieh1_9hg', purging
2023-05-27 06:35:05,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0j3y5i97', purging
2023-05-27 06:35:05,391 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:05,391 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:05,987 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:06,261 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y_lf_mcv', purging
2023-05-27 06:35:06,261 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a1_erjmb', purging
2023-05-27 06:35:06,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:06,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:06,283 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:06,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:06,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:06,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:06,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:06,816 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:07,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tte953x8', purging
2023-05-27 06:35:07,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:07,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:07,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_2jqqqu2', purging
2023-05-27 06:35:07,588 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:07,588 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:07,657 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:07,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:07,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:08,118 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:08,170 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:08,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1y7lwtdx', purging
2023-05-27 06:35:08,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w_u6lt34', purging
2023-05-27 06:35:08,350 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:08,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:08,729 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:09,198 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:09,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xadq9_z7', purging
2023-05-27 06:35:09,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6z21jgb3', purging
2023-05-27 06:35:09,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:09,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:09,697 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:09,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0x603453', purging
2023-05-27 06:35:09,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:09,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:09,784 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:09,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:10,149 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:10,333 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lorlel0m', purging
2023-05-27 06:35:10,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:10,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:10,770 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:10,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mvdc0fm8', purging
2023-05-27 06:35:10,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:10,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:11,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:11,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:11,464 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:11,526 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:11,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mtlajeli', purging
2023-05-27 06:35:11,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l5pac518', purging
2023-05-27 06:35:11,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:11,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:12,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w_uaa73y', purging
2023-05-27 06:35:12,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:12,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:12,420 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:12,516 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:13,083 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jpnpxe0y', purging
2023-05-27 06:35:13,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bk8h7_ni', purging
2023-05-27 06:35:13,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:13,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:13,148 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:13,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:13,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:13,661 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:13,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i24drpnk', purging
2023-05-27 06:35:13,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l4gzv4se', purging
2023-05-27 06:35:13,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:13,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:13,914 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:14,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:14,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:14,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:14,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:14,907 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:14,944 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:15,292 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-83zy31qz', purging
2023-05-27 06:35:15,292 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pqp0w3kk', purging
2023-05-27 06:35:15,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:15,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:15,415 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:15,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u9csbb8l', purging
2023-05-27 06:35:15,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bxylc4h1', purging
2023-05-27 06:35:15,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:15,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:15,836 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:16,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zofm_7vc', purging
2023-05-27 06:35:16,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:16,516 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:16,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:16,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:16,722 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:16,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v8gi980i', purging
2023-05-27 06:35:16,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:16,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:17,010 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:17,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kwokas_5', purging
2023-05-27 06:35:17,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:17,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:18,113 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:18,172 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:18,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s3niu01j', purging
2023-05-27 06:35:18,400 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8uax_s6c', purging
2023-05-27 06:35:18,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:18,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:18,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:18,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:18,716 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:18,960 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:19,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-459526jv', purging
2023-05-27 06:35:19,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_c38yxsm', purging
2023-05-27 06:35:19,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:19,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:19,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t22tzpb_', purging
2023-05-27 06:35:19,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:19,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:19,857 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:20,052 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:20,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-514acf5k', purging
2023-05-27 06:35:20,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:20,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:20,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:20,648 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:21,092 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:21,191 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:21,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e3de18ju', purging
2023-05-27 06:35:21,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b45gjg__', purging
2023-05-27 06:35:21,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:21,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:21,709 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:21,720 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kui9ejjo', purging
2023-05-27 06:35:21,721 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:21,721 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:22,185 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:22,703 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:22,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vxjynwvr', purging
2023-05-27 06:35:22,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-06o4t2_y', purging
2023-05-27 06:35:22,706 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:22,706 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:22,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:22,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:23,010 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:23,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e4awlkoq', purging
2023-05-27 06:35:23,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:23,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:23,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:23,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:24,080 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:24,141 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:24,289 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t94grgpj', purging
2023-05-27 06:35:24,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-txahovrm', purging
2023-05-27 06:35:24,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:24,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:24,495 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:24,548 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mtncwose', purging
2023-05-27 06:35:24,549 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:24,549 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:24,811 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:25,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7dl8c12q', purging
2023-05-27 06:35:25,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6fn7ktgr', purging
2023-05-27 06:35:25,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:25,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:25,685 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:25,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:25,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:26,004 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:26,060 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a_qvv7_p', purging
2023-05-27 06:35:26,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:26,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:26,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:26,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:26,910 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:27,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5scdxrur', purging
2023-05-27 06:35:27,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m94cee42', purging
2023-05-27 06:35:27,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:27,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:27,295 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:27,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:27,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:27,762 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:27,979 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:28,451 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ncy4isob', purging
2023-05-27 06:35:28,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mlsa1ozc', purging
2023-05-27 06:35:28,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:28,452 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:28,658 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:28,864 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-li1wxb5l', purging
2023-05-27 06:35:28,865 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:28,865 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:29,215 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:29,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s6jna_qj', purging
2023-05-27 06:35:29,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:29,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:29,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:29,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:29,843 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:30,142 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:30,205 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b34ar46x', purging
2023-05-27 06:35:30,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ezhp02x0', purging
2023-05-27 06:35:30,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:30,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:30,608 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:30,740 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c8rokoh1', purging
2023-05-27 06:35:30,741 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s6fssgji', purging
2023-05-27 06:35:30,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:30,742 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:30,845 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:31,412 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:31,412 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:31,735 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-evf04mpn', purging
2023-05-27 06:35:31,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:31,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:31,831 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:32,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:32,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:32,319 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:32,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xpybffsq', purging
2023-05-27 06:35:32,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:32,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:32,947 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:33,361 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:33,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2i_c7iw_', purging
2023-05-27 06:35:33,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cj2c8nah', purging
2023-05-27 06:35:33,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:33,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:33,599 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:33,646 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:33,863 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w2dvq5ro', purging
2023-05-27 06:35:33,863 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qi4v9s6y', purging
2023-05-27 06:35:33,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:33,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:34,386 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:34,542 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c8baflfv', purging
2023-05-27 06:35:34,543 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:34,543 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:35,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:35,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:35,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:35,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:35,276 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rc5c_b01', purging
2023-05-27 06:35:35,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:35,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:35,312 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:35,845 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:36,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wil2oo8a', purging
2023-05-27 06:35:36,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:36,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:36,488 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:36,864 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7hb6iitq', purging
2023-05-27 06:35:36,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:36,865 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:36,996 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:37,026 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:37,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v31exd1x', purging
2023-05-27 06:35:37,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k7ox1qd5', purging
2023-05-27 06:35:37,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i99i_qtg', purging
2023-05-27 06:35:37,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:37,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:37,609 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:38,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:38,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:38,265 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:38,615 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-it3zuyjx', purging
2023-05-27 06:35:38,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:38,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:38,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:38,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:38,844 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:39,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vfvwy7jb', purging
2023-05-27 06:35:39,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:39,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:39,440 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:39,905 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xn6efizz', purging
2023-05-27 06:35:39,906 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1i504_ah', purging
2023-05-27 06:35:39,906 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v16ojkqb', purging
2023-05-27 06:35:39,907 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:39,907 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:40,049 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:40,075 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:40,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:40,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:40,477 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:41,008 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mpqtiqqh', purging
2023-05-27 06:35:41,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:41,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:41,426 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:41,569 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dsjt62kj', purging
2023-05-27 06:35:41,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:41,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:41,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:41,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:41,912 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:42,102 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bm8z4zoi', purging
2023-05-27 06:35:42,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:42,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:42,465 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:42,894 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:43,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-apj4zaws', purging
2023-05-27 06:35:43,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xaqrfcrm', purging
2023-05-27 06:35:43,060 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-od6jkr8x', purging
2023-05-27 06:35:43,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:43,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:43,095 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:43,468 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:43,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-070vzov5', purging
2023-05-27 06:35:43,515 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:43,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:44,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:44,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:44,399 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:44,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cv781fh6', purging
2023-05-27 06:35:44,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:44,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:44,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:44,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:44,914 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:44,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kptvs8qj', purging
2023-05-27 06:35:44,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:44,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:45,560 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:45,907 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:46,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0n65qfl9', purging
2023-05-27 06:35:46,079 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1pqy8a54', purging
2023-05-27 06:35:46,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:46,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:46,170 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:46,507 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:46,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cly1xuyg', purging
2023-05-27 06:35:46,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-69le56ws', purging
2023-05-27 06:35:46,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:46,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:47,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:47,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:47,520 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g798g469', purging
2023-05-27 06:35:47,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:47,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:47,630 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:47,797 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:47,797 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:48,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d7768swl', purging
2023-05-27 06:35:48,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:48,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:48,218 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:48,627 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:48,674 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:49,212 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:49,257 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c4d5q19l', purging
2023-05-27 06:35:49,258 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ja9_v775', purging
2023-05-27 06:35:49,258 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-73m_t26n', purging
2023-05-27 06:35:49,259 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:49,259 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:49,552 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:49,881 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y8bkt04k', purging
2023-05-27 06:35:49,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:49,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:50,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:50,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:50,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:50,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:50,425 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:50,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3wc8i1dp', purging
2023-05-27 06:35:50,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:50,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:51,173 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:51,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:51,234 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:51,859 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:51,886 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:52,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5yvez_ck', purging
2023-05-27 06:35:52,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2k3vka9', purging
2023-05-27 06:35:52,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6a0p3_mb', purging
2023-05-27 06:35:52,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:52,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:52,241 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:52,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uuuykn02', purging
2023-05-27 06:35:52,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4s1c53tg', purging
2023-05-27 06:35:52,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:52,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:52,930 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:53,448 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:53,522 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r5zwj560', purging
2023-05-27 06:35:53,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:53,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:53,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:53,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:53,935 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4w4o5nn8', purging
2023-05-27 06:35:53,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:53,936 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:54,023 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:54,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:54,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:54,803 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:54,831 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:55,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-frgkgx4t', purging
2023-05-27 06:35:55,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-andngvyl', purging
2023-05-27 06:35:55,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:55,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:55,238 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:55,592 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:55,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ftbjjcdh', purging
2023-05-27 06:35:55,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5jk7cey7', purging
2023-05-27 06:35:55,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:55,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:56,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:56,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:56,456 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:56,456 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:56,618 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:56,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-elzhkf_e', purging
2023-05-27 06:35:56,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:56,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:57,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:57,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:57,258 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:58,028 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:58,030 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:58,180 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-epygbnk1', purging
2023-05-27 06:35:58,181 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-frhmg4eu', purging
2023-05-27 06:35:58,181 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j7vxoq3n', purging
2023-05-27 06:35:58,182 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:58,182 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:58,313 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:58,366 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:58,808 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t9kd78ue', purging
2023-05-27 06:35:58,808 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iniw1hq9', purging
2023-05-27 06:35:58,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:58,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:59,125 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:59,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jgbh0nsv', purging
2023-05-27 06:35:59,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:59,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:59,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:59,698 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:59,840 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:59,884 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xg3selou', purging
2023-05-27 06:35:59,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:59,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:59,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:59,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:00,742 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:00,742 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:01,031 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:01,116 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:01,473 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3krkyrox', purging
2023-05-27 06:36:01,474 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mphmsju0', purging
2023-05-27 06:36:01,474 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:01,474 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:01,695 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:01,757 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:02,339 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:02,711 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sjvirbtp', purging
2023-05-27 06:36:02,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-scy5gsnf', purging
2023-05-27 06:36:02,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yymps6iz', purging
2023-05-27 06:36:02,713 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:02,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:02,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:02,768 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:02,842 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:03,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bag0actn', purging
2023-05-27 06:36:03,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:03,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:03,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:03,442 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:03,513 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:03,565 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:04,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6ivsjun', purging
2023-05-27 06:36:04,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x633z849', purging
2023-05-27 06:36:04,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:04,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:04,385 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:04,474 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-as4dlba5', purging
2023-05-27 06:36:04,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:04,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:04,691 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:05,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-thf9i35t', purging
2023-05-27 06:36:05,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:05,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:05,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:05,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:05,626 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:06,019 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ax6sk4cq', purging
2023-05-27 06:36:06,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:06,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:06,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:06,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:06,367 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:06,940 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:07,144 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:07,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oyaesvxv', purging
2023-05-27 06:36:07,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nc4vbogc', purging
2023-05-27 06:36:07,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ypd1bgub', purging
2023-05-27 06:36:07,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:07,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:07,391 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:07,429 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:08,019 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5fevrjrh', purging
2023-05-27 06:36:08,020 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-348bmftb', purging
2023-05-27 06:36:08,020 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eain_36w', purging
2023-05-27 06:36:08,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:08,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:08,045 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:08,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:08,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:08,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:08,806 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:09,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:09,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:09,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:09,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:09,206 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:09,667 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nzvb9lpa', purging
2023-05-27 06:36:09,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:09,668 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:09,818 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:10,328 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:10,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_s3d1rw8', purging
2023-05-27 06:36:10,788 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-npp9q_ij', purging
2023-05-27 06:36:10,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:10,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:10,916 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:10,953 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:11,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-043rdlt2', purging
2023-05-27 06:36:11,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-124zar82', purging
2023-05-27 06:36:11,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-94suiwbk', purging
2023-05-27 06:36:11,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:11,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:11,486 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:11,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:11,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:12,137 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:12,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6a1fuymm', purging
2023-05-27 06:36:12,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:12,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:12,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:12,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:12,614 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:13,107 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-itamvcii', purging
2023-05-27 06:36:13,108 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g2vrtaaz', purging
2023-05-27 06:36:13,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:13,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:13,169 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:13,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zmm00z3d', purging
2023-05-27 06:36:13,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c9xdf4x6', purging
2023-05-27 06:36:13,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:13,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:13,743 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:13,781 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:14,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:14,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:14,370 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:14,804 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bc6apqnr', purging
2023-05-27 06:36:14,804 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mccoqhox', purging
2023-05-27 06:36:14,805 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:14,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:14,805 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:15,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:15,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:15,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:15,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:15,574 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:15,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-57fgs5lu', purging
2023-05-27 06:36:15,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:15,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:16,154 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:16,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wn_43y_a', purging
2023-05-27 06:36:16,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-drmzt4d2', purging
2023-05-27 06:36:16,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8tx4i2qj', purging
2023-05-27 06:36:16,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:16,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:16,561 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:16,731 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:17,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:17,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:17,344 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:17,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kuuzqhas', purging
2023-05-27 06:36:17,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:17,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:17,919 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:18,178 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-93wsszi8', purging
2023-05-27 06:36:18,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:18,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:18,312 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:18,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yhjnfqmc', purging
2023-05-27 06:36:18,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:18,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:18,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iwkrnofp', purging
2023-05-27 06:36:18,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:18,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:19,119 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:19,217 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:19,624 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jfuujquy', purging
2023-05-27 06:36:19,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:19,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:19,713 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:19,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-azv13xal', purging
2023-05-27 06:36:19,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:19,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:20,151 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:20,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a1lojg_7', purging
2023-05-27 06:36:20,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:20,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:20,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kc8sgbhp', purging
2023-05-27 06:36:20,869 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:20,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:20,904 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:21,310 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:21,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u7fslzb5', purging
2023-05-27 06:36:21,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:21,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:21,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:21,679 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:22,127 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:22,371 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:22,538 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kurm7yp2', purging
2023-05-27 06:36:22,539 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v1_4f877', purging
2023-05-27 06:36:22,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:22,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:22,970 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:22,980 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nng27gyx', purging
2023-05-27 06:36:22,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:22,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:23,081 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:23,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j5fs8exg', purging
2023-05-27 06:36:23,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:23,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:23,862 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:23,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2qya7uhs', purging
2023-05-27 06:36:23,970 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:23,970 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:24,266 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:24,729 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ubyf0i64', purging
2023-05-27 06:36:24,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:24,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:24,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:24,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:24,842 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:25,137 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:25,539 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vk24u91q', purging
2023-05-27 06:36:25,539 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4fd2lka7', purging
2023-05-27 06:36:25,540 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:25,540 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:25,914 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z0fy3emm', purging
2023-05-27 06:36:25,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yx19fspg', purging
2023-05-27 06:36:25,915 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:25,915 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:25,962 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:25,994 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:26,514 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:26,514 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:26,702 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:26,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:26,802 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:27,416 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:27,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-18owdp8v', purging
2023-05-27 06:36:27,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wuhnwoom', purging
2023-05-27 06:36:27,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:27,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:27,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:27,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:28,023 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:28,049 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:28,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ua83xh5e', purging
2023-05-27 06:36:28,469 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jbpymnd_', purging
2023-05-27 06:36:28,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:28,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:28,916 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:28,993 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:29,045 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xf4hyg1l', purging
2023-05-27 06:36:29,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tmxpa43d', purging
2023-05-27 06:36:29,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:29,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:29,548 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:29,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zs1j6zz8', purging
2023-05-27 06:36:29,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:29,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:29,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:29,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:30,531 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:30,583 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-evl1tsfg', purging
2023-05-27 06:36:30,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:30,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:30,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:30,586 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:31,013 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:31,031 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:31,238 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jurt41cj', purging
2023-05-27 06:36:31,239 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rj5f6lss', purging
2023-05-27 06:36:31,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:31,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:32,055 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:32,093 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:32,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vtlngdlr', purging
2023-05-27 06:36:32,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ppjlxkgc', purging
2023-05-27 06:36:32,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:32,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:32,445 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:32,569 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4tj6q72n', purging
2023-05-27 06:36:32,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:32,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:32,662 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:32,662 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:33,221 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:33,711 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ikgqks4t', purging
2023-05-27 06:36:33,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:33,712 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:33,737 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:33,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:33,836 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:33,892 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:34,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t0ftrucr', purging
2023-05-27 06:36:34,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hotm54_g', purging
2023-05-27 06:36:34,092 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:34,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:34,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:34,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:34,995 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:35,029 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:35,389 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:35,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y4kcllwn', purging
2023-05-27 06:36:35,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jfcn1coc', purging
2023-05-27 06:36:35,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oretpfp9', purging
2023-05-27 06:36:35,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:35,430 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:35,437 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:35,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:36,020 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:36,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cje6rmvp', purging
2023-05-27 06:36:36,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:36,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:36,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:36,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:36,805 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:36,832 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:37,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rmjt_u60', purging
2023-05-27 06:36:37,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_eoskmiv', purging
2023-05-27 06:36:37,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:37,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:37,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:37,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:37,936 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:37,981 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:38,333 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9rtsfxrd', purging
2023-05-27 06:36:38,334 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b8x_4x99', purging
2023-05-27 06:36:38,334 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iwr8k599', purging
2023-05-27 06:36:38,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:38,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:38,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:38,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:38,514 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:39,155 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:39,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gwmj6x3x', purging
2023-05-27 06:36:39,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:39,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:39,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:39,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:39,771 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:39,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:40,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xe12b9n9', purging
2023-05-27 06:36:40,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vgiu9viy', purging
2023-05-27 06:36:40,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:40,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:40,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:40,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:40,879 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:40,896 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:41,451 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nezhbjro', purging
2023-05-27 06:36:41,451 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4zjcxkom', purging
2023-05-27 06:36:41,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-64jr7bj0', purging
2023-05-27 06:36:41,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:41,452 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:41,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:41,454 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:41,487 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:41,905 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:42,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u77vkzta', purging
2023-05-27 06:36:42,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:42,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:42,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:42,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:42,683 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:42,724 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:42,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9tho046x', purging
2023-05-27 06:36:42,986 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2sc054ra', purging
2023-05-27 06:36:42,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:42,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:43,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:43,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:43,652 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:43,697 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:44,248 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:44,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_0wypnnr', purging
2023-05-27 06:36:44,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dvtptmuy', purging
2023-05-27 06:36:44,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bz7ovzrf', purging
2023-05-27 06:36:44,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:44,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:44,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:44,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:44,879 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:45,252 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p2dmao8x', purging
2023-05-27 06:36:45,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:45,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:45,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:45,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:45,705 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:45,756 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:45,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oi021fwx', purging
2023-05-27 06:36:45,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qfhpi3s9', purging
2023-05-27 06:36:45,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:45,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:46,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:46,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:46,547 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:46,600 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:47,128 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:47,380 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7dk90xar', purging
2023-05-27 06:36:47,380 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jkd2hqb2', purging
2023-05-27 06:36:47,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-msjd2sbc', purging
2023-05-27 06:36:47,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:47,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:47,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:47,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:47,732 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:48,216 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3xyrvz1u', purging
2023-05-27 06:36:48,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:48,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:48,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:48,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:48,603 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:48,626 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:48,640 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pwmxjfbo', purging
2023-05-27 06:36:48,640 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tq7sn56l', purging
2023-05-27 06:36:48,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:48,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:49,378 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:49,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:49,524 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:49,543 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:50,217 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:50,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gdzoydhs', purging
2023-05-27 06:36:50,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q2yoadoy', purging
2023-05-27 06:36:50,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-huwpwt73', purging
2023-05-27 06:36:50,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:50,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:50,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:50,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:50,648 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:51,116 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2u60po16', purging
2023-05-27 06:36:51,117 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:51,117 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:51,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:51,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:51,281 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:51,499 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:51,855 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2aebm7h7', purging
2023-05-27 06:36:51,855 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2v34u2yx', purging
2023-05-27 06:36:51,856 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:51,856 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:52,179 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:52,231 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:52,298 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wbd12wzy', purging
2023-05-27 06:36:52,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zx47rvt5', purging
2023-05-27 06:36:52,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:52,300 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:52,923 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ta6wf3fz', purging
2023-05-27 06:36:52,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:52,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:52,938 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:53,137 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:53,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:53,802 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:53,879 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-db70jozj', purging
2023-05-27 06:36:53,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:53,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:53,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:53,881 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:54,442 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:54,516 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:54,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ltv39yv', purging
2023-05-27 06:36:54,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x51pgvlx', purging
2023-05-27 06:36:54,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:54,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:55,159 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:55,386 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:55,467 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-spc3v10s', purging
2023-05-27 06:36:55,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cjbei2f6', purging
2023-05-27 06:36:55,468 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:55,468 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:55,944 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:56,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mljl49ce', purging
2023-05-27 06:36:56,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:56,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:56,205 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:56,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:56,737 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:56,802 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7em2604i', purging
2023-05-27 06:36:56,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:56,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:57,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:57,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:57,401 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:57,464 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:57,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ygn3uj1', purging
2023-05-27 06:36:57,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-87nion13', purging
2023-05-27 06:36:57,488 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:57,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:58,114 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:58,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1gkt5ad0', purging
2023-05-27 06:36:58,419 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:58,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:58,522 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:58,888 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:59,055 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2e5xo4fd', purging
2023-05-27 06:36:59,055 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7jw7a99i', purging
2023-05-27 06:36:59,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:59,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:59,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:59,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:59,333 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:59,745 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2enboio', purging
2023-05-27 06:36:59,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:59,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:00,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wci1ydsa', purging
2023-05-27 06:37:00,195 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:00,195 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:00,500 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:00,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c901wrju', purging
2023-05-27 06:37:00,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:00,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:00,542 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:01,002 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:01,002 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:01,223 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:01,779 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:02,184 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ieuj0r3', purging
2023-05-27 06:37:02,184 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lg3nf1dz', purging
2023-05-27 06:37:02,184 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vh2pwqo5', purging
2023-05-27 06:37:02,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:02,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:02,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:02,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:02,404 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:02,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wp19s3l1', purging
2023-05-27 06:37:02,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:02,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:03,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:03,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:03,522 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:03,524 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:03,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_02wf5d8', purging
2023-05-27 06:37:03,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ztsobj6l', purging
2023-05-27 06:37:03,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:03,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:04,085 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:04,716 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:04,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xknwhjh4', purging
2023-05-27 06:37:04,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-95fnajyd', purging
2023-05-27 06:37:04,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:04,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:05,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lg7il676', purging
2023-05-27 06:37:05,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:05,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:05,110 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:05,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:05,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:05,734 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:05,811 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:06,291 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yom9r362', purging
2023-05-27 06:37:06,292 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9swkfnu5', purging
2023-05-27 06:37:06,292 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:06,292 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:06,433 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:06,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ojapfvo0', purging
2023-05-27 06:37:06,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:06,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:07,300 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mk0ggmuv', purging
2023-05-27 06:37:07,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:07,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:07,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:07,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:07,442 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:08,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mbrsmdmq', purging
2023-05-27 06:37:08,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:08,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:08,096 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:08,820 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:08,868 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:09,015 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aysvw_gs', purging
2023-05-27 06:37:09,015 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ga5csusn', purging
2023-05-27 06:37:09,016 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:09,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:09,234 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:09,694 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:09,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uw0mea14', purging
2023-05-27 06:37:09,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ljka1qsy', purging
2023-05-27 06:37:09,706 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:09,706 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:10,488 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:10,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:10,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y65s6ukf', purging
2023-05-27 06:37:10,512 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:10,512 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:10,537 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:10,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:10,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:11,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:11,343 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:11,420 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:11,469 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:12,068 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:12,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gjz2t7k4', purging
2023-05-27 06:37:12,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xtk0nzm8', purging
2023-05-27 06:37:12,140 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9tf1wr_h', purging
2023-05-27 06:37:12,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:12,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:12,648 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:12,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-13k4xkgi', purging
2023-05-27 06:37:12,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:12,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:13,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:13,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:13,232 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:13,679 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qk9jni96', purging
2023-05-27 06:37:13,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:13,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:14,055 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:14,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ahk1ct8j', purging
2023-05-27 06:37:14,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:14,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:14,285 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:14,693 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:14,786 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nvabhinf', purging
2023-05-27 06:37:14,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xah7dado', purging
2023-05-27 06:37:14,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:14,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:15,269 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:15,698 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ceqjou3g', purging
2023-05-27 06:37:15,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:15,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:15,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:15,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:15,869 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:16,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vkfc1ug8', purging
2023-05-27 06:37:16,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:16,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:16,522 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:16,557 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:16,811 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y3q56gnv', purging
2023-05-27 06:37:16,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9hyy95or', purging
2023-05-27 06:37:16,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:16,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:17,287 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:17,389 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t679hksf', purging
2023-05-27 06:37:17,390 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:17,390 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:18,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:18,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:18,122 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:18,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iqdl1yv9', purging
2023-05-27 06:37:18,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:18,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:18,707 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:18,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w8v544ju', purging
2023-05-27 06:37:18,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:18,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:19,149 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:19,240 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:19,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fn6gqe2v', purging
2023-05-27 06:37:19,724 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vig_syr4', purging
2023-05-27 06:37:19,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:19,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:19,974 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:20,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pkpcroro', purging
2023-05-27 06:37:20,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:20,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:20,441 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:20,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5lz1_jv5', purging
2023-05-27 06:37:20,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:20,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:20,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:20,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:21,058 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:21,501 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0np95a8l', purging
2023-05-27 06:37:21,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:21,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:21,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:21,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:22,240 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:22,300 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:22,616 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w_kq5c4x', purging
2023-05-27 06:37:22,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4rtlaiyi', purging
2023-05-27 06:37:22,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:22,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:22,930 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:23,306 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:23,620 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:23,817 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vb4t03e4', purging
2023-05-27 06:37:23,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-slajplyl', purging
2023-05-27 06:37:23,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-68qh_dzu', purging
2023-05-27 06:37:23,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:23,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:23,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:23,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:24,474 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:24,474 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:24,645 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:24,726 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:24,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-noykdw78', purging
2023-05-27 06:37:24,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tehq_bz_', purging
2023-05-27 06:37:24,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:24,933 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:25,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:25,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:25,955 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:26,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1n2w_c7b', purging
2023-05-27 06:37:26,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:26,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:26,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:26,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:26,467 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:26,530 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:27,090 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:27,126 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:27,583 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h78divii', purging
2023-05-27 06:37:27,583 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8n9fa8bb', purging
2023-05-27 06:37:27,583 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g6yhw3xb', purging
2023-05-27 06:37:27,584 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-83kt8rtc', purging
2023-05-27 06:37:27,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:27,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:28,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:28,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:28,119 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:28,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:28,305 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:28,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-un0np569', purging
2023-05-27 06:37:28,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:28,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:28,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:28,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:29,304 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:29,411 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:29,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zw3e5ncd', purging
2023-05-27 06:37:29,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-57e0u5wu', purging
2023-05-27 06:37:29,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:29,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:30,188 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:30,216 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:30,862 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:30,871 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ul2ot33', purging
2023-05-27 06:37:30,872 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eohbcodb', purging
2023-05-27 06:37:30,872 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ptsxm9rz', purging
2023-05-27 06:37:30,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:30,872 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:31,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:31,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:31,476 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:31,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qdn4pzry', purging
2023-05-27 06:37:31,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:31,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:31,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u6h81ko7', purging
2023-05-27 06:37:31,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:31,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:31,949 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:32,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:32,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:33,055 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kloc5o21', purging
2023-05-27 06:37:33,055 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xi3sh_iy', purging
2023-05-27 06:37:33,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:33,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:33,066 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:33,112 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:33,464 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:33,540 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-690qggiw', purging
2023-05-27 06:37:33,541 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:33,541 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:34,277 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:34,638 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:34,719 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mjs58l12', purging
2023-05-27 06:37:34,719 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zxsdytwv', purging
2023-05-27 06:37:34,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:34,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:34,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:34,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:35,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:35,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:35,780 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:35,821 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:35,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ahnbwqrw', purging
2023-05-27 06:37:35,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k13dq2ed', purging
2023-05-27 06:37:35,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:35,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:36,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gkxpywae', purging
2023-05-27 06:37:36,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:36,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:36,239 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:36,857 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:37,330 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:37,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vylq6c0i', purging
2023-05-27 06:37:37,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gstu6_qo', purging
2023-05-27 06:37:37,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:37,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:37,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:37,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:37,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:37,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:38,280 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:38,399 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:38,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bc8p_c3a', purging
2023-05-27 06:37:38,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-55cjhzhp', purging
2023-05-27 06:37:38,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:38,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:38,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:38,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:39,158 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:39,558 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:39,921 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k5d9ho1i', purging
2023-05-27 06:37:39,921 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t3yk7e4b', purging
2023-05-27 06:37:39,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:39,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:40,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:40,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:40,114 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:40,725 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gt7cyprh', purging
2023-05-27 06:37:40,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4n7lp6hl', purging
2023-05-27 06:37:40,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:40,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:40,766 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:41,049 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:41,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fi24veri', purging
2023-05-27 06:37:41,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:41,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:41,695 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:41,696 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:41,896 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:42,190 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:42,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u_7ijy7u', purging
2023-05-27 06:37:42,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g80ymf1y', purging
2023-05-27 06:37:42,295 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:42,295 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:42,525 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:42,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0_szqy85', purging
2023-05-27 06:37:42,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:42,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:43,159 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:43,453 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:43,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8sctwrks', purging
2023-05-27 06:37:43,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i3rylhmp', purging
2023-05-27 06:37:43,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:43,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:43,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:43,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:44,122 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:44,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nxcffeua', purging
2023-05-27 06:37:44,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:44,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:44,471 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:44,736 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vfroeot6', purging
2023-05-27 06:37:44,737 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:44,737 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:44,994 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:45,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2xkgazv', purging
2023-05-27 06:37:45,068 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:45,068 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:45,678 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yrbzhmbg', purging
2023-05-27 06:37:45,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:45,679 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:45,774 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:46,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:46,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:46,180 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:46,570 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-289y2zln', purging
2023-05-27 06:37:46,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-brdxr216', purging
2023-05-27 06:37:46,571 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:46,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:46,671 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:47,050 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:47,359 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-42s9ady8', purging
2023-05-27 06:37:47,360 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5d_xjrlb', purging
2023-05-27 06:37:47,360 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:47,360 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:47,366 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:47,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:47,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:47,823 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:48,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d6de7pwy', purging
2023-05-27 06:37:48,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:48,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:48,492 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:48,629 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hrmb2l16', purging
2023-05-27 06:37:48,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:48,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:48,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gumuxfk2', purging
2023-05-27 06:37:48,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:48,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:49,011 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:49,328 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:49,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:49,734 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:50,109 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ul98oi77', purging
2023-05-27 06:37:50,110 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wap1fdwf', purging
2023-05-27 06:37:50,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:50,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:50,143 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:50,477 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:50,585 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4bj7lr39', purging
2023-05-27 06:37:50,586 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:50,586 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:51,031 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:51,175 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:51,335 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qfi6qi1i', purging
2023-05-27 06:37:51,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3p5byh7_', purging
2023-05-27 06:37:51,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:51,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:51,691 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:51,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:52,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e7dju2kx', purging
2023-05-27 06:37:52,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:52,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:52,133 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:52,735 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:52,735 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:52,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:52,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:52,863 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:53,188 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:53,541 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:53,587 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:53,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-irmm7ols', purging
2023-05-27 06:37:53,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iakfq710', purging
2023-05-27 06:37:53,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kzp7dswn', purging
2023-05-27 06:37:53,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wbw4mpvv', purging
2023-05-27 06:37:53,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:53,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:54,167 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:54,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vcrf0ocn', purging
2023-05-27 06:37:54,468 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:54,468 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:54,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:54,731 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:55,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:55,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:55,114 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:55,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k0vxlrjd', purging
2023-05-27 06:37:55,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:55,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:55,428 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:55,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5ymreagb', purging
2023-05-27 06:37:55,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h5mh1znq', purging
2023-05-27 06:37:55,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:55,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:55,758 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:55,858 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:56,231 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:56,682 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rcxhajbe', purging
2023-05-27 06:37:56,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f3eboxjq', purging
2023-05-27 06:37:56,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:56,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:56,994 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:56,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:57,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:57,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:57,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:57,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:57,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:57,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:00,054 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:00,096 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:00,117 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:00,158 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:00,185 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:01,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-av16y3x8', purging
2023-05-27 06:38:01,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qii1xyk9', purging
2023-05-27 06:38:01,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1x3ufd4w', purging
2023-05-27 06:38:01,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-agaznut8', purging
2023-05-27 06:38:01,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uok60c45', purging
2023-05-27 06:38:01,649 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:01,649 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:01,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:01,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:01,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:01,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:01,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:01,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:01,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:01,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:04,736 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:04,833 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:04,887 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:04,923 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:04,949 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:06,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-avys3e3w', purging
2023-05-27 06:38:06,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-51v2z_fh', purging
2023-05-27 06:38:06,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x4fxizkw', purging
2023-05-27 06:38:06,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dfz7kyn4', purging
2023-05-27 06:38:06,354 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uoii3424', purging
2023-05-27 06:38:06,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:06,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:06,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:06,450 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:06,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:06,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:06,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:06,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:06,571 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:06,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:08,904 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:08,945 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:09,002 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:09,078 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:09,848 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:10,488 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fsmen43q', purging
2023-05-27 06:38:10,488 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tffks1ab', purging
2023-05-27 06:38:10,489 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jo1uw6b7', purging
2023-05-27 06:38:10,489 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1tjl5dj4', purging
2023-05-27 06:38:10,490 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ekqn8qi0', purging
2023-05-27 06:38:10,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:10,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:10,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:10,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:10,577 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:10,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:10,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:10,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:11,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:11,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:11,920 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:12,082 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:12,297 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:12,339 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:12,845 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:13,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5gmqth9o', purging
2023-05-27 06:38:13,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n4xlqxt5', purging
2023-05-27 06:38:13,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u8qqxwn7', purging
2023-05-27 06:38:13,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jzuxgq1w', purging
2023-05-27 06:38:13,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-feple8f1', purging
2023-05-27 06:38:13,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:13,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:13,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:13,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:13,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:13,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:13,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:13,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:14,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:14,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:15,923 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:15,973 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:16,027 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:16,083 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:16,437 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:17,536 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-st7auc92', purging
2023-05-27 06:38:17,536 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mbajl_fg', purging
2023-05-27 06:38:17,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d7hlogg2', purging
2023-05-27 06:38:17,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-edaivalw', purging
2023-05-27 06:38:17,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6yk18577', purging
2023-05-27 06:38:17,538 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:17,538 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:17,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:17,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:17,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:17,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:17,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:17,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:17,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:17,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:20,296 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:20,324 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:20,361 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:20,410 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:20,997 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:21,901 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lv7mf8fj', purging
2023-05-27 06:38:21,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-82ntou7j', purging
2023-05-27 06:38:21,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nrru9foc', purging
2023-05-27 06:38:21,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0pslh4eg', purging
2023-05-27 06:38:21,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ickncro7', purging
2023-05-27 06:38:21,903 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:21,903 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:21,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:21,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:21,953 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:21,953 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:21,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:21,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:22,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:22,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:23,617 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:23,808 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:23,841 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:23,871 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:24,183 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:25,230 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u77vxu8w', purging
2023-05-27 06:38:25,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hchqf39e', purging
2023-05-27 06:38:25,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1nk7buho', purging
2023-05-27 06:38:25,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l9xtyu_i', purging
2023-05-27 06:38:25,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0_e_4vay', purging
2023-05-27 06:38:25,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:25,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:25,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:25,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:25,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:25,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:25,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:25,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:25,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:25,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:27,291 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:27,315 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:27,404 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:27,455 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:27,749 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:28,921 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-am1q1zs3', purging
2023-05-27 06:38:28,921 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9h2b295h', purging
2023-05-27 06:38:28,922 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u56hgywp', purging
2023-05-27 06:38:28,922 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9wt_01o8', purging
2023-05-27 06:38:28,922 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gitpl_8r', purging
2023-05-27 06:38:28,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:28,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:28,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:28,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:28,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:28,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:29,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:29,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:29,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:29,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:31,055 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:31,079 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:31,314 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:31,369 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:31,412 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:32,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vny98hjg', purging
2023-05-27 06:38:32,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-114wam15', purging
2023-05-27 06:38:32,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sx_lx9_5', purging
2023-05-27 06:38:32,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_lyz7tzl', purging
2023-05-27 06:38:32,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-33um933z', purging
2023-05-27 06:38:32,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:32,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:32,696 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:32,696 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:32,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:32,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:33,017 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:33,017 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:33,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:33,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:34,897 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:34,921 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:34,950 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:35,023 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:35,229 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:36,458 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mgjg0k1d', purging
2023-05-27 06:38:36,459 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kbkprh45', purging
2023-05-27 06:38:36,459 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-23xokayw', purging
2023-05-27 06:38:36,459 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8hc_gako', purging
2023-05-27 06:38:36,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-avw7ukia', purging
2023-05-27 06:38:36,460 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:36,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:36,540 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:36,540 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:36,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:36,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:36,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:36,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:36,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:36,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:38,427 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:38,448 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:38,517 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:38,726 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:38,951 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:39,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xrfnu1ao', purging
2023-05-27 06:38:39,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l4a0z1jb', purging
2023-05-27 06:38:39,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zxu6mcv1', purging
2023-05-27 06:38:39,966 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vpcpqh9l', purging
2023-05-27 06:38:39,966 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ssta9l23', purging
2023-05-27 06:38:39,967 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:39,967 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:40,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:40,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:40,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:40,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:40,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:40,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:40,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:40,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:42,096 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:42,125 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:42,217 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:42,286 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:42,881 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:43,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cv1huyux', purging
2023-05-27 06:38:43,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tqkft7e7', purging
2023-05-27 06:38:43,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d6xnztsl', purging
2023-05-27 06:38:43,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dcrhzoov', purging
2023-05-27 06:38:43,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vs77hxmc', purging
2023-05-27 06:38:43,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:43,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:43,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:43,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:43,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:43,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:43,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:43,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:44,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:44,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:45,787 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:45,846 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:45,886 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:45,927 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1530 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
