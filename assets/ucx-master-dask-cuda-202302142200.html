<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>junit-dask-cuda.xml</title>
    <style type="text/css">
        body {
    background-color: white;
    padding-bottom: 20em;
    margin: 0;
    min-height: 15cm;
}

h1, h2, h3, h4, h5, h6, h7 {
    font-family: sans-serif;
}

h1 {
    background-color: #007acc;
    color: white;
    padding: 3mm;
    margin-top: 0;
    margin-bottom: 1mm;
}

.footer {
    font-style: italic;
    font-size: small;
    text-align: right;
    padding: 1em;
}

.testsuite {
    padding-bottom: 2em;
    margin-left: 1em;
}

.proplist {
    width: 100%;
    margin-bottom: 2em;
    border-collapse: collapse;
    border: 1px solid grey;
}

.proplist th {
    background-color: silver;
    width: 5em;
    padding: 2px;
    padding-right: 1em;
    text-align: left;
}

.proplist td {
    padding: 2px;
}

.index-table {
    width: 90%;
    margin-left: 1em;
}

.index-table td {
    vertical-align: top;
    width: 50%;
}

.failure-index {

}

.toc {
    margin-bottom: 2em;
    font-family: monospace;
}

.stdio, pre {
    min-height: 1em;
    background-color: #1e1e1e;
    color: silver;
    padding: 0.5em;
}
.tdpre {
    background-color: #1e1e1e;
}

.test {
    margin-left: 0.5cm;
}

.outcome {
    border-left: 1em;
    padding: 2px;
}

.outcome-failed {
    border-left: 1em solid lightcoral;
}

.outcome-passed {
    border-left: 1em solid lightgreen;
}

.outcome-skipped {
    border-left: 1em solid lightyellow;
}

.stats-table {
}

.stats-table td {
    min-width: 4em;
    text-align: right;
}

.stats-table .failed {
    background-color: lightcoral;
}

.stats-table .passed {
    background-color: lightgreen;
}

.matrix-table {
    table-layout: fixed;
    border-spacing: 0;
    width: available;
    margin-left: 1em;
}

.matrix-table td {
    vertical-align: center;
}

.matrix-table td:last-child {
    width: 0;
}

.matrix-table tr:hover {
    background-color: yellow;
}

.matrix-axis-name {
    white-space: nowrap;
    padding-right: 0.5em;
    border-left: 1px solid black;
    border-top: 1px solid black;
    text-align: right;
}

.matrix-axis-line {
    border-left: 1px solid black;
    width: 0.5em;
}

.matrix-classname {
    text-align: left;
    width: 100%;
    border-top: 2px solid grey;
    border-bottom: 1px solid silver;
}

.matrix-casename {
    text-align: left;
    font-weight: normal;
    font-style: italic;
    padding-left: 1em;
    border-bottom: 1px solid silver;
}

.matrix-result {
    display: block;
    width: 1em;
    text-align: center;
    padding: 1mm;
    margin: 0;
}

.matrix-result-combined {
    white-space: nowrap;
    padding-right: 0.2em;
    text-align: right;
}

.matrix-result-failed {
    background-color: lightcoral;
}

.matrix-result-passed {
    background-color: lightgreen;
}

.matrix-result-skipped {
    background-color: lightyellow;
}

.matrix-even {
    background-color: lightgray;
}
    </style>
</head>
<body>
    
<h1>
    Test Report : junit-dask-cuda.xml
</h1>
<a id="toc"></a>
<table class="index-table">
    <tr>
        <td>
            <ul class="toc">
            
                
                <li>dask_cuda.tests.test_cudf_builtin_spilling
                <ul>
                    
                    <li><a href="#215f3177-58a2-4190-aed8-93c7305e62a4">test_is_spillable_object_when_cudf_spilling_disabled</a></li>
                    
                    <li><a href="#dda56dfc-a773-4782-ac5a-a5f0ae79eaaf">test_is_spillable_object_when_cudf_spilling_enabled</a></li>
                    
                    <li><a href="#33e2f2e4-0b09-4618-a37c-d5b7b9bebfb0">test_device_host_file_when_cudf_spilling_is_disabled</a></li>
                    
                    <li><a href="#79d7a6e7-6e3b-45ed-8646-d887a91725bd">test_device_host_file_step_by_step</a></li>
                    
                    <li><a href="#3865cd37-46b7-49e0-bdf8-169882a47094">test_proxify_host_file</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_dask_cuda_worker
                <ul>
                    
                    <li><a href="#80365f31-45e5-4828-94ce-249e301e86c2">test_cuda_visible_devices_and_memory_limit_and_nthreads</a></li>
                    
                    <li><a href="#41298fb9-e663-48a7-b1c5-734b7a0a5cf4">test_rmm_pool</a></li>
                    
                    <li><a href="#f8e2c662-4e9e-4118-911f-1ee83625c188">test_rmm_managed</a></li>
                    
                    <li><a href="#c8216f9f-d42c-4fd7-8640-32c92c49733d">test_rmm_async</a></li>
                    
                    <li><a href="#e51bd957-eb42-4643-825d-b4e57c60f3dd">test_rmm_logging</a></li>
                    
                    <li><a href="#b9e549a0-cf4b-4f91-be2d-d13f077f21fb">test_dashboard_address</a></li>
                    
                    <li><a href="#979f9268-f882-4412-bdff-22dd2717f910">test_unknown_argument</a></li>
                    
                    <li><a href="#4bb9c00b-0a38-4d39-a835-12ac80595848">test_pre_import</a></li>
                    
                    <li><a href="#25083def-a7c6-4501-8543-083d38733b34">test_pre_import_not_found</a></li>
                    
                    <li><a href="#c251e191-df6d-4a9f-ac48-88a8403223d0">test_cuda_mig_visible_devices_and_memory_limit_and_nthreads</a></li>
                    
                    <li><a href="#346ee6ed-9418-4b72-a366-c58cd92bb20f">test_cuda_visible_devices_uuid</a></li>
                    
                    <li><a href="#c9fa008b-4be5-4dd1-a20f-c56d87393fe8">test_rmm_track_allocations</a></li>
                    
                    <li><a href="#98eb94d3-d361-4ba5-b3af-ac724715d1cc">test_get_cluster_configuration</a></li>
                    
                    <li><a href="#98647bc1-d29e-43db-aad6-6fa7e8fe8f8c">test_worker_fraction_limits</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_device_host_file
                <ul>
                    
                    <li><a href="#c7a3fba1-1529-49d9-a39c-a423df2c357e">test_device_host_file_short[array_size_range0-1-1]</a></li>
                    
                    <li><a href="#9e33c142-5892-4056-98db-63603037ddcd">test_device_host_file_short[array_size_range0-1-10]</a></li>
                    
                    <li><a href="#81bfc490-218c-4d62-bc3f-f4882299da84">test_device_host_file_short[array_size_range0-1-100]</a></li>
                    
                    <li><a href="#5a4e2238-7147-4f62-92a8-71e5c67b84d9">test_device_host_file_short[array_size_range0-10-1]</a></li>
                    
                    <li><a href="#220c90b5-5cdd-43a9-9276-b14ea3da45cb">test_device_host_file_short[array_size_range0-10-10]</a></li>
                    
                    <li><a href="#9ce4ffe6-4b5b-4e52-b43b-64c4a7f6e00c">test_device_host_file_short[array_size_range0-10-100]</a></li>
                    
                    <li><a href="#91004eaa-8049-4e47-8980-742c275ebc2e">test_device_host_file_short[array_size_range0-100-1]</a></li>
                    
                    <li><a href="#1ef37346-e623-4081-b13c-8b168d89f644">test_device_host_file_short[array_size_range0-100-10]</a></li>
                    
                    <li><a href="#ec4d9c81-f1a4-4db0-a6e8-c4f9ccfe54a5">test_device_host_file_short[array_size_range0-100-100]</a></li>
                    
                    <li><a href="#624e905c-3f80-4ee7-8493-4e791369c759">test_device_host_file_short[array_size_range1-1-1]</a></li>
                    
                    <li><a href="#338c9495-9745-4b66-a45f-47e48f6133a2">test_device_host_file_short[array_size_range1-1-10]</a></li>
                    
                    <li><a href="#90f1c993-f323-49cd-94e6-7d5aea023fad">test_device_host_file_short[array_size_range1-1-100]</a></li>
                    
                    <li><a href="#6e1df688-9251-483e-81a1-12c7dd0959e7">test_device_host_file_short[array_size_range1-10-1]</a></li>
                    
                    <li><a href="#f194b233-cb7a-4742-9d4a-7502079e5c59">test_device_host_file_short[array_size_range1-10-10]</a></li>
                    
                    <li><a href="#0e95e93e-91c3-45fd-87d1-f1170bde2d43">test_device_host_file_short[array_size_range1-10-100]</a></li>
                    
                    <li><a href="#227cf4b7-ef05-4c4a-aea7-0e53ef2ff857">test_device_host_file_short[array_size_range1-100-1]</a></li>
                    
                    <li><a href="#6cbbc0f5-9f59-41c5-99b8-be009fabe93c">test_device_host_file_short[array_size_range1-100-10]</a></li>
                    
                    <li><a href="#ee174355-417d-4a6f-9e9b-fef6227d8ec1">test_device_host_file_short[array_size_range1-100-100]</a></li>
                    
                    <li><a href="#aa5f0395-b4ca-46ea-9c51-0feccd1d4825">test_device_host_file_short[array_size_range2-1-1]</a></li>
                    
                    <li><a href="#d3077961-7efe-4276-ad7c-c50e043a2636">test_device_host_file_short[array_size_range2-1-10]</a></li>
                    
                    <li><a href="#a0c3dc77-a0b9-4139-83c7-bc57830fa191">test_device_host_file_short[array_size_range2-1-100]</a></li>
                    
                    <li><a href="#86f03b56-10f9-4ae3-a6a7-8520049e4dd2">test_device_host_file_short[array_size_range2-10-1]</a></li>
                    
                    <li><a href="#fb4da52f-4f2c-427a-ac94-c43b54db738a">test_device_host_file_short[array_size_range2-10-10]</a></li>
                    
                    <li><a href="#ff81d9a1-5ad0-488c-89e6-6ef64b35f450">test_device_host_file_short[array_size_range2-10-100]</a></li>
                    
                    <li><a href="#e944c528-ce65-47c2-a4aa-b0aba04bacce">test_device_host_file_short[array_size_range2-100-1]</a></li>
                    
                    <li><a href="#27a4f79d-6fb9-4f26-ab94-09d64ef1469b">test_device_host_file_short[array_size_range2-100-10]</a></li>
                    
                    <li><a href="#1f047cac-fcd1-4780-9e01-15fb71228c69">test_device_host_file_short[array_size_range2-100-100]</a></li>
                    
                    <li><a href="#420c7d6a-525f-45f2-818d-cb72ee9d4589">test_device_host_file_step_by_step</a></li>
                    
                    <li><a href="#d40463f7-f675-497e-8809-7c93f2ab0d93">test_serialize_cupy_collection[10-0-dict]</a></li>
                    
                    <li><a href="#42b3f6bd-ecd4-49bd-95c4-aa41e79675a8">test_serialize_cupy_collection[10-0-list]</a></li>
                    
                    <li><a href="#a3421cae-844d-465f-93e4-897f8a01083b">test_serialize_cupy_collection[10-0-tuple]</a></li>
                    
                    <li><a href="#05a96d1e-fb56-4ec7-9da5-e0c47b6daa25">test_serialize_cupy_collection[10-1-dict]</a></li>
                    
                    <li><a href="#9c3dc163-0de0-45b0-8e79-213297b47d67">test_serialize_cupy_collection[10-1-list]</a></li>
                    
                    <li><a href="#ecfa46ef-cac6-468d-9b64-cd096d20f76d">test_serialize_cupy_collection[10-1-tuple]</a></li>
                    
                    <li><a href="#23aaa83b-34d7-4cee-bff8-5b0dfe856eed">test_serialize_cupy_collection[10-3-dict]</a></li>
                    
                    <li><a href="#803b76ba-5ab5-4421-bf6f-d6e27d9dac7a">test_serialize_cupy_collection[10-3-list]</a></li>
                    
                    <li><a href="#918573fd-01de-42f3-a406-3e6c6cbfcb1a">test_serialize_cupy_collection[10-3-tuple]</a></li>
                    
                    <li><a href="#24377b1b-ffcf-4207-8479-5f9e7fe74f06">test_serialize_cupy_collection[10-6-dict]</a></li>
                    
                    <li><a href="#fcb74379-6c03-4c3a-ad11-6b1ce189e6c7">test_serialize_cupy_collection[10-6-list]</a></li>
                    
                    <li><a href="#c454974d-0d17-4f9f-a987-7de4c48e85fc">test_serialize_cupy_collection[10-6-tuple]</a></li>
                    
                    <li><a href="#9ae3bc99-5b86-468a-bee8-ba818323db96">test_serialize_cupy_collection[value1-0-dict]</a></li>
                    
                    <li><a href="#9f72172c-4aa4-4929-8169-645e9d9a9703">test_serialize_cupy_collection[value1-0-list]</a></li>
                    
                    <li><a href="#6558b354-2044-4993-98c2-1e50fc9b5858">test_serialize_cupy_collection[value1-0-tuple]</a></li>
                    
                    <li><a href="#bb7a774a-1045-4672-81f7-bcfbc628c578">test_serialize_cupy_collection[value1-1-dict]</a></li>
                    
                    <li><a href="#6c3b1a65-ef28-4ce9-8baf-d67530963583">test_serialize_cupy_collection[value1-1-list]</a></li>
                    
                    <li><a href="#208111db-3eb4-42f1-8ecb-1dccae3f142c">test_serialize_cupy_collection[value1-1-tuple]</a></li>
                    
                    <li><a href="#711433e6-cda2-4363-ba21-f8219a85eb1b">test_serialize_cupy_collection[value1-3-dict]</a></li>
                    
                    <li><a href="#c788ff65-6021-40ae-bbeb-881c1ca15a55">test_serialize_cupy_collection[value1-3-list]</a></li>
                    
                    <li><a href="#5595e146-af71-4b9b-b3c3-f2fb17bac012">test_serialize_cupy_collection[value1-3-tuple]</a></li>
                    
                    <li><a href="#33d054dc-868a-4946-af34-282256b9c04a">test_serialize_cupy_collection[value1-6-dict]</a></li>
                    
                    <li><a href="#af2fcb63-4f61-43d6-9ae8-1cc4701416fd">test_serialize_cupy_collection[value1-6-list]</a></li>
                    
                    <li><a href="#3831f877-dd3b-4dc9-abf9-cf4b5d6f3e50">test_serialize_cupy_collection[value1-6-tuple]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_dgx
                <ul>
                    
                    <li><a href="#30bf9173-adf6-4c57-a910-3764c2c0d158">test_default</a></li>
                    
                    <li><a href="#0a04eb59-5414-4113-9dad-6d9de4bc53be">test_tcp_over_ucx</a></li>
                    
                    <li><a href="#7fa90a61-6dbd-4b76-9ea1-1f177cea6a43">test_tcp_only</a></li>
                    
                    <li><a href="#a8f8599a-1144-429b-ab33-cb65ecd503bb">test_ucx_infiniband_nvlink[params0]</a></li>
                    
                    <li><a href="#417f88b2-3de4-4dff-8799-7eb90f2cc3f1">test_ucx_infiniband_nvlink[params1]</a></li>
                    
                    <li><a href="#370d06d8-a218-4da4-8642-fdaa5db2d632">test_ucx_infiniband_nvlink[params2]</a></li>
                    
                    <li><a href="#bca0824a-424a-4d18-9409-4e85803c0e44">test_ucx_infiniband_nvlink[params3]</a></li>
                    
                    <li><a href="#32281558-de8d-430c-be37-996b3695e0ab">test_ucx_infiniband_nvlink[params4]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_explicit_comms
                <ul>
                    
                    <li><a href="#a7ff0e77-a18a-4435-bce0-52573b584ca3">test_local_cluster[tcp]</a></li>
                    
                    <li><a href="#b4d3fec5-87c5-4120-9d29-e3106baa25ff">test_local_cluster[ucx]</a></li>
                    
                    <li><a href="#a94c63a1-9918-4b1c-ba8b-8e67422de916">test_dataframe_merge_empty_partitions</a></li>
                    
                    <li><a href="#8fc1e345-5218-474c-9fd6-9b540a891ffc">test_dataframe_shuffle[tcp-pandas-1]</a></li>
                    
                    <li><a href="#355390f9-f977-47ef-a04a-6f3c02d200a1">test_dataframe_shuffle[tcp-pandas-2]</a></li>
                    
                    <li><a href="#472bd264-b1dd-4de3-a911-9ff39bf1b440">test_dataframe_shuffle[tcp-pandas-3]</a></li>
                    
                    <li><a href="#49603f52-0735-4206-a919-563ab41cae7d">test_dataframe_shuffle[tcp-cudf-1]</a></li>
                    
                    <li><a href="#ae6c8025-4050-4ceb-876f-df15eabb3878">test_dataframe_shuffle[tcp-cudf-2]</a></li>
                    
                    <li><a href="#8d8e9c10-b9ec-43c7-a337-2c16ece0fe4f">test_dataframe_shuffle[tcp-cudf-3]</a></li>
                    
                    <li><a href="#66dcf089-2894-4d3d-8752-179c388d4340">test_dataframe_shuffle[ucx-pandas-1]</a></li>
                    
                    <li><a href="#24399cb6-1251-45ef-867b-b4fc9f28029b">test_dataframe_shuffle[ucx-pandas-2]</a></li>
                    
                    <li><a href="#a87a1a06-3090-4010-8071-7261cd8cfbe1">test_dataframe_shuffle[ucx-pandas-3]</a></li>
                    
                    <li><a href="#59667a4b-e3f8-49e4-a355-4191da9f2bcf">test_dataframe_shuffle[ucx-cudf-1]</a></li>
                    
                    <li><a href="#b4f70239-4e01-4b36-8743-c963b7c7a5e5">test_dataframe_shuffle[ucx-cudf-2]</a></li>
                    
                    <li><a href="#94f2a235-def8-4fbb-812f-4d0132eb526a">test_dataframe_shuffle[ucx-cudf-3]</a></li>
                    
                    <li><a href="#0b68eb56-bbb3-4bb3-b328-f37fa23c122d">test_dask_use_explicit_comms[True]</a></li>
                    
                    <li><a href="#11ab09d5-0c20-489f-825e-99e0af4ed69e">test_dask_use_explicit_comms[False]</a></li>
                    
                    <li><a href="#5f13cdf7-dbd5-4bc9-aeb0-cdeabf3d7d64">test_dataframe_shuffle_merge[tcp-pandas-1]</a></li>
                    
                    <li><a href="#d1673323-b5b6-4a6f-8e53-2d7d534b8ca4">test_dataframe_shuffle_merge[tcp-pandas-2]</a></li>
                    
                    <li><a href="#474141ab-bad5-48eb-899c-c88ed2871edd">test_dataframe_shuffle_merge[tcp-pandas-4]</a></li>
                    
                    <li><a href="#ca01a75f-87c8-46f4-8c28-84a93869b032">test_dataframe_shuffle_merge[tcp-cudf-1]</a></li>
                    
                    <li><a href="#8d339e4a-8066-460a-a299-f3ea37170e93">test_dataframe_shuffle_merge[tcp-cudf-2]</a></li>
                    
                    <li><a href="#fef0bc65-4f5e-410b-9728-e4f83f3ef266">test_dataframe_shuffle_merge[tcp-cudf-4]</a></li>
                    
                    <li><a href="#24b1c727-7bd8-4259-bbff-088be70f8b28">test_dataframe_shuffle_merge[ucx-pandas-1]</a></li>
                    
                    <li><a href="#8b11706e-f358-45e7-9473-8e7a8ad0b4c5">test_dataframe_shuffle_merge[ucx-pandas-2]</a></li>
                    
                    <li><a href="#5041e605-efcc-4ede-9e5e-81dc2591dbaa">test_dataframe_shuffle_merge[ucx-pandas-4]</a></li>
                    
                    <li><a href="#3a6eb307-7e79-4b97-8aa9-f19cd0475cae">test_dataframe_shuffle_merge[ucx-cudf-1]</a></li>
                    
                    <li><a href="#ebb191fc-eb92-4032-a8c7-8f395dd3623b">test_dataframe_shuffle_merge[ucx-cudf-2]</a></li>
                    
                    <li><a href="#717c7604-23b8-4a56-98e7-d110d5ba6233">test_dataframe_shuffle_merge[ucx-cudf-4]</a></li>
                    
                    <li><a href="#9f06fc7b-e517-4b4b-80d5-0fed2c192b39">test_jit_unspill[tcp]</a></li>
                    
                    <li><a href="#1330eeac-2b95-4816-8559-d53cb202709f">test_jit_unspill[ucx]</a></li>
                    
                    <li><a href="#1e4c315e-db7d-4e79-a6b1-51ff02d19231">test_lock_workers</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_gds
                <ul>
                    
                    <li><a href="#94a4a208-53ba-4bac-aa88-0781b3884692">test_gds[True-cupy]</a></li>
                    
                    <li><a href="#ef2a90d5-cf7a-490c-b3f5-38c8dd826b8d">test_gds[True-cudf]</a></li>
                    
                    <li><a href="#2299c290-26cf-41f7-9d71-c1fd6895df8e">test_gds[True-numba.cuda]</a></li>
                    
                    <li><a href="#b964a54a-c16d-47c7-bc94-610e771d030d">test_gds[False-cupy]</a></li>
                    
                    <li><a href="#3ef56dde-9d08-4d79-b4a7-e3fb2a93101d">test_gds[False-cudf]</a></li>
                    
                    <li><a href="#b01f0a76-2da0-4fc9-ae6e-156e7991acc4">test_gds[False-numba.cuda]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_initialize
                <ul>
                    
                    <li><a href="#5e07880a-6056-48cd-9cf1-02fcef7c87a6">test_initialize_ucx_tcp</a></li>
                    
                    <li><a href="#b8f77a56-c325-456e-8bfc-5f61bcccbc30">test_initialize_ucx_nvlink</a></li>
                    
                    <li><a href="#47bbe595-79ee-48c2-b07b-30645ec26712">test_initialize_ucx_infiniband</a></li>
                    
                    <li><a href="#7bf66402-5b07-4159-baf7-1b5b3d588073">test_initialize_ucx_all</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_local_cuda_cluster
                <ul>
                    
                    <li><a href="#499dc81f-46d7-4935-b036-fbcd1b9a4994">test_local_cuda_cluster</a></li>
                    
                    <li><a href="#3eb63595-1d90-48b0-b109-8cd62e07fed8">test_with_subset_of_cuda_visible_devices</a></li>
                    
                    <li><a href="#845a661b-0069-4355-b3ab-352c037de6aa">test_ucx_protocol[ucx]</a></li>
                    
                    <li><a href="#4b5c21fd-c1ef-4769-95fe-1f511aaa134e">test_ucx_protocol[None]</a></li>
                    
                    <li><a href="#d0df4594-ba2b-46af-96e4-9b7a1d8c6af6">test_ucx_protocol_type_error</a></li>
                    
                    <li><a href="#abef9fc5-17b8-4a38-b364-4bbe41b94d31">test_n_workers</a></li>
                    
                    <li><a href="#f9ff6c84-8835-434a-8d14-e6f98bab958b">test_threads_per_worker_and_memory_limit</a></li>
                    
                    <li><a href="#b01cccf0-f199-4096-8c71-28b5412bee86">test_no_memory_limits_cluster</a></li>
                    
                    <li><a href="#6091f805-dd2b-4649-a927-e19734e24e3e">test_no_memory_limits_cudaworker</a></li>
                    
                    <li><a href="#dd173152-7bac-4ef4-8544-153751b82376">test_all_to_all</a></li>
                    
                    <li><a href="#ef754421-3e4c-453f-9fbc-20cda4464ecd">test_rmm_pool</a></li>
                    
                    <li><a href="#d9d71bdc-906d-4e5d-b05c-6071f7a63009">test_rmm_maximum_poolsize_without_poolsize_error</a></li>
                    
                    <li><a href="#5dd5e540-1aab-4ff4-948e-52ed8321cc8b">test_rmm_managed</a></li>
                    
                    <li><a href="#7e24662d-71eb-486e-a0fa-7c02fcc0ff6d">test_rmm_async</a></li>
                    
                    <li><a href="#4dd4b3c5-aa24-4f2e-b221-7e47036b9335">test_rmm_logging</a></li>
                    
                    <li><a href="#31450e30-ca4c-4bbf-8dab-b2d5d963245b">test_pre_import</a></li>
                    
                    <li><a href="#7699f658-78a0-4a2d-9372-362e6e9b1a66">test_pre_import_not_found</a></li>
                    
                    <li><a href="#e6c11353-71b8-4c33-a96e-9987899676d4">test_cluster_worker</a></li>
                    
                    <li><a href="#923a9f7a-f12b-4819-ba5a-5154d2623595">test_available_mig_workers</a></li>
                    
                    <li><a href="#cf3a02a4-25d8-4ca7-9d0b-7086e63746f6">test_gpu_uuid</a></li>
                    
                    <li><a href="#ea07f764-eded-4486-96bb-aabfba620a2b">test_rmm_track_allocations</a></li>
                    
                    <li><a href="#aa01c178-f8f2-450d-985c-502175078228">test_get_cluster_configuration</a></li>
                    
                    <li><a href="#00dc3616-203e-4e32-998c-04ebcf895a4c">test_worker_fraction_limits</a></li>
                    
                    <li><a href="#2bad76ca-ee2a-4b68-b334-89d7c067e9d3">test_print_cluster_config</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_proxify_host_file
                <ul>
                    
                    <li><a href="#359ba1cc-6d95-43b9-bc59-4e8e76b61ac7">test_one_dev_item_limit</a></li>
                    
                    <li><a href="#d7e1e9f2-60c2-40a3-969b-95eb25649272">test_one_item_host_limit</a></li>
                    
                    <li><a href="#c89ddd2f-d03a-4aeb-b850-b07c3c390d3b">test_spill_on_demand</a></li>
                    
                    <li><a href="#70f86b70-5f96-445a-8374-cd1c9725579f">test_local_cuda_cluster[True]</a></li>
                    
                    <li><a href="#b7a21fb7-91d1-479c-b9fa-6bf13eca9a17">test_local_cuda_cluster[False]</a></li>
                    
                    <li><a href="#259157d4-3125-4fdc-a0e0-6b5a740c9a0c">test_dataframes_share_dev_mem</a></li>
                    
                    <li><a href="#c3a4c1c0-0dd7-454f-b21b-1c7c4b2d74eb">test_cudf_get_device_memory_objects</a></li>
                    
                    <li><a href="#cc2f75eb-9694-4f3e-aea5-9abeb0859d3e">test_externals</a></li>
                    
                    <li><a href="#7afcbdf3-e5f3-48ae-bfcd-caca6140eade">test_incompatible_types</a></li>
                    
                    <li><a href="#9bdf3fa3-4288-45ec-b4ac-6d59b0f7d956">test_compatibility_mode_dataframe_shuffle[True-1]</a></li>
                    
                    <li><a href="#cc411ed3-79da-4d39-b7ce-64418f877c1a">test_compatibility_mode_dataframe_shuffle[True-2]</a></li>
                    
                    <li><a href="#3dc66fbe-2f62-4cce-9125-f878c4d7f587">test_compatibility_mode_dataframe_shuffle[True-3]</a></li>
                    
                    <li><a href="#93f263ce-59ad-4db5-a2fd-be187ec56b82">test_compatibility_mode_dataframe_shuffle[False-1]</a></li>
                    
                    <li><a href="#b44563d0-d207-4c6c-b6c5-58e131473314">test_compatibility_mode_dataframe_shuffle[False-2]</a></li>
                    
                    <li><a href="#fec28444-95e2-4793-bfcf-9ea8e75c8e5a">test_compatibility_mode_dataframe_shuffle[False-3]</a></li>
                    
                    <li><a href="#0f1a59d6-0382-4fc0-9a22-c6586a9e5538">test_worker_force_spill_to_disk</a></li>
                    
                    <li><a href="#edcb805f-372b-42c3-a172-40b5431aab62">test_on_demand_debug_info</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_proxy
                <ul>
                    
                    <li><a href="#26a08922-8f4c-464c-a66b-391047185e1c">test_proxy_object[None]</a></li>
                    
                    <li><a href="#43c5be88-706e-48b6-b318-13047a4c054f">test_proxy_object[serializers1]</a></li>
                    
                    <li><a href="#168a527c-9f2f-480b-9805-5f67e1e781fc">test_proxy_object[serializers2]</a></li>
                    
                    <li><a href="#9b37d21a-987e-4db2-9c29-6b2a0f75a85c">test_proxy_object_serializer</a></li>
                    
                    <li><a href="#9942d034-4d54-46ac-b6cf-abe83bc5750d">test_double_proxy_object[None-None]</a></li>
                    
                    <li><a href="#820306f3-efe7-480f-b3f9-fab24fba3285">test_double_proxy_object[None-serializers_first1]</a></li>
                    
                    <li><a href="#f51df3e8-4b90-48fa-a4bd-29c1c59702ac">test_double_proxy_object[None-serializers_first2]</a></li>
                    
                    <li><a href="#32b5497f-ec7d-4ce0-aed1-361fc9ee9ef7">test_double_proxy_object[serializers_second1-None]</a></li>
                    
                    <li><a href="#d0b58fe3-79b8-4ea9-b9a8-6edfdba4e5c6">test_double_proxy_object[serializers_second1-serializers_first1]</a></li>
                    
                    <li><a href="#d253e279-b085-4a3f-9d63-c3b4f4b31878">test_double_proxy_object[serializers_second1-serializers_first2]</a></li>
                    
                    <li><a href="#d91e7f7d-89b7-4d5a-a76c-765ea0b9186c">test_double_proxy_object[serializers_second2-None]</a></li>
                    
                    <li><a href="#3fa25f8d-28ab-4fd0-8108-89d53271e2c8">test_double_proxy_object[serializers_second2-serializers_first1]</a></li>
                    
                    <li><a href="#573b7776-754f-4c60-b847-cd8ba5dc7281">test_double_proxy_object[serializers_second2-serializers_first2]</a></li>
                    
                    <li><a href="#72f18af5-c10b-4d59-a08f-bf58cfa9a7d0">test_proxy_object_of_array[numpy-None]</a></li>
                    
                    <li><a href="#52668f53-d963-4b51-ba5c-f336423764cc">test_proxy_object_of_array[numpy-serializers1]</a></li>
                    
                    <li><a href="#7d1c95c6-aba9-4e0b-a8c5-3d2290ee5365">test_proxy_object_of_array[numpy-serializers2]</a></li>
                    
                    <li><a href="#e33f8873-7897-4b7f-bfea-7f38b447f709">test_proxy_object_of_array[cupy-None]</a></li>
                    
                    <li><a href="#1901b797-e3b6-47ae-ac3f-f2e3c6156e28">test_proxy_object_of_array[cupy-serializers1]</a></li>
                    
                    <li><a href="#539cbd62-7b7c-42c0-9b20-1ca906280435">test_proxy_object_of_array[cupy-serializers2]</a></li>
                    
                    <li><a href="#4eb9bf33-b3fa-4c99-a423-f2f38580135d">test_proxy_object_of_cudf[None]</a></li>
                    
                    <li><a href="#4cf6fce0-b55c-411f-85b8-aa6cc86544c0">test_proxy_object_of_cudf[serializers1]</a></li>
                    
                    <li><a href="#e3a6b96e-78a2-4608-8976-c369f48d6b14">test_proxy_object_of_cudf[serializers2]</a></li>
                    
                    <li><a href="#3e1f2791-3d1d-4ac2-86b2-96dba7a58a4e">test_serialize_of_proxied_cudf[dask_serializers0-None]</a></li>
                    
                    <li><a href="#6ed7d27f-92a7-469a-99bf-f2f4d721d4f0">test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1]</a></li>
                    
                    <li><a href="#8a600ad2-8414-460f-ac8e-823ef3bcf2b9">test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2]</a></li>
                    
                    <li><a href="#1e10c61d-9c04-47b2-8db1-4f0a630a81fb">test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3]</a></li>
                    
                    <li><a href="#2bf9a23d-2b22-4181-8bac-12e3746d36ab">test_serialize_of_proxied_cudf[dask_serializers1-None]</a></li>
                    
                    <li><a href="#cb5f74f6-79ed-4044-9eb5-b08f29a9888a">test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1]</a></li>
                    
                    <li><a href="#0a11c8ff-6c4b-4ca5-bbeb-abcd9768ad6d">test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2]</a></li>
                    
                    <li><a href="#dbd76310-f04f-4e2d-aaa9-c4e5775c21f5">test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3]</a></li>
                    
                    <li><a href="#ef490fe0-7065-49b6-b8ba-0dd7c71cfbad">test_fixed_attribute_length[numpy]</a></li>
                    
                    <li><a href="#cb419e7b-98be-4c25-abcb-857bd472ed4b">test_fixed_attribute_length[cupy]</a></li>
                    
                    <li><a href="#7e69f8dd-e2c3-4a2a-8470-1b0404f6cb60">test_fixed_attribute_name</a></li>
                    
                    <li><a href="#6aa8bb30-f65d-464b-acc3-e5aa900fe4d5">test_spilling_local_cuda_cluster[True]</a></li>
                    
                    <li><a href="#34572f50-8f1f-4320-92b1-8c07daf62c05">test_spilling_local_cuda_cluster[False]</a></li>
                    
                    <li><a href="#8c97ee80-5d58-4239-bce0-9e28caea8399">test_serializing_to_disk[obj0]</a></li>
                    
                    <li><a href="#3ba57dcb-1e86-4981-91dc-4c4342a3b3ce">test_serializing_to_disk[obj1]</a></li>
                    
                    <li><a href="#372f4e4f-3e5c-44d8-a45c-63e767aa43e9">test_multiple_deserializations[dask]</a></li>
                    
                    <li><a href="#578748c4-b34d-4cbb-bf3c-dd6554184244">test_multiple_deserializations[pickle]</a></li>
                    
                    <li><a href="#dbbbbea3-4104-4cf1-bdd7-bd2a12ffb37d">test_multiple_deserializations[disk]</a></li>
                    
                    <li><a href="#9ccafd11-0f4f-48f0-bca1-780de0518792">test_serializing_array_to_disk[numpy-None-10]</a></li>
                    
                    <li><a href="#0875226a-02f0-4082-bb8c-7565ce5904d4">test_serializing_array_to_disk[numpy-None-10000]</a></li>
                    
                    <li><a href="#c9ded2d6-1d77-480c-b755-1ae8a2ba361a">test_serializing_array_to_disk[numpy-serializers1-10]</a></li>
                    
                    <li><a href="#616903c6-edbf-48c9-a886-2dea92238b73">test_serializing_array_to_disk[numpy-serializers1-10000]</a></li>
                    
                    <li><a href="#a61fe341-6d29-45e4-976a-7492649e73e7">test_serializing_array_to_disk[numpy-serializers2-10]</a></li>
                    
                    <li><a href="#d15f593d-c501-4f6a-9a26-9e5c420bf4e6">test_serializing_array_to_disk[numpy-serializers2-10000]</a></li>
                    
                    <li><a href="#6e375fef-2f07-4855-afa9-1b94c7f07535">test_serializing_array_to_disk[numpy-serializers3-10]</a></li>
                    
                    <li><a href="#de3be6ce-68a9-4190-8022-14319ae843cd">test_serializing_array_to_disk[numpy-serializers3-10000]</a></li>
                    
                    <li><a href="#9be47fb1-fc3b-466d-84e2-6973532bbda8">test_serializing_array_to_disk[numpy-serializers4-10]</a></li>
                    
                    <li><a href="#af668e9b-5191-405a-af4d-16cec12c0987">test_serializing_array_to_disk[numpy-serializers4-10000]</a></li>
                    
                    <li><a href="#9c3a5e6b-1a6d-4806-aaa0-4ce32c496e02">test_serializing_array_to_disk[cupy-None-10]</a></li>
                    
                    <li><a href="#1489aac8-482e-4a22-9eee-0e02defbd33f">test_serializing_array_to_disk[cupy-None-10000]</a></li>
                    
                    <li><a href="#b5f10265-c05d-478c-a9be-83c8910776a1">test_serializing_array_to_disk[cupy-serializers1-10]</a></li>
                    
                    <li><a href="#7427f0bb-17ac-446f-810b-71d9f1b1fd1a">test_serializing_array_to_disk[cupy-serializers1-10000]</a></li>
                    
                    <li><a href="#5a7f08fe-1fc5-4b6b-9699-f9b1068a1a19">test_serializing_array_to_disk[cupy-serializers2-10]</a></li>
                    
                    <li><a href="#ca913be3-c79f-479e-9ae3-ea59a31e7e61">test_serializing_array_to_disk[cupy-serializers2-10000]</a></li>
                    
                    <li><a href="#5ca23284-6783-4e92-81fa-63465d4ba533">test_serializing_array_to_disk[cupy-serializers3-10]</a></li>
                    
                    <li><a href="#5e75d121-8d3e-4f03-98b1-4f39fd36a26e">test_serializing_array_to_disk[cupy-serializers3-10000]</a></li>
                    
                    <li><a href="#7ae3c834-856a-4461-88da-e1b0a57006ec">test_serializing_array_to_disk[cupy-serializers4-10]</a></li>
                    
                    <li><a href="#9653b47d-e9d9-4586-92c5-5a5b5baf33fe">test_serializing_array_to_disk[cupy-serializers4-10000]</a></li>
                    
                    <li><a href="#cc15560e-2364-4fa7-87b9-cb6aa1133f8f">test_communicating_proxy_objects[tcp-None]</a></li>
                    
                    <li><a href="#a471dc46-16a6-4604-8c47-c96f5903fa27">test_communicating_proxy_objects[tcp-send_serializers1]</a></li>
                    
                    <li><a href="#1011cbbf-7894-4496-8e72-78b34c5703fd">test_communicating_proxy_objects[tcp-send_serializers2]</a></li>
                    
                    <li><a href="#1479fe6c-6653-4da4-8213-f1246feee43e">test_communicating_proxy_objects[ucx-None]</a></li>
                    
                    <li><a href="#4b311b4a-543b-4dfa-8f1e-a33a75da6960">test_communicating_proxy_objects[ucx-send_serializers1]</a></li>
                    
                    <li><a href="#de2c5b7b-7b96-44d3-a814-806a3df4303a">test_communicating_proxy_objects[ucx-send_serializers2]</a></li>
                    
                    <li><a href="#466a3216-5095-485f-895e-81ebf8797b03">test_communicating_disk_objects[True-tcp]</a></li>
                    
                    <li><a href="#e0d26d75-ad7e-4409-aa47-ec8f52554813">test_communicating_disk_objects[True-ucx]</a></li>
                    
                    <li><a href="#7f1e5491-63f3-4952-9756-f457e8ae365d">test_communicating_disk_objects[False-tcp]</a></li>
                    
                    <li><a href="#66b39ea8-1340-48a1-92c5-0953351cc34a">test_communicating_disk_objects[False-ucx]</a></li>
                    
                    <li><a href="#f81a7eb5-f5d7-4976-a5a7-61b8e5ba35b9">test_pickle_proxy_object[None-numpy]</a></li>
                    
                    <li><a href="#2afb1559-e828-4f07-b0ea-aa1e82570375">test_pickle_proxy_object[None-cupy]</a></li>
                    
                    <li><a href="#37728d11-e2ad-4e40-8b16-989a04e7fa19">test_pickle_proxy_object[serializers1-numpy]</a></li>
                    
                    <li><a href="#665e8135-4899-4bc4-8f29-78ee034dbeaa">test_pickle_proxy_object[serializers1-cupy]</a></li>
                    
                    <li><a href="#226aed88-edd9-42b9-94dc-6af66728ab22">test_pickle_proxy_object[serializers2-numpy]</a></li>
                    
                    <li><a href="#1731042e-de03-442e-adb5-d4363b7754f1">test_pickle_proxy_object[serializers2-cupy]</a></li>
                    
                    <li><a href="#dfa67ac6-58bd-4398-aa63-c17fbe787994">test_pickle_proxy_object[serializers3-numpy]</a></li>
                    
                    <li><a href="#f5d56cfe-dc64-4a0b-9ddb-069d0682dc56">test_pickle_proxy_object[serializers3-cupy]</a></li>
                    
                    <li><a href="#89551506-9328-4897-afcf-692ed9e89517">test_pandas</a></li>
                    
                    <li><a href="#5332e0ea-fe6d-429e-a931-b3ae02c98098">test_from_cudf_of_proxy_object</a></li>
                    
                    <li><a href="#0274c384-fda6-4651-8c35-98c2c0c838b5">test_proxy_object_parquet</a></li>
                    
                    <li><a href="#093ab30e-67a8-4c22-8d2c-6f3497283578">test_assignments</a></li>
                    
                    <li><a href="#4e238aca-5c86-4254-b7d3-df673acfb633">test_concatenate3_of_proxied_cupy_arrays</a></li>
                    
                    <li><a href="#80144189-b218-48ed-b79b-1f795e9d6dda">test_tensordot_of_proxied_cupy_arrays</a></li>
                    
                    <li><a href="#982f1a63-46ac-498f-be18-6c7014cf03ef">test_einsum_of_proxied_cupy_arrays</a></li>
                    
                    <li><a href="#1ccf1eb9-5dfe-4969-ac4e-78ba77e59274">test_array_ufucn_proxified_object[less]</a></li>
                    
                    <li><a href="#445e6a07-5969-445a-9cd1-5929a6337e1c">test_array_ufucn_proxified_object[less_equal]</a></li>
                    
                    <li><a href="#85a831c5-dc5d-4dfb-9384-26ff83a7ee56">test_array_ufucn_proxified_object[greater]</a></li>
                    
                    <li><a href="#94d5255a-ecb3-4b30-87a2-90beb40c5644">test_array_ufucn_proxified_object[greater_equal]</a></li>
                    
                    <li><a href="#d2c7baec-7a16-465c-afdb-654b4600fd56">test_array_ufucn_proxified_object[equal]</a></li>
                    
                    <li><a href="#6e159b6d-31f8-4404-ab89-f5714b939372">test_cudf_copy</a></li>
                    
                    <li><a href="#36c9d653-bf0c-4886-94c9-847ded967bc7">test_cudf_fillna</a></li>
                    
                    <li><a href="#d8199e08-27fb-44aa-8627-1aab3a574c42">test_sizeof_cupy</a></li>
                    
                    <li><a href="#713f9698-f1cc-4630-964d-98eee2449828">test_sizeof_cudf</a></li>
                    
                    <li><a href="#0020aa84-eec8-4271-bc4e-b3eea69ef874">test_cupy_broadcast_to</a></li>
                    
                    <li><a href="#d2456ea2-15f0-4d81-8361-627a6715cae6">test_cupy_matmul</a></li>
                    
                    <li><a href="#4d9bcc6a-0d1e-4c65-bb34-1f6e4e1c69e1">test_cupy_imatmul</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_spill
                <ul>
                    
                    <li><a href="#21e0bb9c-07ad-49bd-9edd-8c172c53ce1f">test_cupy_cluster_device_spill[params0]</a></li>
                    
                    <li><a href="#a6fc9b76-50e3-40b8-b5be-60f0cf4540fc">test_cupy_cluster_device_spill[params1]</a></li>
                    
                    <li><a href="#de33a73a-db14-4761-9a2c-99d1a9a1966b">test_cupy_cluster_device_spill[params2]</a></li>
                    
                    <li><a href="#0b3b31a5-d8bd-44f7-9878-0762244c0e6b">test_cupy_cluster_device_spill[params3]</a></li>
                    
                    <li><a href="#d5497d87-4581-4f52-bf24-12365d086d6e">test_cudf_cluster_device_spill[params0]</a></li>
                    
                    <li><a href="#ba0e70b5-6c8e-4dc1-a658-700bfa3f0e81">test_cudf_cluster_device_spill[params1]</a></li>
                    
                    <li><a href="#1fdbab93-a991-4621-9480-9164bdc5c363">test_cudf_cluster_device_spill[params2]</a></li>
                    
                    <li><a href="#43890ef5-b48f-4052-99d2-14467dff2ab7">test_cudf_cluster_device_spill[params3]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_utils
                <ul>
                    
                    <li><a href="#4f53ce06-9137-40a5-aa03-061281144c50">test_get_n_gpus</a></li>
                    
                    <li><a href="#1ea0cf24-6f2f-4902-89ce-f8c42496dd3f">test_unpack_bitmask[params0]</a></li>
                    
                    <li><a href="#b9e73dc7-5f90-432f-97a8-697a5a659569">test_unpack_bitmask[params1]</a></li>
                    
                    <li><a href="#9cf6c138-b4c8-4f0d-a302-9ae5a3b1623e">test_unpack_bitmask[params2]</a></li>
                    
                    <li><a href="#08259870-0a57-4f37-8db7-1301a2d47b70">test_unpack_bitmask[params3]</a></li>
                    
                    <li><a href="#3b25cd12-ff32-46e2-bf2d-1680f35d0cf9">test_unpack_bitmask_single_value</a></li>
                    
                    <li><a href="#af403d2e-9cc3-43b0-ae03-672811c22d3d">test_cpu_affinity</a></li>
                    
                    <li><a href="#d19fefd0-857b-4248-84c2-754b96da0581">test_cpu_affinity_and_cuda_visible_devices</a></li>
                    
                    <li><a href="#c2bfdda2-a87d-4362-9053-6c27a8526cf3">test_get_device_total_memory</a></li>
                    
                    <li><a href="#070ba51a-0372-44af-b3c2-7f5d5513a419">test_get_preload_options_default</a></li>
                    
                    <li><a href="#53d36836-7eb8-4ffc-8b59-eee4fa47a205">test_get_preload_options[True-True-True]</a></li>
                    
                    <li><a href="#3a254ef2-7994-431a-a63e-05fdc79887a0">test_get_preload_options[True-True-False]</a></li>
                    
                    <li><a href="#421fef85-21b6-412b-a8bb-3510a801212a">test_get_preload_options[True-False-True]</a></li>
                    
                    <li><a href="#2da811dc-c452-4101-b748-9c8fe78a11b4">test_get_preload_options[True-False-False]</a></li>
                    
                    <li><a href="#f3f9a8e4-bd17-482c-9607-0a068c0f008d">test_get_preload_options[False-True-True]</a></li>
                    
                    <li><a href="#09be2ae8-1473-46ac-b6ca-557d4b283442">test_get_preload_options[False-True-False]</a></li>
                    
                    <li><a href="#db612169-707e-4fe3-828d-b0de3b2bffea">test_get_preload_options[False-False-True]</a></li>
                    
                    <li><a href="#7dfd05db-cb3b-438b-84cf-1120a33a0cf7">test_get_preload_options[False-False-False]</a></li>
                    
                    <li><a href="#98e116f6-be7e-486c-a6b0-983e3a99b967">test_get_ucx_config[True-True-True]</a></li>
                    
                    <li><a href="#efb6f5fa-ad76-4c4b-b5f1-404726b1e79d">test_get_ucx_config[True-True-False]</a></li>
                    
                    <li><a href="#fb1a08df-b3f8-49fa-9ef3-96a7ccf734bf">test_get_ucx_config[True-True-None]</a></li>
                    
                    <li><a href="#46be3456-d3ca-4a54-b90a-cb427d65ced6">test_get_ucx_config[True-False-True]</a></li>
                    
                    <li><a href="#ec830547-1e16-4563-80d4-44dda66bfb99">test_get_ucx_config[True-False-False]</a></li>
                    
                    <li><a href="#3f3ed8e9-15d9-4df0-b938-46c0f0554aa7">test_get_ucx_config[True-False-None]</a></li>
                    
                    <li><a href="#93d3033f-ca49-4c32-9636-c03c9bf6a925">test_get_ucx_config[True-None-True]</a></li>
                    
                    <li><a href="#378d79ea-ec25-441e-a959-2470cf4bcb55">test_get_ucx_config[True-None-False]</a></li>
                    
                    <li><a href="#89c2db5f-8981-42f3-a820-d09748d7caab">test_get_ucx_config[True-None-None]</a></li>
                    
                    <li><a href="#0f6153f8-40cf-4072-86f8-775385d31305">test_get_ucx_config[False-True-True]</a></li>
                    
                    <li><a href="#60b4d960-8cc2-4ac1-ae13-fc69132b15d9">test_get_ucx_config[False-True-False]</a></li>
                    
                    <li><a href="#98b8c2b3-022b-4141-b6b2-78eb3b28fdc6">test_get_ucx_config[False-True-None]</a></li>
                    
                    <li><a href="#0ce65c25-5087-437a-b9e4-6fedcc6f5d31">test_get_ucx_config[False-False-True]</a></li>
                    
                    <li><a href="#d617b776-1c0d-4707-85e8-3bbd81950761">test_get_ucx_config[False-False-False]</a></li>
                    
                    <li><a href="#b5b85a06-95f5-46ae-9869-b880fb058e2b">test_get_ucx_config[False-False-None]</a></li>
                    
                    <li><a href="#bfc62430-ab7b-4cb1-a5b0-de459ea392ca">test_get_ucx_config[False-None-True]</a></li>
                    
                    <li><a href="#17f379d3-9e6f-4dd9-a02f-cc9b29bd218c">test_get_ucx_config[False-None-False]</a></li>
                    
                    <li><a href="#ad61fe35-9ac6-46b1-96ae-db4edc450eb5">test_get_ucx_config[False-None-None]</a></li>
                    
                    <li><a href="#203dd458-fac8-42f2-9849-aa3bf66e1267">test_get_ucx_config[None-True-True]</a></li>
                    
                    <li><a href="#ace0385f-dfdc-4890-9674-879361764d1a">test_get_ucx_config[None-True-False]</a></li>
                    
                    <li><a href="#f3bd32ed-3ffb-48d8-8a6f-2214dd93d000">test_get_ucx_config[None-True-None]</a></li>
                    
                    <li><a href="#9192dea4-cc60-48b2-a3a2-3fcca09762bd">test_get_ucx_config[None-False-True]</a></li>
                    
                    <li><a href="#8458613c-186a-4a25-a963-8c2b53356693">test_get_ucx_config[None-False-False]</a></li>
                    
                    <li><a href="#56e7a3ef-c06c-4dd6-88bf-7a9719e84533">test_get_ucx_config[None-False-None]</a></li>
                    
                    <li><a href="#d7d2ceb8-157e-4ec0-bfcb-4a5f17b27431">test_get_ucx_config[None-None-True]</a></li>
                    
                    <li><a href="#3c45dfca-8bda-44ed-981f-5239dec88871">test_get_ucx_config[None-None-False]</a></li>
                    
                    <li><a href="#9d07c4d9-ad02-4bb1-8038-25f1a4ef739e">test_get_ucx_config[None-None-None]</a></li>
                    
                    <li><a href="#52f60d72-6974-4f65-825f-85945b36edac">test_parse_visible_devices</a></li>
                    
                    <li><a href="#f8681462-fd88-4b1e-bed4-6557091e812e">test_parse_device_memory_limit</a></li>
                    
                    <li><a href="#9c1f51aa-edb0-454d-988e-55ab3b9f3f9c">test_parse_visible_mig_devices</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_worker_spec
                <ul>
                    
                    <li><a href="#246865bc-8833-43a5-967a-6599df423444">test_worker_spec[False-False-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#c0b508f2-2044-4acc-bd5e-3c390e4f2a78">test_worker_spec[False-False-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#95df0cfe-fb22-489a-83ad-abebd1ba0433">test_worker_spec[False-False-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a3b1781e-4c60-4871-a2a0-0b6d91425cc1">test_worker_spec[False-False-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d198f9f5-acf6-4cc3-b6ab-914b145fffbf">test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6da4799b-a0c3-4d9a-a726-8c153ce99a70">test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2760688f-a6f0-427f-86da-1ea38bafb268">test_worker_spec[False-False-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#b4307591-2c50-4d30-8c51-cc9f9ae42eb2">test_worker_spec[False-False-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#529cc9bd-4715-4153-9c21-1c09d537ba9f">test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e861a24f-260d-48da-b653-1fd1e5005cad">test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b4170212-e7fd-44db-89b0-690af0784d31">test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7a3068c5-dd68-48b3-b0dd-27ca53b95fe4">test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#03c4e88d-ccea-4b1d-a3c3-707a9c81698d">test_worker_spec[False-False-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#3742853b-0e17-4db9-8262-3c73247df8ec">test_worker_spec[False-False-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#1c854d7f-a423-41d0-b068-571155ed426f">test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3a331247-6d39-464b-a0ad-86b57f886c80">test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#75b97eb2-9716-4227-b135-169fdb722005">test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8400f42b-bd33-4d7a-9275-a6afa4baee92">test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3da5366d-e09b-4bbd-aaf4-3ef3b03f3bf1">test_worker_spec[False-False-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#7d1c577c-66d2-4056-8265-9a0ab589471c">test_worker_spec[False-False-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#d480c556-683e-4479-97a4-9ee3096d8daf">test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#33cdc9c3-10ee-4430-869a-aa3ed11c26f4">test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a1e98fff-ef3f-47bc-87d2-34ad286b3341">test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#be25645c-82bc-445a-989c-35212081bd8f">test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#62ac7bab-8559-4dfb-a3a0-a7ec60e0deb1">test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#1a334845-6997-4d25-93b0-177f48d093cb">test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#313c10b2-19a9-4bf2-a3a3-785ddf51d6fb">test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#789e9de1-cd68-48a6-88b6-3975591100fe">test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0dde6d4f-3fc2-462c-a102-30e52445cd23">test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3dc08086-1bb6-46f6-ad4e-825c4d8dd8ff">test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7f4a4be2-69a3-4d37-9cf7-8c90fb0ed234">test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#ae956c3c-7d41-47b5-a1b9-fd7d34f29da8">test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#a51387f5-6505-45a2-a9fb-72aeb5e6fc36">test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#61d1cc1b-f70c-40e4-b0e9-75dcbc969556">test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4a255440-899d-47ef-a289-1c12402a3910">test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#87d2c1af-7fa4-4a78-878c-22cdb614903b">test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#6f4ecb13-e81f-445f-9bbe-32b4ff96e4c0">test_worker_spec[False-False-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#1127a6ee-2d5a-4c09-9703-a00ef9c43a3c">test_worker_spec[False-False-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#a565665f-d3f4-4025-a312-674437d25c97">test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#931bdb09-2edf-4cfb-9fe4-a478868cc347">test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7ba71285-4618-49ea-b550-2320febe50f8">test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#19c4151d-4cd9-4590-bd72-c3f335eb3422">test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ae3e85ad-8290-4e78-b082-a9fef94b7f3b">test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#5ce6e2f4-4963-4202-bd7c-ae1ad0246a89">test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#38540e45-0a3c-4641-a503-3c801c35540e">test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#12acb3b5-b78a-455c-90e6-a0fb95d98d10">test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b087070c-d3e8-4c62-ae22-2558fa638d09">test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#44699824-4b9c-4733-ad76-8be45ed3034c">test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#88422ff7-d630-4fa9-a4ee-f38fdcfdda3d">test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#687af4f2-090e-4a8c-b6ed-d70b9ea449aa">test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#e4640eab-8df4-46a6-8d11-a657eab17b91">test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9cc98ec6-01cd-4206-bb0e-f8b7170031a0">test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#58c758b8-4b2c-40f7-9242-60c3e4a9a78a">test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#12dc3e1d-2789-4bfe-b804-6285eac8bb41">test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a019ee34-3e94-4318-9c0a-44c317cb58e7">test_worker_spec[False-False-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#91ccfb2b-ac42-4394-a1c8-2e7bd8b6a0ad">test_worker_spec[False-False-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#1a957cf2-a8f1-4592-b826-cfcf476da478">test_worker_spec[False-False-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#bf6d11e0-c80e-4ff1-9f9a-90a2abf05dbe">test_worker_spec[False-False-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#be6eb6ba-d7cd-4c7b-8c8e-27ee5e26cbed">test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2a8dada8-8238-4b66-bdbb-c15f09c879b4">test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#51edc07d-8379-4f89-a4cf-a3ceb7f04213">test_worker_spec[False-False-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#8bd077b6-9407-46af-8df7-bd0e381c5694">test_worker_spec[False-False-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#086f0031-800a-454e-a506-18d60e16ced3">test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#cce68718-46f4-466a-b521-fee3a15991be">test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#40d8c038-e255-425d-a88d-56c7a22e944f">test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#cd70d71a-eff6-4805-914a-8a08e87284e1">test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4e266610-eae8-4914-a543-3a72d93da130">test_worker_spec[False-False-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#319717df-eca2-410f-bd96-89b8e6291667">test_worker_spec[False-False-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#b4e227c4-5288-4c32-b9d2-7d244e042f18">test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#966902fe-d081-4cdd-a2ac-de350cf0efa5">test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f0cae5c1-c9d1-4dc1-83a4-9e45e7fb3c01">test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e984a969-dde7-47ec-ae71-72608d45a507">test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#cb1b1e83-e551-468a-8944-60a1f4891606">test_worker_spec[False-False-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#788ad7be-451e-4cce-8555-c2d79ac5446b">test_worker_spec[False-False-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#fee0362b-f8a4-4f75-bbc4-9e685d8f8de3">test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c0cfe20d-7921-4b80-8368-e584e8fdddb4">test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5b9ae380-15a8-40bf-acdc-87c9d7773321">test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6df1613b-87ee-4c06-b897-1c24ae4ceb69">test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#64d8fb28-d123-407d-871a-929fe6fe772e">test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#76e0b64f-ec77-45d4-859e-e45ebd19eeab">test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#c36f195a-fbef-424f-8b59-854ef9f515e8">test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d6efd7a2-bfc7-43a9-bc7c-2ce440f1d279">test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#bc8e94a4-c9b3-4382-94b9-65226e200afd">test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6d5abc54-17ae-40a2-bbfa-3459e170e291">test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5c864f32-aa81-4b98-a851-e1adedb62832">test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#59324fa0-8b90-4541-886c-f1aaf9fcce97">test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#09841745-501e-459d-9226-5d6953df4675">test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9ad870aa-129a-4f75-8d8f-df86c13d775e">test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5be1eb04-23ab-4727-94cc-2c4911b411fc">test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b77283a7-b011-4f13-b49c-edca12efa240">test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#1b84ee9d-a5f2-469b-b5f9-d78780090dff">test_worker_spec[False-False-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#e8b7b858-a6cb-4dec-aa15-e229a24bb641">test_worker_spec[False-False-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#0ce97d09-bacb-4118-b27c-b520f2a25488">test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9e259f41-a07f-42e3-b51e-857586127747">test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f5e082b0-464d-4d43-92bd-060bcaee1c77">test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#818b57ca-ab9e-457c-b6e6-82228128902b">test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#048ce25f-9864-40aa-9632-1b0667f62da5">test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#c4bfa6f7-f5b5-4e18-b2d7-dc684ffe269f">test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#a28bcbf9-2678-4e78-9148-c7cb72901d7d">test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5327ceb3-ace8-4ab6-bfd8-30d6b1f95f30">test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#38ae8fa5-b1bd-4386-a846-8517acbf6c3c">test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0e998a3a-6f37-4029-874b-0d1c3af1e09a">test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#23a586c8-9c6d-4086-a34d-bdfd3f018dc9">test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#5c8cca3b-083a-4a23-9cc5-d3872a6da705">test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#8b5479d2-7e73-4753-9733-bd83f2f51793">test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b1a4a1b6-5386-47b7-b087-19f3ac96ae31">test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#19f0a61e-c59d-4743-b831-e45138dfc978">test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#efda85e2-d135-46c4-8edd-e8c23d1e655c">test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7742c74a-47ff-4ce2-83f6-d7f95c9d8489">test_worker_spec[False-False-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#97dc7765-cf9c-47ea-99d6-0eb005bc8fc7">test_worker_spec[False-False-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#dda59ad8-904f-4a9b-bca0-e0b019b1e6c7">test_worker_spec[False-False-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a19724eb-506e-4ede-a123-678db7c70136">test_worker_spec[False-False-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f79adb8d-33f0-45ef-8393-b8cbac451c6f">test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d7e1c8b5-06a0-41d0-927c-b88842ce0bd6">test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e31fc688-a47a-4d36-8dab-aa4d31246291">test_worker_spec[False-False-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#aef3b1f5-b827-4453-ac76-0882a7450584">test_worker_spec[False-False-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#dfb16417-4ecd-44a0-9098-573ca53a7225">test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d604d7d8-047a-4226-95a8-91822ad063da">test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#55c60386-bc02-42f3-a641-b07ed508b56d">test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e99fec9a-d982-4a05-b600-9967fc22ec13">test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#59bddc06-e499-4065-83d1-b7fd0b05c771">test_worker_spec[False-False-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#87fd0ced-c5d0-4da7-821c-99235443e50a">test_worker_spec[False-False-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#3582f37b-848f-48d2-ac0a-1b83c97df9c6">test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#17819869-4ac2-4b04-9202-3f654d939e3e">test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#50a4d8a7-665f-414c-844e-e910ae8953e6">test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#82b99568-2d15-49b5-a2ef-20d20afe7f2a">test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#711e4d86-5562-40bd-bf69-30a51ac442a6">test_worker_spec[False-False-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#7e3a6f59-1965-4c08-a1ae-bca22da1c7c8">test_worker_spec[False-False-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#77961e3b-b344-49c3-be0e-94e72198651e">test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#f247726e-a1eb-41c0-ae42-7bf1ff81e23b">test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9a881ec2-5729-40f1-b698-95f74e304d1b">test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#717ed97b-8cd2-4491-95ea-e227af509d63">test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f0fb752d-58b6-4c94-a475-4ef730c68fba">test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#25925958-5f79-4770-a586-957b71bbcccd">test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#2e918d99-5924-4cd6-8121-85588935a94c">test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4b7710c2-230e-402a-91de-a954989e5087">test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#540d536c-a8a2-4d70-af1b-5450ff9a5305">test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#5202eee9-37c6-4f3f-9a45-9fd901cdc378">test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a25b3e5b-c704-4773-9fe5-c175d0580987">test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#82add809-dc04-4dff-8734-6285acc1dc4d">test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#027feae0-1f4a-4f14-8c4e-2976636d0e43">test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#1d129dda-cb02-4d44-b6ab-e4ee0e27d569">test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#326b2f7c-9d6a-4b09-8cd0-d42214975d4f">test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b3d1fe61-94c8-4d34-b842-219c5eccc23e">test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a1dca115-41b4-47a2-bb5c-78a0ecc17398">test_worker_spec[False-False-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#a15c3934-9ac5-4acb-b8f4-b2c79f56f371">test_worker_spec[False-False-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#49879746-1d69-4894-b936-2a75d0ba940f">test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c8dc42bb-4cdb-4d62-adce-deaa7e92cb67">test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e55bdc82-d0f9-48cf-9349-2f9f05d10ef1">test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#527381a4-6760-4a76-a70f-8d9ab15125c8">test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c294ce23-f64f-4105-bee7-5a158ad62556">test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#0f902e4c-5eeb-4693-876a-d9302f1fc966">test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#3084da22-22b4-4da8-8480-bb6db93b7f9c">test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#167a3512-cfab-40b1-b5bb-3a0033d13f8f">test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d29b8507-c9cd-407e-95c8-799209c3d419">test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2a5d78a1-a027-46bd-9648-e0f66e514d6a">test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#64973d23-da1b-414f-838d-a8a97109de37">test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#7217596d-0491-4627-8185-eb07f6adf3ce">test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#08f20f7a-be60-4590-a50f-95d383169332">test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e1ef1dd4-aea6-451c-94e7-38b08511a18d">test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#27a69cfa-fdf1-4473-aad2-73cfc7dbef9d">test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ae35e041-b3e0-432f-b91d-cfc2feb09430">test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b8dc9a52-9e76-46e1-ba89-1b3a26f05923">test_worker_spec[False-False-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#6b9844b2-ba9c-4e2c-9b7e-784d2f62cc25">test_worker_spec[False-False-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#c090ef14-a5c0-42a9-9a9d-541128c07f69">test_worker_spec[False-False-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#06ad899e-0c97-45f3-8233-aa12514d059b">test_worker_spec[False-False-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#02850020-5b1c-41d1-bd94-96d115dd180a">test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#cdc61405-58a5-40d9-b128-44881ae52cdf">test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b2023cdc-a12b-4849-b73e-adccca89cdc9">test_worker_spec[False-False-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#3d0ce1cf-3bd1-42bf-8d69-08ec2a4b6ece">test_worker_spec[False-False-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#885f64d6-1b08-4ca6-9bda-06b2c7170d9a">test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#1beb1737-a620-4823-acea-c9901d2cac4c">test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2fd4bf21-b400-4a8c-96e8-cae38db5bc20">test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8de2dac4-37bb-48b3-8bcb-fcd9e7378b90">test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#268cdef5-e7a9-4bc4-bd8c-1ae2440ab1ad">test_worker_spec[False-False-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#2859e837-962e-48f5-9604-5ceda004aeb6">test_worker_spec[False-False-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#2720c8d0-b50a-4853-afea-1cfebf1e8103">test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#2b7f4be4-0fec-4f3e-a1b5-183272083e7b">test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#52ad2b3a-e9dc-4fed-b80b-88cb575d55bf">test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a0aba644-9fcc-488c-a13e-e2b4c6f6cf95">test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#dd37902b-da1e-4f65-acb4-a42869f82f0a">test_worker_spec[False-False-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#39725069-e93d-491b-95c8-98eb253937cc">test_worker_spec[False-False-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#5b474927-01cd-4961-8612-4174aa675b9a">test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#16216157-770f-4bf3-a6e2-fbd459a714aa">test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#376a88c8-d60d-4238-9095-fc159eb8ff00">test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#cf6f3ee5-97a4-40b5-b3d3-ff562bbfecd8">test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#215f7c45-9bb8-4455-aefc-b0d92f534c22">test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#8afd9b3f-c29a-47a1-ba6c-689a69422a74">test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#9b0cdd7d-6107-4182-a7b3-28aded74ee3c">test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d29dea37-9ef5-4c47-b781-3fe680b047b0">test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8f11e1b3-190c-4fe3-bc38-f8a8ccf3c157">test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e573991f-9915-4979-8ab3-56e0389e33c5">test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#83705362-9a18-477f-8b71-7d63a0eaedd0">test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#e35b5bc3-caa4-47c6-aa76-2af753010deb">test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#fb8e0fd0-cd4b-4940-ab4a-feace3e31363">test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b31e5385-c4bc-426b-b49c-680a7bca82dc">test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#92248e90-4e19-44f1-b951-52661d74f72b">test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6a0099d4-51d8-45f5-b554-54b4e7d13f1f">test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b06e4811-b220-42bf-a2b8-e2c545006958">test_worker_spec[False-False-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#01246bb7-b193-4ab8-be39-8591fbf43d63">test_worker_spec[False-False-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#af2d3c09-7d06-4a05-b408-b8f83185a8e9">test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#25773c83-51d8-4e05-8a05-76c667ff08ac">test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0e5e5b9c-30a6-4de5-9aff-70e408851af4">test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7a547d90-9a15-46ef-b615-d00b381e666a">test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#efc7164d-a7ba-401f-8346-cfc7537387e2">test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#b86526ee-cf65-4828-b372-10434fe81807">test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#a1108589-07ec-4dfa-a948-a6b3a1c96dff">test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b64157c0-8240-4628-83c2-f999bfed93f4">test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8811253a-b2a9-4c8a-ae94-09ea52b5e667">test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2e274fe0-044b-4b92-80b7-10115c27cdd9">test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#041f0180-9aa7-4779-ba71-eb5cadca473f">test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#e6715a7a-9a25-42c4-8eb6-2a28ef0db7af">test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ba05813c-805b-42b4-bf06-e77f8a30257a">test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ceb4966d-a8f2-4dcc-9015-2f244059fb77">test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b2b392d5-0f5e-4365-809e-c7b1f58645bf">test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e3a9d5f8-e15e-4c38-a1dd-797c4817a69f">test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#752abe59-1f8e-4b54-90cf-5bf94f7dfc8d">test_worker_spec[False-True-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#4d3e6d36-c5cf-4aae-af1f-da0cac408b19">test_worker_spec[False-True-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#9f329ee1-8b40-4ce6-85b0-d9fd06c85769">test_worker_spec[False-True-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7e248ef6-b823-4c09-a973-2994ca2b4aec">test_worker_spec[False-True-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f1a725cb-1309-4eaa-96f5-f0acfbe5945c">test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2d919442-9f25-44be-b7f6-58dd9dfe3587">test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#267de6d9-04b2-40c2-8024-267b40a5585d">test_worker_spec[False-True-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#e863092c-eb6b-4983-95fa-1f1a3cde7acd">test_worker_spec[False-True-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#fcf1c2f6-49ef-4dc8-9f11-72bb511d4b5a">test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#600db932-468d-4412-859c-61023d37287d">test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d90cc7e0-2a45-4078-a502-01933b2cb7ff">test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c36123f4-8f52-43fd-afda-0a84698e7efa">test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#39df3750-367e-493e-9051-017485f97e78">test_worker_spec[False-True-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#59788172-a954-4713-ae98-8b451cbb4d20">test_worker_spec[False-True-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#c7624def-92bd-4772-bb22-e8aa1c11fe70">test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d2cff7d6-33eb-4c43-841d-fae2385fc75a">test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#349bf1a9-9b80-49c5-bb76-954f484d0bf6">test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#284f3065-205c-4ff3-bf87-0b8f10c2bf22">test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7bb33d54-900b-4a85-b185-398d977706e7">test_worker_spec[False-True-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#adef5ff4-d6e1-4051-b47d-7d60fb67d410">test_worker_spec[False-True-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#21435e1e-4a73-47f6-a2b3-e806eaf4a0fa">test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#74295209-6225-4e91-ba5b-a4dc6a5ce0bc">test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3b308137-6cdc-4d68-8369-65084ff62e04">test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#cec07357-b479-4412-b3e1-5205c2d23d95">test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7f2b0b8c-23e1-4324-b04a-9603e567231d">test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#6a0b5a69-bc73-4368-a0ab-1b8dec992663">test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#2feef9c4-ce8b-442d-9c60-17ecd9f3d002">test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5a980949-fa2f-44d1-8c81-f111de18db7e">test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#15860905-c6a6-448e-98e3-995e91e9b6fa">test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#45c40ea1-2431-472f-ba54-5943f4ba63ef">test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a009d98e-8c31-4f0a-8f03-cdb9dcb3c37e">test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#e6d80679-6b1a-4138-83fc-630d3f147f8a">test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#d50037f0-ae03-4830-b288-fc4042cde042">test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e49afe24-0919-4b0e-8ced-c6fec755bb38">test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6f09eca2-a7f0-4225-aa62-d779c781c691">test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c91032fc-5bb5-49cb-b13c-fc8c6165330a">test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#825c4684-ded3-48a8-9e4e-a6a1b03f0347">test_worker_spec[False-True-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#39249569-12a6-44ba-beb5-c92dea1ce641">test_worker_spec[False-True-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#5b1942f0-2f15-45be-80a8-f855e6dd1f7a">test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8ac90939-822a-46ab-a2b5-e2f8de8228b4">test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9c34f61c-f304-4d32-9652-1fd130d900f8">test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e9bb8470-778a-4870-a25b-6e3234ada689">test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#61a086d4-2fd2-4ccc-b69c-9deb6e9da267">test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#7ca0565c-b7b9-44c6-b911-e8ac572ffcba">test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#75ff57f8-a53b-40e9-b0f9-46ced12d8d7e">test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3a9812c6-ef82-4db5-b7f7-50062ca26950">test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a2bd0101-f334-44f6-92ff-f6bad8b4fc53">test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ea23508d-db79-462f-a028-41546dfd07d2">test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4fc4fb92-e3cb-4b04-8d74-398b430dced8">test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#cce9cd94-1846-4974-8ad0-bcde7916cefc">test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#d5fd7c71-0433-4d41-a52b-b0320306732c">test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e48914a7-8517-4a10-9083-237f138659cb">test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#155db986-636d-49ab-bcd0-c034e49d8867">test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3a53f291-cec6-49fb-8474-57341fc6f8f7">test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e37a078f-d0da-4611-bc17-208de82ac45c">test_worker_spec[False-True-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#3353c822-3204-470e-8711-217aff978d33">test_worker_spec[False-True-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#7e351566-ade9-4d9d-8af9-c567332a7983">test_worker_spec[False-True-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#bc320564-8982-4aef-86a9-0c1f2b76bd5a">test_worker_spec[False-True-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#605556e8-3414-45d8-8b96-1d4d19c12c7c">test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#13ba4cf6-0e56-4f6c-8ca8-b85446fca9d1">test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#594b6c9c-752b-46ad-bd36-a9fca4995c9b">test_worker_spec[False-True-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#d3e11522-e56b-4f72-a036-f5da846c909c">test_worker_spec[False-True-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#2b9016de-6839-40eb-8e28-42839223f96c">test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9896001c-05d9-4ebf-8528-77b4e7224d63">test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#51b679bb-f189-4ae8-91ea-e41dc6605e8a">test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0381b1e8-2028-4fb8-9cbe-603a7676f563">test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4225e9cb-0fa2-41e9-80ad-750bb0dd6a59">test_worker_spec[False-True-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#1591258b-b706-4971-adfd-d84968f4bdad">test_worker_spec[False-True-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#8ab72eca-ac1e-48ac-9d62-4568ed273bf4">test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8deec770-4793-4f3b-a628-004ae1346332">test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4e6b18cb-81e1-4c24-96bd-2d3d55d7cd41">test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d475f664-7bfe-46d0-a80a-98f1e2ef8414">test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#bedcd708-14c8-41eb-84fe-ae6e6cc828b7">test_worker_spec[False-True-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f5247ff0-c82c-4484-90fa-314977f8ab51">test_worker_spec[False-True-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#1597c58a-76f4-44c6-8ec5-28e783a4ffc6">test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#25defe51-a168-4eee-b12e-3b4479ce148d">test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9d45f40c-6b14-48f3-b911-a1d32910c22d">test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4ed4bb67-3731-4cc3-8e58-00f761de35cf">test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b0adc551-9355-4d20-97b5-99a35f33637c">test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#eb8e154b-b161-4ae8-b9e0-d7dd60b28b7d">test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#4f6b2b7c-583a-43eb-9920-fb5554fdc263">test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c09b72f8-c0b0-4475-a587-3aaeedcfa0df">test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#62ab47e0-2fb0-4742-944b-09a8fa110f4f">test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#34993dd6-4101-4d35-8f95-15ea81de5ce5">test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f36da503-f6c0-40cc-8637-6a62d77ae466">test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#b1fd7fa3-fb29-4993-88f9-856b6baca602">test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#6961af6e-4afa-4043-becb-394030beeaca">test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#709fd641-24b3-43eb-b2da-4642db96afe5">test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a91231aa-b1b7-469d-9e86-709cf172015b">test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c680f4c1-1fc9-4f2f-8ad9-698cffc5966e">test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4ac056c2-f7a8-467c-b123-4d469dd601f4">test_worker_spec[False-True-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#3aab46b6-675e-45ef-81cb-e195273a31bb">test_worker_spec[False-True-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#32402661-549a-4792-8fc5-545447f52822">test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#758aa3de-4df3-4691-9303-59de3ad1a7c7">test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#da61fe84-2a33-40b3-8176-2b240268dd6d">test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e837abf3-1b36-419c-9f52-f71cef652b04">test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5e80a84e-5a5c-4709-b168-934298701d2e">test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#024310fb-d86c-4edb-8d8a-9c40202b667c">test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#8aafa973-793e-4fcb-b353-d931d91730fc">test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#592f421f-23c2-4bcc-b557-d4b41d551895">test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0bb82677-13f5-4bbf-80d6-c48bc0310518">test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#95070c2c-4f4d-4e30-8fe7-8414d093e6dd">test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#39d621e6-4d7e-4c85-9b40-670151a1de5f">test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#459777d0-7ee6-42b3-8146-be95841f7a16">test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#1b17d40e-5ac4-4779-90e8-82aac676b16d">test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#dd7e500a-292e-4830-9144-e035a017da9f">test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#25710fc5-9ebd-4261-8fd5-8510076f52d2">test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#79ae0940-ff3c-461a-8f67-8c13fe7b23f9">test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4982694e-077d-4dce-8b7f-92195230402c">test_worker_spec[False-True-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f0867037-e929-4118-8c5d-640ecef472a3">test_worker_spec[False-True-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#afde9b63-60c9-4c76-85c0-41a3c7cf9a16">test_worker_spec[False-True-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c346cb4b-7082-4145-83f8-62fa97d5d4c6">test_worker_spec[False-True-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#fe7b7259-e255-4fba-894f-289cbd938a03">test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4aa43d82-35d3-47b3-b4b7-8e1f59ba8bed">test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b91b241e-33d7-4ef5-a956-c24cf594a953">test_worker_spec[False-True-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#aa341c3e-ce2e-432e-babb-3190795bc7d6">test_worker_spec[False-True-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#37878bf8-102d-42ac-b99d-8c999cf087a1">test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#eb3d7277-bef7-49ae-81e9-ea65c8e0dc5e">test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0380f022-e6a0-4b5e-8fdc-06a745d1f7e9">test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b36c12e3-72c3-4ac3-859b-ce621033bb44">test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ca295782-bc57-41d2-91d1-5e7b78e5576e">test_worker_spec[False-True-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#9e700a75-3184-4309-8f5c-9625cd4861c6">test_worker_spec[False-True-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#05f4a1f2-b389-4b2c-8751-01b809e31ca4">test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d8068f5a-db11-4090-88f4-929f0bbfcdbf">test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#64e62881-218e-4bdd-92ad-2317342854c4">test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f3047046-cc0d-4ee8-a1e3-3530167bbd61">test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#45adf65f-b633-4fad-991a-8e05447fc8d5">test_worker_spec[False-True-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#5bdb6558-395b-4a3b-ac17-541a6ad977b7">test_worker_spec[False-True-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#f661e846-d8ed-4fd7-b163-a327bea1ad76">test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ccff87d1-6d79-422f-bd8e-81f0586952da">test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8ec9b2d7-21e8-4735-94b1-d62ad4d7ad1a">test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#897a7830-7a85-400a-b285-bf503dba4373">test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#45070057-e837-48f4-87d0-1e4d0ea47edc">test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#5daee212-ab66-4d2c-b46c-98ce65e5159d">test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#b1719e40-33fa-406c-a875-2ba19da40c0c">test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4d7237c9-0e6c-4ef9-bd99-27009eaadba3">test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#66f55a06-67df-4010-8aa6-72fbbd87f43d">test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7c4a6f4c-7dee-40fa-b24a-a7e2b674a5ea">test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#fc1632dd-6cda-481c-8528-91316bf45f0c">test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#f61c6abb-559a-4c79-84d6-0e7a0b424b11">test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#8aaf03e5-f075-46e3-9df3-26a21a94d4de">test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9208986d-b5f8-4cb0-9f2d-54cd18fa0f37">test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1a146b9e-4a3b-4e79-b063-2e36b04b72a1">test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c1b21655-ab23-472a-9775-cf87ea094543">test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d10be734-7f03-4e68-94dc-2583a5426ad9">test_worker_spec[False-True-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f0ed4cb9-5aa7-421f-811b-687fd135988c">test_worker_spec[False-True-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#18b0ee13-2d47-49b4-a699-07a63589f351">test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b04ad5fd-d742-44fa-894d-607b6605b53a">test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3684740c-3b29-4470-8424-1814fb05f24a">test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#bdeed322-dc03-40f7-a2f2-8876fb26faa7">test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8b0db854-d681-4607-ba9c-e459da5a4e9e">test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#5cdd573e-eac0-4b72-b718-affd6556e7fd">test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#91498e39-42c3-4f48-b392-7877f4632ccc">test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#cdd301db-f3ee-45df-998d-41a40912819b">test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7bf67d09-8ccc-4b14-a118-5b8a676dbe17">test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#18d4a64c-1cce-4785-9b4f-dd3a163d4a89">test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f984dec8-10f8-43da-9c9c-d86ba3e04a2d">test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#2f22422c-2429-409c-a68f-cd38b65bbbe8">test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#76293394-148a-4015-aecd-ed10676d5464">test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4edbcd0d-6dc0-49ef-8447-2091b8efa24f">test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d0ac85f2-3dc1-44e6-b57c-edcbc0c1c58a">test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#eefe532c-9a12-404c-928d-672fa87eaee6">test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#74e053fe-60fc-4d34-a762-c1b661211b0a">test_worker_spec[False-True-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#d681d87c-4cd2-45c7-abc4-f219a7b1033d">test_worker_spec[False-True-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#1dc22b9c-ae78-402a-a784-f8367b47aef2">test_worker_spec[False-True-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#af592ccd-1800-45c3-bf43-6191cdc075f5">test_worker_spec[False-True-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9990eea9-fff0-4a16-ac6f-46c1a5361409">test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#5925611c-4ce7-4ebb-96f4-0082775ae4c2">test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#123c2b2c-46f7-470f-a98f-5a99047934f2">test_worker_spec[False-True-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#510f04ab-23d2-4e5b-afb1-66f7884c409a">test_worker_spec[False-True-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#63e037ce-bec5-4d29-a220-de9951323064">test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e31542c1-5045-456a-be8d-d15fb56f588c">test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7661e417-6f69-4954-a156-0c66c314b4fb">test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c02f635e-93f8-4f83-bed7-047733834f70">test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0d5ee1dd-bbce-4fa5-afd0-82de873c667b">test_worker_spec[False-True-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#6cad8385-29a0-441a-8304-56806e34d002">test_worker_spec[False-True-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ec1ba184-633e-4678-8167-6fb084bddf39">test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#f31e0c55-31ac-4bca-b355-3315ce2ae0dd">test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#97b7b0aa-972e-4e85-a70c-bf7443b41d3b">test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0e0c267a-da7a-4899-a620-0d2edad54978">test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b58de820-db73-4fe9-90b2-2a9ad9355354">test_worker_spec[False-True-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#773b4bb7-a2a0-4417-a229-1f5aefd35426">test_worker_spec[False-True-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#3c3a6ace-0f13-4283-8d36-f40f42c799b5">test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#29605b88-aa64-4c4a-bd97-d3efdc094695">test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#bd22a43e-5ad2-46e7-aa49-a1be65b9d7bc">test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#818fa153-5179-48a3-b47f-d0c3d2cf907d">test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f3769603-a02c-455d-915a-1f6b68e048b1">test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#494fc4db-8f7c-4117-b72b-a233ecd15757">test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#48b9bbae-2b2f-4bc2-81ba-88d508ab626b">test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#dbd63b7a-7d45-4093-81d6-136c7326e627">test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1a8fccd6-f6d7-469c-818a-39415537c62b">test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#28a899c4-6f21-4178-aec9-6001d53a21b8">test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7daa4396-ad66-4373-94e7-1408da743d00">test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#0009934e-228e-49b3-8b88-cf6612165ecd">test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#df7718ef-02e5-474c-82bc-99d6d11d9f5e">test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#71993851-58c1-4b70-a4b6-3494c9600d7d">test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#bc1ff556-89b9-4103-82c0-26842750cff6">test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6b7b9cdc-d60c-4dfa-8d46-dea7527f424e">test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#747ede30-907c-490e-a1e7-41683d56b32b">test_worker_spec[False-True-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#ab253596-8fb6-4b5a-bbcf-98d11c4a61fc">test_worker_spec[False-True-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#498295e4-a9c4-4df3-88fa-dd2f087454e1">test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#78bfc54a-502f-4440-8998-8c5c8275ba8b">test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5f68d1f5-ef1a-4795-b5dc-6c5c854737f0">test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b594ada0-6140-43f8-9a41-5e0c9dc312f5">test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#1db7614d-1fe4-4f34-825d-edff0e8248cf">test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#5f5ef63c-1694-403f-a6f1-83af0ce73f4b">test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#e937d13d-4b9e-4f84-b096-df4cde2f2cd2">test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#498c3a7a-ce23-4a47-b952-1014a06c081f">test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ea349e84-548a-4357-a13d-aa1dcdc1a9e0">test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#416fb747-946a-4265-9678-bc22657e9f88">test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4c09cd47-437a-4fa0-9d62-c974b703ab92">test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#7ada8d10-ac18-4fb7-901b-f8a1470705e9">test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#fc1c88d7-ac5f-4f1d-9546-490502f6672a">test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6af6696a-b038-4413-bca5-49bdcbec86d5">test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#30c51afc-edfe-403e-969b-ecaaddf90c9a">test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#20d6c1d8-18b3-423a-8fea-b1dc3ee5b6b7">test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4bf39269-be5d-4fa9-87c7-f858eb63c402">test_worker_spec[True-False-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#33c9baf9-b825-4f00-adac-096ccf49951c">test_worker_spec[True-False-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#21b048d1-d888-45f1-91e7-38a0e27f7a1a">test_worker_spec[True-False-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7cffb120-bc62-40e7-9fe5-958683703ab3">test_worker_spec[True-False-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4cc483c1-015d-4d48-82ef-201aa9a2b935">test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#03253e84-b3c7-48e7-8222-d6d6b21f4944">test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#eede67a0-f256-4e99-9175-b73bdb609c27">test_worker_spec[True-False-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#525bdbda-b9b2-4b7e-a666-c8be231a8910">test_worker_spec[True-False-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#064c4719-752e-43ce-a575-563ac7e9e81f">test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#788f2646-341b-412f-9f8c-dd81fab17288">test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b6519741-e1cd-4d89-bae1-e456129888cd">test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3bdcae46-8f21-41ad-986a-ae3967b68618">test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a13da595-5e9f-491d-92fa-b71679304645">test_worker_spec[True-False-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#4a0e1064-55db-4ec1-ad44-3b1c0ddda2ca">test_worker_spec[True-False-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#2f0e9617-1b2f-43bb-a8c0-83d7700f3099">test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9f69c547-a0bd-434e-bd3e-f36dbe4bcfa7">test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#af71e209-b490-450d-a297-5094bc996576">test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e75ff8d6-5cbc-4ffa-aaac-fc54390ce1a8">test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d9a2aea2-82ed-4df4-aa83-77410fad4a97">test_worker_spec[True-False-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#ea169e10-1683-4152-b66c-7f3b4c74895a">test_worker_spec[True-False-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#f76c61a8-be05-4908-a024-429929d1199b">test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#066727b2-d246-496d-8538-85d6c553471c">test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3a73324a-31a6-4073-985b-323178c1ce9d">test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3ada8a39-f18c-4d8b-9ea5-78ce72191eab">test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3fc2a6c0-b3d3-4146-88b8-5fe34729cb27">test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#40768369-604d-414d-9844-1ca746d502c5">test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#737fd88f-be39-468f-86b2-37246e3463de">test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e32cd0d1-ab11-4a79-a1d9-c4ccb2541ded">test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5a938544-fc6e-4ba7-84cf-fb5d131af370">test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b0fe9b4c-07aa-4392-b62e-5cb6e27091e9">test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#527553ce-cb04-414b-b2f6-210d1ae0b453">test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#68e22b09-76fa-4f4f-8e68-5b0efe299f98">test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#9990ecc4-ee1c-46f0-a44c-2d0640115da4">test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#00670e2a-fa5f-4f59-a525-e397e70d33a7">test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4bc4e62e-85c5-4e14-bfd1-d7205024327f">test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#65337bab-dc83-4215-8f94-41934c10a9f8">test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#58a10269-378d-4b17-a9b3-d573836ea25c">test_worker_spec[True-False-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#330bbae2-3452-4fd6-955b-9394e55b68da">test_worker_spec[True-False-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#f9373a60-4e3e-42d6-aff5-639511706423">test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b7c82cbb-92e9-47e9-bbb0-a446e72cc75e">test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d34b730e-b389-4b86-8ffa-0dce07ab8a1d">test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#892c0982-46a5-47cc-9fea-d7d35e013098">test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2fa15761-7975-4556-bed0-a485bb9a0e7a">test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#14aaffff-652c-417d-8617-9ee828cf2f0b">test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#34de2c2e-79f9-462f-8cbe-bbdcf9b26016">test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#de344a9f-b835-4d6a-951d-8e68035a279b">test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1b32b47b-eb3c-4bee-9cf3-eeefdacb5545">test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#99b5f012-dd27-4a43-afe0-b381f8234952">test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#93d7c163-0044-42c8-babe-efdc74ead3a1">test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#46dc94e3-6f40-4f94-abb2-c8eab47ffaca">test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#b950e7bd-f66d-4a6c-bcfe-54c04d299b44">test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#cadfafab-0972-4c51-93c6-33308c76e65e">test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#30e3eb3a-84b3-4f48-89cd-d974f0dfd7fe">test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#096dc527-f528-4de3-b4b4-c332c3d812e4">test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9544b838-fc6e-4c61-ae9c-9af468ee2cd7">test_worker_spec[True-False-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#032e01f7-3077-4cf9-a4cd-8e07db74f7d9">test_worker_spec[True-False-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#88c80b1e-6858-458c-804a-e9c8e2325317">test_worker_spec[True-False-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#32e796da-1091-4703-ad52-b31c314858d0">test_worker_spec[True-False-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#66d4ced3-6d81-443a-8526-6c559fa283da">test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a9840261-6247-4ccb-9404-e74666aa163d">test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3da9b99e-2d64-4f33-ba8f-1e730b2c99c2">test_worker_spec[True-False-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#e46fdd41-835b-4704-979f-fab7f2969aca">test_worker_spec[True-False-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#7be50b95-d86c-4233-b7de-421d036cc3f9">test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8c11532a-5e37-4e94-8b96-d39837e01bd0">test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2ca55f5a-0867-4db1-a226-aba0f023cd4d">test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#28294700-6940-44f2-9c88-04a4d1d56833">test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7fd0927d-4849-441b-a4b6-3f1f3fedd64d">test_worker_spec[True-False-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#ed26f3a6-ecac-425e-8a2b-65624cd96617">test_worker_spec[True-False-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ba28a3d5-06d3-4af1-97c2-458fe203a784">test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#1d9901b9-2c86-4f05-af71-7f06f0a8a4ed">test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#feabee0b-a188-4261-8552-1abbc0cc3f33">test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d01ed4bb-27bb-431a-9231-7e619220badd">test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#6ed165e2-189d-4b52-b20f-e9a074de95d0">test_worker_spec[True-False-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#b95b54a5-29b6-4fb0-b3a5-8dc684ab7089">test_worker_spec[True-False-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#27835a7d-0bb7-4618-9633-80ba35e0aa8d">test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d0949401-1afe-4762-8452-892ffc71d965">test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b8cce4d8-52ef-4b73-992d-341e200d1aee">test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ed5aa9ed-a612-4d02-861a-725a6002827d">test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#56f86a13-f026-4ec8-bb75-40e22c3b2c49">test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#6f19213f-e8a6-4754-9331-c09b706d907c">test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#e3a146b0-c68d-4457-93a9-c018b2199782">test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#77102128-bd05-499b-a271-2359b74dce5f">test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#09ddeed9-8801-4aa9-b85b-f3698a7b0d66">test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#1e8ff910-5b3e-452c-8562-92dd00bc51c1">test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#17e2cf5e-67c4-4360-805e-4ec08a149188">test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#96af5b70-f0e7-46a7-9b7b-7e1b51fe0f9d">test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#53a81e0c-3ff5-42d6-b99e-193077560623">test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4ea734ad-b582-47dc-88a8-00ee9acc62ca">test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4e02c155-1ca2-46bf-8101-63faf3b4f1da">test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b3838865-f234-4430-9e95-da50bb7ccee4">test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ea57c5d2-c3f4-4dbb-ad5d-bffd120ea06e">test_worker_spec[True-False-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#673b4aae-9298-49ce-8692-26af1fb15e07">test_worker_spec[True-False-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#5c25b2e0-0e8d-4381-9c1c-f7870b77d000">test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#14330d57-687e-462a-bcc2-72f3b607ce5f">test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e1a8d052-b19b-4623-9fee-ae6a6db33a6c">test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4825523a-f989-48ff-853d-ffe01bf808bf">test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#32fcf296-2fa6-488c-b980-6b9742b121e6">test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#e298000a-f183-430d-89ee-e48c28382984">test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#fd9cfb3b-607d-4493-a2a6-98e88d1d61e2">test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c4906ac0-80a1-457f-9dd0-78ca96dcdbea">test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#681fb3f9-109c-47eb-818f-319b36a53262">test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#bd415ed1-7602-4209-9035-2e13151beb68">test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0749f0d3-42c3-45e9-9a82-bb92804c0bfb">test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#c00be357-8301-4ab1-80b4-dd1d71a0b111">test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#0af6cbbd-7837-4b8f-9a1f-d29a6cc05cba">test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#659f5f15-323f-4eaf-931f-cc310ea61340">test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8a3f520a-5d0d-4bec-8a04-3ffcc841774d">test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#5de613bf-d8fe-496a-bb4c-b8a23a826466">test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#059194ad-24fd-49be-ba32-20dc77823f59">test_worker_spec[True-False-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#67bdd0d9-9e46-4159-bc36-d7ebe4b813f5">test_worker_spec[True-False-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#90bf6439-70ce-470c-aea1-5b52c192300f">test_worker_spec[True-False-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ef59aa6a-1b79-413e-9ab0-633f76ce2347">test_worker_spec[True-False-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e478f63a-25f2-4c7a-baac-2293782d8997">test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#42d0f065-5622-4672-823f-c217096f1ccd">test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b1b8ee2f-4eaa-426b-aa3e-688d9d2cfb91">test_worker_spec[True-False-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#a1f1aaec-cce1-4201-892a-f39ce8f74dab">test_worker_spec[True-False-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#0455273d-9da2-4663-9173-e9404fb93b86">test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c0d2cd13-b158-4662-b2f7-c227b3492b50">test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#dca5c3aa-4384-4967-93fb-3ab674bdd164">test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7080060b-a4bd-4c5e-b43b-840d74b5a779">test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f4fa8652-3cc3-4c12-86ad-b3385fe7f2bc">test_worker_spec[True-False-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#8502af72-6d91-416a-9930-65723bd58731">test_worker_spec[True-False-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#3736fff8-e5bb-41b0-808f-534dddb61db3">test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#33646646-fe71-4fe0-ac66-23a0d5a4448d">test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5fa559c5-6ad5-4653-a03d-92d858c48041">test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c1ba9691-b9be-4e82-9246-d697d3828d14">test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4004d074-724e-43ec-bc2e-212d1c121a35">test_worker_spec[True-False-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#15cc4b78-80d4-48aa-95d1-c67b49a8e7b2">test_worker_spec[True-False-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#04749f5f-90df-451e-ba70-99d555672685">test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ecb1d5b3-4828-4909-aedc-d07ec5c577d1">test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0bdd7f85-de30-4e7a-a04d-23d7203bb8fc">test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#66b7c06d-6008-44c3-aef4-ca3a4d2767af">test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#af6f1fb9-db85-4dfc-8d58-1a6b011b651f">test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#a20f22fe-8fab-4792-a658-76c6eb8a1306">test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#3e85f7c5-7e82-41ee-99c1-139741d038c7">test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b7e818ba-83b1-42ab-9625-af0e8a0711a4">test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#02b54029-da92-48be-8d51-f141a037585f">test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#59093c16-650e-494b-8dc2-27e81e3a6b80">test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#75f66aa1-3d00-484e-b10a-0b6c3aa1245e">test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#ee0c74ee-454c-4297-84fd-19052723223f">test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#71be9642-326a-4e59-bfdf-af60ef0cb1ca">test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e3baa966-1903-48a4-94b6-b23354fe36e0">test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b821955b-3578-4563-9d05-3a33bb1651a6">test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6a4ae312-632c-4011-98fb-02b941461d64">test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5e1960be-3778-4dd1-be95-66aeaee836cb">test_worker_spec[True-False-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#ebed63c6-6dad-4f73-8135-5afbeefb318c">test_worker_spec[True-False-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#bfd79ba6-3179-4a84-a820-36263106cfd7">test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#61732d7a-7f12-4d9e-9d3f-e319e5c5b74a">test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#c644fbeb-2d77-4d0f-941c-f8ac23b16554">test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c5c266e6-ea17-4769-ab18-fac1d1624efa">test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ecdcb3ca-ca84-49c4-8f6e-5bd4d0712a5b">test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#aabf15e8-ba2e-47c8-891e-ce22f38b2bd9">test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#1fc0fa07-9719-496b-9e5b-378a65fe3fa2">test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ccd5cd55-c8ae-4cc8-900f-9f1226ad120d">test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1eb2da55-08e9-4b10-ac67-d2cd396373f6">test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#18d0bea6-b78c-4afe-9d8f-b60597ba41ea">test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7469fe68-efc8-4a6e-8617-ef685156f83b">test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#f3030255-d1c7-4bf7-8b35-45ec4f16eaa4">test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#003aae5a-2cd0-4ae9-a508-e7a20834f2e1">test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c3ee41e6-0fd3-41f2-80e1-d4eb90e4e9d2">test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d6666ec8-ac67-4ed8-b29a-d0563c5781fd">test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c51abf68-db41-4352-8326-9d7ed0f9a00b">test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#df6a99de-9da7-4174-8b12-cf7f01aaf8aa">test_worker_spec[True-False-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#77657fd2-d669-4311-a80e-ad0eb3599566">test_worker_spec[True-False-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#e5477c63-49fa-4873-a732-9b83103484c4">test_worker_spec[True-False-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#93f44b92-acd4-4911-aaae-3770efb6d7d9">test_worker_spec[True-False-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d88c7b6a-e3f1-4f83-9afb-8783a89ac17c">test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#df6e6ec3-a9d4-423a-8db3-cad5cb0c815c">test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3370f017-2733-406b-9d23-023ceb96549c">test_worker_spec[True-False-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#90cc59d9-5a74-4ab4-be1c-17b5238aebc4">test_worker_spec[True-False-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#e7700106-a8ab-4849-b577-be7a982ec579">test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#cfe8c16d-34b7-4f73-808c-ae0f18460e2d">test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6d259ff2-6dc7-4dfa-af6d-3289bdff2fb8">test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f2436194-2da4-4746-84e4-02db4d8cce4c">test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3a69b225-7e86-46e4-9fc1-5e5b463e7375">test_worker_spec[True-False-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#7b55f13c-dff4-4c81-8553-c371ad3ebd6a">test_worker_spec[True-False-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#0bd5f2eb-d32a-4592-b524-f8e259076c5c">test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ce8b24a3-03c3-470f-a435-1ddcdf264c7d">test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#038b5d7e-797e-4a31-beef-b84b47979717">test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a10b89d2-f224-4387-9f32-1d36b98a3c7a">test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c732baea-ecb9-4fb1-a53c-95f0dc7bee36">test_worker_spec[True-False-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f4eefa31-065d-4139-b045-2ecb33b407a5">test_worker_spec[True-False-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#8e539f17-8fc7-4f32-8021-a8dceba000ec">test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a1539072-bd11-4218-9eb6-a085eef119be">test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6e60bad6-71b3-4bcc-a762-8849e3667914">test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2a2ce013-e2da-44be-8809-830b4077cd8c">test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#51e34f88-7d75-423a-a02d-65850c0d454a">test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#cfb88922-db98-4985-a247-88f34c61084b">test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#2ca29bb5-8dd0-43b8-b559-92628401bce1">test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c7b3ba41-d204-4115-98e0-7a1071148c89">test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f87bafa8-7557-4776-b6be-4f43977ed86b">test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#62c21cbd-a88f-4927-8c2a-51313e8a6b92">test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e5c2b90a-8d09-4b55-be51-43b7549850e9">test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#478d8b0a-fb60-4a7e-9bad-49132e85c9be">test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#d523061e-5ab4-4b21-ac2f-f4ac06ef92a3">test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5d41adb1-2ff3-4a64-bae3-9cbcd59f6d78">test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4828a7ac-62ef-4720-ae27-4582f4564adf">test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#612f6020-9c4b-41ba-bcaa-27d6521981c1">test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#87af3af8-d339-4367-9032-a2b624a5b557">test_worker_spec[True-False-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#e5f95c00-aa25-4634-af7c-3996b90899b1">test_worker_spec[True-False-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#7ede0446-d14f-4e5b-9244-645de95bca82">test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ff6ec26c-3d98-415f-8221-c85ff25a4f30">test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#19557a8e-acfc-4148-82e9-6bd6a1a66306">test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#22bd776f-d5dd-41b1-bded-ed8674bdc6d9">test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#915e9503-00c9-4825-bbcc-a1082724d151">test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#587de107-57ff-4272-ab1d-ba8b5495fbe8">test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#85000b00-762d-44cb-954d-b65d5e839cd2">test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c3d638ff-116f-4b14-ac94-744048f3aa3c">test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#fb5ad829-f008-4640-a103-8dce16784a15">test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4e829a88-d946-49ad-bbc0-6bbd55eaf570">test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#52bb8ef7-0211-42e7-9d09-a6bbc4bd6818">test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#01d01a51-d68e-4215-b85f-1bb27a77dc14">test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#2aae36de-274d-4ce5-bf04-3130b51a23c0">test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4252dfb8-f7c6-45cb-975b-d284cdd67a8b">test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#52796e70-6abd-4612-a305-38aeb1854002">test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#23551d94-9db4-407c-9428-0114d8771130">test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#518661f5-3fb1-4c46-b169-cb8e47a0456c">test_worker_spec[True-True-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#8eeda928-f145-4531-9b88-1ccab686271a">test_worker_spec[True-True-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#aa703ebc-c37d-45ca-9123-3c2a0e217dbc">test_worker_spec[True-True-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#2982baec-bac1-40d5-979b-b62b9b51e387">test_worker_spec[True-True-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f04a66d2-9eb2-460e-baf6-da6957eee3f9">test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8a551f62-bc2d-484e-b48b-e68ee463e766">test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3bb6abb9-9257-421b-ba01-04a2ee69909a">test_worker_spec[True-True-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#58e12daa-04f5-4ab6-a89b-7339c1a0c2dd">test_worker_spec[True-True-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#9d0f73ff-f58a-4c76-b634-c5df89f09605">test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5ce303cf-f493-4ff5-83ee-f8d47f418da8">test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4a62abe9-05c8-48e9-8fca-1c0f8da125f6">test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#fcb1ee1e-2e58-4369-95b8-af6d10838f85">test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a0f000d4-f350-4e38-934f-d8ba3941d21c">test_worker_spec[True-True-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#1c431544-80b4-40c8-b978-cdb24c043727">test_worker_spec[True-True-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#7b0078b7-182e-4f69-8207-6743b1610e4c">test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#1047d097-ad68-492a-b690-f849c101236b">test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9f711393-7172-44a3-be8c-b121f502ce7f">test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#58e10824-d1ca-4b7d-ab4b-b9e0c694a164">test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2e26e251-fcc8-4a97-9a83-890820f0c75e">test_worker_spec[True-True-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#d9e779e2-7cb9-43c3-a7f7-f607b104fcc6">test_worker_spec[True-True-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#cd2a47ff-0243-468a-9d48-b653a41795ca">test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#53c837c6-4536-42dc-ab90-3cbfae5bc68d">test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4c0c59c4-b508-4744-8ff1-b45e6497f432">test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6f296d9b-6853-45a0-8130-a1d55333a9ec">test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#451dcc7b-fe06-45ec-afbd-428f41241b54">test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#1a6ea748-df42-4a13-8998-f40709fd043b">test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#1edec294-6d6a-429f-9773-f7565655af01">test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a3ecc7cb-b47c-44a2-b27e-4c4f1a480f6d">test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7ad53d45-ec23-4b31-9513-42764c75a184">test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f37f97fa-151d-438d-b429-2151deb3a281">test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#72a03bf4-476d-42a2-a5d9-5ed8b2bfb7e8">test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#da7542f0-63ea-4f66-a464-bf0523c22a11">test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#700f1639-d9da-439b-baed-a44f03c4cd74">test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7f9f495c-519e-4c89-a085-8d807ff1ab47">test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ffb045e7-54f2-4a44-b0af-899fcea058dd">test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9213711d-a082-48fb-bbd3-9a6329b73e62">test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#58c07cd0-14cb-469c-ab55-94aac8f1adc5">test_worker_spec[True-True-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#8c8e1d93-8b77-48a1-9df6-927a808ce978">test_worker_spec[True-True-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#8fb39fa6-afc1-470e-88ea-fa16eca1a3c2">test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7ad3beeb-2a2c-4769-ab17-4340170ebc3c">test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a24fb72f-6b8d-46c8-9cf3-cdd1b1a3e40b">test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#70e7b6a8-7d9e-4f35-a8e3-dee19a319f52">test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#13b791de-fd2c-4f78-b96c-7eacdd086298">test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#612a0e50-fc59-41cf-8b4a-910990e8a02d">test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#54c23388-f0a0-4bd4-8b8c-64f55e2d04e6">test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c2d56429-80e6-4b14-83fe-f225fa3c596e">test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#03223401-c69f-4a5d-899d-617b42e2290d">test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e2065625-a3b9-4655-9254-fe772d06a7c1">test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#88ffb280-2ac2-4013-963b-73dfcb2c09c4">test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#a8f327b2-db36-4b7f-834f-4ef573b662a3">test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#af75c18d-d5db-449b-a2a9-81275c447300">test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#39deeb50-1df9-40f6-9a94-d19adb0eebeb">test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#52dc05d9-86df-40af-9194-dae185536dd4">test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#559e19e2-4003-4612-9219-b8d153abeab9">test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8d612fc3-d8d7-4623-bcb9-9db9af484471">test_worker_spec[True-True-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#ec78471c-39c9-4462-8650-1216b1b8d863">test_worker_spec[True-True-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#59c5abaa-ce4c-45de-a791-a03507c7ac37">test_worker_spec[True-True-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c8e834d3-4cfa-4cba-8aa7-44752176e64e">test_worker_spec[True-True-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b45e6486-fe3c-429d-8044-677a0f644a9a">test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3c804d98-35d9-46d1-be6a-1e8bc8afa6f9">test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e25343c5-ecbf-4fe5-9578-b9efccad8d98">test_worker_spec[True-True-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#6ba9cac3-1587-491d-8955-4899cb8ac643">test_worker_spec[True-True-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#746c7b52-4677-40ec-be92-110a51d40590">test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e1cba919-9670-4541-84f2-4ca6f2906fcb">test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#07882e7b-b8ac-4688-8cf5-f60c4436e479">test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4e04b7eb-8274-4cb6-844b-157c923083dd">test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#68589621-990a-4fad-9cca-1a61874015d1">test_worker_spec[True-True-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#c111e66d-bf13-47bc-b3b5-de5960696eaf">test_worker_spec[True-True-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#07d78159-f4c4-4354-be25-52ca8fd9508f">test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#fbb5a85e-9347-4b03-bfbc-12271457e240">test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#44cfa71f-84b8-4b3d-b3ae-6bc930717ce4">test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#db583d0d-71b8-47ee-9911-728b41296291">test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4360cb7c-c7fc-42b2-bf3b-925693104475">test_worker_spec[True-True-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#4a259ee7-eb56-4072-b60d-bc4eac6bcd9b">test_worker_spec[True-True-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#02a249b2-5eff-4ada-9739-0dd0a98fa2f4">test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9c55ec8d-2f0d-4c10-afd1-7efe4ec485fe">test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#c8295c14-1749-4e35-a57b-a57d68777de5">test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4f2d4c12-a41e-4b6c-89a7-dd2d9df18be9">test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#69124b5b-54b8-446e-b5b9-fa4e1c6bba22">test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#07b4352a-fff1-4584-b99a-5fbb06cf27d1">test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#77c26d7b-b40e-4db2-9ad5-fb56e58d6fa7">test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#95ea158e-a4df-415f-8018-b18cc2ec33ea">test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ee9b8a00-a37a-459e-9fe6-ade24dccf87f">test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a4603980-2001-44f4-adb0-796d7efaf547">test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ec91b201-9d85-4968-abfb-52bfd87f5928">test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#9c7567d4-3f2f-48c2-a371-1d7172f93c3f">test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#7a5750df-1b07-428e-8f2f-b9e2afb70f16">test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8a83c8f3-bd2f-4c84-b42a-f8a9c549da43">test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3e6efc01-f1bc-477e-9f6e-fc9ede7700dc">test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3f165d08-6141-427c-9ed8-e2af2fedf620">test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#af3bd80d-8f9e-4547-afa0-766fb76337b9">test_worker_spec[True-True-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#beb22682-2207-438a-8bee-aae5121646ef">test_worker_spec[True-True-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#c4a65078-e51c-45c6-973d-1987f4ee9a9d">test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#fcd5ab34-e246-4b87-9a08-81d7fb93c8f8">test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2bce47a6-fda0-4033-b900-cedf1e3eb52f">test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#79d313d3-f598-40d6-9f3e-6703b78ca54c">test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d9d882ad-a1d9-4b08-b222-4d44d9c243b0">test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#2bacc008-f4b0-4e95-9923-f21aa87bf5b9">test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#dc6338d8-dc34-4a65-adcb-c7ad38e06b03">test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8c463236-3228-4389-a6af-70957c4453e6">test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7b6d6056-f71d-4806-bf95-471a3f48c0a4">test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f362d391-784e-4049-9960-4a88fc042f01">test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#86d69c7d-fb5d-4901-8710-e7f383ecc29c">test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#637382d7-4705-473e-a93c-c6d1cae42269">test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#fe292298-f19b-4e87-a648-aa68d6e7a5ab">test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9c95eb45-44ad-4a96-9cbe-aa6e608c8010">test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#55cd639d-1c8e-4dea-a234-f1f8d4502de0">test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#49702189-4a67-42a2-822b-4b52a853a5db">test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b28f5285-2e9d-408f-80bf-b72fbfcb9be6">test_worker_spec[True-True-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#e2056009-c350-4693-bccc-b8ab21537509">test_worker_spec[True-True-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#406797a8-52db-4f0e-b46d-dd5267fd1532">test_worker_spec[True-True-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3be7ff6f-cc66-4238-86ec-9bcb9ccd751a">test_worker_spec[True-True-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#edb97c78-0adf-4ba4-bbee-4481e95e535d">test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f9873020-1d8e-4042-a420-8114c4da68f5">test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#42a12721-6ce3-4ca7-871a-6ccec9ad00b4">test_worker_spec[True-True-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#40e93d6a-8b5a-4a44-8557-dd3f73f4e967">test_worker_spec[True-True-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#36d1bb2a-0618-43d0-8d7b-cd279895357a">test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9a4e57c6-5213-4bcc-9444-f237ef792476">test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#85df194e-eb9b-4ae8-bfad-7a7334f122cb">test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#96abb7f1-18ec-47a6-a981-5e5720f22e0d">test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#baa2e122-d6d4-4f3f-8c7d-36322e9ca9e8">test_worker_spec[True-True-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#92cbe51d-def4-4023-a0f8-1048d535e06d">test_worker_spec[True-True-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#e42bee42-082c-40f4-b474-57a393d4c39e">test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0d25a219-0189-483b-a14b-e26aa937d7cd">test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e9421701-2fa7-4805-9a27-25e039792ccd">test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8efe57fc-ccb9-4631-85af-20e9627e819c">test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f444b0dd-3776-4d49-8ab3-57275f6d20f5">test_worker_spec[True-True-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#3cc141b2-9024-4162-8522-cee91caf78ed">test_worker_spec[True-True-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#55e31c2d-390b-442a-9f6e-e52b7b0cea13">test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7f1803b9-10c3-4020-97fb-cbefc6606714">test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4fe2c251-c8a6-4368-b4e8-2ad962491f65">test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4978cfaf-398e-4485-bfdf-88d5d7c92782">test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ad1d15f4-22d1-4ed7-827f-55b4d807838f">test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#d7362913-a8b2-4d99-a032-ec92069dde03">test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#f836ebad-3723-4e89-b038-6c00d55745d5">test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#fa0b70cd-a5b5-48c2-928d-5fcbcb689747">test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b3684986-17e3-444d-a28b-572bf81a3453">test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f983dba9-da8e-4b1b-a076-1a3e32ac6380">test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#45ff97bb-a25c-47be-bf14-b0045df0c2ef">test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#c67b1898-2ba5-4964-847c-18094f7f0a1f">test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#57b5bcf5-09dc-45c1-8fbd-1312111e41eb">test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#602096f1-4269-4df4-a35f-b7faf8ea0e53">test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#53e58b25-9b2f-45c0-ae40-6535232f6cf4">test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#95147464-816f-4ca1-bc65-92a5045cf451">test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f6e3bdf1-e3a8-4148-88fa-a48173f466ec">test_worker_spec[True-True-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#aa12a3d2-fefd-4bc6-85dd-5c9aeb67f2fc">test_worker_spec[True-True-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#001c1739-538a-47cf-89fa-9a9678051da6">test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#32cdd7c6-f803-4921-ae67-9823e8d042b1">test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#80085e56-9a35-48b6-bceb-a264cfdb3f59">test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d5346bc4-c515-4295-a3ef-99ea3439e000">test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2d959501-f5e7-42b9-8482-a91d6cea25ca">test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#4a596dc3-da80-451c-8d98-57b30df09ccc">test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#b1702a39-d8d1-4518-be48-300f7bd2eb0f">test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b8297117-18b6-4f8c-b864-0857ab598ce7">test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5c8746d9-545f-47de-8aec-2fc55593af2c">test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#17ce4f22-e59e-4ddf-8826-769b089b83de">test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#386ebc9f-400f-44d7-9faf-e98ea5690578">test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#de53a115-d010-4c73-a1a9-4d6ec826c114">test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#bd616019-36f3-4f4e-8ca7-0a06dbe2ba7a">test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#21a68a79-07dc-4d30-be9e-abf1d372c7aa">test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#46230828-da69-45cd-9ce7-d952b15d22fc">test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ab2a560e-0e82-415f-9bba-7fc395c7ef7a">test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#09eb0efc-abf6-4708-ba7b-12716d89b62a">test_worker_spec[True-True-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#4b8ebf54-8231-43e5-a1f6-35fe9d8345a5">test_worker_spec[True-True-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#c72b5076-5dcf-429d-a973-98df8883a587">test_worker_spec[True-True-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ec6b1057-2678-4ee2-939c-940542801889">test_worker_spec[True-True-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d7953247-738d-4ca6-95de-c8d603669ef0">test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8e0f9f5a-5413-4e88-aedd-b0a0a54ab34f">test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4558a2a7-56f2-4a67-a15a-553d25e4efb3">test_worker_spec[True-True-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#a49bb4bd-17ba-4242-a8cf-886077e8904f">test_worker_spec[True-True-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#7500f26d-5d38-4186-9ebb-c4873a98a66e">test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9cd98ec8-d957-43a7-9108-7decc6101dc7">test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e971353d-2891-41d9-b1a8-d3a3ea7b1e4a">test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4320637c-9011-4624-a34b-a3b3d5876f97">test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a675f422-350e-47e2-aed2-e50334947eb4">test_worker_spec[True-True-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#cf72462b-4bf8-4c05-8d41-9bfdb74898e5">test_worker_spec[True-True-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#a8835e7e-9279-4fa0-a210-5d729e914a43">test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#beddbfa5-a788-4ab7-a650-ce5d23c40d04">test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#dabe5358-d6d8-4aff-90af-d1510c568b2b">test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#305b9c46-8e09-4b4d-b1bf-526c94181219">test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ef2390d6-1957-406f-b45b-1fe817c55472">test_worker_spec[True-True-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#c83cebaf-7f4b-4f34-9e44-1b3899a655f2">test_worker_spec[True-True-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#8e705f37-aa88-4241-b2ea-3394a53bf2ba">test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#61573881-06c3-4626-9149-8456594480d8">test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0b3575f6-9fe0-4838-9cc2-84f26d8c200c">test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#43d12613-1576-4cdb-935d-d351435a184e">test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#bb046f09-0cc9-4b25-85fd-0ed2d6d960e8">test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#74c82b79-f696-4ffe-8130-9af477a49a0f">test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#3c7d5d4a-ae5d-49b6-ac37-908ea4cc8e0e">test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#85b0d4f3-47cc-4ca0-954e-3a683aef6a83">test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#038a6877-3589-4e5c-8f17-d28fdaa16b7c">test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#46d594b3-21a0-4b65-adb0-9b8ff7fa4153">test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#eb32529b-62be-4a86-87ce-995308cd9783">test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#d8f1c453-7d6e-4013-8d3a-b36a124bcfa7">test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#88489ff6-88f0-4283-974f-7c5d356fbc5f">test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#652a8876-da36-4d36-b019-83a9d94f3433">test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#849cc3a3-3809-48d8-85b6-fb0397e03df5">test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9bbb576b-195a-43a4-8915-0c7f6d5c6e01">test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#04c88564-fa89-4682-8ab9-6fa03153d330">test_worker_spec[True-True-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#203706cb-a07c-4f80-9db9-7f5bdd3ba791">test_worker_spec[True-True-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#cc1f738f-2982-444a-9594-75da9ebd1a98">test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c2d81bf7-990e-46b9-b222-bc3ab98cf860">test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#97d10a04-08af-4a1e-b68d-828468e75df6">test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#cf213700-cc46-413d-a650-3c321148f1c8">test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d1b1c083-e31d-49fb-a58e-5b01beebe89d">test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#85166a44-93ac-46f8-9ad2-a11613889157">test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#14c0dda1-4f6d-4ded-944d-dd2c908c4d2c">test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#1e90487d-bdef-4e15-b8fc-a52c3974bd6f">test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#00ba050b-1b8b-4b68-96be-1b717b92762f">test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#802f8246-86d0-457b-8b10-1fc48c7dce6d">test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3784928d-2c93-4988-8f41-94bb67e5c34e">test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#bdaf2566-c833-4aaf-aca6-3836b162cd4a">test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#b207899b-9e3f-45e7-9951-87f2d08ae8c6">test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9ec6e2f3-e3e2-4550-ae59-0fcc8a279f08">test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0294a097-877e-4e4a-9d3b-7f25c8518281">test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9d37662a-13dc-4aea-90b4-c6dec5fcdcf2">test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                </ul>
                </li>
                
            
            </ul>
        </td>
        <td class="failure-index">
            <ul class="toc">
            
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#80365f31-45e5-4828-94ce-249e301e86c2">[F] dask_cuda.tests.test_dask_cuda_worker : test_cuda_visible_devices_and_memory_limit_and_nthreads</a></li>
                    
                    
                    
                    <li><a href="#41298fb9-e663-48a7-b1c5-734b7a0a5cf4">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_pool</a></li>
                    
                    
                    
                    <li><a href="#f8e2c662-4e9e-4118-911f-1ee83625c188">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_managed</a></li>
                    
                    
                    
                    <li><a href="#c8216f9f-d42c-4fd7-8640-32c92c49733d">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_async</a></li>
                    
                    
                    
                    <li><a href="#e51bd957-eb42-4643-825d-b4e57c60f3dd">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_logging</a></li>
                    
                    
                    
                    <li><a href="#b9e549a0-cf4b-4f91-be2d-d13f077f21fb">[F] dask_cuda.tests.test_dask_cuda_worker : test_dashboard_address</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#4bb9c00b-0a38-4d39-a835-12ac80595848">[F] dask_cuda.tests.test_dask_cuda_worker : test_pre_import</a></li>
                    
                    
                    
                    <li><a href="#25083def-a7c6-4501-8543-083d38733b34">[F] dask_cuda.tests.test_dask_cuda_worker : test_pre_import_not_found</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#346ee6ed-9418-4b72-a366-c58cd92bb20f">[F] dask_cuda.tests.test_dask_cuda_worker : test_cuda_visible_devices_uuid</a></li>
                    
                    
                    
                    <li><a href="#c9fa008b-4be5-4dd1-a20f-c56d87393fe8">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_track_allocations</a></li>
                    
                    
                    
                    <li><a href="#98eb94d3-d361-4ba5-b3af-ac724715d1cc">[F] dask_cuda.tests.test_dask_cuda_worker : test_get_cluster_configuration</a></li>
                    
                    
                    
                    <li><a href="#98647bc1-d29e-43db-aad6-6fa7e8fe8f8c">[F] dask_cuda.tests.test_dask_cuda_worker : test_worker_fraction_limits</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#30bf9173-adf6-4c57-a910-3764c2c0d158">[F] dask_cuda.tests.test_dgx : test_default</a></li>
                    
                    
                    
                    <li><a href="#0a04eb59-5414-4113-9dad-6d9de4bc53be">[F] dask_cuda.tests.test_dgx : test_tcp_over_ucx</a></li>
                    
                    
                    
                    <li><a href="#7fa90a61-6dbd-4b76-9ea1-1f177cea6a43">[F] dask_cuda.tests.test_dgx : test_tcp_only</a></li>
                    
                    
                    
                    <li><a href="#a8f8599a-1144-429b-ab33-cb65ecd503bb">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params0]</a></li>
                    
                    
                    
                    <li><a href="#417f88b2-3de4-4dff-8799-7eb90f2cc3f1">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params1]</a></li>
                    
                    
                    
                    <li><a href="#370d06d8-a218-4da4-8642-fdaa5db2d632">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params2]</a></li>
                    
                    
                    
                    <li><a href="#bca0824a-424a-4d18-9409-4e85803c0e44">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params3]</a></li>
                    
                    
                    
                    <li><a href="#32281558-de8d-430c-be37-996b3695e0ab">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params4]</a></li>
                    
                    
                
                    
                    
                    <li><a href="#a7ff0e77-a18a-4435-bce0-52573b584ca3">[F] dask_cuda.tests.test_explicit_comms : test_local_cluster[tcp]</a></li>
                    
                    
                    
                    <li><a href="#b4d3fec5-87c5-4120-9d29-e3106baa25ff">[F] dask_cuda.tests.test_explicit_comms : test_local_cluster[ucx]</a></li>
                    
                    
                    
                    <li><a href="#a94c63a1-9918-4b1c-ba8b-8e67422de916">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_merge_empty_partitions</a></li>
                    
                    
                    
                    <li><a href="#8fc1e345-5218-474c-9fd6-9b540a891ffc">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#355390f9-f977-47ef-a04a-6f3c02d200a1">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#472bd264-b1dd-4de3-a911-9ff39bf1b440">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-pandas-3]</a></li>
                    
                    
                    
                    <li><a href="#49603f52-0735-4206-a919-563ab41cae7d">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#ae6c8025-4050-4ceb-876f-df15eabb3878">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#8d8e9c10-b9ec-43c7-a337-2c16ece0fe4f">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-cudf-3]</a></li>
                    
                    
                    
                    <li><a href="#66dcf089-2894-4d3d-8752-179c388d4340">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#24399cb6-1251-45ef-867b-b4fc9f28029b">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#a87a1a06-3090-4010-8071-7261cd8cfbe1">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-pandas-3]</a></li>
                    
                    
                    
                    <li><a href="#59667a4b-e3f8-49e4-a355-4191da9f2bcf">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#b4f70239-4e01-4b36-8743-c963b7c7a5e5">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#94f2a235-def8-4fbb-812f-4d0132eb526a">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-cudf-3]</a></li>
                    
                    
                    
                    <li><a href="#0b68eb56-bbb3-4bb3-b328-f37fa23c122d">[F] dask_cuda.tests.test_explicit_comms : test_dask_use_explicit_comms[True]</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#5f13cdf7-dbd5-4bc9-aeb0-cdeabf3d7d64">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#d1673323-b5b6-4a6f-8e53-2d7d534b8ca4">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#474141ab-bad5-48eb-899c-c88ed2871edd">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-pandas-4]</a></li>
                    
                    
                    
                    <li><a href="#ca01a75f-87c8-46f4-8c28-84a93869b032">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#8d339e4a-8066-460a-a299-f3ea37170e93">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#fef0bc65-4f5e-410b-9728-e4f83f3ef266">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-cudf-4]</a></li>
                    
                    
                    
                    <li><a href="#24b1c727-7bd8-4259-bbff-088be70f8b28">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#8b11706e-f358-45e7-9473-8e7a8ad0b4c5">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#5041e605-efcc-4ede-9e5e-81dc2591dbaa">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-pandas-4]</a></li>
                    
                    
                    
                    <li><a href="#3a6eb307-7e79-4b97-8aa9-f19cd0475cae">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#ebb191fc-eb92-4032-a8c7-8f395dd3623b">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#717c7604-23b8-4a56-98e7-d110d5ba6233">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-cudf-4]</a></li>
                    
                    
                    
                    <li><a href="#9f06fc7b-e517-4b4b-80d5-0fed2c192b39">[F] dask_cuda.tests.test_explicit_comms : test_jit_unspill[tcp]</a></li>
                    
                    
                    
                    <li><a href="#1330eeac-2b95-4816-8559-d53cb202709f">[F] dask_cuda.tests.test_explicit_comms : test_jit_unspill[ucx]</a></li>
                    
                    
                    
                    <li><a href="#1e4c315e-db7d-4e79-a6b1-51ff02d19231">[F] dask_cuda.tests.test_explicit_comms : test_lock_workers</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#5e07880a-6056-48cd-9cf1-02fcef7c87a6">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_tcp</a></li>
                    
                    
                    
                    <li><a href="#b8f77a56-c325-456e-8bfc-5f61bcccbc30">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_nvlink</a></li>
                    
                    
                    
                    <li><a href="#47bbe595-79ee-48c2-b07b-30645ec26712">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_infiniband</a></li>
                    
                    
                    
                    <li><a href="#7bf66402-5b07-4159-baf7-1b5b3d588073">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_all</a></li>
                    
                    
                
                    
                    
                    <li><a href="#499dc81f-46d7-4935-b036-fbcd1b9a4994">[F] dask_cuda.tests.test_local_cuda_cluster : test_local_cuda_cluster</a></li>
                    
                    
                    
                    <li><a href="#3eb63595-1d90-48b0-b109-8cd62e07fed8">[F] dask_cuda.tests.test_local_cuda_cluster : test_with_subset_of_cuda_visible_devices</a></li>
                    
                    
                    
                    <li><a href="#845a661b-0069-4355-b3ab-352c037de6aa">[F] dask_cuda.tests.test_local_cuda_cluster : test_ucx_protocol[ucx]</a></li>
                    
                    
                    
                    <li><a href="#4b5c21fd-c1ef-4769-95fe-1f511aaa134e">[F] dask_cuda.tests.test_local_cuda_cluster : test_ucx_protocol[None]</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#abef9fc5-17b8-4a38-b364-4bbe41b94d31">[F] dask_cuda.tests.test_local_cuda_cluster : test_n_workers</a></li>
                    
                    
                    
                    <li><a href="#f9ff6c84-8835-434a-8d14-e6f98bab958b">[F] dask_cuda.tests.test_local_cuda_cluster : test_threads_per_worker_and_memory_limit</a></li>
                    
                    
                    
                    <li><a href="#b01cccf0-f199-4096-8c71-28b5412bee86">[F] dask_cuda.tests.test_local_cuda_cluster : test_no_memory_limits_cluster</a></li>
                    
                    
                    
                    <li><a href="#6091f805-dd2b-4649-a927-e19734e24e3e">[F] dask_cuda.tests.test_local_cuda_cluster : test_no_memory_limits_cudaworker</a></li>
                    
                    
                    
                    <li><a href="#dd173152-7bac-4ef4-8544-153751b82376">[F] dask_cuda.tests.test_local_cuda_cluster : test_all_to_all</a></li>
                    
                    
                    
                    <li><a href="#ef754421-3e4c-453f-9fbc-20cda4464ecd">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_pool</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#5dd5e540-1aab-4ff4-948e-52ed8321cc8b">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_managed</a></li>
                    
                    
                    
                    <li><a href="#7e24662d-71eb-486e-a0fa-7c02fcc0ff6d">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_async</a></li>
                    
                    
                    
                    <li><a href="#4dd4b3c5-aa24-4f2e-b221-7e47036b9335">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_logging</a></li>
                    
                    
                    
                    <li><a href="#31450e30-ca4c-4bbf-8dab-b2d5d963245b">[F] dask_cuda.tests.test_local_cuda_cluster : test_pre_import</a></li>
                    
                    
                    
                    <li><a href="#7699f658-78a0-4a2d-9372-362e6e9b1a66">[F] dask_cuda.tests.test_local_cuda_cluster : test_pre_import_not_found</a></li>
                    
                    
                    
                    <li><a href="#e6c11353-71b8-4c33-a96e-9987899676d4">[F] dask_cuda.tests.test_local_cuda_cluster : test_cluster_worker</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#cf3a02a4-25d8-4ca7-9d0b-7086e63746f6">[F] dask_cuda.tests.test_local_cuda_cluster : test_gpu_uuid</a></li>
                    
                    
                    
                    <li><a href="#ea07f764-eded-4486-96bb-aabfba620a2b">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_track_allocations</a></li>
                    
                    
                    
                    <li><a href="#aa01c178-f8f2-450d-985c-502175078228">[F] dask_cuda.tests.test_local_cuda_cluster : test_get_cluster_configuration</a></li>
                    
                    
                    
                    <li><a href="#00dc3616-203e-4e32-998c-04ebcf895a4c">[F] dask_cuda.tests.test_local_cuda_cluster : test_worker_fraction_limits</a></li>
                    
                    
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#70f86b70-5f96-445a-8374-cd1c9725579f">[F] dask_cuda.tests.test_proxify_host_file : test_local_cuda_cluster[True]</a></li>
                    
                    
                    
                    <li><a href="#b7a21fb7-91d1-479c-b9fa-6bf13eca9a17">[F] dask_cuda.tests.test_proxify_host_file : test_local_cuda_cluster[False]</a></li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#9bdf3fa3-4288-45ec-b4ac-6d59b0f7d956">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[True-1]</a></li>
                    
                    
                    
                    <li><a href="#cc411ed3-79da-4d39-b7ce-64418f877c1a">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[True-2]</a></li>
                    
                    
                    
                    <li><a href="#3dc66fbe-2f62-4cce-9125-f878c4d7f587">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[True-3]</a></li>
                    
                    
                    
                    <li><a href="#93f263ce-59ad-4db5-a2fd-be187ec56b82">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[False-1]</a></li>
                    
                    
                    
                    <li><a href="#b44563d0-d207-4c6c-b6c5-58e131473314">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[False-2]</a></li>
                    
                    
                    
                    <li><a href="#fec28444-95e2-4793-bfcf-9ea8e75c8e5a">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[False-3]</a></li>
                    
                    
                    
                    <li><a href="#0f1a59d6-0382-4fc0-9a22-c6586a9e5538">[F] dask_cuda.tests.test_proxify_host_file : test_worker_force_spill_to_disk</a></li>
                    
                    
                    
                    <li><a href="#edcb805f-372b-42c3-a172-40b5431aab62">[F] dask_cuda.tests.test_proxify_host_file : test_on_demand_debug_info</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#6aa8bb30-f65d-464b-acc3-e5aa900fe4d5">[F] dask_cuda.tests.test_proxy : test_spilling_local_cuda_cluster[True]</a></li>
                    
                    
                    
                    <li><a href="#34572f50-8f1f-4320-92b1-8c07daf62c05">[F] dask_cuda.tests.test_proxy : test_spilling_local_cuda_cluster[False]</a></li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#cc15560e-2364-4fa7-87b9-cb6aa1133f8f">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[tcp-None]</a></li>
                    
                    
                    
                    <li><a href="#a471dc46-16a6-4604-8c47-c96f5903fa27">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[tcp-send_serializers1]</a></li>
                    
                    
                    
                    <li><a href="#1011cbbf-7894-4496-8e72-78b34c5703fd">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[tcp-send_serializers2]</a></li>
                    
                    
                    
                    <li><a href="#1479fe6c-6653-4da4-8213-f1246feee43e">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[ucx-None]</a></li>
                    
                    
                    
                    <li><a href="#4b311b4a-543b-4dfa-8f1e-a33a75da6960">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[ucx-send_serializers1]</a></li>
                    
                    
                    
                    <li><a href="#de2c5b7b-7b96-44d3-a814-806a3df4303a">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[ucx-send_serializers2]</a></li>
                    
                    
                    
                    <li><a href="#466a3216-5095-485f-895e-81ebf8797b03">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[True-tcp]</a></li>
                    
                    
                    
                    <li><a href="#e0d26d75-ad7e-4409-aa47-ec8f52554813">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[True-ucx]</a></li>
                    
                    
                    
                    <li><a href="#7f1e5491-63f3-4952-9756-f457e8ae365d">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[False-tcp]</a></li>
                    
                    
                    
                    <li><a href="#66b39ea8-1340-48a1-92c5-0953351cc34a">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[False-ucx]</a></li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#21e0bb9c-07ad-49bd-9edd-8c172c53ce1f">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params0]</a></li>
                    
                    
                    
                    <li><a href="#a6fc9b76-50e3-40b8-b5be-60f0cf4540fc">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params1]</a></li>
                    
                    
                    
                    <li><a href="#de33a73a-db14-4761-9a2c-99d1a9a1966b">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params2]</a></li>
                    
                    
                    
                    <li><a href="#0b3b31a5-d8bd-44f7-9878-0762244c0e6b">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params3]</a></li>
                    
                    
                    
                    <li><a href="#d5497d87-4581-4f52-bf24-12365d086d6e">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params0]</a></li>
                    
                    
                    
                    <li><a href="#ba0e70b5-6c8e-4dc1-a658-700bfa3f0e81">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params1]</a></li>
                    
                    
                    
                    <li><a href="#1fdbab93-a991-4621-9480-9164bdc5c363">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params2]</a></li>
                    
                    
                    
                    <li><a href="#43890ef5-b48f-4052-99d2-14467dff2ab7">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params3]</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#52f60d72-6974-4f65-825f-85945b36edac">[F] dask_cuda.tests.test_utils : test_parse_visible_devices</a></li>
                    
                    
                    
                    
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
            
            </ul>
        </td>
    </tr>
</table>


    <div class="testsuite">
        <h2>Test Suite: pytest</h2>
        <a id="560abac1-fd77-4bd4-a7dc-2f498173f359"></a>
        
        
        <h3>Results</h3>
        <table class="proplist">
            <tr>
                <th>Duration</th><td>464.812 sec</td>
            </tr>
            <tr>
                <th>Tests</th><td>1179</td>
            </tr>
            <tr>
                <th>Failures</th><td>106</td>
            </tr>
        </table>

        <div class="testclasses">
            <h3>Tests</h3>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_cudf_builtin_spilling</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="215f3177-58a2-4190-aed8-93c7305e62a4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_is_spillable_object_when_cudf_spilling_disabled</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dda56dfc-a773-4782-ac5a-a5f0ae79eaaf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_is_spillable_object_when_cudf_spilling_enabled</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.042 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="33e2f2e4-0b09-4618-a37c-d5b7b9bebfb0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_when_cudf_spilling_is_disabled</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.006 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="79d7a6e7-6e3b-45ed-8646-d887a91725bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_step_by_step</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.04 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3865cd37-46b7-49e0-bdf8-169882a47094"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxify_host_file</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.068 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_dask_cuda_worker</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="80365f31-45e5-4828-94ce-249e301e86c2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cuda_visible_devices_and_memory_limit_and_nthreads</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.122 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9359 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9359&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9359&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2245e8f100&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f2245e8e0d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-26&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gd...&lt;distributed.comm.tcp.TCPConnector object at 0x7f2245e8f100&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.002916097640991211

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2245e8f100&gt;
address = &#39;127.0.0.1:9359&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9359, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2245e8f100&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f2245e8f100&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2245edcf70&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0,3,7,8&#34;})
    def test_cuda_visible_devices_and_memory_limit_and_nthreads(loop):  # noqa: F811
        nthreads = 4
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9359&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9359&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--device-memory-limit&#34;,
                    &#34;1 MB&#34;,
                    &#34;--nthreads&#34;,
                    str(nthreads),
                    &#34;--no-dashboard&#34;,
                    &#34;--worker-class&#34;,
                    &#34;dask_cuda.utils.MockWorker&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9359&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9359&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9359&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2245e8f100&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f2245e8e0d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9359 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="41298fb9-e663-48a7-b1c5-734b7a0a5cf4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_pool</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.111 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235876670&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f2235cf7a60&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-50&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gd...&lt;distributed.comm.tcp.TCPConnector object at 0x7f2235876670&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0011124610900878906

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235876670&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235876670&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235876670&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2235886b80&gt;

    def test_rmm_pool(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235876670&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f2235cf7a60&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f8e2c662-4e9e-4118-911f-1ee83625c188"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_managed</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.103 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235a544f0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f2235823940&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-73&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 8.630752563476562e-05

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2235a4e880&gt;

    def test_rmm_managed(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-managed-memory&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235a544f0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f2235823940&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="c8216f9f-d42c-4fd7-8640-32c92c49733d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_async</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.084 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235bfa2e0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f2235823e50&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-96&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gd...&lt;distributed.comm.tcp.TCPConnector object at 0x7f2235bfa2e0&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0014164447784423828

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235bfa2e0&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235bfa2e0&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235bfa2e0&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2235d68d30&gt;

    def test_rmm_async(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
        driver_version = rmm._cuda.gpu.driverGetVersion()
        runtime_version = rmm._cuda.gpu.runtimeGetVersion()
        if driver_version &lt; 11020 or runtime_version &lt; 11020:
            pytest.skip(&#34;cudaMallocAsync not supported&#34;)
    
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-async&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235bfa2e0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f2235823e50&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="e51bd957-eb42-4643-825d-b4e57c60f3dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_logging</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.098 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235b16a00&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f22355f8ee0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-118&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/g...&lt;distributed.comm.tcp.TCPConnector object at 0x7f2235b16a00&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0035822391510009766

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235b16a00&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235b16a00&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235b16a00&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f222d59ff70&gt;

    def test_rmm_logging(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--rmm-log-directory&#34;,
                    &#34;.&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235b16a00&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f22355f8ee0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b9e549a0-cf4b-4f91-be2d-d13f077f21fb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dashboard_address</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.116 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235692550&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f22358acf70&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-147&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.00014472007751464844

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2235ca0070&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_dashboard_address(loop):  # noqa: F811
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--dashboard-address&#34;,
                    &#34;127.0.0.1:9370&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235692550&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f22358acf70&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="979f9268-f882-4412-bdff-22dd2717f910"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unknown_argument</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>2.09 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4bb9c00b-0a38-4d39-a835-12ac80595848"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.198 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f22359dab80&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f22356a50d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-169&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.0003151893615722656

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f223590ac70&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_pre_import(loop):  # noqa: F811
        module = None
    
        # Pick a module that isn&#39;t currently loaded
        for m in pkgutil.iter_modules():
            if m.ispkg and m.name not in sys.modules.keys():
                module = m.name
                break
    
        if module is None:
            pytest.skip(&#34;No module found that isn&#39;t already loaded&#34;)
    
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--pre-import&#34;,
                    module,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f22359dab80&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f22356a50d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="25083def-a7c6-4501-8543-083d38733b34"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import_not_found</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.311 sec</td></tr>
                        
                            <tr><th>Failed</th><td>assert b&#34;ModuleNotFoundError: No module named &#39;my_module&#39;&#34; in b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;
 +  where b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39; = CompletedProcess(args=[&#39;dask&#39;, &#39;cuda&#39;, &#39;worker&#39;, &#39;127.0.0.1:9369&#39;, &#39;--pre-import&#39;, &#39;my_module&#39;], returncode=1, stdout=b&#39;&#39;, stderr=b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/minico...ts/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;).stderr</td></tr>
                        
                        
                        </table>

                        
                        <pre>@pytest.mark.timeout(20)
    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_pre_import_not_found():
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            ret = subprocess.run(
                [&#34;dask&#34;, &#34;cuda&#34;, &#34;worker&#34;, &#34;127.0.0.1:9369&#34;, &#34;--pre-import&#34;, &#34;my_module&#34;],
                capture_output=True,
            )
            assert ret.returncode != 0
&gt;           assert b&#34;ModuleNotFoundError: No module named &#39;my_module&#39;&#34; in ret.stderr
E           assert b&#34;ModuleNotFoundError: No module named &#39;my_module&#39;&#34; in b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;
E            +  where b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39; = CompletedProcess(args=[&#39;dask&#39;, &#39;cuda&#39;, &#39;worker&#39;, &#39;127.0.0.1:9369&#39;, &#39;--pre-import&#39;, &#39;my_module&#39;], returncode=1, stdout=b&#39;&#39;, stderr=b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/minico...ts/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;).stderr

dask_cuda/tests/test_dask_cuda_worker.py:246: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="c251e191-df6d-4a9f-ac48-88a8403223d0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cuda_mig_visible_devices_and_memory_limit_and_nthreads</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.006 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>No MIG devices found</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_dask_cuda_worker.py:256: No MIG devices found</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="346ee6ed-9418-4b72-a366-c58cd92bb20f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cuda_visible_devices_uuid</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f223563a610&gt;

    def test_cuda_visible_devices_uuid(loop):  # noqa: F811
&gt;       gpu_uuid = get_gpu_uuid_from_index(0)

dask_cuda/tests/test_dask_cuda_worker.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device_index = 0

    def get_gpu_uuid_from_index(device_index=0):
        &#34;&#34;&#34;Get GPU UUID from CUDA device index.
    
        Parameters
        ----------
        device_index: int or str
            The index of the device from which to obtain the UUID. Default: 0.
    
        Examples
        --------
        &gt;&gt;&gt; get_gpu_uuid_from_index()
        &#39;GPU-9baca7f5-0f2f-01ac-6b05-8da14d6e9005&#39;
    
        &gt;&gt;&gt; get_gpu_uuid_from_index(3)
        &#39;GPU-9fb42d6f-7d6b-368f-f79c-3c3e784c93f6&#39;
        &#34;&#34;&#34;
        import pynvml
    
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
&gt;       return pynvml.nvmlDeviceGetUUID(handle).decode(&#34;utf-8&#34;)
E       AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/utils.py:679: AttributeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="c9fa008b-4be5-4dd1-a20f-c56d87393fe8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_track_allocations</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.115 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f22357dcc40&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f2245e1b550&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-195&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.00012445449829101562

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2235692f40&gt;

    def test_rmm_track_allocations(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--no-dashboard&#34;,
                    &#34;--rmm-track-allocations&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f22357dcc40&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f2245e1b550&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="98eb94d3-d361-4ba5-b3af-ac724715d1cc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_cluster_configuration</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.098 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235af5e50&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f22356a50d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-221&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.00015735626220703125

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2245e11460&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_get_cluster_configuration(loop):  # noqa: F811
        pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--device-memory-limit&#34;,
                    &#34;30 B&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--rmm-maximum-pool-size&#34;,
                    &#34;3 GB&#34;,
                    &#34;--no-dashboard&#34;,
                    &#34;--rmm-track-allocations&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:373: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f2235af5e50&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f22356a50d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="98647bc1-d29e-43db-aad6-6fa7e8fe8f8c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_fraction_limits</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.11 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f22357507f0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f223589c700&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-246&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/g...&lt;distributed.comm.tcp.TCPConnector object at 0x7f22357507f0&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.00079345703125

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f22357507f0&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f22357507f0&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f22357507f0&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2235cbda30&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_worker_fraction_limits(loop):  # noqa: F811
        pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--device-memory-limit&#34;,
                    &#34;0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;0.2&#34;,
                    &#34;--rmm-maximum-pool-size&#34;,
                    &#34;0.3&#34;,
                    &#34;--no-dashboard&#34;,
                    &#34;--rmm-track-allocations&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f1fa74c45e0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f22357507f0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f223589c700&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_device_host_file</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="c7a3fba1-1529-49d9-a39c-a423df2c357e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-1-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.067 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9e33c142-5892-4056-98db-63603037ddcd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="81bfc490-218c-4d62-bc3f-f4882299da84"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-1-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.034 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a4e2238-7147-4f62-92a8-71e5c67b84d9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-10-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.011 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="220c90b5-5cdd-43a9-9276-b14ea3da45cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-10-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.009 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9ce4ffe6-4b5b-4e52-b43b-64c4a7f6e00c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-10-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.039 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="91004eaa-8049-4e47-8980-742c275ebc2e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-100-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.066 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1ef37346-e623-4081-b13c-8b168d89f644"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-100-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.071 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec4d9c81-f1a4-4db0-a6e8-c4f9ccfe54a5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-100-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.101 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="624e905c-3f80-4ee7-8493-4e791369c759"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-1-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="338c9495-9745-4b66-a45f-47e48f6133a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="90f1c993-f323-49cd-94e6-7d5aea023fad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-1-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.028 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6e1df688-9251-483e-81a1-12c7dd0959e7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-10-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f194b233-cb7a-4742-9d4a-7502079e5c59"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-10-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0e95e93e-91c3-45fd-87d1-f1170bde2d43"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-10-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.031 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="227cf4b7-ef05-4c4a-aea7-0e53ef2ff857"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-100-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.053 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6cbbc0f5-9f59-41c5-99b8-be009fabe93c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-100-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.056 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ee174355-417d-4a6f-9e9b-fef6227d8ec1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-100-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.093 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aa5f0395-b4ca-46ea-9c51-0feccd1d4825"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-1-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d3077961-7efe-4276-ad7c-c50e043a2636"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a0c3dc77-a0b9-4139-83c7-bc57830fa191"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-1-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.034 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="86f03b56-10f9-4ae3-a6a7-8520049e4dd2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-10-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.008 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb4da52f-4f2c-427a-ac94-c43b54db738a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-10-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ff81d9a1-5ad0-488c-89e6-6ef64b35f450"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-10-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.04 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e944c528-ce65-47c2-a4aa-b0aba04bacce"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-100-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.069 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="27a4f79d-6fb9-4f26-ab94-09d64ef1469b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-100-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.07 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1f047cac-fcd1-4780-9e01-15fb71228c69"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-100-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.102 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="420c7d6a-525f-45f2-818d-cb72ee9d4589"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_step_by_step</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d40463f7-f675-497e-8809-7c93f2ab0d93"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-0-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="42b3f6bd-ecd4-49bd-95c4-aa41e79675a8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-0-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a3421cae-844d-465f-93e4-897f8a01083b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-0-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="05a96d1e-fb56-4ec7-9da5-e0c47b6daa25"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-1-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c3dc163-0de0-45b0-8e79-213297b47d67"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-1-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ecfa46ef-cac6-468d-9b64-cd096d20f76d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-1-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="23aaa83b-34d7-4cee-bff8-5b0dfe856eed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-3-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="803b76ba-5ab5-4421-bf6f-d6e27d9dac7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-3-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="918573fd-01de-42f3-a406-3e6c6cbfcb1a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-3-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="24377b1b-ffcf-4207-8479-5f9e7fe74f06"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-6-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fcb74379-6c03-4c3a-ad11-6b1ce189e6c7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-6-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c454974d-0d17-4f9f-a987-7de4c48e85fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-6-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9ae3bc99-5b86-468a-bee8-ba818323db96"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-0-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9f72172c-4aa4-4929-8169-645e9d9a9703"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-0-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6558b354-2044-4993-98c2-1e50fc9b5858"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-0-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bb7a774a-1045-4672-81f7-bcfbc628c578"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-1-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.009 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6c3b1a65-ef28-4ce9-8baf-d67530963583"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-1-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="208111db-3eb4-42f1-8ecb-1dccae3f142c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-1-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.009 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="711433e6-cda2-4363-ba21-f8219a85eb1b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-3-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.026 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c788ff65-6021-40ae-bbeb-881c1ca15a55"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-3-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.029 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5595e146-af71-4b9b-b3c3-f2fb17bac012"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-3-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.026 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="33d054dc-868a-4946-af34-282256b9c04a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-6-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.051 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af2fcb63-4f61-43d6-9ae8-1cc4701416fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-6-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.05 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3831f877-dd3b-4dc9-abf9-cf4b5d6f3e50"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-6-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.05 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_dgx</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="30bf9173-adf6-4c57-a910-3764c2c0d158"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_default</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.074 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-1&#39; pid=71732 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_default():
        p = mp.Process(target=_test_default)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-1&#39; pid=71732 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:73: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0a04eb59-5414-4113-9dad-6d9de4bc53be"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_tcp_over_ucx</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.779 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-2&#39; pid=71859 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_tcp_over_ucx():
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        p = mp.Process(target=_test_tcp_over_ucx)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-2&#39; pid=71859 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:102: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="7fa90a61-6dbd-4b76-9ea1-1f177cea6a43"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_tcp_only</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.568 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-3&#39; pid=71945 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_tcp_only():
        p = mp.Process(target=_test_tcp_only)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-3&#39; pid=71945 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:117: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a8f8599a-1144-429b-ab33-cb65ecd503bb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.092 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-4&#39; pid=72031 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: False, &#39;enable_nvlink&#39;: False, &#39;enable_rdmacm&#39;: False}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-4&#39; pid=72031 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="417f88b2-3de4-4dff-8799-7eb90f2cc3f1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.621 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-5&#39; pid=72130 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: True, &#39;enable_nvlink&#39;: True, &#39;enable_rdmacm&#39;: False}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-5&#39; pid=72130 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="370d06d8-a218-4da4-8642-fdaa5db2d632"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.9 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-6&#39; pid=72271 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: True, &#39;enable_nvlink&#39;: False, &#39;enable_rdmacm&#39;: True}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-6&#39; pid=72271 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="bca0824a-424a-4d18-9409-4e85803c0e44"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>4.038 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-7&#39; pid=72365 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: True, &#39;enable_nvlink&#39;: True, &#39;enable_rdmacm&#39;: True}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-7&#39; pid=72365 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="32281558-de8d-430c-be37-996b3695e0ab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.683 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-8&#39; pid=72455 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: None, &#39;enable_nvlink&#39;: None, &#39;enable_rdmacm&#39;: None}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-8&#39; pid=72455 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_explicit_comms</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="a7ff0e77-a18a-4435-bce0-52573b584ca3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cluster[tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.098 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-9&#39; pid=72591 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;tcp&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_local_cluster(protocol):
        p = mp.Process(target=_test_local_cluster, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-9&#39; pid=72591 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:60: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b4d3fec5-87c5-4120-9d29-e3106baa25ff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cluster[ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.362 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-10&#39; pid=72675 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;ucx&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_local_cluster(protocol):
        p = mp.Process(target=_test_local_cluster, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-10&#39; pid=72675 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:60: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a94c63a1-9918-4b1c-ba8b-8e67422de916"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_merge_empty_partitions</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.065 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-11&#39; pid=72764 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_dataframe_merge_empty_partitions():
        # Notice, we use more partitions than rows
        p = mp.Process(target=_test_dataframe_merge_empty_partitions, args=(2, 4))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-11&#39; pid=72764 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:94: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8fc1e345-5218-474c-9fd6-9b540a891ffc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.104 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-12&#39; pid=72851 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-12&#39; pid=72851 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="355390f9-f977-47ef-a04a-6f3c02d200a1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.097 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-13&#39; pid=72980 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-13&#39; pid=72980 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="472bd264-b1dd-4de3-a911-9ff39bf1b440"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-pandas-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.113 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-14&#39; pid=73066 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-14&#39; pid=73066 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="49603f52-0735-4206-a919-563ab41cae7d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.806 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-15&#39; pid=73154 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-15&#39; pid=73154 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ae6c8025-4050-4ceb-876f-df15eabb3878"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.666 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-16&#39; pid=73375 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-16&#39; pid=73375 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8d8e9c10-b9ec-43c7-a337-2c16ece0fe4f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-cudf-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.574 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-17&#39; pid=73643 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-17&#39; pid=73643 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="66dcf089-2894-4d3d-8752-179c388d4340"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.08 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-18&#39; pid=73860 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-18&#39; pid=73860 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="24399cb6-1251-45ef-867b-b4fc9f28029b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.067 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-19&#39; pid=73946 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-19&#39; pid=73946 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a87a1a06-3090-4010-8071-7261cd8cfbe1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-pandas-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.088 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-20&#39; pid=74085 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-20&#39; pid=74085 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="59667a4b-e3f8-49e4-a355-4191da9f2bcf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.613 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-21&#39; pid=74171 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-21&#39; pid=74171 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b4f70239-4e01-4b36-8743-c963b7c7a5e5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.732 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-22&#39; pid=74390 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-22&#39; pid=74390 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="94f2a235-def8-4fbb-812f-4d0132eb526a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-cudf-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.683 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-23&#39; pid=74654 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-23&#39; pid=74654 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0b68eb56-bbb3-4bb3-b328-f37fa23c122d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dask_use_explicit_comms[True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.018 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCluster(98e83156, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f22475c0ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f22475c0ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f22475c0ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f223582c200&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2235ca23c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f22356117f0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2235817140&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

in_cluster = True

    @pytest.mark.parametrize(&#34;in_cluster&#34;, [True, False])
    def test_dask_use_explicit_comms(in_cluster):
        def check_shuffle():
            &#34;&#34;&#34;Check if shuffle use explicit-comms by search for keys named
            &#39;explicit-comms-shuffle&#39;
            &#34;&#34;&#34;
            name = &#34;explicit-comms-shuffle&#34;
            ddf = dd.from_pandas(pd.DataFrame({&#34;key&#34;: np.arange(10)}), npartitions=2)
            with dask.config.set(explicit_comms=False):
                res = ddf.shuffle(on=&#34;key&#34;, npartitions=4, shuffle=&#34;tasks&#34;)
                assert all(name not in str(key) for key in res.dask)
            with dask.config.set(explicit_comms=True):
                res = ddf.shuffle(on=&#34;key&#34;, npartitions=4, shuffle=&#34;tasks&#34;)
                if in_cluster:
                    assert any(name in str(key) for key in res.dask)
                else:  # If not in cluster, we cannot use explicit comms
                    assert all(name not in str(key) for key in res.dask)
    
            if in_cluster:
                # We check environment variables by setting an illegal batchsize
                with patch.dict(
                    os.environ,
                    {&#34;DASK_EXPLICIT_COMMS&#34;: &#34;1&#34;, &#34;DASK_EXPLICIT_COMMS_BATCHSIZE&#34;: &#34;-2&#34;},
                ):
                    dask.config.refresh()  # Trigger re-read of the environment variables
                    with pytest.raises(ValueError, match=&#34;explicit-comms-batchsize&#34;):
                        ddf.shuffle(on=&#34;key&#34;, npartitions=4, shuffle=&#34;tasks&#34;)
    
        if in_cluster:
&gt;           with LocalCluster(
                protocol=&#34;tcp&#34;,
                dashboard_address=None,
                n_workers=2,
                threads_per_worker=1,
                processes=True,
            ) as cluster:

dask_cuda/tests/test_explicit_comms.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/local.py:253: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:286: in __init__
    self.sync(self._start)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:338: in sync
    return sync(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCluster(98e83156, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="11ab09d5-0c20-489f-825e-99e0af4ed69e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dask_use_explicit_comms[False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="5f13cdf7-dbd5-4bc9-aeb0-cdeabf3d7d64"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.116 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-24&#39; pid=74876 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-24&#39; pid=74876 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d1673323-b5b6-4a6f-8e53-2d7d534b8ca4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.132 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-25&#39; pid=74963 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-25&#39; pid=74963 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="474141ab-bad5-48eb-899c-c88ed2871edd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-pandas-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.126 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-26&#39; pid=75052 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-26&#39; pid=75052 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ca01a75f-87c8-46f4-8c28-84a93869b032"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.967 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-27&#39; pid=75179 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-27&#39; pid=75179 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8d339e4a-8066-460a-a299-f3ea37170e93"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.667 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-28&#39; pid=75399 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-28&#39; pid=75399 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="fef0bc65-4f5e-410b-9728-e4f83f3ef266"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-cudf-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.659 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-29&#39; pid=75615 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-29&#39; pid=75615 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="24b1c727-7bd8-4259-bbff-088be70f8b28"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.134 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-30&#39; pid=75878 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-30&#39; pid=75878 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8b11706e-f358-45e7-9473-8e7a8ad0b4c5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.216 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-31&#39; pid=75964 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-31&#39; pid=75964 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="5041e605-efcc-4ede-9e5e-81dc2591dbaa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-pandas-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.605 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-32&#39; pid=76051 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-32&#39; pid=76051 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="3a6eb307-7e79-4b97-8aa9-f19cd0475cae"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.912 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-33&#39; pid=76139 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-33&#39; pid=76139 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ebb191fc-eb92-4032-a8c7-8f395dd3623b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.711 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-34&#39; pid=76401 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-34&#39; pid=76401 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="717c7604-23b8-4a56-98e7-d110d5ba6233"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-cudf-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.665 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-35&#39; pid=76621 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-35&#39; pid=76621 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="9f06fc7b-e517-4b4b-80d5-0fed2c192b39"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_jit_unspill[tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.587 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-36&#39; pid=76837 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;tcp&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_jit_unspill(protocol):
        pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_jit_unspill, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-36&#39; pid=76837 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:313: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="1330eeac-2b95-4816-8559-d53cb202709f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_jit_unspill[ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.571 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-37&#39; pid=77097 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;ucx&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_jit_unspill(protocol):
        pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_jit_unspill, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-37&#39; pid=77097 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:313: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="1e4c315e-db7d-4e79-a6b1-51ff02d19231"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_lock_workers</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCluster(849adcca, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2235a85040&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2235a85040&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2235a85040&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2245ea7840&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2235ab5800&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f2235ae0fa0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2235c10d40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    def test_lock_workers():
        &#34;&#34;&#34;
        Testing `run(...,lock_workers=True)` by spawning 30 runs with overlapping
        and non-overlapping worker sets.
        &#34;&#34;&#34;
        try:
            from distributed import MultiLock  # noqa F401
        except ImportError as e:
            pytest.skip(str(e))
    
&gt;       with LocalCluster(
            protocol=&#34;tcp&#34;,
            dashboard_address=None,
            n_workers=4,
            threads_per_worker=5,
            processes=True,
        ) as cluster:

dask_cuda/tests/test_explicit_comms.py:341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/local.py:253: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:286: in __init__
    self.sync(self._start)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:338: in sync
    return sync(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCluster(849adcca, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_gds</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-skipped">
                        <a id="94a4a208-53ba-4bac-aa88-0781b3884692"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[True-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>GDS not available</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_gds.py:36: GDS not available</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="ef2a90d5-cf7a-490c-b3f5-38c8dd826b8d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[True-cudf]</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>GDS not available</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_gds.py:36: GDS not available</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="2299c290-26cf-41f7-9d71-c1fd6895df8e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[True-numba.cuda]</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>GDS not available</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_gds.py:36: GDS not available</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b964a54a-c16d-47c7-bc94-610e771d030d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[False-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3ef56dde-9d08-4d79-b4a7-e3fb2a93101d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[False-cudf]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b01f0a76-2da0-4fc9-ae6e-156e7991acc4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[False-numba.cuda]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_initialize</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="5e07880a-6056-48cd-9cf1-02fcef7c87a6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_tcp</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.702 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-38&#39; pid=77313 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_initialize_ucx_tcp():
        p = mp.Process(target=_test_initialize_ucx_tcp)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-38&#39; pid=77313 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:55: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b8f77a56-c325-456e-8bfc-5f61bcccbc30"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_nvlink</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.86 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-39&#39; pid=77409 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_initialize_ucx_nvlink():
        p = mp.Process(target=_test_initialize_ucx_nvlink)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-39&#39; pid=77409 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:91: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="47bbe595-79ee-48c2-b07b-30645ec26712"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_infiniband</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.958 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-40&#39; pid=77545 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>@pytest.mark.skipif(
        &#34;ib0&#34; not in psutil.net_if_addrs(), reason=&#34;Infiniband interface ib0 not found&#34;
    )
    def test_initialize_ucx_infiniband():
        p = mp.Process(target=_test_initialize_ucx_infiniband)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-40&#39; pid=77545 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:130: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="7bf66402-5b07-4159-baf7-1b5b3d588073"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_all</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.195 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-41&#39; pid=77634 parent=67615 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_initialize_ucx_all():
        p = mp.Process(target=_test_initialize_ucx_all)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-41&#39; pid=77634 parent=67615 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:168: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_local_cuda_cluster</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="499dc81f-46d7-4935-b036-fbcd1b9a4994"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cuda_cluster</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.528 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(51184766, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2235a859e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2235a859e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2235a859e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202a5d2c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202a5cf00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f2202a58d60&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202bbadc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_local_cuda_cluster():
&gt;       async with LocalCUDACluster(
            scheduler_port=0, asynchronous=True, device_memory_limit=1
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(51184766, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="3eb63595-1d90-48b0-b109-8cd62e07fed8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_with_subset_of_cuda_visible_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(075f4084, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029ec1c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029e4dc0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f22029e72e0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202a6ccc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @pytest.mark.filterwarnings(&#34;ignore:Cannot get CPU affinity&#34;)
    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0,3,6,8&#34;})
    @gen_test(timeout=20)
    async def test_with_subset_of_cuda_visible_devices():
&gt;       async with LocalCUDACluster(
            scheduler_port=0,
            asynchronous=True,
            device_memory_limit=1,
            worker_class=MockWorker,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(075f4084, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="845a661b-0069-4355-b3ab-352c037de6aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_protocol[ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.257 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(ce32201e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2235a859e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2235a859e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2235a859e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202ae1880&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202ae1200&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f2202ad67c0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f22029b66c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;ucx&#34;, None])
    @gen_test(timeout=20)
    async def test_ucx_protocol(protocol):
        pytest.importorskip(&#34;ucp&#34;)
    
        initialize(enable_tcp_over_ucx=True)
&gt;       async with LocalCUDACluster(
            protocol=protocol, enable_tcp_over_ucx=True, asynchronous=True, data=dict
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(ce32201e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4b5c21fd-c1ef-4769-95fe-1f511aaa134e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_protocol[None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.023 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(939ffa64, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029a0f40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029a0700&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f2202a6e5e0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202a496c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = None

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;ucx&#34;, None])
    @gen_test(timeout=20)
    async def test_ucx_protocol(protocol):
        pytest.importorskip(&#34;ucp&#34;)
    
        initialize(enable_tcp_over_ucx=True)
&gt;       async with LocalCUDACluster(
            protocol=protocol, enable_tcp_over_ucx=True, asynchronous=True, data=dict
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(939ffa64, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d0df4594-ba2b-46af-96e4-9b7a1d8c6af6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_protocol_type_error</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="abef9fc5-17b8-4a38-b364-4bbe41b94d31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_n_workers</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(47b58ebb, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9a0cb80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9ad1200&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f99da5b0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f22029bae40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_n_workers():
&gt;       async with LocalCUDACluster(
            CUDA_VISIBLE_DEVICES=&#34;0,1&#34;, worker_class=MockWorker, asynchronous=True
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(47b58ebb, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f9ff6c84-8835-434a-8d14-e6f98bab958b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_threads_per_worker_and_memory_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(c9d4ee4a, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029b3080&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029b3fc0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f997f7c0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202a7a140&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_threads_per_worker_and_memory_limit():
&gt;       async with LocalCUDACluster(threads_per_worker=4, asynchronous=True) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(c9d4ee4a, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b01cccf0-f199-4096-8c71-28b5412bee86"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_no_memory_limits_cluster</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(e7af0dc0, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029d0e40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029d0680&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9c17640&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202a73040&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_no_memory_limits_cluster():
    
&gt;       async with LocalCUDACluster(
            asynchronous=True, memory_limit=None, device_memory_limit=None
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(e7af0dc0, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6091f805-dd2b-4649-a927-e19734e24e3e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_no_memory_limits_cudaworker</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(4ad7a24a, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9776900&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9777e80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f99da400&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202a7bec0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_no_memory_limits_cudaworker():
    
&gt;       async with LocalCUDACluster(
            asynchronous=True,
            memory_limit=None,
            device_memory_limit=None,
            n_workers=1,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:150: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(4ad7a24a, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="dd173152-7bac-4ef4-8544-153751b82376"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_all_to_all</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(63b93db5, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f97ac840&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f97ac500&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9bbc070&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202ac9a40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_all_to_all():
&gt;       async with LocalCUDACluster(
            CUDA_VISIBLE_DEVICES=&#34;0,1&#34;, worker_class=MockWorker, asynchronous=True
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(63b93db5, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ef754421-3e4c-453f-9fbc-20cda4464ecd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_pool</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(c7350658, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9c15600&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9c15480&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f2235a546a0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202990a40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_pool():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(c7350658, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d9d71bdc-906d-4e5d-b05c-6071f7a63009"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_maximum_poolsize_without_poolsize_error</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="5dd5e540-1aab-4ff4-948e-52ed8321cc8b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_managed</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(20cf859b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202a65d00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202aeb300&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f220278b370&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202af5ac0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_managed():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_managed_memory=True,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(20cf859b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="7e24662d-71eb-486e-a0fa-7c02fcc0ff6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_async</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d66eff89, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9a83c40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9a839c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f22029eaa60&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f22029858c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_async():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
        driver_version = rmm._cuda.gpu.driverGetVersion()
        runtime_version = rmm._cuda.gpu.runtimeGetVersion()
        if driver_version &lt; 11020 or runtime_version &lt; 11020:
            pytest.skip(&#34;cudaMallocAsync not supported&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_async=True,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d66eff89, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4dd4b3c5-aa24-4f2e-b221-7e47036b9335"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_logging</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.226 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(957381a9, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e92aed40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e92aeb00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9909af0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f220299d840&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_logging():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            rmm_log_directory=&#34;.&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(957381a9, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="31450e30-ca4c-4bbf-8dab-b2d5d963245b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.1 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(4fb64475, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e9049180&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e9049f80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9688ee0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202985840&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_pre_import():
        module = None
    
        # Pick a module that isn&#39;t currently loaded
        for m in pkgutil.iter_modules():
            if m.ispkg and m.name not in sys.modules.keys():
                module = m.name
                break
    
        if module is None:
            pytest.skip(&#34;No module found that isn&#39;t already loaded&#34;)
    
&gt;       async with LocalCUDACluster(
            n_workers=1,
            pre_import=module,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:274: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(4fb64475, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="7699f658-78a0-4a2d-9372-362e6e9b1a66"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import_not_found</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(802674c7, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202857d40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029d18c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f2202619790&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f22029a8540&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    def test_pre_import_not_found():
        async def _test_pre_import_not_found():
            with raises_with_cause(RuntimeError, None, ImportError, None):
                await LocalCUDACluster(
                    n_workers=1,
                    pre_import=&#34;my_module&#34;,
                    asynchronous=True,
                    silence_logs=True,
                )
    
&gt;       asyncio.run(_test_pre_import_not_found())

dask_cuda/tests/test_local_cuda_cluster.py:296: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/asyncio/runners.py:44: in run
    return loop.run_until_complete(main)
../../../miniconda3/envs/gdf/lib/python3.8/asyncio/base_events.py:616: in run_until_complete
    return future.result()
dask_cuda/tests/test_local_cuda_cluster.py:289: in _test_pre_import_not_found
    await LocalCUDACluster(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(802674c7, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="e6c11353-71b8-4c33-a96e-9987899676d4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cluster_worker</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(186b3c22, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22026effc0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22026ef2c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f220266d370&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f98e3e40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_cluster_worker():
&gt;       async with LocalCUDACluster(
            scheduler_port=0,
            asynchronous=True,
            device_memory_limit=1,
            n_workers=1,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(186b3c22, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="923a9f7a-f12b-4819-ba5a-5154d2623595"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_available_mig_workers</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>No MIG devices found</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_local_cuda_cluster.py:321: No MIG devices found</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="cf3a02a4-25d8-4ca7-9d0b-7086e63746f6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gpu_uuid</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>@gen_test(timeout=20)
    async def test_gpu_uuid():
&gt;       gpu_uuid = get_gpu_uuid_from_index(0)

dask_cuda/tests/test_local_cuda_cluster.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device_index = 0

    def get_gpu_uuid_from_index(device_index=0):
        &#34;&#34;&#34;Get GPU UUID from CUDA device index.
    
        Parameters
        ----------
        device_index: int or str
            The index of the device from which to obtain the UUID. Default: 0.
    
        Examples
        --------
        &gt;&gt;&gt; get_gpu_uuid_from_index()
        &#39;GPU-9baca7f5-0f2f-01ac-6b05-8da14d6e9005&#39;
    
        &gt;&gt;&gt; get_gpu_uuid_from_index(3)
        &#39;GPU-9fb42d6f-7d6b-368f-f79c-3c3e784c93f6&#39;
        &#34;&#34;&#34;
        import pynvml
    
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
&gt;       return pynvml.nvmlDeviceGetUUID(handle).decode(&#34;utf-8&#34;)
E       AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/utils.py:679: AttributeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ea07f764-eded-4486-96bb-aabfba620a2b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_track_allocations</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(22229bb5, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202ae1980&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202ae1800&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f22029de4c0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f99f4a40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_track_allocations():
        rmm = pytest.importorskip(&#34;rmm&#34;)
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            asynchronous=True,
            rmm_track_allocations=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(22229bb5, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="aa01c178-f8f2-450d-985c-502175078228"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_cluster_configuration</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d0ca699e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202a43780&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202a43300&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f98a88e0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f97b96c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_get_cluster_configuration():
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            rmm_maximum_pool_size=&#34;3GB&#34;,
            device_memory_limit=&#34;30B&#34;,
            CUDA_VISIBLE_DEVICES=&#34;0&#34;,
            scheduler_port=0,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:384: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d0ca699e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="00dc3616-203e-4e32-998c-04ebcf895a4c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_fraction_limits</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(e852fdf4, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029a5980&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f222d5ca180&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f95fa460&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f22027d4d40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_worker_fraction_limits():
&gt;       async with LocalCUDACluster(
            device_memory_limit=0.1,
            rmm_pool_size=0.2,
            rmm_maximum_pool_size=0.3,
            CUDA_VISIBLE_DEVICES=&#34;0&#34;,
            scheduler_port=0,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:402: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(e852fdf4, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="2bad76ca-ee2a-4b68-b334-89d7c067e9d3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_print_cluster_config</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>could not import &#39;rich&#39;: No module named &#39;rich&#39;</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_local_cuda_cluster.py:426: could not import &#39;rich&#39;: No module named &#39;rich&#39;</pre>
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_proxify_host_file</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="359ba1cc-6d95-43b9-bc59-4e8e76b61ac7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_one_dev_item_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7e1e9f2-60c2-40a3-969b-95eb25649272"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_one_item_host_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c89ddd2f-d03a-4aeb-b850-b07c3c390d3b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_spill_on_demand</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>7.1 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="70f86b70-5f96-445a-8374-cd1c9725579f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cuda_cluster[True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.024 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(5bdf5e9c, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202b1b580&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22029ec700&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9a01070&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9b78140&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = True

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(5bdf5e9c, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b7a21fb7-91d1-479c-b9fa-6bf13eca9a17"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cuda_cluster[False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(97680989, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09b40&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09b40&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09b40&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f974ef00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f97be9c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9b67820&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9b8ce40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = False

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(97680989, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="259157d4-3125-4fdc-a0e0-6b5a740c9a0c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframes_share_dev_mem</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c3a4c1c0-0dd7-454f-b21b-1c7c4b2d74eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_get_device_memory_objects</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc2f75eb-9694-4f3e-aea5-9abeb0859d3e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_externals</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7afcbdf3-e5f3-48ae-bfcd-caca6140eade"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_incompatible_types</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="9bdf3fa3-4288-45ec-b4ac-6d59b0f7d956"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[True-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(1caf57f9, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f99459c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9927c00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f97cb1f0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9b899c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = True, npartitions = 1

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(1caf57f9, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="cc411ed3-79da-4d39-b7ce-64418f877c1a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[True-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(45bda478, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f220267ebc0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f220267e540&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f99405e0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21e94ae9c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = True, npartitions = 2

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(45bda478, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="3dc66fbe-2f62-4cce-9125-f878c4d7f587"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[True-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.123 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d8fe443d, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e948afc0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e948a080&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9a68190&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21e94ae940&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = True, npartitions = 3

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d8fe443d, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="93f263ce-59ad-4db5-a2fd-be187ec56b82"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[False-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(87397c7d, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09b40&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09b40&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09b40&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202a5b240&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202988d00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f997f3a0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f22028272c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = False, npartitions = 1

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(87397c7d, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b44563d0-d207-4c6c-b6c5-58e131473314"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[False-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(54e92842, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f985b700&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f985bd00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9ad0f10&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9b284c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = False, npartitions = 2

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(54e92842, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="fec28444-95e2-4793-bfcf-9ea8e75c8e5a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[False-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d742cec5, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e94b7540&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e94b77c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9851df0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9b48e40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = False, npartitions = 3

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d742cec5, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0f1a59d6-0382-4fc0-9a22-c6586a9e5538"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_force_spill_to_disk</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(0fd9bda4, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e948a9c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e948aec0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9640df0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9b2f340&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=60)
    async def test_worker_force_spill_to_disk():
        &#34;&#34;&#34;Test Dask triggering CPU-to-Disk spilling&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, device_memory_limit=&#34;1MB&#34;, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(0fd9bda4, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="edcb805f-372b-42c3-a172-40b5431aab62"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_on_demand_debug_info</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.019 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(3bf77eee, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09b40&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09b40&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09b40&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f97c4580&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9b986c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9a09fa0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9b3f9c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    def test_on_demand_debug_info():
        &#34;&#34;&#34;Test worker logging when on-demand-spilling fails&#34;&#34;&#34;
        rmm = pytest.importorskip(&#34;rmm&#34;)
        if not hasattr(rmm.mr, &#34;FailureCallbackResourceAdaptor&#34;):
            pytest.skip(&#34;RMM doesn&#39;t implement FailureCallbackResourceAdaptor&#34;)
    
        rmm_pool_size = 2**20
    
        def task():
            (
                rmm.DeviceBuffer(size=rmm_pool_size // 2),
                rmm.DeviceBuffer(size=rmm_pool_size // 2),
                rmm.DeviceBuffer(size=rmm_pool_size),  # Trigger OOM
            )
    
&gt;       with dask_cuda.LocalCUDACluster(
            n_workers=1,
            jit_unspill=True,
            rmm_pool_size=rmm_pool_size,
            rmm_maximum_pool_size=rmm_pool_size,
            rmm_track_allocations=True,
        ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/local_cuda_cluster.py:336: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/local.py:253: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:286: in __init__
    self.sync(self._start)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:338: in sync
    return sync(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(3bf77eee, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_proxy</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="26a08922-8f4c-464c-a66b-391047185e1c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object[None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="43c5be88-706e-48b6-b318-13047a4c054f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object[serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="168a527c-9f2f-480b-9805-5f67e1e781fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object[serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9b37d21a-987e-4db2-9c29-6b2a0f75a85c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_serializer</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9942d034-4d54-46ac-b6cf-abe83bc5750d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="820306f3-efe7-480f-b3f9-fab24fba3285"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[None-serializers_first1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f51df3e8-4b90-48fa-a4bd-29c1c59702ac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[None-serializers_first2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="32b5497f-ec7d-4ce0-aed1-361fc9ee9ef7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second1-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d0b58fe3-79b8-4ea9-b9a8-6edfdba4e5c6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second1-serializers_first1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d253e279-b085-4a3f-9d63-c3b4f4b31878"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second1-serializers_first2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d91e7f7d-89b7-4d5a-a76c-765ea0b9186c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second2-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3fa25f8d-28ab-4fd0-8108-89d53271e2c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second2-serializers_first1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="573b7776-754f-4c60-b847-cd8ba5dc7281"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second2-serializers_first2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="72f18af5-c10b-4d59-a08f-bf58cfa9a7d0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[numpy-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="52668f53-d963-4b51-ba5c-f336423764cc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[numpy-serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7d1c95c6-aba9-4e0b-a8c5-3d2290ee5365"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[numpy-serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.018 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e33f8873-7897-4b7f-bfea-7f38b447f709"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[cupy-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.114 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1901b797-e3b6-47ae-ac3f-f2e3c6156e28"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[cupy-serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.064 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="539cbd62-7b7c-42c0-9b20-1ca906280435"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[cupy-serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.075 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4eb9bf33-b3fa-4c99-a423-f2f38580135d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_cudf[None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4cf6fce0-b55c-411f-85b8-aa6cc86544c0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_cudf[serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e3a6b96e-78a2-4608-8976-c369f48d6b14"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_cudf[serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e1f2791-3d1d-4ac2-86b2-96dba7a58a4e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6ed7d27f-92a7-469a-99bf-f2f4d721d4f0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8a600ad2-8414-460f-ac8e-823ef3bcf2b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1e10c61d-9c04-47b2-8db1-4f0a630a81fb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2bf9a23d-2b22-4181-8bac-12e3746d36ab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cb5f74f6-79ed-4044-9eb5-b08f29a9888a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0a11c8ff-6c4b-4ca5-bbeb-abcd9768ad6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dbd76310-f04f-4e2d-aaa9-c4e5775c21f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ef490fe0-7065-49b6-b8ba-0dd7c71cfbad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_fixed_attribute_length[numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cb419e7b-98be-4c25-abcb-857bd472ed4b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_fixed_attribute_length[cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7e69f8dd-e2c3-4a2a-8470-1b0404f6cb60"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_fixed_attribute_name</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6aa8bb30-f65d-464b-acc3-e5aa900fe4d5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_spilling_local_cuda_cluster[True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(ed5d829d, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f97b8340&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f97b8180&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9a53be0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f22026abb40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = True

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_spilling_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(ed5d829d, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="34572f50-8f1f-4320-92b1-8c07daf62c05"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_spilling_local_cuda_cluster[False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(30d43374, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9b9cd80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9b9c600&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f22026191c0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21e94be340&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = False

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_spilling_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(30d43374, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8c97ee80-5d58-4239-bce0-9e28caea8399"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_to_disk[obj0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3ba57dcb-1e86-4981-91dc-4c4342a3b3ce"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_to_disk[obj1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="372f4e4f-3e5c-44d8-a45c-63e767aa43e9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_multiple_deserializations[dask]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="578748c4-b34d-4cbb-bf3c-dd6554184244"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_multiple_deserializations[pickle]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dbbbbea3-4104-4cf1-bdd7-bd2a12ffb37d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_multiple_deserializations[disk]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9ccafd11-0f4f-48f0-bca1-780de0518792"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-None-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0875226a-02f0-4082-bb8c-7565ce5904d4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-None-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c9ded2d6-1d77-480c-b755-1ae8a2ba361a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="616903c6-edbf-48c9-a886-2dea92238b73"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers1-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a61fe341-6d29-45e4-976a-7492649e73e7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers2-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d15f593d-c501-4f6a-9a26-9e5c420bf4e6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers2-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6e375fef-2f07-4855-afa9-1b94c7f07535"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers3-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="de3be6ce-68a9-4190-8022-14319ae843cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers3-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9be47fb1-fc3b-466d-84e2-6973532bbda8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers4-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af668e9b-5191-405a-af4d-16cec12c0987"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers4-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c3a5e6b-1a6d-4806-aaa0-4ce32c496e02"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-None-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1489aac8-482e-4a22-9eee-0e02defbd33f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-None-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.621 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b5f10265-c05d-478c-a9be-83c8910776a1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7427f0bb-17ac-446f-810b-71d9f1b1fd1a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers1-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.676 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a7f08fe-1fc5-4b6b-9699-f9b1068a1a19"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers2-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ca913be3-c79f-479e-9ae3-ea59a31e7e61"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers2-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.625 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5ca23284-6783-4e92-81fa-63465d4ba533"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers3-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5e75d121-8d3e-4f03-98b1-4f39fd36a26e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers3-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.671 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ae3c834-856a-4461-88da-e1b0a57006ec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers4-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9653b47d-e9d9-4586-92c5-5a5b5baf33fe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers4-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.623 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="cc15560e-2364-4fa7-87b9-cb6aa1133f8f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[tcp-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(c66eb5ad, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f96044c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9604680&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f22026bfd90&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21e94b8f40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, send_serializers = None

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(c66eb5ad, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a471dc46-16a6-4604-8c47-c96f5903fa27"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[tcp-send_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(54cf4a72, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f96c15c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f96c1080&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21e900d3a0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f96a9540&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, send_serializers = (&#39;dask&#39;, &#39;pickle&#39;)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(54cf4a72, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="1011cbbf-7894-4496-8e72-78b34c5703fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[tcp-send_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(58c846f3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e8e40400&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e8e40c40&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21e8c07d30&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21e9236dc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, send_serializers = (&#39;cuda&#39;,)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(58c846f3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="1479fe6c-6653-4da4-8213-f1246feee43e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[ucx-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(8f3f4118, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e94ff080&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f98ce480&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9601880&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f96db7c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, send_serializers = None

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(8f3f4118, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4b311b4a-543b-4dfa-8f1e-a33a75da6960"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[ucx-send_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(ed43436c, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e90c09c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e90c0a40&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f972aa00&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21e920d440&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, send_serializers = (&#39;dask&#39;, &#39;pickle&#39;)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(ed43436c, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="de2c5b7b-7b96-44d3-a814-806a3df4303a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[ucx-send_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(08ac9055, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202a51a00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22027886c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f2202619d30&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f96dac40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, send_serializers = (&#39;cuda&#39;,)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(08ac9055, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="466a3216-5095-485f-895e-81ebf8797b03"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[True-tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(ae102feb, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202803f40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f99e4d80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f2202998910&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f22026adc40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, shared_fs = True

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(ae102feb, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="e0d26d75-ad7e-4409-aa47-ec8f52554813"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[True-ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(4d9ae7ad, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e935c480&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e935cd40&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21e923dca0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21e923f740&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, shared_fs = True

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(4d9ae7ad, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="7f1e5491-63f3-4952-9756-f457e8ae365d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[False-tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(f31dfc26, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22027fa0c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f97be0c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21e9092700&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f22026876c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, shared_fs = False

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(f31dfc26, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="66b39ea8-1340-48a1-92c5-0953351cc34a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[False-ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.091 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(b8bec0c6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e91ae680&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e93e8b40&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9688910&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f220271f8c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, shared_fs = False

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(b8bec0c6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f81a7eb5-f5d7-4976-a5a7-61b8e5ba35b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[None-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2afb1559-e828-4f07-b0ea-aa1e82570375"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[None-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="37728d11-e2ad-4e40-8b16-989a04e7fa19"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers1-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="665e8135-4899-4bc4-8f29-78ee034dbeaa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers1-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="226aed88-edd9-42b9-94dc-6af66728ab22"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers2-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1731042e-de03-442e-adb5-d4363b7754f1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers2-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dfa67ac6-58bd-4398-aa63-c17fbe787994"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers3-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f5d56cfe-dc64-4a0b-9ddb-069d0682dc56"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers3-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="89551506-9328-4897-afcf-692ed9e89517"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pandas</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5332e0ea-fe6d-429e-a931-b3ae02c98098"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_from_cudf_of_proxy_object</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0274c384-fda6-4651-8c35-98c2c0c838b5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_parquet</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.013 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="093ab30e-67a8-4c22-8d2c-6f3497283578"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_assignments</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e238aca-5c86-4254-b7d3-df673acfb633"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_concatenate3_of_proxied_cupy_arrays</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="80144189-b218-48ed-b79b-1f795e9d6dda"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_tensordot_of_proxied_cupy_arrays</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="982f1a63-46ac-498f-be18-6c7014cf03ef"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_einsum_of_proxied_cupy_arrays</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.012 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1ccf1eb9-5dfe-4969-ac4e-78ba77e59274"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[less]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="445e6a07-5969-445a-9cd1-5929a6337e1c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[less_equal]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="85a831c5-dc5d-4dfb-9384-26ff83a7ee56"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[greater]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="94d5255a-ecb3-4b30-87a2-90beb40c5644"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[greater_equal]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d2c7baec-7a16-465c-afdb-654b4600fd56"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[equal]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6e159b6d-31f8-4404-ab89-f5714b939372"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_copy</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="36c9d653-bf0c-4886-94c9-847ded967bc7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_fillna</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d8199e08-27fb-44aa-8627-1aab3a574c42"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_sizeof_cupy</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.032 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="713f9698-f1cc-4630-964d-98eee2449828"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_sizeof_cudf</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.529 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0020aa84-eec8-4271-bc4e-b3eea69ef874"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_broadcast_to</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.015 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="d2456ea2-15f0-4d81-8361-627a6715cae6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_matmul</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>See: https://github.com/rapidsai/dask-cuda/issues/995</td></tr>
                        
                        </table>

                        
                        
                        <pre>skipped</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="4d9bcc6a-0d1e-4c65-bb34-1f6e4e1c69e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_imatmul</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>See: https://github.com/rapidsai/dask-cuda/issues/995</td></tr>
                        
                        </table>

                        
                        
                        <pre>skipped</pre>
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_spill</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="21e0bb9c-07ad-49bd-9edd-8c172c53ce1f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(62a9dd81, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9ad1ec0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f969ff00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f99042e0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f2202724ac0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(62a9dd81, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a6fc9b76-50e3-40b8-b5be-60f0cf4540fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(4074891f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f220273b1c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f220273b100&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f9ce41f0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9a89b40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(4074891f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="de33a73a-db14-4761-9a2c-99d1a9a1966b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(5c3c432f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9ab8a80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9833480&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21e900d5e0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9a8b740&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: None, &#39;host_target&#39;: None, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(5c3c432f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0b3b31a5-d8bd-44f7-9878-0762244c0e6b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.006 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(75247a68, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9964900&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9964f40&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f97e82e0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9a988c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(75247a68, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d5497d87-4581-4f52-bf24-12365d086d6e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(b13b13e0, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f998a500&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f998a1c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21f97e3d30&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9a70ec0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(b13b13e0, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ba0e70b5-6c8e-4dc1-a658-700bfa3f0e81"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(dffb80eb, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b099e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f2202722240&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f22027220c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21e90587f0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f21f9a70f40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(dffb80eb, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="1fdbab93-a991-4621-9480-9164bdc5c363"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d16f4c78, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b09460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e95a1380&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21e95a1800&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21e9598250&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f220278d2c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: None, &#39;host_target&#39;: None, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d16f4c78, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="43890ef5-b48f-4052-99d2-14467dff2ab7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.076 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d44783d8, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f2202b091a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f96e6480&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f21f9b279c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f21e8eee760&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f220263b4c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d44783d8, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_utils</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="4f53ce06-9137-40a5-aa03-061281144c50"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_n_gpus</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1ea0cf24-6f2f-4902-89ce-f8c42496dd3f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b9e73dc7-5f90-432f-97a8-697a5a659569"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9cf6c138-b4c8-4f0d-a302-9ae5a3b1623e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="08259870-0a57-4f37-8db7-1301a2d47b70"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3b25cd12-ff32-46e2-bf2d-1680f35d0cf9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask_single_value</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af403d2e-9cc3-43b0-ae03-672811c22d3d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cpu_affinity</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d19fefd0-857b-4248-84c2-754b96da0581"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cpu_affinity_and_cuda_visible_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c2bfdda2-a87d-4362-9053-6c27a8526cf3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_device_total_memory</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.89 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="070ba51a-0372-44af-b3c2-7f5d5513a419"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options_default</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="53d36836-7eb8-4ffc-8b59-eee4fa47a205"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a254ef2-7994-431a-a63e-05fdc79887a0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="421fef85-21b6-412b-a8bb-3510a801212a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2da811dc-c452-4101-b748-9c8fe78a11b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f3f9a8e4-bd17-482c-9607-0a068c0f008d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="09be2ae8-1473-46ac-b6ca-557d4b283442"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="db612169-707e-4fe3-828d-b0de3b2bffea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7dfd05db-cb3b-438b-84cf-1120a33a0cf7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="98e116f6-be7e-486c-a6b0-983e3a99b967"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="efb6f5fa-ad76-4c4b-b5f1-404726b1e79d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb1a08df-b3f8-49fa-9ef3-96a7ccf734bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-True-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="46be3456-d3ca-4a54-b90a-cb427d65ced6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec830547-1e16-4563-80d4-44dda66bfb99"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3f3ed8e9-15d9-4df0-b938-46c0f0554aa7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-False-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="93d3033f-ca49-4c32-9636-c03c9bf6a925"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-None-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="378d79ea-ec25-441e-a959-2470cf4bcb55"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-None-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="89c2db5f-8981-42f3-a820-d09748d7caab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0f6153f8-40cf-4072-86f8-775385d31305"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="60b4d960-8cc2-4ac1-ae13-fc69132b15d9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="98b8c2b3-022b-4141-b6b2-78eb3b28fdc6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-True-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0ce65c25-5087-437a-b9e4-6fedcc6f5d31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d617b776-1c0d-4707-85e8-3bbd81950761"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b5b85a06-95f5-46ae-9869-b880fb058e2b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-False-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bfc62430-ab7b-4cb1-a5b0-de459ea392ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-None-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17f379d3-9e6f-4dd9-a02f-cc9b29bd218c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-None-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ad61fe35-9ac6-46b1-96ae-db4edc450eb5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="203dd458-fac8-42f2-9849-aa3bf66e1267"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ace0385f-dfdc-4890-9674-879361764d1a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f3bd32ed-3ffb-48d8-8a6f-2214dd93d000"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-True-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9192dea4-cc60-48b2-a3a2-3fcca09762bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8458613c-186a-4a25-a963-8c2b53356693"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="56e7a3ef-c06c-4dd6-88bf-7a9719e84533"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-False-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7d2ceb8-157e-4ec0-bfcb-4a5f17b27431"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-None-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c45dfca-8bda-44ed-981f-5239dec88871"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-None-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9d07c4d9-ad02-4bb1-8038-25f1a4ef739e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="52f60d72-6974-4f65-825f-85945b36edac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_parse_visible_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_parse_visible_devices():
        pynvml = pytest.importorskip(&#34;pynvml&#34;)
        pynvml.nvmlInit()
        indices = []
        uuids = []
        for index in range(get_gpu_count()):
            handle = pynvml.nvmlDeviceGetHandleByIndex(index)
&gt;           uuid = pynvml.nvmlDeviceGetUUID(handle).decode(&#34;utf-8&#34;)
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

dask_cuda/tests/test_utils.py:192: AttributeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f8681462-fd88-4b1e-bed4-6557091e812e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_parse_device_memory_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c1f51aa-edb0-454d-988e-55ab3b9f3f9c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_parse_visible_mig_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_worker_spec</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="246865bc-8833-43a5-967a-6599df423444"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c0b508f2-2044-4acc-bd5e-3c390e4f2a78"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95df0cfe-fb22-489a-83ad-abebd1ba0433"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a3b1781e-4c60-4871-a2a0-0b6d91425cc1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d198f9f5-acf6-4cc3-b6ab-914b145fffbf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6da4799b-a0c3-4d9a-a726-8c153ce99a70"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2760688f-a6f0-427f-86da-1ea38bafb268"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b4307591-2c50-4d30-8c51-cc9f9ae42eb2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="529cc9bd-4715-4153-9c21-1c09d537ba9f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e861a24f-260d-48da-b653-1fd1e5005cad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b4170212-e7fd-44db-89b0-690af0784d31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7a3068c5-dd68-48b3-b0dd-27ca53b95fe4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="03c4e88d-ccea-4b1d-a3c3-707a9c81698d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3742853b-0e17-4db9-8262-3c73247df8ec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1c854d7f-a423-41d0-b068-571155ed426f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a331247-6d39-464b-a0ad-86b57f886c80"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="75b97eb2-9716-4227-b135-169fdb722005"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8400f42b-bd33-4d7a-9275-a6afa4baee92"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3da5366d-e09b-4bbd-aaf4-3ef3b03f3bf1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7d1c577c-66d2-4056-8265-9a0ab589471c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d480c556-683e-4479-97a4-9ee3096d8daf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="33cdc9c3-10ee-4430-869a-aa3ed11c26f4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a1e98fff-ef3f-47bc-87d2-34ad286b3341"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="be25645c-82bc-445a-989c-35212081bd8f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="62ac7bab-8559-4dfb-a3a0-a7ec60e0deb1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1a334845-6997-4d25-93b0-177f48d093cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="313c10b2-19a9-4bf2-a3a3-785ddf51d6fb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="789e9de1-cd68-48a6-88b6-3975591100fe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0dde6d4f-3fc2-462c-a102-30e52445cd23"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3dc08086-1bb6-46f6-ad4e-825c4d8dd8ff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7f4a4be2-69a3-4d37-9cf7-8c90fb0ed234"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ae956c3c-7d41-47b5-a1b9-fd7d34f29da8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a51387f5-6505-45a2-a9fb-72aeb5e6fc36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="61d1cc1b-f70c-40e4-b0e9-75dcbc969556"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a255440-899d-47ef-a289-1c12402a3910"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="87d2c1af-7fa4-4a78-878c-22cdb614903b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6f4ecb13-e81f-445f-9bbe-32b4ff96e4c0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1127a6ee-2d5a-4c09-9703-a00ef9c43a3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a565665f-d3f4-4025-a312-674437d25c97"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="931bdb09-2edf-4cfb-9fe4-a478868cc347"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ba71285-4618-49ea-b550-2320febe50f8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="19c4151d-4cd9-4590-bd72-c3f335eb3422"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ae3e85ad-8290-4e78-b082-a9fef94b7f3b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5ce6e2f4-4963-4202-bd7c-ae1ad0246a89"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="38540e45-0a3c-4641-a503-3c801c35540e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="12acb3b5-b78a-455c-90e6-a0fb95d98d10"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b087070c-d3e8-4c62-ae22-2558fa638d09"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="44699824-4b9c-4733-ad76-8be45ed3034c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="88422ff7-d630-4fa9-a4ee-f38fdcfdda3d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="687af4f2-090e-4a8c-b6ed-d70b9ea449aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e4640eab-8df4-46a6-8d11-a657eab17b91"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9cc98ec6-01cd-4206-bb0e-f8b7170031a0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="58c758b8-4b2c-40f7-9242-60c3e4a9a78a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="12dc3e1d-2789-4bfe-b804-6285eac8bb41"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a019ee34-3e94-4318-9c0a-44c317cb58e7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="91ccfb2b-ac42-4394-a1c8-2e7bd8b6a0ad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1a957cf2-a8f1-4592-b826-cfcf476da478"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf6d11e0-c80e-4ff1-9f9a-90a2abf05dbe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="be6eb6ba-d7cd-4c7b-8c8e-27ee5e26cbed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2a8dada8-8238-4b66-bdbb-c15f09c879b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="51edc07d-8379-4f89-a4cf-a3ceb7f04213"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8bd077b6-9407-46af-8df7-bd0e381c5694"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="086f0031-800a-454e-a506-18d60e16ced3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cce68718-46f4-466a-b521-fee3a15991be"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="40d8c038-e255-425d-a88d-56c7a22e944f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cd70d71a-eff6-4805-914a-8a08e87284e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e266610-eae8-4914-a543-3a72d93da130"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="319717df-eca2-410f-bd96-89b8e6291667"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b4e227c4-5288-4c32-b9d2-7d244e042f18"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="966902fe-d081-4cdd-a2ac-de350cf0efa5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0cae5c1-c9d1-4dc1-83a4-9e45e7fb3c01"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e984a969-dde7-47ec-ae71-72608d45a507"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cb1b1e83-e551-468a-8944-60a1f4891606"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="788ad7be-451e-4cce-8555-c2d79ac5446b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fee0362b-f8a4-4f75-bbc4-9e685d8f8de3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c0cfe20d-7921-4b80-8368-e584e8fdddb4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5b9ae380-15a8-40bf-acdc-87c9d7773321"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6df1613b-87ee-4c06-b897-1c24ae4ceb69"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="64d8fb28-d123-407d-871a-929fe6fe772e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="76e0b64f-ec77-45d4-859e-e45ebd19eeab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c36f195a-fbef-424f-8b59-854ef9f515e8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d6efd7a2-bfc7-43a9-bc7c-2ce440f1d279"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bc8e94a4-c9b3-4382-94b9-65226e200afd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6d5abc54-17ae-40a2-bbfa-3459e170e291"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5c864f32-aa81-4b98-a851-e1adedb62832"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="59324fa0-8b90-4541-886c-f1aaf9fcce97"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="09841745-501e-459d-9226-5d6953df4675"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9ad870aa-129a-4f75-8d8f-df86c13d775e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5be1eb04-23ab-4727-94cc-2c4911b411fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b77283a7-b011-4f13-b49c-edca12efa240"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1b84ee9d-a5f2-469b-b5f9-d78780090dff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e8b7b858-a6cb-4dec-aa15-e229a24bb641"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0ce97d09-bacb-4118-b27c-b520f2a25488"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9e259f41-a07f-42e3-b51e-857586127747"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f5e082b0-464d-4d43-92bd-060bcaee1c77"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="818b57ca-ab9e-457c-b6e6-82228128902b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="048ce25f-9864-40aa-9632-1b0667f62da5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c4bfa6f7-f5b5-4e18-b2d7-dc684ffe269f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a28bcbf9-2678-4e78-9148-c7cb72901d7d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5327ceb3-ace8-4ab6-bfd8-30d6b1f95f30"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="38ae8fa5-b1bd-4386-a846-8517acbf6c3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0e998a3a-6f37-4029-874b-0d1c3af1e09a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="23a586c8-9c6d-4086-a34d-bdfd3f018dc9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5c8cca3b-083a-4a23-9cc5-d3872a6da705"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8b5479d2-7e73-4753-9733-bd83f2f51793"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1a4a1b6-5386-47b7-b087-19f3ac96ae31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="19f0a61e-c59d-4743-b831-e45138dfc978"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="efda85e2-d135-46c4-8edd-e8c23d1e655c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7742c74a-47ff-4ce2-83f6-d7f95c9d8489"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="97dc7765-cf9c-47ea-99d6-0eb005bc8fc7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dda59ad8-904f-4a9b-bca0-e0b019b1e6c7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a19724eb-506e-4ede-a123-678db7c70136"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f79adb8d-33f0-45ef-8393-b8cbac451c6f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7e1c8b5-06a0-41d0-927c-b88842ce0bd6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e31fc688-a47a-4d36-8dab-aa4d31246291"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aef3b1f5-b827-4453-ac76-0882a7450584"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dfb16417-4ecd-44a0-9098-573ca53a7225"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d604d7d8-047a-4226-95a8-91822ad063da"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="55c60386-bc02-42f3-a641-b07ed508b56d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e99fec9a-d982-4a05-b600-9967fc22ec13"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="59bddc06-e499-4065-83d1-b7fd0b05c771"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="87fd0ced-c5d0-4da7-821c-99235443e50a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3582f37b-848f-48d2-ac0a-1b83c97df9c6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17819869-4ac2-4b04-9202-3f654d939e3e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="50a4d8a7-665f-414c-844e-e910ae8953e6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="82b99568-2d15-49b5-a2ef-20d20afe7f2a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="711e4d86-5562-40bd-bf69-30a51ac442a6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7e3a6f59-1965-4c08-a1ae-bca22da1c7c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="77961e3b-b344-49c3-be0e-94e72198651e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f247726e-a1eb-41c0-ae42-7bf1ff81e23b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9a881ec2-5729-40f1-b698-95f74e304d1b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="717ed97b-8cd2-4491-95ea-e227af509d63"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0fb752d-58b6-4c94-a475-4ef730c68fba"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="25925958-5f79-4770-a586-957b71bbcccd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e918d99-5924-4cd6-8121-85588935a94c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4b7710c2-230e-402a-91de-a954989e5087"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="540d536c-a8a2-4d70-af1b-5450ff9a5305"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5202eee9-37c6-4f3f-9a45-9fd901cdc378"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a25b3e5b-c704-4773-9fe5-c175d0580987"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="82add809-dc04-4dff-8734-6285acc1dc4d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="027feae0-1f4a-4f14-8c4e-2976636d0e43"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1d129dda-cb02-4d44-b6ab-e4ee0e27d569"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="326b2f7c-9d6a-4b09-8cd0-d42214975d4f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b3d1fe61-94c8-4d34-b842-219c5eccc23e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a1dca115-41b4-47a2-bb5c-78a0ecc17398"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a15c3934-9ac5-4acb-b8f4-b2c79f56f371"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49879746-1d69-4894-b936-2a75d0ba940f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c8dc42bb-4cdb-4d62-adce-deaa7e92cb67"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e55bdc82-d0f9-48cf-9349-2f9f05d10ef1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="527381a4-6760-4a76-a70f-8d9ab15125c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c294ce23-f64f-4105-bee7-5a158ad62556"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0f902e4c-5eeb-4693-876a-d9302f1fc966"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3084da22-22b4-4da8-8480-bb6db93b7f9c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="167a3512-cfab-40b1-b5bb-3a0033d13f8f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d29b8507-c9cd-407e-95c8-799209c3d419"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2a5d78a1-a027-46bd-9648-e0f66e514d6a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="64973d23-da1b-414f-838d-a8a97109de37"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7217596d-0491-4627-8185-eb07f6adf3ce"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="08f20f7a-be60-4590-a50f-95d383169332"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1ef1dd4-aea6-451c-94e7-38b08511a18d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="27a69cfa-fdf1-4473-aad2-73cfc7dbef9d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ae35e041-b3e0-432f-b91d-cfc2feb09430"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b8dc9a52-9e76-46e1-ba89-1b3a26f05923"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6b9844b2-ba9c-4e2c-9b7e-784d2f62cc25"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c090ef14-a5c0-42a9-9a9d-541128c07f69"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="06ad899e-0c97-45f3-8233-aa12514d059b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="02850020-5b1c-41d1-bd94-96d115dd180a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cdc61405-58a5-40d9-b128-44881ae52cdf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b2023cdc-a12b-4849-b73e-adccca89cdc9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3d0ce1cf-3bd1-42bf-8d69-08ec2a4b6ece"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="885f64d6-1b08-4ca6-9bda-06b2c7170d9a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1beb1737-a620-4823-acea-c9901d2cac4c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2fd4bf21-b400-4a8c-96e8-cae38db5bc20"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8de2dac4-37bb-48b3-8bcb-fcd9e7378b90"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="268cdef5-e7a9-4bc4-bd8c-1ae2440ab1ad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2859e837-962e-48f5-9604-5ceda004aeb6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2720c8d0-b50a-4853-afea-1cfebf1e8103"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2b7f4be4-0fec-4f3e-a1b5-183272083e7b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="52ad2b3a-e9dc-4fed-b80b-88cb575d55bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a0aba644-9fcc-488c-a13e-e2b4c6f6cf95"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dd37902b-da1e-4f65-acb4-a42869f82f0a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39725069-e93d-491b-95c8-98eb253937cc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5b474927-01cd-4961-8612-4174aa675b9a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="16216157-770f-4bf3-a6e2-fbd459a714aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="376a88c8-d60d-4238-9095-fc159eb8ff00"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cf6f3ee5-97a4-40b5-b3d3-ff562bbfecd8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="215f7c45-9bb8-4455-aefc-b0d92f534c22"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8afd9b3f-c29a-47a1-ba6c-689a69422a74"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9b0cdd7d-6107-4182-a7b3-28aded74ee3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d29dea37-9ef5-4c47-b781-3fe680b047b0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8f11e1b3-190c-4fe3-bc38-f8a8ccf3c157"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e573991f-9915-4979-8ab3-56e0389e33c5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="83705362-9a18-477f-8b71-7d63a0eaedd0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e35b5bc3-caa4-47c6-aa76-2af753010deb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb8e0fd0-cd4b-4940-ab4a-feace3e31363"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b31e5385-c4bc-426b-b49c-680a7bca82dc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="92248e90-4e19-44f1-b951-52661d74f72b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6a0099d4-51d8-45f5-b554-54b4e7d13f1f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b06e4811-b220-42bf-a2b8-e2c545006958"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="01246bb7-b193-4ab8-be39-8591fbf43d63"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af2d3c09-7d06-4a05-b408-b8f83185a8e9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="25773c83-51d8-4e05-8a05-76c667ff08ac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0e5e5b9c-30a6-4de5-9aff-70e408851af4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7a547d90-9a15-46ef-b615-d00b381e666a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="efc7164d-a7ba-401f-8346-cfc7537387e2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b86526ee-cf65-4828-b372-10434fe81807"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a1108589-07ec-4dfa-a948-a6b3a1c96dff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b64157c0-8240-4628-83c2-f999bfed93f4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8811253a-b2a9-4c8a-ae94-09ea52b5e667"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e274fe0-044b-4b92-80b7-10115c27cdd9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="041f0180-9aa7-4779-ba71-eb5cadca473f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e6715a7a-9a25-42c4-8eb6-2a28ef0db7af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ba05813c-805b-42b4-bf06-e77f8a30257a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ceb4966d-a8f2-4dcc-9015-2f244059fb77"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b2b392d5-0f5e-4365-809e-c7b1f58645bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e3a9d5f8-e15e-4c38-a1dd-797c4817a69f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="752abe59-1f8e-4b54-90cf-5bf94f7dfc8d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4d3e6d36-c5cf-4aae-af1f-da0cac408b19"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9f329ee1-8b40-4ce6-85b0-d9fd06c85769"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7e248ef6-b823-4c09-a973-2994ca2b4aec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f1a725cb-1309-4eaa-96f5-f0acfbe5945c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d919442-9f25-44be-b7f6-58dd9dfe3587"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="267de6d9-04b2-40c2-8024-267b40a5585d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e863092c-eb6b-4983-95fa-1f1a3cde7acd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fcf1c2f6-49ef-4dc8-9f11-72bb511d4b5a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="600db932-468d-4412-859c-61023d37287d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d90cc7e0-2a45-4078-a502-01933b2cb7ff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c36123f4-8f52-43fd-afda-0a84698e7efa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39df3750-367e-493e-9051-017485f97e78"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="59788172-a954-4713-ae98-8b451cbb4d20"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c7624def-92bd-4772-bb22-e8aa1c11fe70"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d2cff7d6-33eb-4c43-841d-fae2385fc75a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="349bf1a9-9b80-49c5-bb76-954f484d0bf6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="284f3065-205c-4ff3-bf87-0b8f10c2bf22"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7bb33d54-900b-4a85-b185-398d977706e7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="adef5ff4-d6e1-4051-b47d-7d60fb67d410"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="21435e1e-4a73-47f6-a2b3-e806eaf4a0fa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="74295209-6225-4e91-ba5b-a4dc6a5ce0bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3b308137-6cdc-4d68-8369-65084ff62e04"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cec07357-b479-4412-b3e1-5205c2d23d95"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7f2b0b8c-23e1-4324-b04a-9603e567231d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6a0b5a69-bc73-4368-a0ab-1b8dec992663"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2feef9c4-ce8b-442d-9c60-17ecd9f3d002"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a980949-fa2f-44d1-8c81-f111de18db7e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="15860905-c6a6-448e-98e3-995e91e9b6fa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="45c40ea1-2431-472f-ba54-5943f4ba63ef"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a009d98e-8c31-4f0a-8f03-cdb9dcb3c37e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e6d80679-6b1a-4138-83fc-630d3f147f8a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d50037f0-ae03-4830-b288-fc4042cde042"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e49afe24-0919-4b0e-8ced-c6fec755bb38"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6f09eca2-a7f0-4225-aa62-d779c781c691"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c91032fc-5bb5-49cb-b13c-fc8c6165330a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="825c4684-ded3-48a8-9e4e-a6a1b03f0347"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39249569-12a6-44ba-beb5-c92dea1ce641"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5b1942f0-2f15-45be-80a8-f855e6dd1f7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8ac90939-822a-46ab-a2b5-e2f8de8228b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c34f61c-f304-4d32-9652-1fd130d900f8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e9bb8470-778a-4870-a25b-6e3234ada689"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="61a086d4-2fd2-4ccc-b69c-9deb6e9da267"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ca0565c-b7b9-44c6-b911-e8ac572ffcba"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="75ff57f8-a53b-40e9-b0f9-46ced12d8d7e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a9812c6-ef82-4db5-b7f7-50062ca26950"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a2bd0101-f334-44f6-92ff-f6bad8b4fc53"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea23508d-db79-462f-a028-41546dfd07d2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4fc4fb92-e3cb-4b04-8d74-398b430dced8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cce9cd94-1846-4974-8ad0-bcde7916cefc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d5fd7c71-0433-4d41-a52b-b0320306732c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e48914a7-8517-4a10-9083-237f138659cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="155db986-636d-49ab-bcd0-c034e49d8867"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a53f291-cec6-49fb-8474-57341fc6f8f7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e37a078f-d0da-4611-bc17-208de82ac45c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3353c822-3204-470e-8711-217aff978d33"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7e351566-ade9-4d9d-8af9-c567332a7983"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bc320564-8982-4aef-86a9-0c1f2b76bd5a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="605556e8-3414-45d8-8b96-1d4d19c12c7c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="13ba4cf6-0e56-4f6c-8ca8-b85446fca9d1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="594b6c9c-752b-46ad-bd36-a9fca4995c9b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d3e11522-e56b-4f72-a036-f5da846c909c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2b9016de-6839-40eb-8e28-42839223f96c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9896001c-05d9-4ebf-8528-77b4e7224d63"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="51b679bb-f189-4ae8-91ea-e41dc6605e8a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0381b1e8-2028-4fb8-9cbe-603a7676f563"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4225e9cb-0fa2-41e9-80ad-750bb0dd6a59"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1591258b-b706-4971-adfd-d84968f4bdad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8ab72eca-ac1e-48ac-9d62-4568ed273bf4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8deec770-4793-4f3b-a628-004ae1346332"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e6b18cb-81e1-4c24-96bd-2d3d55d7cd41"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d475f664-7bfe-46d0-a80a-98f1e2ef8414"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bedcd708-14c8-41eb-84fe-ae6e6cc828b7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f5247ff0-c82c-4484-90fa-314977f8ab51"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1597c58a-76f4-44c6-8ec5-28e783a4ffc6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="25defe51-a168-4eee-b12e-3b4479ce148d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9d45f40c-6b14-48f3-b911-a1d32910c22d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4ed4bb67-3731-4cc3-8e58-00f761de35cf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b0adc551-9355-4d20-97b5-99a35f33637c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eb8e154b-b161-4ae8-b9e0-d7dd60b28b7d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4f6b2b7c-583a-43eb-9920-fb5554fdc263"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c09b72f8-c0b0-4475-a587-3aaeedcfa0df"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="62ab47e0-2fb0-4742-944b-09a8fa110f4f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="34993dd6-4101-4d35-8f95-15ea81de5ce5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f36da503-f6c0-40cc-8637-6a62d77ae466"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1fd7fa3-fb29-4993-88f9-856b6baca602"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6961af6e-4afa-4043-becb-394030beeaca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="709fd641-24b3-43eb-b2da-4642db96afe5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a91231aa-b1b7-469d-9e86-709cf172015b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c680f4c1-1fc9-4f2f-8ad9-698cffc5966e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4ac056c2-f7a8-467c-b123-4d469dd601f4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3aab46b6-675e-45ef-81cb-e195273a31bb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="32402661-549a-4792-8fc5-545447f52822"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="758aa3de-4df3-4691-9303-59de3ad1a7c7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="da61fe84-2a33-40b3-8176-2b240268dd6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e837abf3-1b36-419c-9f52-f71cef652b04"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5e80a84e-5a5c-4709-b168-934298701d2e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="024310fb-d86c-4edb-8d8a-9c40202b667c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8aafa973-793e-4fcb-b353-d931d91730fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="592f421f-23c2-4bcc-b557-d4b41d551895"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0bb82677-13f5-4bbf-80d6-c48bc0310518"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95070c2c-4f4d-4e30-8fe7-8414d093e6dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39d621e6-4d7e-4c85-9b40-670151a1de5f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="459777d0-7ee6-42b3-8146-be95841f7a16"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1b17d40e-5ac4-4779-90e8-82aac676b16d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dd7e500a-292e-4830-9144-e035a017da9f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="25710fc5-9ebd-4261-8fd5-8510076f52d2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="79ae0940-ff3c-461a-8f67-8c13fe7b23f9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4982694e-077d-4dce-8b7f-92195230402c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0867037-e929-4118-8c5d-640ecef472a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="afde9b63-60c9-4c76-85c0-41a3c7cf9a16"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c346cb4b-7082-4145-83f8-62fa97d5d4c6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fe7b7259-e255-4fba-894f-289cbd938a03"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4aa43d82-35d3-47b3-b4b7-8e1f59ba8bed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b91b241e-33d7-4ef5-a956-c24cf594a953"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aa341c3e-ce2e-432e-babb-3190795bc7d6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="37878bf8-102d-42ac-b99d-8c999cf087a1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eb3d7277-bef7-49ae-81e9-ea65c8e0dc5e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0380f022-e6a0-4b5e-8fdc-06a745d1f7e9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b36c12e3-72c3-4ac3-859b-ce621033bb44"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ca295782-bc57-41d2-91d1-5e7b78e5576e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9e700a75-3184-4309-8f5c-9625cd4861c6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="05f4a1f2-b389-4b2c-8751-01b809e31ca4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d8068f5a-db11-4090-88f4-929f0bbfcdbf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="64e62881-218e-4bdd-92ad-2317342854c4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f3047046-cc0d-4ee8-a1e3-3530167bbd61"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="45adf65f-b633-4fad-991a-8e05447fc8d5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5bdb6558-395b-4a3b-ac17-541a6ad977b7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f661e846-d8ed-4fd7-b163-a327bea1ad76"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ccff87d1-6d79-422f-bd8e-81f0586952da"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8ec9b2d7-21e8-4735-94b1-d62ad4d7ad1a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="897a7830-7a85-400a-b285-bf503dba4373"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="45070057-e837-48f4-87d0-1e4d0ea47edc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5daee212-ab66-4d2c-b46c-98ce65e5159d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1719e40-33fa-406c-a875-2ba19da40c0c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4d7237c9-0e6c-4ef9-bd99-27009eaadba3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="66f55a06-67df-4010-8aa6-72fbbd87f43d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7c4a6f4c-7dee-40fa-b24a-a7e2b674a5ea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fc1632dd-6cda-481c-8528-91316bf45f0c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f61c6abb-559a-4c79-84d6-0e7a0b424b11"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8aaf03e5-f075-46e3-9df3-26a21a94d4de"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9208986d-b5f8-4cb0-9f2d-54cd18fa0f37"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1a146b9e-4a3b-4e79-b063-2e36b04b72a1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c1b21655-ab23-472a-9775-cf87ea094543"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d10be734-7f03-4e68-94dc-2583a5426ad9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0ed4cb9-5aa7-421f-811b-687fd135988c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="18b0ee13-2d47-49b4-a699-07a63589f351"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b04ad5fd-d742-44fa-894d-607b6605b53a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3684740c-3b29-4470-8424-1814fb05f24a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bdeed322-dc03-40f7-a2f2-8876fb26faa7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8b0db854-d681-4607-ba9c-e459da5a4e9e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5cdd573e-eac0-4b72-b718-affd6556e7fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="91498e39-42c3-4f48-b392-7877f4632ccc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cdd301db-f3ee-45df-998d-41a40912819b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7bf67d09-8ccc-4b14-a118-5b8a676dbe17"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="18d4a64c-1cce-4785-9b4f-dd3a163d4a89"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f984dec8-10f8-43da-9c9c-d86ba3e04a2d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2f22422c-2429-409c-a68f-cd38b65bbbe8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="76293394-148a-4015-aecd-ed10676d5464"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4edbcd0d-6dc0-49ef-8447-2091b8efa24f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d0ac85f2-3dc1-44e6-b57c-edcbc0c1c58a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eefe532c-9a12-404c-928d-672fa87eaee6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="74e053fe-60fc-4d34-a762-c1b661211b0a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d681d87c-4cd2-45c7-abc4-f219a7b1033d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1dc22b9c-ae78-402a-a784-f8367b47aef2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af592ccd-1800-45c3-bf43-6191cdc075f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9990eea9-fff0-4a16-ac6f-46c1a5361409"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5925611c-4ce7-4ebb-96f4-0082775ae4c2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="123c2b2c-46f7-470f-a98f-5a99047934f2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="510f04ab-23d2-4e5b-afb1-66f7884c409a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="63e037ce-bec5-4d29-a220-de9951323064"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e31542c1-5045-456a-be8d-d15fb56f588c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7661e417-6f69-4954-a156-0c66c314b4fb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c02f635e-93f8-4f83-bed7-047733834f70"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0d5ee1dd-bbce-4fa5-afd0-82de873c667b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6cad8385-29a0-441a-8304-56806e34d002"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec1ba184-633e-4678-8167-6fb084bddf39"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f31e0c55-31ac-4bca-b355-3315ce2ae0dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="97b7b0aa-972e-4e85-a70c-bf7443b41d3b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0e0c267a-da7a-4899-a620-0d2edad54978"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b58de820-db73-4fe9-90b2-2a9ad9355354"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="773b4bb7-a2a0-4417-a229-1f5aefd35426"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c3a6ace-0f13-4283-8d36-f40f42c799b5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="29605b88-aa64-4c4a-bd97-d3efdc094695"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bd22a43e-5ad2-46e7-aa49-a1be65b9d7bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="818fa153-5179-48a3-b47f-d0c3d2cf907d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f3769603-a02c-455d-915a-1f6b68e048b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="494fc4db-8f7c-4117-b72b-a233ecd15757"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="48b9bbae-2b2f-4bc2-81ba-88d508ab626b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dbd63b7a-7d45-4093-81d6-136c7326e627"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1a8fccd6-f6d7-469c-818a-39415537c62b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="28a899c4-6f21-4178-aec9-6001d53a21b8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7daa4396-ad66-4373-94e7-1408da743d00"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0009934e-228e-49b3-8b88-cf6612165ecd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="df7718ef-02e5-474c-82bc-99d6d11d9f5e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="71993851-58c1-4b70-a4b6-3494c9600d7d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bc1ff556-89b9-4103-82c0-26842750cff6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6b7b9cdc-d60c-4dfa-8d46-dea7527f424e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="747ede30-907c-490e-a1e7-41683d56b32b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ab253596-8fb6-4b5a-bbcf-98d11c4a61fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="498295e4-a9c4-4df3-88fa-dd2f087454e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="78bfc54a-502f-4440-8998-8c5c8275ba8b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5f68d1f5-ef1a-4795-b5dc-6c5c854737f0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b594ada0-6140-43f8-9a41-5e0c9dc312f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1db7614d-1fe4-4f34-825d-edff0e8248cf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5f5ef63c-1694-403f-a6f1-83af0ce73f4b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e937d13d-4b9e-4f84-b096-df4cde2f2cd2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="498c3a7a-ce23-4a47-b952-1014a06c081f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea349e84-548a-4357-a13d-aa1dcdc1a9e0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="416fb747-946a-4265-9678-bc22657e9f88"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4c09cd47-437a-4fa0-9d62-c974b703ab92"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ada8d10-ac18-4fb7-901b-f8a1470705e9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fc1c88d7-ac5f-4f1d-9546-490502f6672a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6af6696a-b038-4413-bca5-49bdcbec86d5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="30c51afc-edfe-403e-969b-ecaaddf90c9a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20d6c1d8-18b3-423a-8fea-b1dc3ee5b6b7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4bf39269-be5d-4fa9-87c7-f858eb63c402"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="33c9baf9-b825-4f00-adac-096ccf49951c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="21b048d1-d888-45f1-91e7-38a0e27f7a1a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7cffb120-bc62-40e7-9fe5-958683703ab3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4cc483c1-015d-4d48-82ef-201aa9a2b935"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="03253e84-b3c7-48e7-8222-d6d6b21f4944"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eede67a0-f256-4e99-9175-b73bdb609c27"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="525bdbda-b9b2-4b7e-a666-c8be231a8910"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="064c4719-752e-43ce-a575-563ac7e9e81f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="788f2646-341b-412f-9f8c-dd81fab17288"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b6519741-e1cd-4d89-bae1-e456129888cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3bdcae46-8f21-41ad-986a-ae3967b68618"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a13da595-5e9f-491d-92fa-b71679304645"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a0e1064-55db-4ec1-ad44-3b1c0ddda2ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2f0e9617-1b2f-43bb-a8c0-83d7700f3099"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9f69c547-a0bd-434e-bd3e-f36dbe4bcfa7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af71e209-b490-450d-a297-5094bc996576"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e75ff8d6-5cbc-4ffa-aaac-fc54390ce1a8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d9a2aea2-82ed-4df4-aa83-77410fad4a97"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea169e10-1683-4152-b66c-7f3b4c74895a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f76c61a8-be05-4908-a024-429929d1199b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="066727b2-d246-496d-8538-85d6c553471c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a73324a-31a6-4073-985b-323178c1ce9d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3ada8a39-f18c-4d8b-9ea5-78ce72191eab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3fc2a6c0-b3d3-4146-88b8-5fe34729cb27"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="40768369-604d-414d-9844-1ca746d502c5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="737fd88f-be39-468f-86b2-37246e3463de"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e32cd0d1-ab11-4a79-a1d9-c4ccb2541ded"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a938544-fc6e-4ba7-84cf-fb5d131af370"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b0fe9b4c-07aa-4392-b62e-5cb6e27091e9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="527553ce-cb04-414b-b2f6-210d1ae0b453"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="68e22b09-76fa-4f4f-8e68-5b0efe299f98"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9990ecc4-ee1c-46f0-a44c-2d0640115da4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="00670e2a-fa5f-4f59-a525-e397e70d33a7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4bc4e62e-85c5-4e14-bfd1-d7205024327f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="65337bab-dc83-4215-8f94-41934c10a9f8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="58a10269-378d-4b17-a9b3-d573836ea25c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="330bbae2-3452-4fd6-955b-9394e55b68da"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f9373a60-4e3e-42d6-aff5-639511706423"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b7c82cbb-92e9-47e9-bbb0-a446e72cc75e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d34b730e-b389-4b86-8ffa-0dce07ab8a1d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="892c0982-46a5-47cc-9fea-d7d35e013098"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2fa15761-7975-4556-bed0-a485bb9a0e7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="14aaffff-652c-417d-8617-9ee828cf2f0b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="34de2c2e-79f9-462f-8cbe-bbdcf9b26016"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="de344a9f-b835-4d6a-951d-8e68035a279b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1b32b47b-eb3c-4bee-9cf3-eeefdacb5545"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="99b5f012-dd27-4a43-afe0-b381f8234952"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="93d7c163-0044-42c8-babe-efdc74ead3a1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="46dc94e3-6f40-4f94-abb2-c8eab47ffaca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b950e7bd-f66d-4a6c-bcfe-54c04d299b44"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cadfafab-0972-4c51-93c6-33308c76e65e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="30e3eb3a-84b3-4f48-89cd-d974f0dfd7fe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="096dc527-f528-4de3-b4b4-c332c3d812e4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9544b838-fc6e-4c61-ae9c-9af468ee2cd7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="032e01f7-3077-4cf9-a4cd-8e07db74f7d9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="88c80b1e-6858-458c-804a-e9c8e2325317"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="32e796da-1091-4703-ad52-b31c314858d0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="66d4ced3-6d81-443a-8526-6c559fa283da"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a9840261-6247-4ccb-9404-e74666aa163d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3da9b99e-2d64-4f33-ba8f-1e730b2c99c2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e46fdd41-835b-4704-979f-fab7f2969aca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7be50b95-d86c-4233-b7de-421d036cc3f9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8c11532a-5e37-4e94-8b96-d39837e01bd0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2ca55f5a-0867-4db1-a226-aba0f023cd4d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="28294700-6940-44f2-9c88-04a4d1d56833"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7fd0927d-4849-441b-a4b6-3f1f3fedd64d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed26f3a6-ecac-425e-8a2b-65624cd96617"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ba28a3d5-06d3-4af1-97c2-458fe203a784"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1d9901b9-2c86-4f05-af71-7f06f0a8a4ed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="feabee0b-a188-4261-8552-1abbc0cc3f33"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d01ed4bb-27bb-431a-9231-7e619220badd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6ed165e2-189d-4b52-b20f-e9a074de95d0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b95b54a5-29b6-4fb0-b3a5-8dc684ab7089"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="27835a7d-0bb7-4618-9633-80ba35e0aa8d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d0949401-1afe-4762-8452-892ffc71d965"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b8cce4d8-52ef-4b73-992d-341e200d1aee"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed5aa9ed-a612-4d02-861a-725a6002827d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="56f86a13-f026-4ec8-bb75-40e22c3b2c49"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6f19213f-e8a6-4754-9331-c09b706d907c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e3a146b0-c68d-4457-93a9-c018b2199782"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="77102128-bd05-499b-a271-2359b74dce5f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="09ddeed9-8801-4aa9-b85b-f3698a7b0d66"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1e8ff910-5b3e-452c-8562-92dd00bc51c1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17e2cf5e-67c4-4360-805e-4ec08a149188"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="96af5b70-f0e7-46a7-9b7b-7e1b51fe0f9d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="53a81e0c-3ff5-42d6-b99e-193077560623"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4ea734ad-b582-47dc-88a8-00ee9acc62ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e02c155-1ca2-46bf-8101-63faf3b4f1da"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b3838865-f234-4430-9e95-da50bb7ccee4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea57c5d2-c3f4-4dbb-ad5d-bffd120ea06e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="673b4aae-9298-49ce-8692-26af1fb15e07"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5c25b2e0-0e8d-4381-9c1c-f7870b77d000"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="14330d57-687e-462a-bcc2-72f3b607ce5f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1a8d052-b19b-4623-9fee-ae6a6db33a6c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4825523a-f989-48ff-853d-ffe01bf808bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="32fcf296-2fa6-488c-b980-6b9742b121e6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e298000a-f183-430d-89ee-e48c28382984"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fd9cfb3b-607d-4493-a2a6-98e88d1d61e2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c4906ac0-80a1-457f-9dd0-78ca96dcdbea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="681fb3f9-109c-47eb-818f-319b36a53262"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bd415ed1-7602-4209-9035-2e13151beb68"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0749f0d3-42c3-45e9-9a82-bb92804c0bfb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.117 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c00be357-8301-4ab1-80b4-dd1d71a0b111"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.131 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0af6cbbd-7837-4b8f-9a1f-d29a6cc05cba"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="659f5f15-323f-4eaf-931f-cc310ea61340"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8a3f520a-5d0d-4bec-8a04-3ffcc841774d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5de613bf-d8fe-496a-bb4c-b8a23a826466"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="059194ad-24fd-49be-ba32-20dc77823f59"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="67bdd0d9-9e46-4159-bc36-d7ebe4b813f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="90bf6439-70ce-470c-aea1-5b52c192300f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ef59aa6a-1b79-413e-9ab0-633f76ce2347"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e478f63a-25f2-4c7a-baac-2293782d8997"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="42d0f065-5622-4672-823f-c217096f1ccd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1b8ee2f-4eaa-426b-aa3e-688d9d2cfb91"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a1f1aaec-cce1-4201-892a-f39ce8f74dab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0455273d-9da2-4663-9173-e9404fb93b86"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c0d2cd13-b158-4662-b2f7-c227b3492b50"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dca5c3aa-4384-4967-93fb-3ab674bdd164"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7080060b-a4bd-4c5e-b43b-840d74b5a779"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f4fa8652-3cc3-4c12-86ad-b3385fe7f2bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8502af72-6d91-416a-9930-65723bd58731"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3736fff8-e5bb-41b0-808f-534dddb61db3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="33646646-fe71-4fe0-ac66-23a0d5a4448d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5fa559c5-6ad5-4653-a03d-92d858c48041"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c1ba9691-b9be-4e82-9246-d697d3828d14"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4004d074-724e-43ec-bc2e-212d1c121a35"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="15cc4b78-80d4-48aa-95d1-c67b49a8e7b2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="04749f5f-90df-451e-ba70-99d555672685"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ecb1d5b3-4828-4909-aedc-d07ec5c577d1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0bdd7f85-de30-4e7a-a04d-23d7203bb8fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="66b7c06d-6008-44c3-aef4-ca3a4d2767af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af6f1fb9-db85-4dfc-8d58-1a6b011b651f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a20f22fe-8fab-4792-a658-76c6eb8a1306"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e85f7c5-7e82-41ee-99c1-139741d038c7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b7e818ba-83b1-42ab-9625-af0e8a0711a4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="02b54029-da92-48be-8d51-f141a037585f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="59093c16-650e-494b-8dc2-27e81e3a6b80"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="75f66aa1-3d00-484e-b10a-0b6c3aa1245e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ee0c74ee-454c-4297-84fd-19052723223f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="71be9642-326a-4e59-bfdf-af60ef0cb1ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e3baa966-1903-48a4-94b6-b23354fe36e0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b821955b-3578-4563-9d05-3a33bb1651a6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6a4ae312-632c-4011-98fb-02b941461d64"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5e1960be-3778-4dd1-be95-66aeaee836cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ebed63c6-6dad-4f73-8135-5afbeefb318c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bfd79ba6-3179-4a84-a820-36263106cfd7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="61732d7a-7f12-4d9e-9d3f-e319e5c5b74a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c644fbeb-2d77-4d0f-941c-f8ac23b16554"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c5c266e6-ea17-4769-ab18-fac1d1624efa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ecdcb3ca-ca84-49c4-8f6e-5bd4d0712a5b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aabf15e8-ba2e-47c8-891e-ce22f38b2bd9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1fc0fa07-9719-496b-9e5b-378a65fe3fa2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ccd5cd55-c8ae-4cc8-900f-9f1226ad120d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1eb2da55-08e9-4b10-ac67-d2cd396373f6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="18d0bea6-b78c-4afe-9d8f-b60597ba41ea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7469fe68-efc8-4a6e-8617-ef685156f83b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f3030255-d1c7-4bf7-8b35-45ec4f16eaa4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="003aae5a-2cd0-4ae9-a508-e7a20834f2e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c3ee41e6-0fd3-41f2-80e1-d4eb90e4e9d2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d6666ec8-ac67-4ed8-b29a-d0563c5781fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c51abf68-db41-4352-8326-9d7ed0f9a00b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="df6a99de-9da7-4174-8b12-cf7f01aaf8aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="77657fd2-d669-4311-a80e-ad0eb3599566"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e5477c63-49fa-4873-a732-9b83103484c4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="93f44b92-acd4-4911-aaae-3770efb6d7d9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d88c7b6a-e3f1-4f83-9afb-8783a89ac17c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="df6e6ec3-a9d4-423a-8db3-cad5cb0c815c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3370f017-2733-406b-9d23-023ceb96549c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="90cc59d9-5a74-4ab4-be1c-17b5238aebc4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e7700106-a8ab-4849-b577-be7a982ec579"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cfe8c16d-34b7-4f73-808c-ae0f18460e2d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6d259ff2-6dc7-4dfa-af6d-3289bdff2fb8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f2436194-2da4-4746-84e4-02db4d8cce4c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a69b225-7e86-46e4-9fc1-5e5b463e7375"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7b55f13c-dff4-4c81-8553-c371ad3ebd6a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0bd5f2eb-d32a-4592-b524-f8e259076c5c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ce8b24a3-03c3-470f-a435-1ddcdf264c7d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="038b5d7e-797e-4a31-beef-b84b47979717"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a10b89d2-f224-4387-9f32-1d36b98a3c7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c732baea-ecb9-4fb1-a53c-95f0dc7bee36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f4eefa31-065d-4139-b045-2ecb33b407a5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8e539f17-8fc7-4f32-8021-a8dceba000ec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a1539072-bd11-4218-9eb6-a085eef119be"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6e60bad6-71b3-4bcc-a762-8849e3667914"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2a2ce013-e2da-44be-8809-830b4077cd8c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="51e34f88-7d75-423a-a02d-65850c0d454a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cfb88922-db98-4985-a247-88f34c61084b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2ca29bb5-8dd0-43b8-b559-92628401bce1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c7b3ba41-d204-4115-98e0-7a1071148c89"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f87bafa8-7557-4776-b6be-4f43977ed86b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="62c21cbd-a88f-4927-8c2a-51313e8a6b92"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e5c2b90a-8d09-4b55-be51-43b7549850e9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="478d8b0a-fb60-4a7e-9bad-49132e85c9be"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d523061e-5ab4-4b21-ac2f-f4ac06ef92a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5d41adb1-2ff3-4a64-bae3-9cbcd59f6d78"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4828a7ac-62ef-4720-ae27-4582f4564adf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="612f6020-9c4b-41ba-bcaa-27d6521981c1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="87af3af8-d339-4367-9032-a2b624a5b557"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e5f95c00-aa25-4634-af7c-3996b90899b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ede0446-d14f-4e5b-9244-645de95bca82"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ff6ec26c-3d98-415f-8221-c85ff25a4f30"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="19557a8e-acfc-4148-82e9-6bd6a1a66306"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="22bd776f-d5dd-41b1-bded-ed8674bdc6d9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="915e9503-00c9-4825-bbcc-a1082724d151"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="587de107-57ff-4272-ab1d-ba8b5495fbe8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="85000b00-762d-44cb-954d-b65d5e839cd2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c3d638ff-116f-4b14-ac94-744048f3aa3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb5ad829-f008-4640-a103-8dce16784a15"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e829a88-d946-49ad-bbc0-6bbd55eaf570"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="52bb8ef7-0211-42e7-9d09-a6bbc4bd6818"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="01d01a51-d68e-4215-b85f-1bb27a77dc14"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2aae36de-274d-4ce5-bf04-3130b51a23c0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4252dfb8-f7c6-45cb-975b-d284cdd67a8b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="52796e70-6abd-4612-a305-38aeb1854002"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="23551d94-9db4-407c-9428-0114d8771130"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="518661f5-3fb1-4c46-b169-cb8e47a0456c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8eeda928-f145-4531-9b88-1ccab686271a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aa703ebc-c37d-45ca-9123-3c2a0e217dbc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2982baec-bac1-40d5-979b-b62b9b51e387"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f04a66d2-9eb2-460e-baf6-da6957eee3f9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8a551f62-bc2d-484e-b48b-e68ee463e766"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3bb6abb9-9257-421b-ba01-04a2ee69909a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="58e12daa-04f5-4ab6-a89b-7339c1a0c2dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9d0f73ff-f58a-4c76-b634-c5df89f09605"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5ce303cf-f493-4ff5-83ee-f8d47f418da8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a62abe9-05c8-48e9-8fca-1c0f8da125f6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fcb1ee1e-2e58-4369-95b8-af6d10838f85"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a0f000d4-f350-4e38-934f-d8ba3941d21c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1c431544-80b4-40c8-b978-cdb24c043727"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7b0078b7-182e-4f69-8207-6743b1610e4c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1047d097-ad68-492a-b690-f849c101236b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9f711393-7172-44a3-be8c-b121f502ce7f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="58e10824-d1ca-4b7d-ab4b-b9e0c694a164"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e26e251-fcc8-4a97-9a83-890820f0c75e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d9e779e2-7cb9-43c3-a7f7-f607b104fcc6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cd2a47ff-0243-468a-9d48-b653a41795ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="53c837c6-4536-42dc-ab90-3cbfae5bc68d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4c0c59c4-b508-4744-8ff1-b45e6497f432"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6f296d9b-6853-45a0-8130-a1d55333a9ec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="451dcc7b-fe06-45ec-afbd-428f41241b54"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1a6ea748-df42-4a13-8998-f40709fd043b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1edec294-6d6a-429f-9773-f7565655af01"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a3ecc7cb-b47c-44a2-b27e-4c4f1a480f6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ad53d45-ec23-4b31-9513-42764c75a184"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f37f97fa-151d-438d-b429-2151deb3a281"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="72a03bf4-476d-42a2-a5d9-5ed8b2bfb7e8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="da7542f0-63ea-4f66-a464-bf0523c22a11"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="700f1639-d9da-439b-baed-a44f03c4cd74"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7f9f495c-519e-4c89-a085-8d807ff1ab47"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ffb045e7-54f2-4a44-b0af-899fcea058dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9213711d-a082-48fb-bbd3-9a6329b73e62"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="58c07cd0-14cb-469c-ab55-94aac8f1adc5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8c8e1d93-8b77-48a1-9df6-927a808ce978"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8fb39fa6-afc1-470e-88ea-fa16eca1a3c2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ad3beeb-2a2c-4769-ab17-4340170ebc3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a24fb72f-6b8d-46c8-9cf3-cdd1b1a3e40b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="70e7b6a8-7d9e-4f35-a8e3-dee19a319f52"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="13b791de-fd2c-4f78-b96c-7eacdd086298"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="612a0e50-fc59-41cf-8b4a-910990e8a02d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="54c23388-f0a0-4bd4-8b8c-64f55e2d04e6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c2d56429-80e6-4b14-83fe-f225fa3c596e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="03223401-c69f-4a5d-899d-617b42e2290d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e2065625-a3b9-4655-9254-fe772d06a7c1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="88ffb280-2ac2-4013-963b-73dfcb2c09c4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a8f327b2-db36-4b7f-834f-4ef573b662a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af75c18d-d5db-449b-a2a9-81275c447300"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39deeb50-1df9-40f6-9a94-d19adb0eebeb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="52dc05d9-86df-40af-9194-dae185536dd4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="559e19e2-4003-4612-9219-b8d153abeab9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8d612fc3-d8d7-4623-bcb9-9db9af484471"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec78471c-39c9-4462-8650-1216b1b8d863"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="59c5abaa-ce4c-45de-a791-a03507c7ac37"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c8e834d3-4cfa-4cba-8aa7-44752176e64e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b45e6486-fe3c-429d-8044-677a0f644a9a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c804d98-35d9-46d1-be6a-1e8bc8afa6f9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e25343c5-ecbf-4fe5-9578-b9efccad8d98"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6ba9cac3-1587-491d-8955-4899cb8ac643"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="746c7b52-4677-40ec-be92-110a51d40590"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1cba919-9670-4541-84f2-4ca6f2906fcb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="07882e7b-b8ac-4688-8cf5-f60c4436e479"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e04b7eb-8274-4cb6-844b-157c923083dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="68589621-990a-4fad-9cca-1a61874015d1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c111e66d-bf13-47bc-b3b5-de5960696eaf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="07d78159-f4c4-4354-be25-52ca8fd9508f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fbb5a85e-9347-4b03-bfbc-12271457e240"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="44cfa71f-84b8-4b3d-b3ae-6bc930717ce4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="db583d0d-71b8-47ee-9911-728b41296291"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4360cb7c-c7fc-42b2-bf3b-925693104475"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a259ee7-eb56-4072-b60d-bc4eac6bcd9b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="02a249b2-5eff-4ada-9739-0dd0a98fa2f4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c55ec8d-2f0d-4c10-afd1-7efe4ec485fe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c8295c14-1749-4e35-a57b-a57d68777de5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4f2d4c12-a41e-4b6c-89a7-dd2d9df18be9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="69124b5b-54b8-446e-b5b9-fa4e1c6bba22"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="07b4352a-fff1-4584-b99a-5fbb06cf27d1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="77c26d7b-b40e-4db2-9ad5-fb56e58d6fa7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95ea158e-a4df-415f-8018-b18cc2ec33ea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ee9b8a00-a37a-459e-9fe6-ade24dccf87f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a4603980-2001-44f4-adb0-796d7efaf547"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec91b201-9d85-4968-abfb-52bfd87f5928"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c7567d4-3f2f-48c2-a371-1d7172f93c3f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7a5750df-1b07-428e-8f2f-b9e2afb70f16"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8a83c8f3-bd2f-4c84-b42a-f8a9c549da43"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e6efc01-f1bc-477e-9f6e-fc9ede7700dc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3f165d08-6141-427c-9ed8-e2af2fedf620"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af3bd80d-8f9e-4547-afa0-766fb76337b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="beb22682-2207-438a-8bee-aae5121646ef"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c4a65078-e51c-45c6-973d-1987f4ee9a9d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fcd5ab34-e246-4b87-9a08-81d7fb93c8f8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2bce47a6-fda0-4033-b900-cedf1e3eb52f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="79d313d3-f598-40d6-9f3e-6703b78ca54c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d9d882ad-a1d9-4b08-b222-4d44d9c243b0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2bacc008-f4b0-4e95-9923-f21aa87bf5b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dc6338d8-dc34-4a65-adcb-c7ad38e06b03"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8c463236-3228-4389-a6af-70957c4453e6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7b6d6056-f71d-4806-bf95-471a3f48c0a4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f362d391-784e-4049-9960-4a88fc042f01"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="86d69c7d-fb5d-4901-8710-e7f383ecc29c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="637382d7-4705-473e-a93c-c6d1cae42269"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fe292298-f19b-4e87-a648-aa68d6e7a5ab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c95eb45-44ad-4a96-9cbe-aa6e608c8010"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="55cd639d-1c8e-4dea-a234-f1f8d4502de0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49702189-4a67-42a2-822b-4b52a853a5db"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b28f5285-2e9d-408f-80bf-b72fbfcb9be6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e2056009-c350-4693-bccc-b8ab21537509"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="406797a8-52db-4f0e-b46d-dd5267fd1532"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3be7ff6f-cc66-4238-86ec-9bcb9ccd751a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="edb97c78-0adf-4ba4-bbee-4481e95e535d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f9873020-1d8e-4042-a420-8114c4da68f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="42a12721-6ce3-4ca7-871a-6ccec9ad00b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="40e93d6a-8b5a-4a44-8557-dd3f73f4e967"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="36d1bb2a-0618-43d0-8d7b-cd279895357a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9a4e57c6-5213-4bcc-9444-f237ef792476"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="85df194e-eb9b-4ae8-bfad-7a7334f122cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="96abb7f1-18ec-47a6-a981-5e5720f22e0d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="baa2e122-d6d4-4f3f-8c7d-36322e9ca9e8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="92cbe51d-def4-4023-a0f8-1048d535e06d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e42bee42-082c-40f4-b474-57a393d4c39e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0d25a219-0189-483b-a14b-e26aa937d7cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e9421701-2fa7-4805-9a27-25e039792ccd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8efe57fc-ccb9-4631-85af-20e9627e819c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f444b0dd-3776-4d49-8ab3-57275f6d20f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3cc141b2-9024-4162-8522-cee91caf78ed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="55e31c2d-390b-442a-9f6e-e52b7b0cea13"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7f1803b9-10c3-4020-97fb-cbefc6606714"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4fe2c251-c8a6-4368-b4e8-2ad962491f65"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4978cfaf-398e-4485-bfdf-88d5d7c92782"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ad1d15f4-22d1-4ed7-827f-55b4d807838f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7362913-a8b2-4d99-a032-ec92069dde03"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f836ebad-3723-4e89-b038-6c00d55745d5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fa0b70cd-a5b5-48c2-928d-5fcbcb689747"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b3684986-17e3-444d-a28b-572bf81a3453"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f983dba9-da8e-4b1b-a076-1a3e32ac6380"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="45ff97bb-a25c-47be-bf14-b0045df0c2ef"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c67b1898-2ba5-4964-847c-18094f7f0a1f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="57b5bcf5-09dc-45c1-8fbd-1312111e41eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="602096f1-4269-4df4-a35f-b7faf8ea0e53"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="53e58b25-9b2f-45c0-ae40-6535232f6cf4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95147464-816f-4ca1-bc65-92a5045cf451"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f6e3bdf1-e3a8-4148-88fa-a48173f466ec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aa12a3d2-fefd-4bc6-85dd-5c9aeb67f2fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="001c1739-538a-47cf-89fa-9a9678051da6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="32cdd7c6-f803-4921-ae67-9823e8d042b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="80085e56-9a35-48b6-bceb-a264cfdb3f59"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d5346bc4-c515-4295-a3ef-99ea3439e000"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d959501-f5e7-42b9-8482-a91d6cea25ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a596dc3-da80-451c-8d98-57b30df09ccc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1702a39-d8d1-4518-be48-300f7bd2eb0f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b8297117-18b6-4f8c-b864-0857ab598ce7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5c8746d9-545f-47de-8aec-2fc55593af2c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17ce4f22-e59e-4ddf-8826-769b089b83de"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="386ebc9f-400f-44d7-9faf-e98ea5690578"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="de53a115-d010-4c73-a1a9-4d6ec826c114"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bd616019-36f3-4f4e-8ca7-0a06dbe2ba7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="21a68a79-07dc-4d30-be9e-abf1d372c7aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="46230828-da69-45cd-9ce7-d952b15d22fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ab2a560e-0e82-415f-9bba-7fc395c7ef7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="09eb0efc-abf6-4708-ba7b-12716d89b62a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4b8ebf54-8231-43e5-a1f6-35fe9d8345a5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c72b5076-5dcf-429d-a973-98df8883a587"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec6b1057-2678-4ee2-939c-940542801889"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7953247-738d-4ca6-95de-c8d603669ef0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8e0f9f5a-5413-4e88-aedd-b0a0a54ab34f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4558a2a7-56f2-4a67-a15a-553d25e4efb3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a49bb4bd-17ba-4242-a8cf-886077e8904f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7500f26d-5d38-4186-9ebb-c4873a98a66e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9cd98ec8-d957-43a7-9108-7decc6101dc7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e971353d-2891-41d9-b1a8-d3a3ea7b1e4a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4320637c-9011-4624-a34b-a3b3d5876f97"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a675f422-350e-47e2-aed2-e50334947eb4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cf72462b-4bf8-4c05-8d41-9bfdb74898e5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a8835e7e-9279-4fa0-a210-5d729e914a43"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="beddbfa5-a788-4ab7-a650-ce5d23c40d04"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dabe5358-d6d8-4aff-90af-d1510c568b2b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="305b9c46-8e09-4b4d-b1bf-526c94181219"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ef2390d6-1957-406f-b45b-1fe817c55472"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c83cebaf-7f4b-4f34-9e44-1b3899a655f2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8e705f37-aa88-4241-b2ea-3394a53bf2ba"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="61573881-06c3-4626-9149-8456594480d8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0b3575f6-9fe0-4838-9cc2-84f26d8c200c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="43d12613-1576-4cdb-935d-d351435a184e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bb046f09-0cc9-4b25-85fd-0ed2d6d960e8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="74c82b79-f696-4ffe-8130-9af477a49a0f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c7d5d4a-ae5d-49b6-ac37-908ea4cc8e0e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="85b0d4f3-47cc-4ca0-954e-3a683aef6a83"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="038a6877-3589-4e5c-8f17-d28fdaa16b7c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="46d594b3-21a0-4b65-adb0-9b8ff7fa4153"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eb32529b-62be-4a86-87ce-995308cd9783"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d8f1c453-7d6e-4013-8d3a-b36a124bcfa7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="88489ff6-88f0-4283-974f-7c5d356fbc5f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="652a8876-da36-4d36-b019-83a9d94f3433"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="849cc3a3-3809-48d8-85b6-fb0397e03df5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9bbb576b-195a-43a4-8915-0c7f6d5c6e01"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="04c88564-fa89-4682-8ab9-6fa03153d330"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="203706cb-a07c-4f80-9db9-7f5bdd3ba791"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc1f738f-2982-444a-9594-75da9ebd1a98"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c2d81bf7-990e-46b9-b222-bc3ab98cf860"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="97d10a04-08af-4a1e-b68d-828468e75df6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cf213700-cc46-413d-a650-3c321148f1c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d1b1c083-e31d-49fb-a58e-5b01beebe89d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="85166a44-93ac-46f8-9ad2-a11613889157"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="14c0dda1-4f6d-4ded-944d-dd2c908c4d2c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1e90487d-bdef-4e15-b8fc-a52c3974bd6f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="00ba050b-1b8b-4b68-96be-1b717b92762f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="802f8246-86d0-457b-8b10-1fc48c7dce6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3784928d-2c93-4988-8f41-94bb67e5c34e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bdaf2566-c833-4aaf-aca6-3836b162cd4a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b207899b-9e3f-45e7-9951-87f2d08ae8c6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9ec6e2f3-e3e2-4550-ae59-0fcc8a279f08"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0294a097-877e-4e4a-9d3b-7f25c8518281"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9d37662a-13dc-4aea-90b4-c6dec5fcdcf2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
        </div>
    </div>
    



<p class="footer">
    Generated by junit2html
</p>
</body>
</html>