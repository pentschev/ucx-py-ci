2023-04-18 01:07:12,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:12,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:12,025 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 01:07:12,026 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:12,026 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:12,025 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 01:07:12,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:12,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:12,048 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 01:07:12,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:12,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:12,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:12,052 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:12,052 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 01:07:12,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:12,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:12,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:12,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:12,056 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 01:07:12,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:12,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:62162:0:62162] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  62162) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fb1d805fc2d]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29e34) [0x7fb1d805fe34]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29ffa) [0x7fb1d805fffa]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7fb24eeb0980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fb1d80d9534]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fb1d80fe939]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x2042c) [0x7fb1c1b0842c]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x236d8) [0x7fb1c1b0b6d8]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fb1d8068559]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7e) [0x7fb1c1b0a5ce]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fb1d80d6b9a]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7fb1c1b4b2d9]
12  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x55f7df217343]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55f7df2221fa]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x55f7df208b8b]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55f7df2012f1]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55f7df21293c]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55f7df202a55]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55f7df2271e8]
19  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7003) [0x7fb1e9081003]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_MakeTpCall+0x3db) [0x55f7df20b30b]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x55f7df1c9b07]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x55f7df209f96]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x55f7df2201ea]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55f7df208178]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55f7df2128a6]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55f7df202a55]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55f7df2128a6]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55f7df202a55]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55f7df2128a6]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55f7df202a55]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55f7df2128a6]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55f7df202a55]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55f7df2012f1]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55f7df21293c]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x55f7df206efb]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55f7df2012f1]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55f7df21293c]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55f7df21fe8c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x55f7df20aa92]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x55f7df2d7049]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x55f7df222283]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55f7df2043de]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55f7df2128a6]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55f7df21fe8c]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55f7df2221fa]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55f7df2043de]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55f7df2128a6]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55f7df202a55]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55f7df2012f1]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55f7df21293c]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55f7df202a55]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55f7df2128a6]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x55f7df202729]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55f7df2012f1]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55f7df21293c]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55f7df20353f]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55f7df2012f1]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55f7df2b3e99]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55f7df2b3e5b]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x55f7df2d47f9]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ea7f3) [0x55f7df2d37f3]
=================================
2023-04-18 01:07:20,317 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40935 -> ucx://127.0.0.1:53103
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1b91be4100, tag: 0x228e4981d982b6c4, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 01:07:20,317 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34051 -> ucx://127.0.0.1:53103
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1ab0ad1100, tag: 0x92d7148b3f3701b1, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 01:07:20,317 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:55273 -> ucx://127.0.0.1:53103
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f14a0480100, tag: 0xc856d4c2aad562aa, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 01:07:20,398 - distributed.nanny - WARNING - Restarting worker
[dgx13:62170:0:62170] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  62170) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fc3051ccc2d]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29e34) [0x7fc3051cce34]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29ffa) [0x7fc3051ccffa]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7fc38e529980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fc305246534]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fc30526b939]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x2042c) [0x7fc3184f542c]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x236d8) [0x7fc3184f86d8]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fc3051d5559]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7e) [0x7fc3184f75ce]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fc305243b9a]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7fc3052ea2d9]
12  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x559c3b28f343]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x559c3b29a1fa]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x559c3b280b8b]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x559c3b2792f1]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x559c3b28a93c]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x559c3b27aa55]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x559c3b29f1e8]
19  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7003) [0x7fc3808b9003]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_MakeTpCall+0x3db) [0x559c3b28330b]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x559c3b241b07]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x559c3b281f96]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x559c3b2981ea]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x559c3b280178]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x559c3b28a8a6]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x559c3b27aa55]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x559c3b28a8a6]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x559c3b27aa55]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x559c3b28a8a6]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x559c3b27aa55]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x559c3b28a8a6]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x559c3b27aa55]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x559c3b2792f1]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x559c3b28a93c]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x559c3b27eefb]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x559c3b2792f1]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x559c3b28a93c]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x559c3b297e8c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x559c3b282a92]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x559c3b34f049]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x559c3b29a283]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x559c3b27c3de]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x559c3b28a8a6]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x559c3b297e8c]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x559c3b29a1fa]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x559c3b27c3de]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x559c3b28a8a6]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x559c3b27aa55]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x559c3b2792f1]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x559c3b28a93c]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x559c3b27aa55]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x559c3b28a8a6]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x559c3b27a729]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x559c3b2792f1]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x559c3b28a93c]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x559c3b27b53f]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x559c3b2792f1]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x559c3b32be99]
[dgx13:62177:0:62177] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x559c3b32be5b]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x559c3b34c7f9]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ea7f3) [0x559c3b34b7f3]
=================================
==== backtrace (tid:  62177) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fcd0817bc2d]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29e34) [0x7fcd0817be34]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29ffa) [0x7fcd0817bffa]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7fcd8d49a980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fcd081f5534]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fcd0821a939]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x2042c) [0x7fcd0813642c]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x236d8) [0x7fcd081396d8]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fcd08184559]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7e) [0x7fcd081385ce]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fcd081f2b9a]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7fcd082992d9]
12  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x55705068a343]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x5570506951fa]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x55705067bb8b]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5570506742f1]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55705068593c]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x557050675a55]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55705069a1e8]
19  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7003) [0x7fcd2766b003]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_MakeTpCall+0x3db) [0x55705067e30b]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x55705063cb07]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x55705067cf96]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x5570506931ea]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55705067b178]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5570506858a6]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x557050675a55]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5570506858a6]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x557050675a55]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5570506858a6]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x557050675a55]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5570506858a6]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x557050675a55]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5570506742f1]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55705068593c]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x557050679efb]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5570506742f1]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55705068593c]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x557050692e8c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x55705067da92]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x55705074a049]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x557050695283]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x5570506773de]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5570506858a6]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x557050692e8c]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x5570506951fa]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x5570506773de]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5570506858a6]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x557050675a55]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5570506742f1]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55705068593c]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x557050675a55]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5570506858a6]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x557050675729]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5570506742f1]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55705068593c]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55705067653f]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5570506742f1]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x557050726e99]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x557050726e5b]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x5570507477f9]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ea7f3) [0x5570507467f3]
=================================
[dgx13:62166:0:62166] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  62166) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f49f8082c2d]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29e34) [0x7f49f8082e34]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29ffa) [0x7f49f8082ffa]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7f4a7c2a3980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f49f2f39534]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f49f2f5e939]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x2042c) [0x7f49f803d42c]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x236d8) [0x7f49f80406d8]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f49f808b559]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7e) [0x7f49f803f5ce]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f49f2f36b9a]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7f49f2fdd2d9]
12  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x55bfba8f1343]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55bfba8fc1fa]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x55bfba8e2b8b]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bfba8db2f1]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55bfba8ec93c]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bfba8dca55]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55bfba9011e8]
19  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7003) [0x7f4a1646d003]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_MakeTpCall+0x3db) [0x55bfba8e530b]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x55bfba8a3b07]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x55bfba8e3f96]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x55bfba8fa1ea]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55bfba8e2178]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bfba8ec8a6]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bfba8dca55]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bfba8ec8a6]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bfba8dca55]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bfba8ec8a6]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bfba8dca55]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bfba8ec8a6]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bfba8dca55]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bfba8db2f1]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55bfba8ec93c]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x55bfba8e0efb]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bfba8db2f1]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55bfba8ec93c]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55bfba8f9e8c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x55bfba8e4a92]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x55bfba9b1049]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x55bfba8fc283]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55bfba8de3de]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bfba8ec8a6]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55bfba8f9e8c]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55bfba8fc1fa]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55bfba8de3de]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bfba8ec8a6]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bfba8dca55]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bfba8db2f1]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55bfba8ec93c]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bfba8dca55]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bfba8ec8a6]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x55bfba8dc729]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bfba8db2f1]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55bfba8ec93c]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55bfba8dd53f]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bfba8db2f1]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55bfba98de99]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55bfba98de5b]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x55bfba9ae7f9]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ea7f3) [0x55bfba9ad7f3]
=================================
2023-04-18 01:07:21,049 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40935 -> ucx://127.0.0.1:33589
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1b91be4300, tag: 0xd46cb8d21c8bc2a1, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 01:07:21,049 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33589
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f1ab0ad1200, tag: 0x8693eb787b9c7427, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f1ab0ad1200, tag: 0x8693eb787b9c7427, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-04-18 01:07:21,050 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33589
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f1b91be4200, tag: 0xb562ba5e5ee66987, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f1b91be4200, tag: 0xb562ba5e5ee66987, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-04-18 01:07:21,058 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55121
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #010] ep: 0x7f1b91be4180, tag: 0xef417cf052a59381, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #010] ep: 0x7f1b91be4180, tag: 0xef417cf052a59381, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-04-18 01:07:21,059 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34051 -> ucx://127.0.0.1:55121
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1ab0ad1300, tag: 0x141ae85dea67de49, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 01:07:21,059 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55121
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f1ab0ad1140, tag: 0x715a2d5bc710de1f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f1ab0ad1140, tag: 0x715a2d5bc710de1f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 01:07:21,083 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55121
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f2f202fe380, tag: 0x380df41d174969b, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f2f202fe380, tag: 0x380df41d174969b, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-04-18 01:07:21,087 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49819
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 481, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 484, in wait_for
    return fut.result()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f2f202fe280, tag: 0xaab1070f0e0ce305, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:49819 after 30 s
2023-04-18 01:07:21,094 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49819
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f1b91be4140, tag: 0x4cab31f8ead5079d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f1b91be4140, tag: 0x4cab31f8ead5079d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-04-18 01:07:21,102 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40935 -> ucx://127.0.0.1:49819
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #012] ep: 0x7f1b91be4100, tag: 0xf0c9935a3fc1d825, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1793, in get_data
    response = await comm.read(deserializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #012] ep: 0x7f1b91be4100, tag: 0xf0c9935a3fc1d825, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 01:07:21,122 - distributed.nanny - WARNING - Restarting worker
2023-04-18 01:07:21,177 - distributed.nanny - WARNING - Restarting worker
2023-04-18 01:07:21,192 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49819
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f1ab0ad1100, tag: 0xe2d5b0c0023d1e03, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f1ab0ad1100, tag: 0xe2d5b0c0023d1e03, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 01:07:21,224 - distributed.nanny - WARNING - Restarting worker
2023-04-18 01:07:22,422 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 01:07:22,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:22,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:23,021 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 01:07:23,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:23,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:23,093 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 01:07:23,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:23,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:23,126 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 01:07:23,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 01:07:23,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 01:07:50,755 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33589
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:33589 after 30 s
2023-04-18 01:07:50,849 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49819
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:49819 after 30 s
2023-04-18 01:07:50,849 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33589
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:33589 after 30 s
2023-04-18 01:07:50,850 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55121
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:55121 after 30 s
/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
