============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-24 06:37:42,356 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:37:42,360 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34131 instead
  warnings.warn(
2024-01-24 06:37:42,364 - distributed.scheduler - INFO - State start
2024-01-24 06:37:42,386 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:37:42,387 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-24 06:37:42,388 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34131/status
2024-01-24 06:37:42,388 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:37:42,492 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38577'
2024-01-24 06:37:42,508 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39457'
2024-01-24 06:37:42,511 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35633'
2024-01-24 06:37:42,518 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38775'
2024-01-24 06:37:42,679 - distributed.scheduler - INFO - Receive client connection: Client-12608d7c-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:42,693 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47820
2024-01-24 06:37:44,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:44,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:44,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:44,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:44,231 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:44,231 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:44,232 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33959
2024-01-24 06:37:44,232 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43551
2024-01-24 06:37:44,232 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33959
2024-01-24 06:37:44,232 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43551
2024-01-24 06:37:44,232 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41471
2024-01-24 06:37:44,232 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37529
2024-01-24 06:37:44,232 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-24 06:37:44,232 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-24 06:37:44,232 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,232 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,232 - distributed.worker - INFO -               Threads:                          4
2024-01-24 06:37:44,232 - distributed.worker - INFO -               Threads:                          4
2024-01-24 06:37:44,232 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-24 06:37:44,232 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-24 06:37:44,232 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-kgkizf4p
2024-01-24 06:37:44,232 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-18uk7rsc
2024-01-24 06:37:44,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3195a867-56b3-4574-8c45-94371a40dc26
2024-01-24 06:37:44,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c4683e50-0fe6-4757-bfe2-37f15c5769d5
2024-01-24 06:37:44,233 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-76034f7e-c383-482c-8fba-583d5195eb03
2024-01-24 06:37:44,233 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a43fd1e4-07cf-4ee3-81e9-92be1b105a33
2024-01-24 06:37:44,233 - distributed.worker - INFO - Starting Worker plugin PreImport-0e4501a1-61c6-4345-b36d-90d702757224
2024-01-24 06:37:44,233 - distributed.worker - INFO - Starting Worker plugin PreImport-e1d6c914-890a-4c80-ad94-686abd80bc69
2024-01-24 06:37:44,233 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,233 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:44,235 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:44,239 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:44,239 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37301
2024-01-24 06:37:44,240 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37301
2024-01-24 06:37:44,240 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42683
2024-01-24 06:37:44,240 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-24 06:37:44,240 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,240 - distributed.worker - INFO -               Threads:                          4
2024-01-24 06:37:44,240 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-24 06:37:44,240 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-tin2xj42
2024-01-24 06:37:44,240 - distributed.worker - INFO - Starting Worker plugin PreImport-ec6a128f-d381-4905-8271-edb68b431d10
2024-01-24 06:37:44,240 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f8cdf970-d2df-4815-84b6-57766b1d32a1
2024-01-24 06:37:44,241 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:44,241 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:44,241 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9b4d9f8a-b000-4dba-9ffd-f1f7f1bd0c9b
2024-01-24 06:37:44,242 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,245 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:44,246 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40399
2024-01-24 06:37:44,246 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40399
2024-01-24 06:37:44,246 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34023
2024-01-24 06:37:44,246 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-24 06:37:44,246 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,246 - distributed.worker - INFO -               Threads:                          4
2024-01-24 06:37:44,247 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-24 06:37:44,247 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-23xzaty5
2024-01-24 06:37:44,247 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9e914a9a-d686-44be-9493-b9b987d843ce
2024-01-24 06:37:44,247 - distributed.worker - INFO - Starting Worker plugin PreImport-c8af26ec-902a-4518-9585-c8b976fe7176
2024-01-24 06:37:44,248 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2947a3a1-d40d-4940-8e8e-41b00a6b6862
2024-01-24 06:37:44,248 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,353 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33959', status: init, memory: 0, processing: 0>
2024-01-24 06:37:44,355 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33959
2024-01-24 06:37:44,355 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47836
2024-01-24 06:37:44,355 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:44,356 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-24 06:37:44,356 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,358 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-24 06:37:44,358 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43551', status: init, memory: 0, processing: 0>
2024-01-24 06:37:44,359 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43551
2024-01-24 06:37:44,359 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47850
2024-01-24 06:37:44,360 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:44,360 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-24 06:37:44,360 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,361 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-24 06:37:44,377 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37301', status: init, memory: 0, processing: 0>
2024-01-24 06:37:44,377 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37301
2024-01-24 06:37:44,377 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47862
2024-01-24 06:37:44,378 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:44,379 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-24 06:37:44,379 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,380 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40399', status: init, memory: 0, processing: 0>
2024-01-24 06:37:44,380 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-24 06:37:44,381 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40399
2024-01-24 06:37:44,381 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47870
2024-01-24 06:37:44,382 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:44,383 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-24 06:37:44,383 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:44,384 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-24 06:37:44,434 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-24 06:37:44,434 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-24 06:37:44,434 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-24 06:37:44,434 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-24 06:37:44,439 - distributed.scheduler - INFO - Remove client Client-12608d7c-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:44,439 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47820; closing.
2024-01-24 06:37:44,439 - distributed.scheduler - INFO - Remove client Client-12608d7c-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:44,440 - distributed.scheduler - INFO - Close client connection: Client-12608d7c-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:44,441 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38577'. Reason: nanny-close
2024-01-24 06:37:44,441 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:44,441 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39457'. Reason: nanny-close
2024-01-24 06:37:44,442 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:44,442 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35633'. Reason: nanny-close
2024-01-24 06:37:44,442 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40399. Reason: nanny-close
2024-01-24 06:37:44,443 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:44,443 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43551. Reason: nanny-close
2024-01-24 06:37:44,443 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38775'. Reason: nanny-close
2024-01-24 06:37:44,443 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:44,443 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37301. Reason: nanny-close
2024-01-24 06:37:44,444 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33959. Reason: nanny-close
2024-01-24 06:37:44,444 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-24 06:37:44,444 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47870; closing.
2024-01-24 06:37:44,444 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-24 06:37:44,445 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40399', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078264.4449997')
2024-01-24 06:37:44,445 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-24 06:37:44,446 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47862; closing.
2024-01-24 06:37:44,446 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:44,446 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-24 06:37:44,446 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47850; closing.
2024-01-24 06:37:44,446 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:44,446 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37301', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078264.4468517')
2024-01-24 06:37:44,447 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:44,447 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43551', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078264.4472556')
2024-01-24 06:37:44,447 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:44,447 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:47862>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:47862>: Stream is closed
2024-01-24 06:37:44,449 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47836; closing.
2024-01-24 06:37:44,449 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33959', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078264.449629')
2024-01-24 06:37:44,449 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:37:45,106 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:37:45,107 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:37:45,107 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:37:45,108 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-24 06:37:45,108 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-24 06:37:47,189 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:37:47,193 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-24 06:37:47,196 - distributed.scheduler - INFO - State start
2024-01-24 06:37:47,218 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:37:47,219 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:37:47,220 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-24 06:37:47,220 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:37:47,452 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40697'
2024-01-24 06:37:47,463 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45559'
2024-01-24 06:37:47,471 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37397'
2024-01-24 06:37:47,485 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43659'
2024-01-24 06:37:47,489 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38711'
2024-01-24 06:37:47,497 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38881'
2024-01-24 06:37:47,508 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37271'
2024-01-24 06:37:47,518 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44371'
2024-01-24 06:37:48,119 - distributed.scheduler - INFO - Receive client connection: Client-15307a89-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:48,132 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54704
2024-01-24 06:37:49,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:49,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:49,271 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:49,272 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43541
2024-01-24 06:37:49,272 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43541
2024-01-24 06:37:49,272 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39671
2024-01-24 06:37:49,272 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:49,272 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:49,272 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:49,272 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:49,272 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n6t6376a
2024-01-24 06:37:49,273 - distributed.worker - INFO - Starting Worker plugin PreImport-4d15b6dc-e32c-4844-b9da-6efcbc4f3e4b
2024-01-24 06:37:49,273 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e5ba3539-7919-4171-a440-bc09b9b538a6
2024-01-24 06:37:49,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:49,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:49,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:49,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:49,501 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:49,501 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:49,502 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43509
2024-01-24 06:37:49,502 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38015
2024-01-24 06:37:49,502 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38015
2024-01-24 06:37:49,502 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43509
2024-01-24 06:37:49,502 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39109
2024-01-24 06:37:49,502 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45743
2024-01-24 06:37:49,502 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:49,502 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:49,502 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:49,502 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:49,502 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:49,502 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:49,503 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:49,503 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:49,503 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kx68r_h1
2024-01-24 06:37:49,503 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-26y1b1t8
2024-01-24 06:37:49,503 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c9c3319f-5074-49e1-9116-f1b19d4dc351
2024-01-24 06:37:49,503 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b2c5abaa-c3cb-41f4-b464-1c6c74950f8d
2024-01-24 06:37:49,503 - distributed.worker - INFO - Starting Worker plugin RMMSetup-761f3611-e2aa-48ad-a13b-b6d57233c85c
2024-01-24 06:37:49,504 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c4749a26-c326-4230-a7a5-5567c686a743
2024-01-24 06:37:49,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:49,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:49,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:49,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:49,512 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:49,512 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45811
2024-01-24 06:37:49,512 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:49,513 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45811
2024-01-24 06:37:49,513 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39915
2024-01-24 06:37:49,513 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:49,513 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:49,513 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:49,513 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:49,513 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3oqt3i5g
2024-01-24 06:37:49,513 - distributed.worker - INFO - Starting Worker plugin PreImport-9c8af7ba-81bc-4d39-bcf9-6e22484decf6
2024-01-24 06:37:49,513 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0a469d36-5018-49f2-8ffb-a2dad2bc3c20
2024-01-24 06:37:49,514 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46129
2024-01-24 06:37:49,514 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46129
2024-01-24 06:37:49,514 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38017
2024-01-24 06:37:49,514 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:49,514 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:49,514 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:49,514 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:49,514 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nnjgqt_v
2024-01-24 06:37:49,514 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9f542963-90ac-46a6-9479-f09890dfc15d
2024-01-24 06:37:49,514 - distributed.worker - INFO - Starting Worker plugin PreImport-7e8d3ead-67ec-4e16-90af-93f0d1dad812
2024-01-24 06:37:49,514 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ec51dad8-b480-44ff-a512-dc05e3e754e4
2024-01-24 06:37:49,515 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0fb1d16-fe35-4b2b-a9cf-16811cab6520
2024-01-24 06:37:49,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:49,517 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:49,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:49,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:49,525 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:49,526 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:49,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:49,527 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36307
2024-01-24 06:37:49,527 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36307
2024-01-24 06:37:49,527 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45581
2024-01-24 06:37:49,527 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:49,527 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:49,527 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:49,527 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:49,527 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7xpjlnmz
2024-01-24 06:37:49,528 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-095e78e4-cda7-4078-b15c-54bc7f725d35
2024-01-24 06:37:49,528 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aa934f39-46a5-44bd-bf00-afe5c6bb8662
2024-01-24 06:37:49,529 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:49,530 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42345
2024-01-24 06:37:49,530 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42345
2024-01-24 06:37:49,531 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34909
2024-01-24 06:37:49,531 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:49,531 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:49,531 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:49,531 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:49,531 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pu4wgp14
2024-01-24 06:37:49,531 - distributed.worker - INFO - Starting Worker plugin PreImport-94e08fcd-6ad5-4bac-aac7-247c9a8928d9
2024-01-24 06:37:49,531 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a88b1041-84f0-4fdc-9f7b-e9db2e6ce1c7
2024-01-24 06:37:49,531 - distributed.worker - INFO - Starting Worker plugin RMMSetup-805a25a6-2c0d-4ff3-9d36-efdf9d16ab43
2024-01-24 06:37:49,533 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:49,534 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32865
2024-01-24 06:37:49,534 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32865
2024-01-24 06:37:49,535 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42691
2024-01-24 06:37:49,535 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:49,535 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:49,535 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:49,535 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:49,535 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dj8xd2li
2024-01-24 06:37:49,535 - distributed.worker - INFO - Starting Worker plugin PreImport-b53e0051-7c7d-4aec-bc3c-8e5bc54be97f
2024-01-24 06:37:49,535 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4c6403ba-76a2-4e3d-9177-426e51028fb4
2024-01-24 06:37:49,539 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0813adf2-fdda-4b54-8819-4bf9f01894d0
2024-01-24 06:37:49,749 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c5eb6d93-48f9-45be-9382-84ab135ac2e0
2024-01-24 06:37:49,752 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:49,780 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43541', status: init, memory: 0, processing: 0>
2024-01-24 06:37:49,782 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43541
2024-01-24 06:37:49,782 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54728
2024-01-24 06:37:49,784 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:49,785 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:49,785 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:49,787 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:51,493 - distributed.worker - INFO - Starting Worker plugin PreImport-165e67f3-80eb-4bfb-92f0-2ff3aa5bed35
2024-01-24 06:37:51,494 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,506 - distributed.worker - INFO - Starting Worker plugin PreImport-aa5bbdb8-8fd6-446b-834d-e9400a264579
2024-01-24 06:37:51,508 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,516 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43509', status: init, memory: 0, processing: 0>
2024-01-24 06:37:51,517 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43509
2024-01-24 06:37:51,517 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60130
2024-01-24 06:37:51,518 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:51,518 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:51,518 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,520 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:51,537 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38015', status: init, memory: 0, processing: 0>
2024-01-24 06:37:51,537 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,538 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38015
2024-01-24 06:37:51,538 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60142
2024-01-24 06:37:51,539 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:51,540 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:51,540 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,541 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,543 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:51,547 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,550 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,566 - distributed.worker - INFO - Starting Worker plugin PreImport-8ad63214-7ee2-48d0-92ed-15b7761dcf14
2024-01-24 06:37:51,567 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,567 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32865', status: init, memory: 0, processing: 0>
2024-01-24 06:37:51,567 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32865
2024-01-24 06:37:51,567 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60160
2024-01-24 06:37:51,568 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45811', status: init, memory: 0, processing: 0>
2024-01-24 06:37:51,569 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:51,569 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45811
2024-01-24 06:37:51,569 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60144
2024-01-24 06:37:51,570 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:51,570 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,570 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:51,571 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:51,572 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,572 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:51,572 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46129', status: init, memory: 0, processing: 0>
2024-01-24 06:37:51,573 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46129
2024-01-24 06:37:51,573 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60164
2024-01-24 06:37:51,574 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:51,574 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:51,574 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42345', status: init, memory: 0, processing: 0>
2024-01-24 06:37:51,574 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:51,574 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,575 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42345
2024-01-24 06:37:51,575 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60168
2024-01-24 06:37:51,576 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:51,576 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:51,576 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:51,577 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,578 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:51,592 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36307', status: init, memory: 0, processing: 0>
2024-01-24 06:37:51,593 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36307
2024-01-24 06:37:51,593 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60180
2024-01-24 06:37:51,594 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:51,595 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:51,595 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:51,597 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:51,675 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:51,675 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:51,675 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:51,675 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:51,676 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:51,676 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:51,676 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:51,676 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:51,681 - distributed.scheduler - INFO - Remove client Client-15307a89-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:51,681 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54704; closing.
2024-01-24 06:37:51,682 - distributed.scheduler - INFO - Remove client Client-15307a89-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:51,682 - distributed.scheduler - INFO - Close client connection: Client-15307a89-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:51,683 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40697'. Reason: nanny-close
2024-01-24 06:37:51,683 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:51,683 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45559'. Reason: nanny-close
2024-01-24 06:37:51,684 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:51,684 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37397'. Reason: nanny-close
2024-01-24 06:37:51,685 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38015. Reason: nanny-close
2024-01-24 06:37:51,685 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:51,685 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43659'. Reason: nanny-close
2024-01-24 06:37:51,685 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32865. Reason: nanny-close
2024-01-24 06:37:51,685 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:51,685 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38711'. Reason: nanny-close
2024-01-24 06:37:51,686 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46129. Reason: nanny-close
2024-01-24 06:37:51,686 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:51,686 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38881'. Reason: nanny-close
2024-01-24 06:37:51,686 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43509. Reason: nanny-close
2024-01-24 06:37:51,686 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:51,686 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37271'. Reason: nanny-close
2024-01-24 06:37:51,687 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:51,687 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36307. Reason: nanny-close
2024-01-24 06:37:51,687 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44371'. Reason: nanny-close
2024-01-24 06:37:51,687 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:51,687 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45811. Reason: nanny-close
2024-01-24 06:37:51,687 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:51,687 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60142; closing.
2024-01-24 06:37:51,687 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42345. Reason: nanny-close
2024-01-24 06:37:51,687 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:51,688 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38015', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078271.687964')
2024-01-24 06:37:51,688 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:51,688 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:51,688 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43541. Reason: nanny-close
2024-01-24 06:37:51,688 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60164; closing.
2024-01-24 06:37:51,689 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60160; closing.
2024-01-24 06:37:51,689 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:51,689 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:51,689 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:51,689 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:51,690 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:51,690 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46129', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078271.6900144')
2024-01-24 06:37:51,690 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32865', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078271.6903725')
2024-01-24 06:37:51,690 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60130; closing.
2024-01-24 06:37:51,690 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:51,691 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:51,691 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:51,691 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:51,691 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43509', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078271.6916583')
2024-01-24 06:37:51,692 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60180; closing.
2024-01-24 06:37:51,692 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:51,692 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:51,692 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36307', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078271.6926942')
2024-01-24 06:37:51,693 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:51,693 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60168; closing.
2024-01-24 06:37:51,693 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60144; closing.
2024-01-24 06:37:51,693 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54728; closing.
2024-01-24 06:37:51,693 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42345', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078271.6938035')
2024-01-24 06:37:51,694 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45811', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078271.6941776')
2024-01-24 06:37:51,694 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43541', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078271.694576')
2024-01-24 06:37:51,694 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:37:52,649 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:37:52,649 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:37:52,650 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:37:52,651 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:37:52,651 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-24 06:37:54,715 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:37:54,721 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-24 06:37:54,725 - distributed.scheduler - INFO - State start
2024-01-24 06:37:54,751 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:37:54,753 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:37:54,753 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-24 06:37:54,754 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:37:54,757 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40135'
2024-01-24 06:37:54,778 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45443'
2024-01-24 06:37:54,781 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35491'
2024-01-24 06:37:54,801 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35385'
2024-01-24 06:37:54,803 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35143'
2024-01-24 06:37:54,817 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41117'
2024-01-24 06:37:54,821 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42605'
2024-01-24 06:37:54,830 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33187'
2024-01-24 06:37:56,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:56,638 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:56,642 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:56,643 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43449
2024-01-24 06:37:56,643 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43449
2024-01-24 06:37:56,643 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35269
2024-01-24 06:37:56,643 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:56,643 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:56,643 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:56,643 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:56,643 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-flhmaetn
2024-01-24 06:37:56,643 - distributed.worker - INFO - Starting Worker plugin PreImport-75e34fef-6ff7-4c88-ae7e-fac52de69d92
2024-01-24 06:37:56,643 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b5431292-d6e0-4f73-964b-270729380ddf
2024-01-24 06:37:56,878 - distributed.scheduler - INFO - Receive client connection: Client-19afa29b-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:56,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:56,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:56,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:56,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:56,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:56,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:56,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:56,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:56,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:56,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:56,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:56,889 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:56,889 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:56,889 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:37:56,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:37:56,890 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39197
2024-01-24 06:37:56,890 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:56,890 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39197
2024-01-24 06:37:56,890 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:56,890 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34511
2024-01-24 06:37:56,890 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:56,890 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:56,890 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:56,890 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:56,890 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6kipn1cl
2024-01-24 06:37:56,891 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dc8f0789-265b-4479-92bb-1e995b9635ea
2024-01-24 06:37:56,891 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38343
2024-01-24 06:37:56,891 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5f5cfffb-d3e8-41b5-855d-dce6c0c31fee
2024-01-24 06:37:56,891 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39799
2024-01-24 06:37:56,891 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38343
2024-01-24 06:37:56,892 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39799
2024-01-24 06:37:56,892 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38365
2024-01-24 06:37:56,892 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:56,892 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45425
2024-01-24 06:37:56,892 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:56,892 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:56,892 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:56,892 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:56,892 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:56,892 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tvwbt8jz
2024-01-24 06:37:56,892 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:56,892 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:56,892 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p_w1bk1e
2024-01-24 06:37:56,892 - distributed.worker - INFO - Starting Worker plugin PreImport-f7bc3c70-b7d9-44f3-bf74-ad7905faaeff
2024-01-24 06:37:56,892 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0e7177a8-917b-40ff-9715-4b02e623464f
2024-01-24 06:37:56,892 - distributed.worker - INFO - Starting Worker plugin PreImport-4c7197e5-0d9c-4fc7-a68e-ed826c6801cc
2024-01-24 06:37:56,892 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:56,893 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d907551a-3c05-4c80-9cb3-2f2c7b980add
2024-01-24 06:37:56,893 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60580
2024-01-24 06:37:56,894 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37393
2024-01-24 06:37:56,894 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:56,894 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37393
2024-01-24 06:37:56,894 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45491
2024-01-24 06:37:56,894 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:56,894 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:56,894 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:56,894 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:56,894 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-e0vybga6
2024-01-24 06:37:56,895 - distributed.worker - INFO - Starting Worker plugin PreImport-ccf3e5a1-2003-4ec7-85e1-cc6cb76fffa3
2024-01-24 06:37:56,895 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0c31d9c-e7fc-4375-ad5c-4832bf9ee379
2024-01-24 06:37:56,895 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38915
2024-01-24 06:37:56,895 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38915
2024-01-24 06:37:56,895 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33929
2024-01-24 06:37:56,895 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:56,895 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:56,895 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:56,896 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:56,896 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:56,896 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bpoo9t61
2024-01-24 06:37:56,896 - distributed.worker - INFO - Starting Worker plugin PreImport-f920597c-e0cc-428d-b82b-e2e602ee9234
2024-01-24 06:37:56,896 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6ee18c0b-ff3e-4b4c-b726-2f738e9b7271
2024-01-24 06:37:56,897 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42847
2024-01-24 06:37:56,897 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42847
2024-01-24 06:37:56,897 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36913
2024-01-24 06:37:56,897 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:56,897 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:56,897 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:56,897 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:56,897 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-enkzr8s2
2024-01-24 06:37:56,898 - distributed.worker - INFO - Starting Worker plugin PreImport-ec629f06-20d0-4595-9ad0-85b8c1da67c8
2024-01-24 06:37:56,898 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4baa7625-fa9e-44b9-ac02-e08f081d9abe
2024-01-24 06:37:56,903 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:37:56,905 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39485
2024-01-24 06:37:56,905 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39485
2024-01-24 06:37:56,905 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36485
2024-01-24 06:37:56,905 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:37:56,906 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:56,906 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:37:56,906 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:37:56,906 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gap3etb5
2024-01-24 06:37:56,906 - distributed.worker - INFO - Starting Worker plugin PreImport-b1e17011-9e7a-4e1a-918c-66700f10e63c
2024-01-24 06:37:56,907 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5ed4d1e3-818b-4688-95a5-02fba5755ff0
2024-01-24 06:37:57,110 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1be24e1a-0834-4fae-91cf-73a2cc0ea33e
2024-01-24 06:37:57,111 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:57,133 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43449', status: init, memory: 0, processing: 0>
2024-01-24 06:37:57,135 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43449
2024-01-24 06:37:57,135 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60598
2024-01-24 06:37:57,136 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:57,137 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:57,137 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:57,139 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:58,645 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b498c8ae-67a1-41fd-97cd-6436c0935afe
2024-01-24 06:37:58,645 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,672 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38343', status: init, memory: 0, processing: 0>
2024-01-24 06:37:58,673 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38343
2024-01-24 06:37:58,673 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60626
2024-01-24 06:37:58,674 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:58,675 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:58,675 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,677 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:58,726 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-97f5b73f-3a98-4368-a156-b66ee7235d64
2024-01-24 06:37:58,726 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,746 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39799', status: init, memory: 0, processing: 0>
2024-01-24 06:37:58,747 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39799
2024-01-24 06:37:58,747 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60630
2024-01-24 06:37:58,748 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:58,749 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:58,749 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,750 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:58,800 - distributed.worker - INFO - Starting Worker plugin PreImport-c2150f2d-1e6c-4ed1-aa5e-c4c3948dbd65
2024-01-24 06:37:58,802 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,807 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a3fa944f-d8c0-4e33-917a-606a39b524d3
2024-01-24 06:37:58,808 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,821 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-042884f1-d625-4ab7-8c3d-dc2c0d98113e
2024-01-24 06:37:58,822 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,834 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-21e80782-4444-4d1c-8314-cb2e26afaf6d
2024-01-24 06:37:58,835 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,835 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39197', status: init, memory: 0, processing: 0>
2024-01-24 06:37:58,836 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6bfa8da8-549d-4064-bb65-f44d09854ba4
2024-01-24 06:37:58,836 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39197
2024-01-24 06:37:58,836 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60636
2024-01-24 06:37:58,836 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,837 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38915', status: init, memory: 0, processing: 0>
2024-01-24 06:37:58,837 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38915
2024-01-24 06:37:58,838 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60650
2024-01-24 06:37:58,838 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:58,839 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:58,839 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,839 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:58,840 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:58,840 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,841 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:58,842 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:58,845 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39485', status: init, memory: 0, processing: 0>
2024-01-24 06:37:58,845 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39485
2024-01-24 06:37:58,845 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60666
2024-01-24 06:37:58,846 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:58,847 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:58,847 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,848 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:58,859 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42847', status: init, memory: 0, processing: 0>
2024-01-24 06:37:58,860 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42847
2024-01-24 06:37:58,860 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60694
2024-01-24 06:37:58,861 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:58,861 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:58,861 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,863 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:58,866 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37393', status: init, memory: 0, processing: 0>
2024-01-24 06:37:58,867 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37393
2024-01-24 06:37:58,867 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60682
2024-01-24 06:37:58,869 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:37:58,871 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:37:58,871 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:37:58,873 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:37:58,908 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:58,908 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:58,908 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:58,908 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:58,908 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:58,908 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:58,908 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:58,908 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:37:58,914 - distributed.scheduler - INFO - Remove client Client-19afa29b-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:58,914 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60580; closing.
2024-01-24 06:37:58,914 - distributed.scheduler - INFO - Remove client Client-19afa29b-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:58,915 - distributed.scheduler - INFO - Close client connection: Client-19afa29b-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:37:58,916 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42605'. Reason: nanny-close
2024-01-24 06:37:58,916 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:58,916 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35143'. Reason: nanny-close
2024-01-24 06:37:58,917 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:58,917 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35491'. Reason: nanny-close
2024-01-24 06:37:58,917 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39197. Reason: nanny-close
2024-01-24 06:37:58,917 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:58,918 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33187'. Reason: nanny-close
2024-01-24 06:37:58,918 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38915. Reason: nanny-close
2024-01-24 06:37:58,918 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:58,918 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41117'. Reason: nanny-close
2024-01-24 06:37:58,918 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42847. Reason: nanny-close
2024-01-24 06:37:58,918 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:58,919 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40135'. Reason: nanny-close
2024-01-24 06:37:58,919 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39485. Reason: nanny-close
2024-01-24 06:37:58,919 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:58,919 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35385'. Reason: nanny-close
2024-01-24 06:37:58,919 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:58,919 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38343. Reason: nanny-close
2024-01-24 06:37:58,919 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45443'. Reason: nanny-close
2024-01-24 06:37:58,920 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:37:58,920 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60636; closing.
2024-01-24 06:37:58,920 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:58,920 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37393. Reason: nanny-close
2024-01-24 06:37:58,920 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:58,920 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39197', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078278.9203942')
2024-01-24 06:37:58,920 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39799. Reason: nanny-close
2024-01-24 06:37:58,920 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:58,921 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43449. Reason: nanny-close
2024-01-24 06:37:58,921 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:58,922 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:58,922 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:58,922 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60650; closing.
2024-01-24 06:37:58,922 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:58,922 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:58,922 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:58,922 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:58,923 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:58,923 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60666; closing.
2024-01-24 06:37:58,923 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:37:58,924 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:58,924 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38915', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078278.923956')
2024-01-24 06:37:58,924 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:58,924 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60694; closing.
2024-01-24 06:37:58,924 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:58,925 - distributed.nanny - INFO - Worker closed
2024-01-24 06:37:58,925 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39485', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078278.925778')
2024-01-24 06:37:58,926 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42847', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078278.9263406')
2024-01-24 06:37:58,926 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60626; closing.
2024-01-24 06:37:58,928 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38343', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078278.9282298')
2024-01-24 06:37:58,928 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60630; closing.
2024-01-24 06:37:58,929 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60682; closing.
2024-01-24 06:37:58,929 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60598; closing.
2024-01-24 06:37:58,930 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39799', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078278.9300134')
2024-01-24 06:37:58,930 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37393', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078278.930699')
2024-01-24 06:37:58,931 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43449', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078278.9312375')
2024-01-24 06:37:58,931 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:37:59,882 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:37:59,882 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:37:59,883 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:37:59,884 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:37:59,884 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-24 06:38:01,956 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:01,960 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-24 06:38:01,963 - distributed.scheduler - INFO - State start
2024-01-24 06:38:01,986 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:01,987 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:38:01,988 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-24 06:38:01,988 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:38:02,087 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44393'
2024-01-24 06:38:02,098 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38841'
2024-01-24 06:38:02,105 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33345'
2024-01-24 06:38:02,119 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35073'
2024-01-24 06:38:02,123 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43115'
2024-01-24 06:38:02,130 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34887'
2024-01-24 06:38:02,138 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44883'
2024-01-24 06:38:02,147 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36585'
2024-01-24 06:38:04,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:04,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:04,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:04,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:04,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:04,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:04,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:04,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:04,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:04,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:04,032 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:04,032 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:04,032 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:04,032 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:04,033 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:04,033 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42707
2024-01-24 06:38:04,033 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:04,033 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42707
2024-01-24 06:38:04,033 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45237
2024-01-24 06:38:04,033 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:04,033 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38007
2024-01-24 06:38:04,033 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:04,033 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:04,033 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38007
2024-01-24 06:38:04,033 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36415
2024-01-24 06:38:04,033 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:04,033 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:04,033 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-27z8ht42
2024-01-24 06:38:04,033 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:04,033 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:04,033 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:04,033 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vzz9v312
2024-01-24 06:38:04,033 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b33f3d4f-7f58-43cb-8e69-4e82be9201a5
2024-01-24 06:38:04,033 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-df435422-8d89-482a-8735-55777d272816
2024-01-24 06:38:04,033 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:04,033 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36031
2024-01-24 06:38:04,034 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36031
2024-01-24 06:38:04,034 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34177
2024-01-24 06:38:04,034 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38179
2024-01-24 06:38:04,034 - distributed.worker - INFO - Starting Worker plugin RMMSetup-65623569-4f8a-4e2d-9146-b631e7d1c7a8
2024-01-24 06:38:04,034 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:04,034 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38179
2024-01-24 06:38:04,034 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:04,034 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:04,034 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43945
2024-01-24 06:38:04,034 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:04,034 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:04,034 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-94g1sfbj
2024-01-24 06:38:04,034 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:04,034 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:04,034 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:04,034 - distributed.worker - INFO - Starting Worker plugin PreImport-d73ab517-cc1f-4e8b-8fa0-ba74c19c4b88
2024-01-24 06:38:04,034 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wkxfluqz
2024-01-24 06:38:04,034 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cae3f9e0-0672-4d8a-a762-1b0be86916d6
2024-01-24 06:38:04,034 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41695
2024-01-24 06:38:04,034 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41695
2024-01-24 06:38:04,034 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-43a340a2-6c28-48a5-9a43-580a9ccc7bb6
2024-01-24 06:38:04,034 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37633
2024-01-24 06:38:04,034 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:04,035 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:04,035 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f1bfd4cd-86d1-4b64-ae3d-d607a7dd4213
2024-01-24 06:38:04,035 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:04,035 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:04,035 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i4q9ae64
2024-01-24 06:38:04,035 - distributed.worker - INFO - Starting Worker plugin PreImport-2f675c88-13f6-4f22-a50e-b1e5e941450c
2024-01-24 06:38:04,035 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2c21bcd6-283b-45f0-8dd9-6a572caf0513
2024-01-24 06:38:04,035 - distributed.worker - INFO - Starting Worker plugin RMMSetup-56d0abf6-51cd-45ed-93ac-1c6174c5f724
2024-01-24 06:38:04,035 - distributed.worker - INFO - Starting Worker plugin RMMSetup-31593222-abad-4da3-9bfa-00c99ef50b95
2024-01-24 06:38:04,036 - distributed.worker - INFO - Starting Worker plugin RMMSetup-714b7939-53af-4cb7-a0a4-a738be81292a
2024-01-24 06:38:04,036 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:04,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:04,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:04,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:04,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:04,037 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37965
2024-01-24 06:38:04,037 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37965
2024-01-24 06:38:04,038 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34817
2024-01-24 06:38:04,038 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:04,038 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:04,038 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:04,038 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:04,038 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uz9_mjvw
2024-01-24 06:38:04,038 - distributed.worker - INFO - Starting Worker plugin PreImport-5536ce7e-8c33-40e9-8111-f886f938b6be
2024-01-24 06:38:04,038 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6da3fb65-517e-4340-97a4-121d3057178d
2024-01-24 06:38:04,038 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cbeac6b5-93c7-4cf2-bbb6-d788dcedf579
2024-01-24 06:38:04,041 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:04,041 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:04,042 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44311
2024-01-24 06:38:04,042 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44311
2024-01-24 06:38:04,042 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38543
2024-01-24 06:38:04,042 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40023
2024-01-24 06:38:04,042 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:04,042 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40023
2024-01-24 06:38:04,042 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:04,042 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34077
2024-01-24 06:38:04,042 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:04,042 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:04,042 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:04,042 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:04,042 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mt6v6rg1
2024-01-24 06:38:04,042 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:04,042 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:04,042 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0vkq3p_c
2024-01-24 06:38:04,042 - distributed.worker - INFO - Starting Worker plugin PreImport-67e4c64a-78a4-4724-a4d7-92d00914ef03
2024-01-24 06:38:04,042 - distributed.worker - INFO - Starting Worker plugin RMMSetup-633ad64a-60ec-4f7c-b86d-76597627fe61
2024-01-24 06:38:04,042 - distributed.worker - INFO - Starting Worker plugin PreImport-ddbf0db0-f91d-4e51-bfcc-69ce432d11f4
2024-01-24 06:38:04,043 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bda4f769-f3db-4a2a-b72f-2fcfe7c1ffa8
2024-01-24 06:38:04,043 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8d33aefe-a644-43e2-8c70-eb16e49776fa
2024-01-24 06:38:06,189 - distributed.scheduler - INFO - Receive client connection: Client-1e0895dc-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:06,207 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57610
2024-01-24 06:38:06,263 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,283 - distributed.worker - INFO - Starting Worker plugin PreImport-b2ad1e3a-3d67-485e-ae3e-f518e22d7dbe
2024-01-24 06:38:06,285 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,295 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36031', status: init, memory: 0, processing: 0>
2024-01-24 06:38:06,296 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36031
2024-01-24 06:38:06,296 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57638
2024-01-24 06:38:06,297 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:06,298 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:06,298 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,300 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:06,309 - distributed.worker - INFO - Starting Worker plugin PreImport-b0338d50-8a3b-4a00-beb0-4309a5b4b42a
2024-01-24 06:38:06,309 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,310 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,315 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38007', status: init, memory: 0, processing: 0>
2024-01-24 06:38:06,315 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38007
2024-01-24 06:38:06,316 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57654
2024-01-24 06:38:06,317 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:06,318 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:06,318 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,320 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:06,321 - distributed.worker - INFO - Starting Worker plugin PreImport-33004ca3-38e8-4a81-b641-32918cca932e
2024-01-24 06:38:06,322 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,333 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38179', status: init, memory: 0, processing: 0>
2024-01-24 06:38:06,334 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38179
2024-01-24 06:38:06,334 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57664
2024-01-24 06:38:06,335 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:06,335 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:06,335 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,337 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:06,338 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a41054d6-fbfa-4009-966f-3265488c9ca7
2024-01-24 06:38:06,338 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,341 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41695', status: init, memory: 0, processing: 0>
2024-01-24 06:38:06,342 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41695
2024-01-24 06:38:06,342 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57676
2024-01-24 06:38:06,343 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:06,344 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:06,344 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,346 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:06,349 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,349 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,354 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42707', status: init, memory: 0, processing: 0>
2024-01-24 06:38:06,355 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42707
2024-01-24 06:38:06,355 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57678
2024-01-24 06:38:06,356 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:06,357 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:06,357 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,359 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:06,362 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44311', status: init, memory: 0, processing: 0>
2024-01-24 06:38:06,363 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44311
2024-01-24 06:38:06,363 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57694
2024-01-24 06:38:06,364 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:06,365 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:06,365 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,366 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:06,371 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40023', status: init, memory: 0, processing: 0>
2024-01-24 06:38:06,372 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40023
2024-01-24 06:38:06,372 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57706
2024-01-24 06:38:06,373 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37965', status: init, memory: 0, processing: 0>
2024-01-24 06:38:06,373 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:06,373 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37965
2024-01-24 06:38:06,373 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57708
2024-01-24 06:38:06,373 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:06,374 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,374 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:06,375 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:06,375 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:06,375 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:06,376 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:06,422 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:06,422 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:06,422 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:06,422 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:06,422 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:06,423 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:06,423 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:06,423 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:06,433 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:06,433 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:06,433 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:06,434 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:06,434 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:06,434 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:06,434 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:06,434 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:06,442 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:06,444 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:06,446 - distributed.scheduler - INFO - Remove client Client-1e0895dc-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:06,446 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57610; closing.
2024-01-24 06:38:06,446 - distributed.scheduler - INFO - Remove client Client-1e0895dc-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:06,447 - distributed.scheduler - INFO - Close client connection: Client-1e0895dc-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:06,448 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44393'. Reason: nanny-close
2024-01-24 06:38:06,448 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:06,449 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38841'. Reason: nanny-close
2024-01-24 06:38:06,449 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:06,449 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33345'. Reason: nanny-close
2024-01-24 06:38:06,450 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42707. Reason: nanny-close
2024-01-24 06:38:06,450 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:06,450 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35073'. Reason: nanny-close
2024-01-24 06:38:06,450 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36031. Reason: nanny-close
2024-01-24 06:38:06,450 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:06,450 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43115'. Reason: nanny-close
2024-01-24 06:38:06,450 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37965. Reason: nanny-close
2024-01-24 06:38:06,451 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:06,451 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34887'. Reason: nanny-close
2024-01-24 06:38:06,451 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38179. Reason: nanny-close
2024-01-24 06:38:06,451 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:06,451 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44883'. Reason: nanny-close
2024-01-24 06:38:06,452 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:06,452 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38007. Reason: nanny-close
2024-01-24 06:38:06,452 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36585'. Reason: nanny-close
2024-01-24 06:38:06,452 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57678; closing.
2024-01-24 06:38:06,452 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:06,452 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41695. Reason: nanny-close
2024-01-24 06:38:06,452 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:06,452 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42707', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078286.4525075')
2024-01-24 06:38:06,452 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40023. Reason: nanny-close
2024-01-24 06:38:06,452 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:06,452 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:06,453 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:06,453 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44311. Reason: nanny-close
2024-01-24 06:38:06,453 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57664; closing.
2024-01-24 06:38:06,454 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:06,454 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:06,454 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:06,454 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:06,454 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38179', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078286.4544873')
2024-01-24 06:38:06,454 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:06,454 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:06,454 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:06,454 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57638; closing.
2024-01-24 06:38:06,455 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57708; closing.
2024-01-24 06:38:06,455 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:06,455 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:06,456 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:06,456 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:06,456 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:06,455 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:57664>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:57664>: Stream is closed
2024-01-24 06:38:06,457 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36031', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078286.4575663')
2024-01-24 06:38:06,458 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37965', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078286.4579828')
2024-01-24 06:38:06,458 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57654; closing.
2024-01-24 06:38:06,458 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38007', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078286.458935')
2024-01-24 06:38:06,459 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57676; closing.
2024-01-24 06:38:06,459 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57706; closing.
2024-01-24 06:38:06,460 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41695', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078286.4600503')
2024-01-24 06:38:06,460 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40023', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078286.460424')
2024-01-24 06:38:06,460 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57694; closing.
2024-01-24 06:38:06,461 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44311', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078286.461309')
2024-01-24 06:38:06,461 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:38:06,461 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:57694>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 262, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-24 06:38:07,364 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:38:07,364 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:38:07,365 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:38:07,366 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:38:07,366 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-24 06:38:09,426 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:09,430 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41707 instead
  warnings.warn(
2024-01-24 06:38:09,434 - distributed.scheduler - INFO - State start
2024-01-24 06:38:09,456 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:09,457 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:38:09,458 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41707/status
2024-01-24 06:38:09,458 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:38:09,608 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46825'
2024-01-24 06:38:09,619 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36497'
2024-01-24 06:38:09,632 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44881'
2024-01-24 06:38:09,634 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34323'
2024-01-24 06:38:09,643 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37773'
2024-01-24 06:38:09,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44357'
2024-01-24 06:38:09,659 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38301'
2024-01-24 06:38:09,669 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42823'
2024-01-24 06:38:11,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:11,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:11,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:11,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:11,470 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:11,471 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:11,471 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40485
2024-01-24 06:38:11,471 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40485
2024-01-24 06:38:11,471 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38579
2024-01-24 06:38:11,471 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:11,471 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:11,471 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:11,471 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:11,471 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40957
2024-01-24 06:38:11,472 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dusvgt1v
2024-01-24 06:38:11,472 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40957
2024-01-24 06:38:11,472 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43513
2024-01-24 06:38:11,472 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:11,472 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:11,472 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:11,472 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e6a22091-ce82-4fa6-8ff6-b641e48eb10b
2024-01-24 06:38:11,472 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:11,472 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jms2b0_j
2024-01-24 06:38:11,472 - distributed.worker - INFO - Starting Worker plugin PreImport-9b070bd9-e0d5-44cb-b112-8bba91b62a86
2024-01-24 06:38:11,472 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d1709808-2aa7-45c8-964b-19b2616e623a
2024-01-24 06:38:11,472 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9f113c29-90b0-4db5-bb1c-d7b9541a1c19
2024-01-24 06:38:11,473 - distributed.worker - INFO - Starting Worker plugin RMMSetup-00512800-9060-47c1-80b0-7aa237a36c4e
2024-01-24 06:38:11,486 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:11,486 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:11,486 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:11,486 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:11,490 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:11,491 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:11,491 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39031
2024-01-24 06:38:11,491 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39031
2024-01-24 06:38:11,491 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34425
2024-01-24 06:38:11,492 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:11,492 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:11,492 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42247
2024-01-24 06:38:11,492 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:11,492 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42247
2024-01-24 06:38:11,492 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:11,492 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43819
2024-01-24 06:38:11,492 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a1mo0m5g
2024-01-24 06:38:11,492 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:11,492 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:11,492 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:11,492 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:11,492 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-09fa01e8-45e6-444e-add8-9d09a270d91b
2024-01-24 06:38:11,492 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-m41mwrih
2024-01-24 06:38:11,492 - distributed.worker - INFO - Starting Worker plugin PreImport-12cee7d6-ba15-4eab-9cd9-19c9339df452
2024-01-24 06:38:11,492 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dbb937ff-cc3b-4108-acd8-d742c0bcbe71
2024-01-24 06:38:11,492 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-11da1ff5-8de6-4e57-8687-729ff0346c37
2024-01-24 06:38:11,495 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4f8c98b8-589c-461d-a9ad-60cbe1343f63
2024-01-24 06:38:11,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:11,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:11,498 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:11,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:11,502 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:11,503 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:11,503 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45703
2024-01-24 06:38:11,503 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45703
2024-01-24 06:38:11,503 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39937
2024-01-24 06:38:11,503 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:11,503 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:11,503 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:11,503 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:11,503 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35049
2024-01-24 06:38:11,504 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rafyii_7
2024-01-24 06:38:11,504 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35049
2024-01-24 06:38:11,504 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44799
2024-01-24 06:38:11,504 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:11,504 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:11,504 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:11,504 - distributed.worker - INFO - Starting Worker plugin PreImport-ec9b7613-f66e-479f-aa4e-250efb3ceac3
2024-01-24 06:38:11,504 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:11,504 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-186a124a-3f02-4068-b1e8-d75671f044d1
2024-01-24 06:38:11,504 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vc7vik2y
2024-01-24 06:38:11,504 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1047ed09-a49f-4421-ae75-570da146b9f2
2024-01-24 06:38:11,504 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-25d3d337-7d88-4bd3-b829-cac7e1ed05cf
2024-01-24 06:38:11,504 - distributed.worker - INFO - Starting Worker plugin RMMSetup-69f21bb2-9d1b-493e-8cc3-0ba0f69033c5
2024-01-24 06:38:11,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:11,516 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:11,520 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:11,521 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41797
2024-01-24 06:38:11,521 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41797
2024-01-24 06:38:11,522 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43333
2024-01-24 06:38:11,522 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:11,522 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:11,522 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:11,522 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:11,522 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9d_pwck1
2024-01-24 06:38:11,522 - distributed.worker - INFO - Starting Worker plugin PreImport-d6b67145-8610-4452-ac52-f626874e611e
2024-01-24 06:38:11,522 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8b75bcd9-f80a-45f2-a054-a19fe9f6eb7d
2024-01-24 06:38:11,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:11,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:11,548 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:11,549 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41149
2024-01-24 06:38:11,549 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41149
2024-01-24 06:38:11,550 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38861
2024-01-24 06:38:11,550 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:11,550 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:11,550 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:11,550 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:11,550 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1w5vnl8s
2024-01-24 06:38:11,550 - distributed.worker - INFO - Starting Worker plugin PreImport-65c8b80a-30ac-4ea9-bf4f-496d70dcba34
2024-01-24 06:38:11,550 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-46e9773e-1b49-4cf4-a347-cd28c456f091
2024-01-24 06:38:11,550 - distributed.worker - INFO - Starting Worker plugin RMMSetup-98c9f688-8379-4f28-b3bf-8320d545afba
2024-01-24 06:38:11,651 - distributed.scheduler - INFO - Receive client connection: Client-227e20f6-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:11,663 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33256
2024-01-24 06:38:13,687 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,712 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40957', status: init, memory: 0, processing: 0>
2024-01-24 06:38:13,713 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40957
2024-01-24 06:38:13,714 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33278
2024-01-24 06:38:13,715 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:13,715 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:13,715 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,717 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:13,852 - distributed.worker - INFO - Starting Worker plugin PreImport-58bf3d27-0d39-4d5e-bf9f-24c65fae4e9d
2024-01-24 06:38:13,853 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,885 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40485', status: init, memory: 0, processing: 0>
2024-01-24 06:38:13,886 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40485
2024-01-24 06:38:13,886 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33280
2024-01-24 06:38:13,888 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:13,889 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:13,889 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,891 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:13,892 - distributed.worker - INFO - Starting Worker plugin PreImport-b0f2dd2f-c101-496c-9f53-758650893088
2024-01-24 06:38:13,894 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,897 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,913 - distributed.worker - INFO - Starting Worker plugin PreImport-21a83855-1dfc-4a93-ad92-4644ac0c9830
2024-01-24 06:38:13,914 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,915 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,917 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b465809a-951e-4e05-9700-dcefc98f3f94
2024-01-24 06:38:13,918 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,922 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41149', status: init, memory: 0, processing: 0>
2024-01-24 06:38:13,923 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41149
2024-01-24 06:38:13,923 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33298
2024-01-24 06:38:13,924 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:13,925 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:13,925 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,926 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:13,927 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39031', status: init, memory: 0, processing: 0>
2024-01-24 06:38:13,928 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39031
2024-01-24 06:38:13,928 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33282
2024-01-24 06:38:13,930 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:13,931 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:13,931 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,933 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:13,940 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35049', status: init, memory: 0, processing: 0>
2024-01-24 06:38:13,940 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35049
2024-01-24 06:38:13,941 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33310
2024-01-24 06:38:13,941 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41797', status: init, memory: 0, processing: 0>
2024-01-24 06:38:13,941 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:13,942 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41797
2024-01-24 06:38:13,942 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33324
2024-01-24 06:38:13,942 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:13,942 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,943 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:13,944 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:13,944 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:13,944 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,945 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:13,953 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42247', status: init, memory: 0, processing: 0>
2024-01-24 06:38:13,954 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42247
2024-01-24 06:38:13,954 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33332
2024-01-24 06:38:13,956 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:13,957 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:13,957 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:13,959 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:14,016 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:14,044 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45703', status: init, memory: 0, processing: 0>
2024-01-24 06:38:14,044 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45703
2024-01-24 06:38:14,044 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33348
2024-01-24 06:38:14,046 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:14,047 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:14,047 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:14,049 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:14,129 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:14,129 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:14,129 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:14,130 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:14,130 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:14,130 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:14,130 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:14,131 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:14,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:14,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:14,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:14,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:14,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:14,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:14,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:14,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:38:14,151 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:14,153 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:14,155 - distributed.scheduler - INFO - Remove client Client-227e20f6-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:14,155 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33256; closing.
2024-01-24 06:38:14,156 - distributed.scheduler - INFO - Remove client Client-227e20f6-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:14,156 - distributed.scheduler - INFO - Close client connection: Client-227e20f6-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:14,157 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46825'. Reason: nanny-close
2024-01-24 06:38:14,157 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:14,158 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36497'. Reason: nanny-close
2024-01-24 06:38:14,158 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:14,158 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44881'. Reason: nanny-close
2024-01-24 06:38:14,159 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:14,159 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40485. Reason: nanny-close
2024-01-24 06:38:14,159 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34323'. Reason: nanny-close
2024-01-24 06:38:14,159 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:14,159 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45703. Reason: nanny-close
2024-01-24 06:38:14,159 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37773'. Reason: nanny-close
2024-01-24 06:38:14,160 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40957. Reason: nanny-close
2024-01-24 06:38:14,160 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:14,160 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44357'. Reason: nanny-close
2024-01-24 06:38:14,160 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:14,160 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35049. Reason: nanny-close
2024-01-24 06:38:14,160 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38301'. Reason: nanny-close
2024-01-24 06:38:14,161 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:14,161 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39031. Reason: nanny-close
2024-01-24 06:38:14,161 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42823'. Reason: nanny-close
2024-01-24 06:38:14,161 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:14,161 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42247. Reason: nanny-close
2024-01-24 06:38:14,161 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41149. Reason: nanny-close
2024-01-24 06:38:14,161 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:14,162 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:14,162 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33278; closing.
2024-01-24 06:38:14,162 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41797. Reason: nanny-close
2024-01-24 06:38:14,162 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:14,162 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33280; closing.
2024-01-24 06:38:14,162 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40957', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078294.1626828')
2024-01-24 06:38:14,163 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:14,163 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40485', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078294.1634505')
2024-01-24 06:38:14,163 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:14,163 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:14,163 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:14,164 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:14,164 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:14,164 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:14,164 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33348; closing.
2024-01-24 06:38:14,165 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:14,165 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:14,165 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:14,165 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:14,165 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45703', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078294.1657884')
2024-01-24 06:38:14,165 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:14,166 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33282; closing.
2024-01-24 06:38:14,166 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33298; closing.
2024-01-24 06:38:14,166 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33310; closing.
2024-01-24 06:38:14,167 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39031', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078294.1673586')
2024-01-24 06:38:14,167 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:14,167 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41149', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078294.1678164')
2024-01-24 06:38:14,168 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35049', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078294.1681767')
2024-01-24 06:38:14,168 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33324; closing.
2024-01-24 06:38:14,168 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33332; closing.
2024-01-24 06:38:14,169 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41797', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078294.1691577')
2024-01-24 06:38:14,169 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42247', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078294.1696322')
2024-01-24 06:38:14,169 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:38:15,073 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:38:15,073 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:38:15,074 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:38:15,075 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:38:15,076 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-24 06:38:17,100 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:17,104 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38871 instead
  warnings.warn(
2024-01-24 06:38:17,108 - distributed.scheduler - INFO - State start
2024-01-24 06:38:17,130 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:17,131 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:38:17,131 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38871/status
2024-01-24 06:38:17,132 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:38:17,267 - distributed.scheduler - INFO - Receive client connection: Client-27170bc1-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:17,279 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33428
2024-01-24 06:38:17,307 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43301'
2024-01-24 06:38:17,317 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43207'
2024-01-24 06:38:17,326 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33991'
2024-01-24 06:38:17,339 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38663'
2024-01-24 06:38:17,343 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33689'
2024-01-24 06:38:17,351 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46749'
2024-01-24 06:38:17,360 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35057'
2024-01-24 06:38:17,369 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41485'
2024-01-24 06:38:19,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:19,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:19,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:19,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:19,211 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:19,211 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:19,211 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33885
2024-01-24 06:38:19,212 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33885
2024-01-24 06:38:19,212 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35225
2024-01-24 06:38:19,212 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44725
2024-01-24 06:38:19,212 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:19,212 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44725
2024-01-24 06:38:19,212 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:19,212 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:19,212 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44067
2024-01-24 06:38:19,212 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:19,212 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:19,212 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k2irdlt4
2024-01-24 06:38:19,212 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:19,212 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:19,212 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:19,212 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6f2f2c70-e488-4828-9653-00d223c5d8e5
2024-01-24 06:38:19,212 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k0qwjw8x
2024-01-24 06:38:19,212 - distributed.worker - INFO - Starting Worker plugin PreImport-9b2212f3-0165-4ac4-99a4-67a3e0c71eef
2024-01-24 06:38:19,212 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8698eea9-a991-4a52-8072-e73e3db44142
2024-01-24 06:38:19,213 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ea3cdd66-862c-46ae-9fc0-0a4a401e81d9
2024-01-24 06:38:19,213 - distributed.worker - INFO - Starting Worker plugin RMMSetup-88181e97-c530-43f3-8c09-0b8d17651702
2024-01-24 06:38:19,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:19,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:19,241 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:19,242 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39063
2024-01-24 06:38:19,242 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39063
2024-01-24 06:38:19,242 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46229
2024-01-24 06:38:19,242 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:19,242 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:19,242 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:19,242 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:19,242 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zawob4v6
2024-01-24 06:38:19,243 - distributed.worker - INFO - Starting Worker plugin PreImport-d83e9c37-6d6b-4cb4-ba20-400a29965876
2024-01-24 06:38:19,243 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7394302a-9a3d-4470-8af6-5616498dcc3c
2024-01-24 06:38:19,243 - distributed.worker - INFO - Starting Worker plugin RMMSetup-84b6a909-8e47-415d-9d89-d22f54026d2a
2024-01-24 06:38:19,250 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:19,250 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:19,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:19,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:19,254 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:19,255 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34707
2024-01-24 06:38:19,256 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34707
2024-01-24 06:38:19,256 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37687
2024-01-24 06:38:19,256 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:19,256 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:19,256 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:19,256 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:19,256 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ksed70l5
2024-01-24 06:38:19,256 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:19,256 - distributed.worker - INFO - Starting Worker plugin PreImport-6012deea-4488-480a-af60-5619968ec822
2024-01-24 06:38:19,256 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d8af17c6-73af-4fe5-8637-161031a7d52b
2024-01-24 06:38:19,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:19,256 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:19,256 - distributed.worker - INFO - Starting Worker plugin RMMSetup-37a04001-9324-4bb2-a32f-049f4e311b51
2024-01-24 06:38:19,257 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44931
2024-01-24 06:38:19,257 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44931
2024-01-24 06:38:19,257 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40555
2024-01-24 06:38:19,257 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:19,257 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:19,257 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:19,257 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:19,257 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5qgprk2v
2024-01-24 06:38:19,257 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8121c01a-4191-445c-a67e-50a7a6e5d590
2024-01-24 06:38:19,258 - distributed.worker - INFO - Starting Worker plugin RMMSetup-37d798fa-29cc-4ce6-a693-4da7a8eb4de4
2024-01-24 06:38:19,261 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:19,262 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37135
2024-01-24 06:38:19,262 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37135
2024-01-24 06:38:19,262 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35783
2024-01-24 06:38:19,262 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:19,262 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:19,262 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:19,262 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:19,262 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i0dcvjqb
2024-01-24 06:38:19,262 - distributed.worker - INFO - Starting Worker plugin PreImport-d3d6e666-2c15-4de7-8958-c5078253321e
2024-01-24 06:38:19,262 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d3a685b4-8af5-41fc-b0ab-580f240aafc9
2024-01-24 06:38:19,263 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8bad93de-00b3-437e-83a3-5bcd79569735
2024-01-24 06:38:19,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:19,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:19,323 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:19,324 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34977
2024-01-24 06:38:19,324 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34977
2024-01-24 06:38:19,324 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41793
2024-01-24 06:38:19,324 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:19,324 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:19,324 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:19,324 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:19,324 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-203y8wgc
2024-01-24 06:38:19,324 - distributed.worker - INFO - Starting Worker plugin PreImport-5e562660-3811-4fe3-aefb-e78d04cab948
2024-01-24 06:38:19,325 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b0e7d0f3-1caf-40d2-b6c2-359cba9e497c
2024-01-24 06:38:19,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:19,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:19,373 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:19,375 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43395
2024-01-24 06:38:19,375 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43395
2024-01-24 06:38:19,375 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44511
2024-01-24 06:38:19,375 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:19,375 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:19,375 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:19,375 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:19,375 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3d7_xqvx
2024-01-24 06:38:19,376 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-125f76bc-ae29-4f92-b593-52d40f622236
2024-01-24 06:38:19,376 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0f1172f-79f5-478f-bfde-31c591f6b6eb
2024-01-24 06:38:21,444 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,452 - distributed.worker - INFO - Starting Worker plugin PreImport-1e98abcb-f5d7-4347-ab78-234f6594d72c
2024-01-24 06:38:21,454 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,467 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44725', status: init, memory: 0, processing: 0>
2024-01-24 06:38:21,469 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44725
2024-01-24 06:38:21,469 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43020
2024-01-24 06:38:21,470 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:21,471 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:21,471 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,472 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:21,483 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33885', status: init, memory: 0, processing: 0>
2024-01-24 06:38:21,484 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33885
2024-01-24 06:38:21,484 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43022
2024-01-24 06:38:21,485 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:21,486 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:21,486 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,488 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:21,555 - distributed.worker - INFO - Starting Worker plugin PreImport-d46ad2af-7aa8-4698-9e27-614b1f8eb31b
2024-01-24 06:38:21,556 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,577 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,586 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44931', status: init, memory: 0, processing: 0>
2024-01-24 06:38:21,587 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44931
2024-01-24 06:38:21,587 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43032
2024-01-24 06:38:21,588 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:21,589 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:21,590 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,592 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:21,598 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39063', status: init, memory: 0, processing: 0>
2024-01-24 06:38:21,598 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39063
2024-01-24 06:38:21,598 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43042
2024-01-24 06:38:21,599 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:21,600 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:21,600 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,601 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:21,604 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,608 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-784c78d6-469f-4201-a558-acea68f92648
2024-01-24 06:38:21,609 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,623 - distributed.worker - INFO - Starting Worker plugin PreImport-fd7d7e0e-1206-4df6-aabb-b44504bc4d39
2024-01-24 06:38:21,623 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,629 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34977', status: init, memory: 0, processing: 0>
2024-01-24 06:38:21,630 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34977
2024-01-24 06:38:21,630 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43068
2024-01-24 06:38:21,631 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:21,632 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:21,632 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,633 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:21,633 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,636 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34707', status: init, memory: 0, processing: 0>
2024-01-24 06:38:21,637 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34707
2024-01-24 06:38:21,637 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43054
2024-01-24 06:38:21,638 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:21,639 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:21,639 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,641 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:21,643 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43395', status: init, memory: 0, processing: 0>
2024-01-24 06:38:21,643 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43395
2024-01-24 06:38:21,644 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43072
2024-01-24 06:38:21,644 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:21,645 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:21,645 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,647 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:21,666 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37135', status: init, memory: 0, processing: 0>
2024-01-24 06:38:21,666 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37135
2024-01-24 06:38:21,667 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43084
2024-01-24 06:38:21,668 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:21,669 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:21,669 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:21,671 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:21,758 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:21,758 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:21,758 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:21,758 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:21,758 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:21,758 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:21,759 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:21,759 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:21,763 - distributed.scheduler - INFO - Remove client Client-27170bc1-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:21,763 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33428; closing.
2024-01-24 06:38:21,764 - distributed.scheduler - INFO - Remove client Client-27170bc1-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:21,764 - distributed.scheduler - INFO - Close client connection: Client-27170bc1-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:21,765 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43301'. Reason: nanny-close
2024-01-24 06:38:21,765 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:21,766 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43207'. Reason: nanny-close
2024-01-24 06:38:21,766 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:21,767 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33991'. Reason: nanny-close
2024-01-24 06:38:21,767 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:21,767 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33885. Reason: nanny-close
2024-01-24 06:38:21,767 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38663'. Reason: nanny-close
2024-01-24 06:38:21,767 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37135. Reason: nanny-close
2024-01-24 06:38:21,767 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:21,768 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33689'. Reason: nanny-close
2024-01-24 06:38:21,768 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44725. Reason: nanny-close
2024-01-24 06:38:21,768 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:21,768 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46749'. Reason: nanny-close
2024-01-24 06:38:21,768 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43395. Reason: nanny-close
2024-01-24 06:38:21,768 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:21,769 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35057'. Reason: nanny-close
2024-01-24 06:38:21,769 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44931. Reason: nanny-close
2024-01-24 06:38:21,769 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:21,769 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41485'. Reason: nanny-close
2024-01-24 06:38:21,769 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34707. Reason: nanny-close
2024-01-24 06:38:21,769 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:21,770 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39063. Reason: nanny-close
2024-01-24 06:38:21,770 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:21,770 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43022; closing.
2024-01-24 06:38:21,770 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:21,770 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:21,770 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33885', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078301.7704725')
2024-01-24 06:38:21,770 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:21,770 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34977. Reason: nanny-close
2024-01-24 06:38:21,771 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43084; closing.
2024-01-24 06:38:21,771 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37135', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078301.7717407')
2024-01-24 06:38:21,771 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:21,771 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:21,771 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:21,772 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43020; closing.
2024-01-24 06:38:21,772 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:21,772 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:21,772 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43072; closing.
2024-01-24 06:38:21,772 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:21,772 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:21,772 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:21,773 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:21,773 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44725', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078301.7732406')
2024-01-24 06:38:21,773 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43395', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078301.773664')
2024-01-24 06:38:21,773 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:21,774 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:21,774 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:21,774 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43084>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 262, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-24 06:38:21,776 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43032; closing.
2024-01-24 06:38:21,776 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43042; closing.
2024-01-24 06:38:21,776 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43054; closing.
2024-01-24 06:38:21,777 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44931', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078301.7774231')
2024-01-24 06:38:21,777 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39063', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078301.777846')
2024-01-24 06:38:21,778 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34707', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078301.778285')
2024-01-24 06:38:21,778 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43068; closing.
2024-01-24 06:38:21,779 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34977', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078301.7790558')
2024-01-24 06:38:21,779 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:38:22,631 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:38:22,631 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:38:22,633 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:38:22,634 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:38:22,635 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-24 06:38:24,612 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:24,617 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-24 06:38:24,620 - distributed.scheduler - INFO - State start
2024-01-24 06:38:24,641 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:24,642 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:38:24,643 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-24 06:38:24,643 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:38:24,708 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39513'
2024-01-24 06:38:26,016 - distributed.scheduler - INFO - Receive client connection: Client-2b95600e-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:26,029 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43172
2024-01-24 06:38:26,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:26,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:26,730 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:26,731 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46751
2024-01-24 06:38:26,734 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46751
2024-01-24 06:38:26,735 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-24 06:38:26,735 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:26,735 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:26,735 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:26,735 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-24 06:38:26,735 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8cfxizwq
2024-01-24 06:38:26,736 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-38756a9b-85dd-4660-b594-a965ddedd45e
2024-01-24 06:38:26,737 - distributed.worker - INFO - Starting Worker plugin PreImport-3ae2a015-41e3-4631-90c8-0b73c79bd7a6
2024-01-24 06:38:26,737 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5aa270ff-4198-432f-90d1-12494b5a9f6b
2024-01-24 06:38:26,737 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:26,808 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46751', status: init, memory: 0, processing: 0>
2024-01-24 06:38:26,809 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46751
2024-01-24 06:38:26,809 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43188
2024-01-24 06:38:26,811 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:26,812 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:26,812 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:26,814 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:26,849 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:26,852 - distributed.scheduler - INFO - Remove client Client-2b95600e-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:26,852 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43172; closing.
2024-01-24 06:38:26,853 - distributed.scheduler - INFO - Remove client Client-2b95600e-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:26,853 - distributed.scheduler - INFO - Close client connection: Client-2b95600e-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:26,854 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39513'. Reason: nanny-close
2024-01-24 06:38:26,854 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:26,856 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46751. Reason: nanny-close
2024-01-24 06:38:26,858 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:26,858 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43188; closing.
2024-01-24 06:38:26,859 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46751', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078306.8591008')
2024-01-24 06:38:26,859 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:38:26,860 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:27,469 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:38:27,470 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:38:27,470 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:38:27,471 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:38:27,472 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-24 06:38:31,608 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:31,612 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-24 06:38:31,616 - distributed.scheduler - INFO - State start
2024-01-24 06:38:31,641 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:31,642 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:38:31,643 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-24 06:38:31,643 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:38:31,819 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39379'
2024-01-24 06:38:32,299 - distributed.scheduler - INFO - Receive client connection: Client-2fb86910-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:32,310 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50844
2024-01-24 06:38:33,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:33,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:34,304 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:34,305 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45707
2024-01-24 06:38:34,305 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45707
2024-01-24 06:38:34,305 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43069
2024-01-24 06:38:34,305 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:34,306 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:34,306 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:34,306 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-24 06:38:34,306 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4hptiyc3
2024-01-24 06:38:34,306 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-97c84088-5408-4b77-ade3-918c45aa1d7c
2024-01-24 06:38:34,306 - distributed.worker - INFO - Starting Worker plugin PreImport-4dea0a0a-54f2-4c93-bebc-74c25afaeace
2024-01-24 06:38:34,308 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4390b370-9633-40cb-81f4-942b80618c04
2024-01-24 06:38:34,308 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:34,358 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45707', status: init, memory: 0, processing: 0>
2024-01-24 06:38:34,359 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45707
2024-01-24 06:38:34,359 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50870
2024-01-24 06:38:34,360 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:34,361 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:34,361 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:34,362 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:34,452 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:34,455 - distributed.scheduler - INFO - Remove client Client-2fb86910-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:34,455 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50844; closing.
2024-01-24 06:38:34,455 - distributed.scheduler - INFO - Remove client Client-2fb86910-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:34,456 - distributed.scheduler - INFO - Close client connection: Client-2fb86910-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:34,457 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39379'. Reason: nanny-close
2024-01-24 06:38:34,457 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:34,458 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45707. Reason: nanny-close
2024-01-24 06:38:34,459 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50870; closing.
2024-01-24 06:38:34,459 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:34,459 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45707', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078314.4598725')
2024-01-24 06:38:34,460 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:38:34,460 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:34,972 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:38:34,972 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:38:34,973 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:38:34,974 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:38:34,974 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-24 06:38:37,272 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:37,277 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-24 06:38:37,280 - distributed.scheduler - INFO - State start
2024-01-24 06:38:37,302 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:37,303 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:38:37,304 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-24 06:38:37,304 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:38:39,757 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:50872'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 970, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4440, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:50872>: Stream is closed
2024-01-24 06:38:40,005 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:38:40,006 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:38:40,006 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:38:40,007 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:38:40,007 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-24 06:38:42,102 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:42,106 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-24 06:38:42,109 - distributed.scheduler - INFO - State start
2024-01-24 06:38:42,208 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:42,209 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-24 06:38:42,209 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-24 06:38:42,210 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:38:42,293 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46167'
2024-01-24 06:38:44,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:44,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:44,102 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:44,103 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43437
2024-01-24 06:38:44,103 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43437
2024-01-24 06:38:44,103 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40673
2024-01-24 06:38:44,103 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-24 06:38:44,103 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:44,103 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:44,103 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-24 06:38:44,103 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-t1oopnno
2024-01-24 06:38:44,103 - distributed.worker - INFO - Starting Worker plugin PreImport-7fd7bcba-1d63-4279-a0e9-4f749fedaa5a
2024-01-24 06:38:44,104 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c071cd60-657d-4f72-a7c1-646f31db9a8b
2024-01-24 06:38:44,104 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ec8dfb65-c6c7-4ddb-8bd9-3ffd865d4ba1
2024-01-24 06:38:44,104 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:44,203 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43437', status: init, memory: 0, processing: 0>
2024-01-24 06:38:44,216 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43437
2024-01-24 06:38:44,216 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51124
2024-01-24 06:38:44,217 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:44,218 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-24 06:38:44,218 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:44,219 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-24 06:38:47,805 - distributed.scheduler - INFO - Receive client connection: Client-35ea9990-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:47,805 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51144
2024-01-24 06:38:47,811 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:47,818 - distributed.scheduler - INFO - Remove client Client-35ea9990-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:47,818 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51144; closing.
2024-01-24 06:38:47,818 - distributed.scheduler - INFO - Remove client Client-35ea9990-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:47,818 - distributed.scheduler - INFO - Close client connection: Client-35ea9990-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:47,819 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46167'. Reason: nanny-close
2024-01-24 06:38:47,820 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:47,821 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43437. Reason: nanny-close
2024-01-24 06:38:47,822 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-24 06:38:47,822 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51124; closing.
2024-01-24 06:38:47,823 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43437', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078327.8232346')
2024-01-24 06:38:47,823 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:38:47,824 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:48,485 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:38:48,485 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:38:48,486 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:38:48,487 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-24 06:38:48,487 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-24 06:38:50,761 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:50,766 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-24 06:38:50,770 - distributed.scheduler - INFO - State start
2024-01-24 06:38:50,800 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:50,801 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:38:50,802 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-24 06:38:50,802 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:38:50,912 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36855'
2024-01-24 06:38:50,924 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46123'
2024-01-24 06:38:50,938 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43535'
2024-01-24 06:38:50,940 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38785'
2024-01-24 06:38:50,950 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44967'
2024-01-24 06:38:50,959 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45565'
2024-01-24 06:38:50,968 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40051'
2024-01-24 06:38:50,978 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36319'
2024-01-24 06:38:51,465 - distributed.scheduler - INFO - Receive client connection: Client-3b08f4a3-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:51,477 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49590
2024-01-24 06:38:52,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:52,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:52,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:52,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:52,802 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:52,802 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:52,803 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32891
2024-01-24 06:38:52,803 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37827
2024-01-24 06:38:52,803 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32891
2024-01-24 06:38:52,803 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37827
2024-01-24 06:38:52,803 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34405
2024-01-24 06:38:52,803 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34705
2024-01-24 06:38:52,803 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:52,803 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:52,803 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:52,803 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:52,803 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:52,803 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:52,803 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:52,803 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:52,803 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-c388x77m
2024-01-24 06:38:52,803 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sundi63i
2024-01-24 06:38:52,804 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-05e138fb-3e26-46f0-a5ab-9d007cd62b99
2024-01-24 06:38:52,804 - distributed.worker - INFO - Starting Worker plugin PreImport-8c5c15d4-b6b7-4b0e-8462-35805931fb01
2024-01-24 06:38:52,804 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-79df3678-08b4-4658-aeff-2d4ce4c7b7e6
2024-01-24 06:38:52,804 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6b644d06-ac6a-4cb9-ac97-f3f46ecbc112
2024-01-24 06:38:52,804 - distributed.worker - INFO - Starting Worker plugin RMMSetup-500aef04-1171-4686-b767-340860da66e4
2024-01-24 06:38:52,839 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:52,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:52,845 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:52,846 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33511
2024-01-24 06:38:52,846 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33511
2024-01-24 06:38:52,846 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38249
2024-01-24 06:38:52,846 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:52,846 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:52,846 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:52,846 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:52,846 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vp3c8ufc
2024-01-24 06:38:52,847 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a7f4fedf-8416-4f0c-a922-c3d5b48e7381
2024-01-24 06:38:52,847 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3dd7ce69-ab8f-4e10-aa59-b4103f1b93ed
2024-01-24 06:38:52,889 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:52,889 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:52,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:52,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:52,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:52,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:52,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:52,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:52,894 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:52,895 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43089
2024-01-24 06:38:52,895 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43089
2024-01-24 06:38:52,895 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42587
2024-01-24 06:38:52,895 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:52,895 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:52,895 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:52,895 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:52,895 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:52,895 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gci5oy9q
2024-01-24 06:38:52,895 - distributed.worker - INFO - Starting Worker plugin PreImport-03d68da6-45a8-432b-b010-aeb6a9cfd57f
2024-01-24 06:38:52,896 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-950f47b3-2151-4b05-bc38-2d710fa6eb16
2024-01-24 06:38:52,896 - distributed.worker - INFO - Starting Worker plugin RMMSetup-736582bd-c626-4127-a8b7-7804fc20705f
2024-01-24 06:38:52,896 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38241
2024-01-24 06:38:52,896 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38241
2024-01-24 06:38:52,896 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33407
2024-01-24 06:38:52,896 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:52,896 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:52,896 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:52,896 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:52,896 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:52,896 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mmy8at6a
2024-01-24 06:38:52,896 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:52,897 - distributed.worker - INFO - Starting Worker plugin PreImport-d682d8de-be31-4803-bb91-d0e40594e1da
2024-01-24 06:38:52,897 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ec5b8159-69bc-4a0e-9c7a-ef7717482178
2024-01-24 06:38:52,897 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40243
2024-01-24 06:38:52,897 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40243
2024-01-24 06:38:52,897 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45979
2024-01-24 06:38:52,897 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:52,897 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:52,897 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:52,897 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:52,897 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45119
2024-01-24 06:38:52,897 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5wz2_i3e
2024-01-24 06:38:52,897 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45119
2024-01-24 06:38:52,897 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46179
2024-01-24 06:38:52,897 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:52,897 - distributed.worker - INFO - Starting Worker plugin PreImport-bea121fe-3348-4e67-ba52-1f5571bba597
2024-01-24 06:38:52,897 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:52,898 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:52,898 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b80ed195-6878-4136-ae2a-96e3771a9ce5
2024-01-24 06:38:52,898 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:52,898 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-eidhkb2z
2024-01-24 06:38:52,898 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b68de396-8f6c-4b66-8861-6345e2e7a05e
2024-01-24 06:38:52,898 - distributed.worker - INFO - Starting Worker plugin PreImport-38e61dc7-2800-4d97-be82-2c852e7d8e0d
2024-01-24 06:38:52,898 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-97ae938c-bcde-42bd-acaf-1107e51c9508
2024-01-24 06:38:52,898 - distributed.worker - INFO - Starting Worker plugin RMMSetup-51860e8c-c3bb-4ee6-a340-5af9d6af3e3e
2024-01-24 06:38:53,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:38:53,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:38:53,287 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:38:53,289 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40695
2024-01-24 06:38:53,289 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40695
2024-01-24 06:38:53,289 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40027
2024-01-24 06:38:53,289 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:38:53,289 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:53,289 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:38:53,289 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-24 06:38:53,289 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nbsycy1h
2024-01-24 06:38:53,289 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cccf2624-2614-48c7-9ce4-214b6232ee3f
2024-01-24 06:38:53,290 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0285dfbb-15f7-4b31-b954-488a5f40ea75
2024-01-24 06:38:54,928 - distributed.worker - INFO - Starting Worker plugin PreImport-13ee5f61-1d60-42a4-8362-9957852377cd
2024-01-24 06:38:54,930 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:54,942 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:54,962 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32891', status: init, memory: 0, processing: 0>
2024-01-24 06:38:54,965 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32891
2024-01-24 06:38:54,966 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49608
2024-01-24 06:38:54,967 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:54,968 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:54,968 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:54,970 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:54,973 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37827', status: init, memory: 0, processing: 0>
2024-01-24 06:38:54,973 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37827
2024-01-24 06:38:54,973 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49612
2024-01-24 06:38:54,975 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:54,976 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:54,976 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:54,978 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:55,031 - distributed.worker - INFO - Starting Worker plugin PreImport-afbe82b6-6db5-477e-a15c-8113d12136af
2024-01-24 06:38:55,031 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,058 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33511', status: init, memory: 0, processing: 0>
2024-01-24 06:38:55,058 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33511
2024-01-24 06:38:55,059 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49622
2024-01-24 06:38:55,060 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:55,060 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:55,061 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,062 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:55,132 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,149 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d6716fbe-0608-454b-be08-af4dbc7b7c50
2024-01-24 06:38:55,150 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,155 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43089', status: init, memory: 0, processing: 0>
2024-01-24 06:38:55,155 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43089
2024-01-24 06:38:55,156 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49634
2024-01-24 06:38:55,156 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:55,157 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:55,157 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,159 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:55,170 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,172 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38241', status: init, memory: 0, processing: 0>
2024-01-24 06:38:55,172 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38241
2024-01-24 06:38:55,172 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49648
2024-01-24 06:38:55,173 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:55,174 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:55,174 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,176 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:55,178 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,181 - distributed.worker - INFO - Starting Worker plugin PreImport-8a4796b7-2b7e-457a-9b66-9c9b86714b0e
2024-01-24 06:38:55,181 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,201 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40243', status: init, memory: 0, processing: 0>
2024-01-24 06:38:55,201 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40243
2024-01-24 06:38:55,201 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49668
2024-01-24 06:38:55,202 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45119', status: init, memory: 0, processing: 0>
2024-01-24 06:38:55,202 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:55,203 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45119
2024-01-24 06:38:55,203 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49660
2024-01-24 06:38:55,203 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:55,203 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,204 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:55,204 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:55,205 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:55,205 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,206 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40695', status: init, memory: 0, processing: 0>
2024-01-24 06:38:55,207 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40695
2024-01-24 06:38:55,207 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49684
2024-01-24 06:38:55,207 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:55,208 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:38:55,209 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:38:55,209 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:38:55,211 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:38:55,310 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:55,310 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:55,310 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:55,310 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:55,310 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:55,310 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:55,310 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:55,311 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-24 06:38:55,327 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:55,327 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:55,327 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:55,327 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:55,327 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:55,327 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:55,327 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:55,328 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:38:55,333 - distributed.scheduler - INFO - Remove client Client-3b08f4a3-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:55,333 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49590; closing.
2024-01-24 06:38:55,333 - distributed.scheduler - INFO - Remove client Client-3b08f4a3-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:55,333 - distributed.scheduler - INFO - Close client connection: Client-3b08f4a3-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:55,335 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36855'. Reason: nanny-close
2024-01-24 06:38:55,335 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:55,335 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46123'. Reason: nanny-close
2024-01-24 06:38:55,336 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:55,337 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43535'. Reason: nanny-close
2024-01-24 06:38:55,337 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32891. Reason: nanny-close
2024-01-24 06:38:55,337 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:55,337 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38785'. Reason: nanny-close
2024-01-24 06:38:55,337 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:55,337 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37827. Reason: nanny-close
2024-01-24 06:38:55,338 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44967'. Reason: nanny-close
2024-01-24 06:38:55,338 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43089. Reason: nanny-close
2024-01-24 06:38:55,338 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:55,338 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45565'. Reason: nanny-close
2024-01-24 06:38:55,338 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33511. Reason: nanny-close
2024-01-24 06:38:55,338 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:55,339 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40051'. Reason: nanny-close
2024-01-24 06:38:55,339 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40695. Reason: nanny-close
2024-01-24 06:38:55,339 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:55,339 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36319'. Reason: nanny-close
2024-01-24 06:38:55,339 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45119. Reason: nanny-close
2024-01-24 06:38:55,339 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:38:55,339 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:55,339 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40243. Reason: nanny-close
2024-01-24 06:38:55,340 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:55,340 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49608; closing.
2024-01-24 06:38:55,340 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38241. Reason: nanny-close
2024-01-24 06:38:55,340 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:55,340 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32891', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078335.3404522')
2024-01-24 06:38:55,340 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:55,341 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49634; closing.
2024-01-24 06:38:55,341 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:55,341 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:55,341 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:55,341 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:55,341 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43089', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078335.3418975')
2024-01-24 06:38:55,342 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:55,342 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:55,342 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:38:55,342 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:55,342 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49612; closing.
2024-01-24 06:38:55,342 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:55,343 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:55,343 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49684; closing.
2024-01-24 06:38:55,343 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:55,343 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37827', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078335.343683')
2024-01-24 06:38:55,343 - distributed.nanny - INFO - Worker closed
2024-01-24 06:38:55,344 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49622; closing.
2024-01-24 06:38:55,344 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:49634>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 262, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-24 06:38:55,347 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40695', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078335.3472826')
2024-01-24 06:38:55,347 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33511', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078335.347757')
2024-01-24 06:38:55,348 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49660; closing.
2024-01-24 06:38:55,348 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49668; closing.
2024-01-24 06:38:55,348 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49648; closing.
2024-01-24 06:38:55,349 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45119', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078335.3489618')
2024-01-24 06:38:55,349 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40243', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078335.3493493')
2024-01-24 06:38:55,349 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38241', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078335.349736')
2024-01-24 06:38:55,349 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:38:56,251 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:38:56,251 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:38:56,252 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:38:56,253 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:38:56,254 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-24 06:38:58,562 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:58,567 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-24 06:38:58,570 - distributed.scheduler - INFO - State start
2024-01-24 06:38:58,592 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:38:58,592 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:38:58,593 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-24 06:38:58,593 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:38:58,605 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41957'
2024-01-24 06:38:59,552 - distributed.scheduler - INFO - Receive client connection: Client-3fb4c828-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:38:59,563 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49820
2024-01-24 06:39:00,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:39:00,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:39:00,211 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:39:00,211 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35807
2024-01-24 06:39:00,211 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35807
2024-01-24 06:39:00,212 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41939
2024-01-24 06:39:00,212 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:39:00,212 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:39:00,212 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:39:00,212 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-24 06:39:00,212 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l55f6uxy
2024-01-24 06:39:00,212 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5bd3226f-cc53-444b-a246-a20c55d6cbf8
2024-01-24 06:39:00,212 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f6f563cf-d1e3-454f-a164-1f7575e3bcaf
2024-01-24 06:39:00,484 - distributed.worker - INFO - Starting Worker plugin PreImport-c8132cd6-72bb-46e4-a822-48465c5e6b7d
2024-01-24 06:39:00,484 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:39:00,543 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35807', status: init, memory: 0, processing: 0>
2024-01-24 06:39:00,544 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35807
2024-01-24 06:39:00,544 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47230
2024-01-24 06:39:00,545 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:39:00,546 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:39:00,546 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:39:00,547 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:39:00,584 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:39:00,588 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:39:00,589 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:39:00,591 - distributed.scheduler - INFO - Remove client Client-3fb4c828-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:39:00,592 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49820; closing.
2024-01-24 06:39:00,592 - distributed.scheduler - INFO - Remove client Client-3fb4c828-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:39:00,593 - distributed.scheduler - INFO - Close client connection: Client-3fb4c828-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:39:00,593 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41957'. Reason: nanny-close
2024-01-24 06:39:00,594 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:39:00,595 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35807. Reason: nanny-close
2024-01-24 06:39:00,596 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:39:00,596 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47230; closing.
2024-01-24 06:39:00,597 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35807', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078340.597123')
2024-01-24 06:39:00,597 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:39:00,597 - distributed.nanny - INFO - Worker closed
2024-01-24 06:39:01,208 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:39:01,209 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:39:01,209 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:39:01,210 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:39:01,210 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-24 06:39:03,309 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:39:03,313 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36057 instead
  warnings.warn(
2024-01-24 06:39:03,317 - distributed.scheduler - INFO - State start
2024-01-24 06:39:03,338 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-24 06:39:03,339 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-24 06:39:03,340 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36057/status
2024-01-24 06:39:03,340 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-24 06:39:03,434 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44347'
2024-01-24 06:39:04,388 - distributed.scheduler - INFO - Receive client connection: Client-4298d09b-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:39:04,402 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47294
2024-01-24 06:39:05,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-24 06:39:05,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-24 06:39:05,093 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-24 06:39:05,094 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43283
2024-01-24 06:39:05,094 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43283
2024-01-24 06:39:05,094 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37909
2024-01-24 06:39:05,094 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-24 06:39:05,094 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:39:05,094 - distributed.worker - INFO -               Threads:                          1
2024-01-24 06:39:05,094 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-24 06:39:05,094 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fce3rwwz
2024-01-24 06:39:05,094 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a2fb95e6-c582-46c9-8fd7-0b93d3f1b2e9
2024-01-24 06:39:05,095 - distributed.worker - INFO - Starting Worker plugin RMMSetup-022e2915-dbce-4061-a16f-47680e1f0b2b
2024-01-24 06:39:05,425 - distributed.worker - INFO - Starting Worker plugin PreImport-7672780a-cbaf-44d2-a611-7cc65c0fb2bc
2024-01-24 06:39:05,425 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:39:05,468 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43283', status: init, memory: 0, processing: 0>
2024-01-24 06:39:05,469 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43283
2024-01-24 06:39:05,469 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47304
2024-01-24 06:39:05,470 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-24 06:39:05,471 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-24 06:39:05,471 - distributed.worker - INFO - -------------------------------------------------
2024-01-24 06:39:05,472 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-24 06:39:05,523 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-24 06:39:05,527 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-24 06:39:05,530 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:39:05,532 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-24 06:39:05,534 - distributed.scheduler - INFO - Remove client Client-4298d09b-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:39:05,535 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47294; closing.
2024-01-24 06:39:05,535 - distributed.scheduler - INFO - Remove client Client-4298d09b-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:39:05,535 - distributed.scheduler - INFO - Close client connection: Client-4298d09b-ba83-11ee-b078-d8c49764f6bb
2024-01-24 06:39:05,536 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44347'. Reason: nanny-close
2024-01-24 06:39:05,537 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-24 06:39:05,538 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43283. Reason: nanny-close
2024-01-24 06:39:05,539 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47304; closing.
2024-01-24 06:39:05,539 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-24 06:39:05,540 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43283', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1706078345.54015')
2024-01-24 06:39:05,540 - distributed.scheduler - INFO - Lost all workers
2024-01-24 06:39:05,541 - distributed.nanny - INFO - Worker closed
2024-01-24 06:39:06,151 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-24 06:39:06,152 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-24 06:39:06,152 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-24 06:39:06,153 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-24 06:39:06,154 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42973 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38731 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] 2024-01-24 06:39:35,798 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 413, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 841, in wait
  File "libucxx.pyx", line 825, in wait_yield
  File "libucxx.pyx", line 820, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
2024-01-24 06:39:35,799 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 406, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 413, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 841, in wait
  File "libucxx.pyx", line 826, in wait_yield
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 641, in sleep
    await __sleep0()
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 630, in __sleep0
    yield
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CancelledError()
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44587 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43811 instead
  warnings.warn(
2024-01-24 06:40:04,580 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 413, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 841, in wait
  File "libucxx.pyx", line 825, in wait_yield
  File "libucxx.pyx", line 820, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
2024-01-24 06:40:04,581 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 406, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 413, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 841, in wait
  File "libucxx.pyx", line 825, in wait_yield
  File "libucxx.pyx", line 820, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
2024-01-24 06:40:04,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 413, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 841, in wait
  File "libucxx.pyx", line 825, in wait_yield
  File "libucxx.pyx", line 820, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38653 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41717 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42345 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34135 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44637 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46283 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37815 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37275 instead
  warnings.warn(
[1706078497.308890] [dgx13:68044:0]            sock.c:470  UCX  ERROR bind(fd=183 addr=0.0.0.0:43769) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36813 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44553 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35635 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39631 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41155 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40545 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40421 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42175 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35635 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33113 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33277 instead
  warnings.warn(
[1706078667.902649] [dgx13:71493:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:37039) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45613 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38931 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44083 instead
  warnings.warn(
Future exception was never retrieved
future: <Future finished exception=UCXCanceled('<[Recv shutdown] ep: 0x7fec50687140, tag: 0xcd040d9614c3b63b>: ')>
ucp._libs.exceptions.UCXCanceled: <[Recv shutdown] ep: 0x7fec50687140, tag: 0xcd040d9614c3b63b>: 
sys:1: RuntimeWarning: coroutine 'BlockingMode._arm_worker' was never awaited
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Task was destroyed but it is pending!
task: <Task cancelling name='Task-4970' coro=<BlockingMode._arm_worker() running at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/continuous_ucx_progress.py:88>>
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41753 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33541 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37013 instead
  warnings.warn(
[1706078799.396023] [dgx13:73602:0]            sock.c:470  UCX  ERROR bind(fd=126 addr=0.0.0.0:57068) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37661 instead
  warnings.warn(
[1706078831.017440] [dgx13:74024:0]            sock.c:470  UCX  ERROR bind(fd=155 addr=0.0.0.0:37634) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40545 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34095 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38621 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39191 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37555 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45253 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41733 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40231 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45797 instead
  warnings.warn(
[1706079078.784633] [dgx13:77876:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:44933) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46081 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44575 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41139 instead
  warnings.warn(
Future exception was never retrieved
future: <Future finished exception=UCXCanceled('<[Recv shutdown] ep: 0x7fe280cb4140, tag: 0xdc15bb8ac3039acb>: ')>
ucp._libs.exceptions.UCXCanceled: <[Recv shutdown] ep: 0x7fe280cb4140, tag: 0xdc15bb8ac3039acb>: 
Future exception was never retrieved
future: <Future finished exception=UCXCanceled('<[Recv shutdown] ep: 0x7fe280cb4180, tag: 0xced9c1db4fa8a871>: ')>
ucp._libs.exceptions.UCXCanceled: <[Recv shutdown] ep: 0x7fe280cb4180, tag: 0xced9c1db4fa8a871>: 
sys:1: RuntimeWarning: coroutine 'BlockingMode._arm_worker' was never awaited
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Task was destroyed but it is pending!
task: <Task cancelling name='Task-5470' coro=<BlockingMode._arm_worker() running at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/continuous_ucx_progress.py:88>>
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33685 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34737 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40579 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39083 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39723 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36185 instead
  warnings.warn(
[1706079371.242155] [dgx13:81679:0]            sock.c:470  UCX  ERROR bind(fd=160 addr=0.0.0.0:50049) failed: Address already in use
[1706079372.892719] [dgx13:81859:0]            sock.c:470  UCX  ERROR bind(fd=123 addr=0.0.0.0:40088) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34403 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36967 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44157 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35311 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36909 instead
  warnings.warn(
2024-01-24 06:57:39,878 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 175, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 172, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 178, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 179, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 136, in as_buffer
    return buffer_class(owner=owner_class._from_host_memory(data))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 197, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory
2024-01-24 06:57:39,885 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:39781'.
2024-01-24 06:57:39,885 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:39781'. Shutting down.
2024-01-24 06:57:39,889 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f0f3a6dfa00>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:203> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 206, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1299, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1025, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 247, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 78, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 61, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 175, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 172, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 178, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 179, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 136, in as_buffer
    return buffer_class(owner=owner_class._from_host_memory(data))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 197, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:203> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 206, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1299, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1025, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 247, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 78, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 61, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 175, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 172, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 178, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 179, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 136, in as_buffer
    return buffer_class(owner=owner_class._from_host_memory(data))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 197, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory
2024-01-24 06:57:41,892 - distributed.nanny - ERROR - Worker process died unexpectedly
