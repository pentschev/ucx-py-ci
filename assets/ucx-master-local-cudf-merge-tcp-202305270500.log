2023-05-27 06:58:13,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ik965vck', purging
2023-05-27 06:58:13,437 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:13,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:13,527 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:13,527 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:13,615 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:13,615 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:13,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:13,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:13,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:13,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:13,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:13,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:13,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:13,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:13,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:13,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:15,679 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:15,847 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:15,848 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:15,859 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:15,866 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:15,874 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:15,889 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:16,030 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:17,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fwlnq0n4', purging
2023-05-27 06:58:17,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xwr14b2h', purging
2023-05-27 06:58:17,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jfice4qx', purging
2023-05-27 06:58:17,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wdhe5j49', purging
2023-05-27 06:58:17,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0v6pvpm6', purging
2023-05-27 06:58:17,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qvn323s3', purging
2023-05-27 06:58:17,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-84jh3qas', purging
2023-05-27 06:58:17,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wphntshj', purging
2023-05-27 06:58:17,068 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:17,068 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:17,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:17,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:17,378 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:17,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:17,378 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:17,379 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:17,380 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:17,380 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:17,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:17,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:17,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:17,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:17,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:17,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:18,954 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:19,005 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:19,356 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:19,402 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:19,432 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:19,456 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:19,482 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:19,633 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:20,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8zwbjctf', purging
2023-05-27 06:58:20,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aggm6vri', purging
2023-05-27 06:58:20,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3f4kzewt', purging
2023-05-27 06:58:20,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gz1w43mv', purging
2023-05-27 06:58:20,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d7j5y0mc', purging
2023-05-27 06:58:20,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_btjcm4', purging
2023-05-27 06:58:20,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-spmubcw2', purging
2023-05-27 06:58:20,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oyx9bu37', purging
2023-05-27 06:58:20,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:20,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:20,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:20,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:20,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:20,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:20,921 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:20,921 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:20,928 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:20,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:20,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:20,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:20,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:20,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:21,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:21,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:22,343 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:22,372 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:22,792 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:22,794 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:22,818 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:22,852 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:22,880 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:23,062 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:23,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_is5fbm6', purging
2023-05-27 06:58:23,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sw25et17', purging
2023-05-27 06:58:23,938 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-equ3pg4u', purging
2023-05-27 06:58:23,938 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mdc1_hv8', purging
2023-05-27 06:58:23,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n741jf9y', purging
2023-05-27 06:58:23,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j14wjm0m', purging
2023-05-27 06:58:23,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h092__vi', purging
2023-05-27 06:58:23,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pv6ho8kz', purging
2023-05-27 06:58:23,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:23,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:23,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:23,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:24,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:24,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:24,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:24,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:24,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:24,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:24,428 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:24,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:24,454 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:24,454 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:24,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:24,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:25,167 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:26,016 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:26,102 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:26,340 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:26,387 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:26,411 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:26,451 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:26,619 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:26,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c1szev97', purging
2023-05-27 06:58:26,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8k8arexo', purging
2023-05-27 06:58:26,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7soxaoyt', purging
2023-05-27 06:58:26,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rl0if0o6', purging
2023-05-27 06:58:26,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ul5f4hn', purging
2023-05-27 06:58:26,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-usgrjjo8', purging
2023-05-27 06:58:26,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z74_0d29', purging
2023-05-27 06:58:26,710 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f3b3h2ch', purging
2023-05-27 06:58:26,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:26,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:27,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:27,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:27,532 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:27,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6mw43c4z', purging
2023-05-27 06:58:27,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:27,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:27,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:27,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:27,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:27,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:27,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:27,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:27,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:27,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:28,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:28,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:29,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-edbqn9io', purging
2023-05-27 06:58:29,022 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6roevapc', purging
2023-05-27 06:58:29,023 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:29,023 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:29,113 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:29,300 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:29,623 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:29,840 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:29,865 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:29,890 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:29,915 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:30,218 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:30,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2389qyh7', purging
2023-05-27 06:58:30,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mgxwt15i', purging
2023-05-27 06:58:30,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qzhqbqrv', purging
2023-05-27 06:58:30,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9nk6fgs0', purging
2023-05-27 06:58:30,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w_15vxge', purging
2023-05-27 06:58:30,561 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2l9dtu4h', purging
2023-05-27 06:58:30,561 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:30,561 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:30,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:30,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:31,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:31,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:31,396 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:31,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t6hpzdmv', purging
2023-05-27 06:58:31,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:31,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:31,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:31,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:31,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:31,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:31,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:31,459 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:31,669 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:31,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d13w8zsu', purging
2023-05-27 06:58:31,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:31,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:32,363 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:32,953 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:32,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-698q5tdj', purging
2023-05-27 06:58:32,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-em_7hxhr', purging
2023-05-27 06:58:32,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:32,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:33,010 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:33,036 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:33,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m1u94eit', purging
2023-05-27 06:58:33,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aotait1n', purging
2023-05-27 06:58:33,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1yi7s5t0', purging
2023-05-27 06:58:33,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:33,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:33,088 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:33,352 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:33,633 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:33,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:33,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8to4s8fn', purging
2023-05-27 06:58:33,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-36bt8s9e', purging
2023-05-27 06:58:33,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n3nlf7ww', purging
2023-05-27 06:58:33,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:33,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:34,456 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:34,456 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:34,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:34,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:34,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:34,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:34,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:34,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:34,766 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:34,858 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3eggi6pa', purging
2023-05-27 06:58:34,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:34,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:35,117 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:35,157 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-45tqsd4t', purging
2023-05-27 06:58:35,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:35,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:35,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:35,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:35,838 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:36,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ieyt_4s_', purging
2023-05-27 06:58:36,193 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k18j3w7a', purging
2023-05-27 06:58:36,193 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ulpmr9lr', purging
2023-05-27 06:58:36,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:36,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:36,279 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:36,304 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:36,498 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:36,641 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e7qz2vhz', purging
2023-05-27 06:58:36,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:36,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:36,715 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:36,739 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:37,037 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:37,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-57okrsnd', purging
2023-05-27 06:58:37,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yomdrvx2', purging
2023-05-27 06:58:37,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2h6_j7o3', purging
2023-05-27 06:58:37,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m6i7_ykm', purging
2023-05-27 06:58:37,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:37,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:37,330 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:37,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:37,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:37,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:37,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:37,993 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:37,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:38,172 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:38,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:38,243 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:38,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4evs473i', purging
2023-05-27 06:58:38,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:38,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:38,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:38,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:38,709 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:38,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gskm0tmh', purging
2023-05-27 06:58:38,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hxhvagyp', purging
2023-05-27 06:58:38,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:38,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:38,780 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:39,575 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:39,699 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oolzgeui', purging
2023-05-27 06:58:39,700 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:39,700 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:39,794 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:39,824 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:40,163 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:40,188 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:40,214 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w03ekx4a', purging
2023-05-27 06:58:40,214 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1n1ebgtm', purging
2023-05-27 06:58:40,215 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nj21lzs2', purging
2023-05-27 06:58:40,215 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ryxdfq3k', purging
2023-05-27 06:58:40,216 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:40,216 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:40,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:40,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:40,494 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:41,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ywa4j3w', purging
2023-05-27 06:58:41,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:41,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:41,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:41,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:41,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:41,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:41,447 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:41,471 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:41,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aftmjcgg', purging
2023-05-27 06:58:41,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ndi5q3zv', purging
2023-05-27 06:58:41,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:41,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:41,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:41,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:41,981 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:41,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mqk_v24e', purging
2023-05-27 06:58:41,994 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:41,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:42,579 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:42,767 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:42,907 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wank97bs', purging
2023-05-27 06:58:42,907 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k5qdnrpr', purging
2023-05-27 06:58:42,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:42,908 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:42,971 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w3_o5n__', purging
2023-05-27 06:58:42,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hvpai0_u', purging
2023-05-27 06:58:42,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:42,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:42,978 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:43,002 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:43,224 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:43,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-swr7dwtg', purging
2023-05-27 06:58:43,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:43,453 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:44,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:44,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:44,195 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:44,222 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:44,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gfy5s74c', purging
2023-05-27 06:58:44,326 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xc2g7nd2', purging
2023-05-27 06:58:44,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:44,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:44,454 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:44,454 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:44,498 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:44,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g9t78sqq', purging
2023-05-27 06:58:44,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:44,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:44,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:44,795 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:45,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:45,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:45,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:45,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:45,943 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:45,971 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:46,016 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:46,044 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:46,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2nqep5bu', purging
2023-05-27 06:58:46,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xvmtexkl', purging
2023-05-27 06:58:46,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xivpzyha', purging
2023-05-27 06:58:46,077 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ra77dodl', purging
2023-05-27 06:58:46,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:46,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:46,511 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:46,895 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:46,922 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:47,148 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:47,483 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e_zzlzbj', purging
2023-05-27 06:58:47,483 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s3ncdpo_', purging
2023-05-27 06:58:47,483 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fty0rn6q', purging
2023-05-27 06:58:47,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2up3r_e7', purging
2023-05-27 06:58:47,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:47,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:47,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:47,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:47,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:47,528 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:47,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:47,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:47,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:47,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:48,361 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:48,361 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:48,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:48,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:48,621 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:48,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:49,437 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:49,460 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:49,492 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:49,518 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:49,947 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:49,967 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:50,013 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:50,186 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:50,883 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zj_r1p5b', purging
2023-05-27 06:58:50,884 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tbr_at22', purging
2023-05-27 06:58:50,884 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5vl55dqi', purging
2023-05-27 06:58:50,885 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nty__67h', purging
2023-05-27 06:58:50,885 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i0en1a7n', purging
2023-05-27 06:58:50,885 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bgocy4qo', purging
2023-05-27 06:58:50,885 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wou0rpm9', purging
2023-05-27 06:58:50,886 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c1fh_91i', purging
2023-05-27 06:58:50,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:50,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:51,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:51,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:51,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:51,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:51,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:51,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:51,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:51,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:51,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:51,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:51,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:51,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:51,706 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:51,706 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:52,339 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:53,005 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:53,029 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:53,054 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:53,299 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:53,339 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:53,365 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:53,536 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:53,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-510bwpah', purging
2023-05-27 06:58:53,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l765oqmy', purging
2023-05-27 06:58:53,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ctsauy79', purging
2023-05-27 06:58:53,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cipxauzb', purging
2023-05-27 06:58:53,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9tua0by3', purging
2023-05-27 06:58:53,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9o50lojd', purging
2023-05-27 06:58:53,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-33rr9gqa', purging
2023-05-27 06:58:53,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wihwjr0g', purging
2023-05-27 06:58:53,862 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:53,862 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:54,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:54,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:54,615 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:54,615 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:54,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:54,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:54,703 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:54,756 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3sxai52s', purging
2023-05-27 06:58:54,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:54,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:54,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:54,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:54,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:54,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:55,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:55,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:56,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:56,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:56,693 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:56,730 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:56,776 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:56,795 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:56,827 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:56,857 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:57,062 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:58:57,357 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:58:58,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ygrfq3fr', purging
2023-05-27 06:58:58,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-613k7sfi', purging
2023-05-27 06:58:58,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gx41ts8s', purging
2023-05-27 06:58:58,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i9vinkwb', purging
2023-05-27 06:58:58,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-py6_z_zz', purging
2023-05-27 06:58:58,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mx899rod', purging
2023-05-27 06:58:58,245 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9279_ac9', purging
2023-05-27 06:58:58,245 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jkf4qrkt', purging
2023-05-27 06:58:58,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:58,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:58,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:58,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:58,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:58,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:58,327 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:58,327 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:58,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:58,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:58,361 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:58,361 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:58,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:58,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:58:58,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:58:58,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:00,445 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:00,474 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:00,501 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:00,543 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:00,565 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:00,593 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:00,611 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:00,910 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:02,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pic45r10', purging
2023-05-27 06:59:02,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9erreybf', purging
2023-05-27 06:59:02,001 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sbv0nixp', purging
2023-05-27 06:59:02,001 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v88acvwg', purging
2023-05-27 06:59:02,001 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qpvdbo35', purging
2023-05-27 06:59:02,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i9us87ts', purging
2023-05-27 06:59:02,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y273otxi', purging
2023-05-27 06:59:02,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6tvrbab', purging
2023-05-27 06:59:02,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:02,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:02,024 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:02,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:02,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:02,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:02,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:02,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:02,092 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:02,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:02,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:02,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:02,166 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:02,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:02,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:02,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:04,184 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:04,343 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:04,345 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:04,356 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:04,364 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:04,390 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:04,546 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:05,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zo3fvr_k', purging
2023-05-27 06:59:05,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cwlgbkxd', purging
2023-05-27 06:59:05,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mkttgmis', purging
2023-05-27 06:59:05,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6ju3mrtf', purging
2023-05-27 06:59:05,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yc42ab98', purging
2023-05-27 06:59:05,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qu0lwdqt', purging
2023-05-27 06:59:05,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-csu5ai5t', purging
2023-05-27 06:59:05,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jttelm8j', purging
2023-05-27 06:59:05,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:05,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:05,774 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:05,774 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:05,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:05,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:05,903 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:05,903 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:05,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:05,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:05,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:05,908 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:06,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:06,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:07,645 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:07,704 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:07,723 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:07,745 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:07,771 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:07,812 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:07,983 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:09,082 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f2xpq8k0', purging
2023-05-27 06:59:09,082 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gkdjmwki', purging
2023-05-27 06:59:09,083 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iuqk8c6l', purging
2023-05-27 06:59:09,083 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o02obeax', purging
2023-05-27 06:59:09,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bjf3bal5', purging
2023-05-27 06:59:09,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7za9m3gj', purging
2023-05-27 06:59:09,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_3g7kcxs', purging
2023-05-27 06:59:09,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:09,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:09,228 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:09,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:09,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:09,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:09,276 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:09,276 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:09,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:09,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:09,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:09,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:09,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:09,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:11,020 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:11,100 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:11,121 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:11,145 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:11,170 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:11,196 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:11,439 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:12,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-azt3ey85', purging
2023-05-27 06:59:12,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y5ndj_ch', purging
2023-05-27 06:59:12,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wcikw9ok', purging
2023-05-27 06:59:12,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9dsjwobd', purging
2023-05-27 06:59:12,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c2yyfco2', purging
2023-05-27 06:59:12,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dcx6n12h', purging
2023-05-27 06:59:12,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w801pvo0', purging
2023-05-27 06:59:12,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:12,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:12,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:12,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:12,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:12,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:12,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:12,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:12,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:12,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:12,701 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:12,701 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:12,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:12,915 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:14,330 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:14,390 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:14,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:14,444 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:14,466 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:14,494 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:14,791 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:15,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sbxxqahg', purging
2023-05-27 06:59:15,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j3vwkxli', purging
2023-05-27 06:59:15,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p0nqmd7g', purging
2023-05-27 06:59:15,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2tvq_nm', purging
2023-05-27 06:59:15,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pu82t9s0', purging
2023-05-27 06:59:15,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aewuo8d7', purging
2023-05-27 06:59:15,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5fa77cav', purging
2023-05-27 06:59:15,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:15,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:15,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:15,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:15,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:15,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:15,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:15,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:16,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:16,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:16,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:16,032 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:16,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:16,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:17,696 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:17,729 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:17,821 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:17,823 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:17,835 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:17,859 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:18,152 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:19,230 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dlk0u9be', purging
2023-05-27 06:59:19,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xvn8sr2x', purging
2023-05-27 06:59:19,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m4zr5uoh', purging
2023-05-27 06:59:19,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hk98kjk9', purging
2023-05-27 06:59:19,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4spgmt56', purging
2023-05-27 06:59:19,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k22q_dmy', purging
2023-05-27 06:59:19,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z64nr9pb', purging
2023-05-27 06:59:19,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:19,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:19,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:19,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:19,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:19,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:19,334 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:19,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:19,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:19,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:19,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:19,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:19,643 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:19,643 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:21,176 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:21,237 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:21,264 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:21,286 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:21,326 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:21,356 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:21,574 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:22,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y8uneads', purging
2023-05-27 06:59:22,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jtv4rh7x', purging
2023-05-27 06:59:22,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8xew8384', purging
2023-05-27 06:59:22,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p1vw8baj', purging
2023-05-27 06:59:22,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pn16myi3', purging
2023-05-27 06:59:22,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1_4_llk7', purging
2023-05-27 06:59:22,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sr4fy8xj', purging
2023-05-27 06:59:22,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:22,709 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:22,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:22,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:22,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:22,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:22,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:22,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:22,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:22,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:22,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:22,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:23,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:23,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:24,706 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:24,731 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:24,790 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:24,818 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:24,839 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:24,870 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:25,013 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:26,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:26,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qobnp1zn', purging
2023-05-27 06:59:26,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:26,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h9oq0q65', purging
2023-05-27 06:59:26,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqna2env', purging
2023-05-27 06:59:26,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5z5h4n5x', purging
2023-05-27 06:59:26,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u7t9hlla', purging
2023-05-27 06:59:26,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s890d1k7', purging
2023-05-27 06:59:26,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4cssn0na', purging
2023-05-27 06:59:26,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:26,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:26,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:26,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:26,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:26,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:26,324 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:26,324 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:26,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:26,338 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:26,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:26,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:28,167 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:28,200 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:28,247 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:28,277 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:28,304 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:28,328 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:28,481 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:29,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pitrgz0x', purging
2023-05-27 06:59:29,580 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bqytga86', purging
2023-05-27 06:59:29,580 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q819noem', purging
2023-05-27 06:59:29,581 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4hxes6m2', purging
2023-05-27 06:59:29,581 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gpeefg45', purging
2023-05-27 06:59:29,582 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n6821gp7', purging
2023-05-27 06:59:29,582 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rpqtzffq', purging
2023-05-27 06:59:29,582 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:29,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:29,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:29,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:29,727 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:29,727 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:29,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:29,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:29,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:29,806 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:29,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:29,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:29,967 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:29,967 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:31,511 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:31,570 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:31,596 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:31,617 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:31,643 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:31,675 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:31,896 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:33,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5e_ew32s', purging
2023-05-27 06:59:33,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ozokygwv', purging
2023-05-27 06:59:33,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-egdbc3je', purging
2023-05-27 06:59:33,012 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mi35s7eg', purging
2023-05-27 06:59:33,012 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tcu46hm7', purging
2023-05-27 06:59:33,013 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hogkp_09', purging
2023-05-27 06:59:33,013 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-murmhfaa', purging
2023-05-27 06:59:33,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:33,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:33,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:33,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:33,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:33,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:33,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:33,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:33,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:33,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:33,156 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:33,156 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:33,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:33,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:34,980 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:35,006 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:35,065 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:35,092 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:35,114 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:35,139 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:35,313 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:36,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9syzizi_', purging
2023-05-27 06:59:36,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uhu2c7u9', purging
2023-05-27 06:59:36,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-asj5m0od', purging
2023-05-27 06:59:36,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_tikx2c', purging
2023-05-27 06:59:36,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w_06ckul', purging
2023-05-27 06:59:36,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xwlwj46k', purging
2023-05-27 06:59:36,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9jn6dkzg', purging
2023-05-27 06:59:36,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:36,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:36,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:36,445 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:36,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:36,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:36,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:36,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:36,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:36,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:36,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:36,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:36,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:36,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:38,337 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:38,360 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:38,411 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:38,440 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:38,465 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:38,493 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:38,738 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:39,790 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j3g48_h8', purging
2023-05-27 06:59:39,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9k0oobdr', purging
2023-05-27 06:59:39,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s37jtikj', purging
2023-05-27 06:59:39,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2cnjtgu4', purging
2023-05-27 06:59:39,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pc6hfpxo', purging
2023-05-27 06:59:39,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7x8r5nyn', purging
2023-05-27 06:59:39,793 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vskjld1i', purging
2023-05-27 06:59:39,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:39,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:39,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:39,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:39,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:39,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:39,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:39,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:39,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:39,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:39,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:39,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:40,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:40,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:41,719 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:41,754 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:41,807 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:41,832 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:41,858 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:41,879 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:42,041 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:43,145 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5kf5p_e9', purging
2023-05-27 06:59:43,146 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bxnphcjr', purging
2023-05-27 06:59:43,146 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cqmq8i9n', purging
2023-05-27 06:59:43,147 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hc8zzyy_', purging
2023-05-27 06:59:43,147 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6w8ofxj9', purging
2023-05-27 06:59:43,147 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a_spyk7b', purging
2023-05-27 06:59:43,148 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a2wkondi', purging
2023-05-27 06:59:43,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:43,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:43,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:43,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:43,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:43,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:43,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:43,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:43,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:43,362 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:43,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:43,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:43,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:43,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:45,097 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:45,126 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:45,152 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:45,174 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:45,200 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:45,230 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:45,432 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:46,497 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0vuq9h7l', purging
2023-05-27 06:59:46,497 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bt92fi5y', purging
2023-05-27 06:59:46,498 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m4mtj9j3', purging
2023-05-27 06:59:46,498 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zvcxzs7n', purging
2023-05-27 06:59:46,499 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sbqeugi3', purging
2023-05-27 06:59:46,499 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-csdw4zcj', purging
2023-05-27 06:59:46,500 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s4ftp55n', purging
2023-05-27 06:59:46,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:46,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:46,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:46,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:46,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:46,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:46,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:46,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:46,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:46,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:46,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:46,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:46,841 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:46,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:48,460 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:48,519 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:48,547 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:48,578 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:48,599 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:48,627 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:48,784 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:50,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hm4djkla', purging
2023-05-27 06:59:50,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4vbfl_1u', purging
2023-05-27 06:59:50,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vksvf51e', purging
2023-05-27 06:59:50,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ha0xzxzw', purging
2023-05-27 06:59:50,030 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8xmu9bth', purging
2023-05-27 06:59:50,030 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q_d22x82', purging
2023-05-27 06:59:50,030 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7z_28kr3', purging
2023-05-27 06:59:50,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:50,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:50,032 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:50,032 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:50,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:50,106 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:50,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:50,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:50,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:50,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:50,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:50,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:50,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:50,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:52,049 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:52,076 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:52,103 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:52,127 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:52,151 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:52,179 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:52,347 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:53,501 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rtrra_ob', purging
2023-05-27 06:59:53,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8tyczssl', purging
2023-05-27 06:59:53,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s6f9p46v', purging
2023-05-27 06:59:53,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mux3ye6r', purging
2023-05-27 06:59:53,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z9bbgjnn', purging
2023-05-27 06:59:53,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ogvf426h', purging
2023-05-27 06:59:53,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xrz6jwpp', purging
2023-05-27 06:59:53,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:53,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:53,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:53,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:53,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:53,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:53,649 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:53,649 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:53,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:53,679 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:53,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:53,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:53,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:53,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:55,451 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:55,494 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:55,519 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:55,573 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:55,597 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:55,622 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:55,778 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:56,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:56,941 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ksk3htlk', purging
2023-05-27 06:59:56,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:56,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3hmgtm0o', purging
2023-05-27 06:59:56,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-im99m7yw', purging
2023-05-27 06:59:56,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ygjachbh', purging
2023-05-27 06:59:56,943 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1qi700wv', purging
2023-05-27 06:59:56,943 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k_6qe1it', purging
2023-05-27 06:59:56,943 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-68q7wci0', purging
2023-05-27 06:59:56,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:56,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:57,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:57,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:57,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:57,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:57,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:57,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:57,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:57,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:59:57,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:59:57,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:59:58,901 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:58,978 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:58,996 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:59,017 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:59,041 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:59,065 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:59:59,273 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:00,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gicdd0sk', purging
2023-05-27 07:00:00,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u1kmx5ci', purging
2023-05-27 07:00:00,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uf6_sj4u', purging
2023-05-27 07:00:00,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-592o9yp9', purging
2023-05-27 07:00:00,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dhnqp16l', purging
2023-05-27 07:00:00,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-twur79oa', purging
2023-05-27 07:00:00,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-khzup53o', purging
2023-05-27 07:00:00,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:00,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:00,509 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:00,509 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:00,514 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:00,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:00,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:00,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:00,569 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:00,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:00,569 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:00,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:00,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:00,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:02,398 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:02,449 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:02,485 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:02,514 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:02,541 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:02,563 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:02,714 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:03,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yyv6ussi', purging
2023-05-27 07:00:03,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xeb6l504', purging
2023-05-27 07:00:03,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qdk0q5b5', purging
2023-05-27 07:00:03,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f9n_ez0c', purging
2023-05-27 07:00:03,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nom90bh3', purging
2023-05-27 07:00:03,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7mhiczm9', purging
2023-05-27 07:00:03,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5shmuz96', purging
2023-05-27 07:00:03,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:03,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:03,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:03,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:03,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:03,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:04,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:04,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:04,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:04,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:04,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:04,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:04,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:04,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:05,835 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:05,902 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:05,926 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:05,954 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:05,978 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:06,021 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:06,185 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:07,393 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dp4v3mx7', purging
2023-05-27 07:00:07,393 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u40x5_m_', purging
2023-05-27 07:00:07,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7g46gb7r', purging
2023-05-27 07:00:07,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ecteuts', purging
2023-05-27 07:00:07,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jpjxxy72', purging
2023-05-27 07:00:07,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-91disojt', purging
2023-05-27 07:00:07,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v7vh9kw9', purging
2023-05-27 07:00:07,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:07,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:07,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:07,453 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:07,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:07,485 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:07,552 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:07,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:07,552 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:07,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:07,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:07,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:07,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:07,638 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:09,328 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:09,387 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:09,445 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:09,474 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:09,497 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:09,527 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:09,681 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:10,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tq50n7cv', purging
2023-05-27 07:00:10,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iyqps51c', purging
2023-05-27 07:00:10,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ihenlabe', purging
2023-05-27 07:00:10,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k0gkv5i8', purging
2023-05-27 07:00:10,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iod562f3', purging
2023-05-27 07:00:10,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4v0w75zm', purging
2023-05-27 07:00:10,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0gbt2s6o', purging
2023-05-27 07:00:10,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:10,709 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:10,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:10,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:10,979 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:10,979 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:10,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:10,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:10,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:10,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:11,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:11,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:11,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:11,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:12,589 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:12,646 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:12,709 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:12,735 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:12,835 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:12,856 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:13,077 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:13,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aahx9a8b', purging
2023-05-27 07:00:13,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sa7n7ib1', purging
2023-05-27 07:00:13,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gzgacalr', purging
2023-05-27 07:00:13,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p9ov2je6', purging
2023-05-27 07:00:13,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yfkfl726', purging
2023-05-27 07:00:13,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mnkk8_op', purging
2023-05-27 07:00:13,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bi55q6ac', purging
2023-05-27 07:00:13,977 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:13,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:14,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:14,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:14,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:14,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:14,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:14,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:14,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:14,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:14,317 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:14,317 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:14,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:14,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:15,822 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:15,853 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:15,975 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:16,007 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:16,087 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:16,125 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:16,312 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:17,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0x4j8jfb', purging
2023-05-27 07:00:17,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9cy3ib1z', purging
2023-05-27 07:00:17,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4n4tdmc7', purging
2023-05-27 07:00:17,234 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-at2jyrwx', purging
2023-05-27 07:00:17,234 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ug1l_q_r', purging
2023-05-27 07:00:17,234 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-70h3a2sy', purging
2023-05-27 07:00:17,235 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ed9fh1k', purging
2023-05-27 07:00:17,235 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:17,235 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:17,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:17,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:17,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:17,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:17,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:17,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:17,582 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:17,582 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:17,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:17,615 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:17,791 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:17,791 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:18,865 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:18,902 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:19,289 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:19,338 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:19,367 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:19,402 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:19,600 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:20,264 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-92qg3xlt', purging
2023-05-27 07:00:20,264 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p76moqna', purging
2023-05-27 07:00:20,264 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p2bciwcq', purging
2023-05-27 07:00:20,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xgglu46g', purging
2023-05-27 07:00:20,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-enw1uqlv', purging
2023-05-27 07:00:20,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psfcj8fy', purging
2023-05-27 07:00:20,266 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jhog8edl', purging
2023-05-27 07:00:20,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:20,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:20,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:20,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:20,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:20,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:20,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:20,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:20,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:20,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:20,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:20,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:21,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:21,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:21,740 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:21,930 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:22,388 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:22,420 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:22,436 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:22,478 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:22,690 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:23,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hz1od2vy', purging
2023-05-27 07:00:23,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-048g3c1r', purging
2023-05-27 07:00:23,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4t4hr0gw', purging
2023-05-27 07:00:23,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tipsz_6f', purging
2023-05-27 07:00:23,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jn4zwor5', purging
2023-05-27 07:00:23,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6h6pefgz', purging
2023-05-27 07:00:23,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vxgc1wv2', purging
2023-05-27 07:00:23,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:23,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:23,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:23,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:23,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:23,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:23,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:23,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:23,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:23,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:23,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:23,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:24,070 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:24,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-clmxyq1k', purging
2023-05-27 07:00:24,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xgn4ion3', purging
2023-05-27 07:00:24,198 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:24,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:24,274 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:25,054 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:25,332 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:25,404 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:25,443 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:25,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pt8f3_ka', purging
2023-05-27 07:00:25,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nufhfybf', purging
2023-05-27 07:00:25,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-imo60csb', purging
2023-05-27 07:00:25,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ksf1eie', purging
2023-05-27 07:00:25,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:25,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:25,656 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:25,730 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jc38nef9', purging
2023-05-27 07:00:25,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:25,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:26,400 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:26,561 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:26,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bvk6zyce', purging
2023-05-27 07:00:26,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i7per3lg', purging
2023-05-27 07:00:26,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:26,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:26,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:26,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:26,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:26,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:26,977 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:26,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:27,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:27,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:27,841 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yxo85dnl', purging
2023-05-27 07:00:27,842 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:27,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:27,859 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:28,094 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:28,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-du6whm3v', purging
2023-05-27 07:00:28,099 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:28,099 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:28,512 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:28,547 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:28,577 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:28,921 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:29,095 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:29,252 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-75a408s7', purging
2023-05-27 07:00:29,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-if676ww8', purging
2023-05-27 07:00:29,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cb3nquld', purging
2023-05-27 07:00:29,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-towp5na6', purging
2023-05-27 07:00:29,254 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2cggqmb_', purging
2023-05-27 07:00:29,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:29,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:29,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:29,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:30,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:30,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:30,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:30,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:30,063 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cdcexdz0', purging
2023-05-27 07:00:30,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:30,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:30,089 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:30,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:30,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:30,450 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:30,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-658z5l4c', purging
2023-05-27 07:00:30,538 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:30,538 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:31,368 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:31,412 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:31,464 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:31,498 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zy1c6l4x', purging
2023-05-27 07:00:31,498 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ijouh5sv', purging
2023-05-27 07:00:31,499 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-390z5bdw', purging
2023-05-27 07:00:31,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:31,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:31,620 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:31,815 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:31,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m0zsmypf', purging
2023-05-27 07:00:31,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1eh14bzl', purging
2023-05-27 07:00:31,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:31,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:32,587 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:32,763 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:32,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ritho31', purging
2023-05-27 07:00:32,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gbxzvmyy', purging
2023-05-27 07:00:32,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:32,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:32,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:32,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:32,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:32,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:33,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:33,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:33,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:33,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:34,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:34,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:34,218 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:34,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:34,381 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:34,405 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:34,432 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:34,483 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:34,951 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:35,071 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:35,284 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:35,841 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1cbwh472', purging
2023-05-27 07:00:35,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k6hibdyk', purging
2023-05-27 07:00:35,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jpmrsafc', purging
2023-05-27 07:00:35,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g4fqrxmx', purging
2023-05-27 07:00:35,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a9agl7b2', purging
2023-05-27 07:00:35,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dtib1o4g', purging
2023-05-27 07:00:35,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rz4__k24', purging
2023-05-27 07:00:35,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:35,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:35,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:35,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:35,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:35,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:35,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:35,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:36,386 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:36,386 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:36,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:36,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:36,735 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:36,735 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:37,574 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:37,763 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:37,781 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:37,807 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:38,036 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:38,080 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:38,250 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:39,085 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oz5w95gi', purging
2023-05-27 07:00:39,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pza2lo6u', purging
2023-05-27 07:00:39,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qnnp7zsp', purging
2023-05-27 07:00:39,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7u35jlt', purging
2023-05-27 07:00:39,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r2b151me', purging
2023-05-27 07:00:39,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xekb0l4c', purging
2023-05-27 07:00:39,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f0fou6gd', purging
2023-05-27 07:00:39,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:39,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:39,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:39,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:39,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:39,304 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:39,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:39,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:39,542 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:39,542 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:39,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:39,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:39,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:39,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:40,942 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:40,983 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:41,023 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:41,041 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:41,241 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 07:00:41,465 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:42,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ingjqi9f', purging
2023-05-27 07:00:42,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-545zq1u1', purging
2023-05-27 07:00:42,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u56yck1y', purging
2023-05-27 07:00:42,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1orlswiu', purging
2023-05-27 07:00:42,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1p7_xq3z', purging
2023-05-27 07:00:42,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4a6zhajf', purging
2023-05-27 07:00:42,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bfgkmnc1', purging
2023-05-27 07:00:42,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:42,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:42,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:42,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:42,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:42,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:42,514 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:42,514 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:42,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:42,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:42,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:42,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:43,779 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:43,991 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:44,018 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:44,040 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:44,184 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:44,373 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:45,163 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b0wb3bm4', purging
2023-05-27 07:00:45,164 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0ypa_jr', purging
2023-05-27 07:00:45,164 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pi5rg0ft', purging
2023-05-27 07:00:45,164 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-33y0v0od', purging
2023-05-27 07:00:45,165 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a4gos_er', purging
2023-05-27 07:00:45,165 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dm65ykow', purging
2023-05-27 07:00:45,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:45,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:45,491 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:45,491 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:45,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:45,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:45,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:45,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:45,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:45,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:45,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:45,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:46,192 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:46,934 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:46,983 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:47,035 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:47,066 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:47,326 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:47,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-15an4p5_', purging
2023-05-27 07:00:47,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pbt3xqsz', purging
2023-05-27 07:00:47,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kdxv8j5h', purging
2023-05-27 07:00:47,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3uqtl6g_', purging
2023-05-27 07:00:47,596 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ae4k7d4n', purging
2023-05-27 07:00:47,596 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6ta621n5', purging
2023-05-27 07:00:47,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:47,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:48,361 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ol360vht', purging
2023-05-27 07:00:48,361 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:48,361 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:48,387 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:48,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:48,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:48,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:48,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:48,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:48,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:48,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:48,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:49,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:49,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:49,874 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:49,937 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:49,962 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:49,989 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:50,263 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:50,502 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:51,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ibzh1lx', purging
2023-05-27 07:00:51,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1o23mzj4', purging
2023-05-27 07:00:51,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ah61b784', purging
2023-05-27 07:00:51,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xckv_0zw', purging
2023-05-27 07:00:51,338 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sfq9emfo', purging
2023-05-27 07:00:51,338 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oiaa743f', purging
2023-05-27 07:00:51,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:51,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:51,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:51,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:51,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:51,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:51,442 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:51,442 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:51,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:51,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:51,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:51,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:52,996 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:53,016 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:53,049 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:53,069 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:53,250 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:53,418 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:54,493 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqbydfpm', purging
2023-05-27 07:00:54,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-avcc5mn_', purging
2023-05-27 07:00:54,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-swdd2qdz', purging
2023-05-27 07:00:54,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-07ghfr6z', purging
2023-05-27 07:00:54,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kzaliz7n', purging
2023-05-27 07:00:54,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vw4fxrct', purging
2023-05-27 07:00:54,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:54,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:54,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:54,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:54,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:54,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:54,524 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:54,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:54,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:54,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:54,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:54,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:56,195 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:56,221 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:56,274 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:56,297 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:56,328 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:56,481 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:57,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-163ivp13', purging
2023-05-27 07:00:57,682 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a38r70fs', purging
2023-05-27 07:00:57,682 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tdw84zp4', purging
2023-05-27 07:00:57,682 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8zrza67s', purging
2023-05-27 07:00:57,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uear3_6a', purging
2023-05-27 07:00:57,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6tm9t4fg', purging
2023-05-27 07:00:57,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:57,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:57,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:57,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:57,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:57,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:57,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:57,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:57,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:57,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:00:57,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:00:57,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:00:59,412 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:59,473 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:59,500 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:59,520 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:59,553 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:00:59,704 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:00,907 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_7dd2xoe', purging
2023-05-27 07:01:00,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7r0xz3ld', purging
2023-05-27 07:01:00,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a3ss2u76', purging
2023-05-27 07:01:00,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nsqvjcwe', purging
2023-05-27 07:01:00,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lydq9u9w', purging
2023-05-27 07:01:00,909 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cx_y80ll', purging
2023-05-27 07:01:00,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:00,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:00,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:00,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:01,000 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:01,000 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:01,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:01,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:01,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:01,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:01,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:01,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:02,667 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:02,695 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:02,718 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:02,770 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:02,772 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:02,931 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:04,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r2phpoks', purging
2023-05-27 07:01:04,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-scobws4o', purging
2023-05-27 07:01:04,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vzs7745a', purging
2023-05-27 07:01:04,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-grd3wy_7', purging
2023-05-27 07:01:04,140 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ubg4p0a4', purging
2023-05-27 07:01:04,140 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9rrayjf7', purging
2023-05-27 07:01:04,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:04,141 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:04,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:04,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:04,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:04,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:04,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:04,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:04,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:04,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:04,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:04,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:05,875 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:05,905 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:05,946 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 07:01:06,025 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:06,168 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:07,324 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mldtqbae', purging
2023-05-27 07:01:07,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o4xmpvxe', purging
2023-05-27 07:01:07,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f8ykb_8k', purging
2023-05-27 07:01:07,326 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ybneyum', purging
2023-05-27 07:01:07,326 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l5s0e9dz', purging
2023-05-27 07:01:07,326 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kimbmj5v', purging
2023-05-27 07:01:07,327 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:07,327 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:07,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:07,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:07,405 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:07,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:07,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:07,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:07,586 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:07,586 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:08,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:08,890 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:08,903 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:08,941 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:09,099 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:10,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4wnqyjjb', purging
2023-05-27 07:01:10,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ua9oeu58', purging
2023-05-27 07:01:10,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bvr_dvmt', purging
2023-05-27 07:01:10,260 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-__c5bplz', purging
2023-05-27 07:01:10,260 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t9cx8fwb', purging
2023-05-27 07:01:10,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:10,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:10,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:10,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:10,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:10,355 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:10,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:10,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:10,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:10,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:11,795 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:11,828 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:11,846 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:11,881 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:12,030 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:13,147 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fmfmvic4', purging
2023-05-27 07:01:13,148 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cf_8ddhn', purging
2023-05-27 07:01:13,148 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0l1lehoc', purging
2023-05-27 07:01:13,148 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dt5iay55', purging
2023-05-27 07:01:13,149 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ttpl1d12', purging
2023-05-27 07:01:13,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:13,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:13,287 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:13,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:13,292 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:13,292 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:13,309 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:13,309 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:13,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:13,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:14,688 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:14,714 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:14,737 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:14,760 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:14,930 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:16,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w8m44mos', purging
2023-05-27 07:01:16,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9tpftoen', purging
2023-05-27 07:01:16,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q8y1qctx', purging
2023-05-27 07:01:16,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u_vgh5pw', purging
2023-05-27 07:01:16,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e9skmp8l', purging
2023-05-27 07:01:16,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:16,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:16,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:16,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:16,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:16,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:16,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:16,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:16,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:16,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:17,604 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:17,655 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:17,681 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:17,701 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:17,874 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:19,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wkdfxvhm', purging
2023-05-27 07:01:19,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zfziic40', purging
2023-05-27 07:01:19,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o3uywdda', purging
2023-05-27 07:01:19,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f2jxbmbt', purging
2023-05-27 07:01:19,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whpjs0ur', purging
2023-05-27 07:01:19,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:19,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:19,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:19,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:19,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:19,116 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:19,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:19,120 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:19,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:19,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:20,519 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:20,572 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:20,597 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:20,614 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:20,795 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:21,971 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zjmyex5o', purging
2023-05-27 07:01:21,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-24f6bidl', purging
2023-05-27 07:01:21,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k8woe3m5', purging
2023-05-27 07:01:21,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j9b01y5b', purging
2023-05-27 07:01:21,973 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ljgcj0di', purging
2023-05-27 07:01:21,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:21,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:22,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:22,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:22,018 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:22,018 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:22,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:22,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:22,226 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:22,226 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:23,490 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:23,532 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:23,550 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:23,584 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:23,742 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:24,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whzjgor8', purging
2023-05-27 07:01:24,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6yean5cw', purging
2023-05-27 07:01:24,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m3udkhi6', purging
2023-05-27 07:01:24,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-evw2oez5', purging
2023-05-27 07:01:24,941 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wvlliy73', purging
2023-05-27 07:01:24,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:24,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:25,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:25,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:25,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:25,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:25,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:25,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:25,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:25,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:26,435 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:26,492 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:26,518 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:26,544 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:26,709 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:27,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ubbmm6sq', purging
2023-05-27 07:01:27,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-51pb_xds', purging
2023-05-27 07:01:27,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6vqzscbk', purging
2023-05-27 07:01:27,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cxggiz6s', purging
2023-05-27 07:01:27,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vlnfssc9', purging
2023-05-27 07:01:27,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:27,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:27,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:27,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:27,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:27,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:27,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:27,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:28,195 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:28,195 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:29,345 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:29,368 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:29,398 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:29,430 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:29,651 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:30,800 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x098sinc', purging
2023-05-27 07:01:30,801 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mov25o7n', purging
2023-05-27 07:01:30,801 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s7uctra_', purging
2023-05-27 07:01:30,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:30,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:30,801 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-481ubehm', purging
2023-05-27 07:01:30,802 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t2tv6i9p', purging
2023-05-27 07:01:30,802 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:30,802 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:30,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:30,810 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:30,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:30,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:31,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:31,116 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:32,292 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:32,332 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:32,356 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:32,383 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:32,540 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:33,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4f4p1m2l', purging
2023-05-27 07:01:33,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aawaqm8t', purging
2023-05-27 07:01:33,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ndf1ydr5', purging
2023-05-27 07:01:33,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j5e9xyge', purging
2023-05-27 07:01:33,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8my8k0f9', purging
2023-05-27 07:01:33,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:33,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:33,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:33,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:33,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:33,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:33,854 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:33,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:33,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:33,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:35,179 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:35,208 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:35,277 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:35,279 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:35,441 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:36,633 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bz7bsz55', purging
2023-05-27 07:01:36,633 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uyzv3g95', purging
2023-05-27 07:01:36,633 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wh1lu3pg', purging
2023-05-27 07:01:36,634 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l21no8e7', purging
2023-05-27 07:01:36,634 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8uu3z33a', purging
2023-05-27 07:01:36,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:36,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:36,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:36,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:36,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:36,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:36,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:36,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:36,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:36,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:38,135 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:38,161 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:38,189 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:38,212 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:38,401 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:39,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2yfpcc4e', purging
2023-05-27 07:01:39,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p2182t0b', purging
2023-05-27 07:01:39,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lmp262dp', purging
2023-05-27 07:01:39,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-td0o77go', purging
2023-05-27 07:01:39,497 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ci988ejd', purging
2023-05-27 07:01:39,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:39,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:39,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:39,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:39,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:39,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:39,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:39,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:39,810 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:39,810 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:40,963 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:41,013 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:41,036 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:41,064 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:41,225 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:42,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr2z_evr', purging
2023-05-27 07:01:42,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lpnk471i', purging
2023-05-27 07:01:42,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-esl3z__2', purging
2023-05-27 07:01:42,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3sy8hehs', purging
2023-05-27 07:01:42,430 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-80o4zrl2', purging
2023-05-27 07:01:42,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:42,430 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:42,451 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:42,452 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:42,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:42,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:42,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:42,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:42,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:42,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:43,947 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:43,985 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:44,000 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:44,036 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:44,188 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:45,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_63jpv5c', purging
2023-05-27 07:01:45,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4nc3ef6f', purging
2023-05-27 07:01:45,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yf7yy110', purging
2023-05-27 07:01:45,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-50k65530', purging
2023-05-27 07:01:45,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4qsrfonj', purging
2023-05-27 07:01:45,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:45,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:45,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:45,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:45,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:45,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:45,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:45,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:45,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:45,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:46,859 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:46,916 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:46,938 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:46,965 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:47,135 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:48,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kvaei3bn', purging
2023-05-27 07:01:48,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n09u5kt6', purging
2023-05-27 07:01:48,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1mi1ohdl', purging
2023-05-27 07:01:48,315 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vn094ji0', purging
2023-05-27 07:01:48,315 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qm6ff1vc', purging
2023-05-27 07:01:48,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:48,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:48,368 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:48,368 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:48,392 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:48,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:48,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:48,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:48,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:48,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:49,809 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:49,825 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:49,860 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:49,884 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:50,060 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:51,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iiqxxnud', purging
2023-05-27 07:01:51,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dnslemsv', purging
2023-05-27 07:01:51,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qbgw8c1o', purging
2023-05-27 07:01:51,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bnr0jcad', purging
2023-05-27 07:01:51,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_10mqz_l', purging
2023-05-27 07:01:51,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:51,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:51,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:51,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:51,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:51,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:51,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:51,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:51,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:51,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:52,739 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:52,768 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:52,790 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:52,812 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:52,988 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:54,154 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_9_cq6vn', purging
2023-05-27 07:01:54,154 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9h393696', purging
2023-05-27 07:01:54,154 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vxsnqr3l', purging
2023-05-27 07:01:54,155 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j3y2yyw1', purging
2023-05-27 07:01:54,155 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9a0ylm90', purging
2023-05-27 07:01:54,156 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:54,156 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:54,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:54,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:54,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:54,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:54,250 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:54,250 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:54,428 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:54,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:55,656 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:55,691 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:55,704 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:55,744 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:55,896 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:57,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i2wcevk4', purging
2023-05-27 07:01:57,105 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6777u4mp', purging
2023-05-27 07:01:57,105 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q56h75h7', purging
2023-05-27 07:01:57,105 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ysd_9ypn', purging
2023-05-27 07:01:57,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dinwqsx_', purging
2023-05-27 07:01:57,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:57,106 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:57,119 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:57,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:57,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:57,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:57,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:57,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:01:57,356 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:01:57,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:01:58,644 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:58,673 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:58,695 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:58,722 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:01:58,879 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:00,080 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rgyff7oj', purging
2023-05-27 07:02:00,080 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jeyvic2i', purging
2023-05-27 07:02:00,080 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-earegn_p', purging
2023-05-27 07:02:00,081 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-py6q3lgl', purging
2023-05-27 07:02:00,081 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p5hrewd1', purging
2023-05-27 07:02:00,082 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:00,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:00,115 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:00,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:00,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:00,116 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:00,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:00,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:00,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:00,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:01,564 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:01,617 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:01,656 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:01,666 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:01,821 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:02,934 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_banj1z_', purging
2023-05-27 07:02:02,935 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rbjlc4uc', purging
2023-05-27 07:02:02,935 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v697jnqa', purging
2023-05-27 07:02:02,936 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y6ualhqi', purging
2023-05-27 07:02:02,936 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hptnoped', purging
2023-05-27 07:02:02,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:02,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:03,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:03,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:03,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:03,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:03,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:03,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:03,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:03,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:04,386 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:04,425 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:04,454 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:04,482 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:04,665 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:05,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-scn28zei', purging
2023-05-27 07:02:05,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bq0domak', purging
2023-05-27 07:02:05,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1gncwbf2', purging
2023-05-27 07:02:05,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-294qnlt9', purging
2023-05-27 07:02:05,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z9vj0aq5', purging
2023-05-27 07:02:05,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:05,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:05,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:05,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:05,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:05,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:05,959 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:05,959 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:06,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:06,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:07,281 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:07,328 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:07,348 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:07,379 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:07,595 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:08,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q0png140', purging
2023-05-27 07:02:08,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1qnvq4_a', purging
2023-05-27 07:02:08,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-889uj32_', purging
2023-05-27 07:02:08,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-levoap9l', purging
2023-05-27 07:02:08,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pw1u4rk7', purging
2023-05-27 07:02:08,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:08,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:08,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:08,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:08,777 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:08,777 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:08,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:08,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:09,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:09,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:10,153 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:10,182 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:10,205 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:10,235 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:10,481 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:11,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f75vimug', purging
2023-05-27 07:02:11,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0uqagov6', purging
2023-05-27 07:02:11,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gq2kflm6', purging
2023-05-27 07:02:11,636 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_veyo6qp', purging
2023-05-27 07:02:11,636 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-med1buqh', purging
2023-05-27 07:02:11,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:11,637 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:11,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:11,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:11,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:11,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:11,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:11,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:11,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:11,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:13,108 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:13,153 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:13,182 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:13,201 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:13,355 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:14,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ik40qvjc', purging
2023-05-27 07:02:14,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jydgctzn', purging
2023-05-27 07:02:14,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_7iu_pzg', purging
2023-05-27 07:02:14,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1kqzuo3f', purging
2023-05-27 07:02:14,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7lj7kwa', purging
2023-05-27 07:02:14,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:14,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:14,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:14,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:14,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:14,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:14,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:14,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:14,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:14,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:16,060 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:16,095 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:16,126 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:16,155 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:16,327 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:17,511 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tgspe6qd', purging
2023-05-27 07:02:17,511 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kyyinrd6', purging
2023-05-27 07:02:17,511 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-879ou9ka', purging
2023-05-27 07:02:17,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jqhn0xdu', purging
2023-05-27 07:02:17,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mnrfevid', purging
2023-05-27 07:02:17,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:17,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:17,527 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:17,527 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:17,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:17,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:17,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:17,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:17,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:17,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:18,972 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:19,004 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:19,037 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:19,063 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:19,229 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:20,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gez8fdry', purging
2023-05-27 07:02:20,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-80xm52x6', purging
2023-05-27 07:02:20,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jxop1uxp', purging
2023-05-27 07:02:20,409 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6ttcn8xq', purging
2023-05-27 07:02:20,409 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y1bvumpc', purging
2023-05-27 07:02:20,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:20,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:20,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:20,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:20,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:20,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:20,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:20,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:20,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:20,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:21,916 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:21,968 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:21,994 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:22,018 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:22,195 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:23,279 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e4s1ga8t', purging
2023-05-27 07:02:23,279 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r31_a7xr', purging
2023-05-27 07:02:23,280 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a5ntoj16', purging
2023-05-27 07:02:23,280 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5ncjersh', purging
2023-05-27 07:02:23,280 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dqkqe5_b', purging
2023-05-27 07:02:23,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:23,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:23,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:23,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:23,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:23,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:23,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:23,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:23,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:23,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:24,755 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:24,807 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:24,839 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:24,859 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:25,082 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:26,193 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vdv_fri5', purging
2023-05-27 07:02:26,193 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nz90zai_', purging
2023-05-27 07:02:26,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-28m3h0wz', purging
2023-05-27 07:02:26,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-43pwj6ru', purging
2023-05-27 07:02:26,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t98fvjii', purging
2023-05-27 07:02:26,195 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:26,195 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:26,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:26,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:26,276 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:26,276 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:26,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:26,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:26,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:26,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:27,713 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:27,733 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:27,777 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:27,800 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 07:02:29,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ch2csrsl', purging
2023-05-27 07:02:29,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kbth7bhy', purging
2023-05-27 07:02:29,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yggb_sgy', purging
2023-05-27 07:02:29,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3kiqyz5z', purging
2023-05-27 07:02:29,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n1kga8g8', purging
2023-05-27 07:02:29,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:29,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:29,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:29,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:29,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:29,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:29,258 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:29,258 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:30,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:30,438 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:30,464 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:30,634 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:31,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cb9s7cb6', purging
2023-05-27 07:02:31,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-41aiu339', purging
2023-05-27 07:02:31,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-um1tpd6f', purging
2023-05-27 07:02:31,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r3jtq2bi', purging
2023-05-27 07:02:31,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:31,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:31,841 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:31,841 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:31,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:31,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:32,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:32,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:33,036 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:33,080 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:33,109 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:33,279 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:34,411 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qzmofuda', purging
2023-05-27 07:02:34,412 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vvkr7c_s', purging
2023-05-27 07:02:34,412 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-__u93utt', purging
2023-05-27 07:02:34,412 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nceytzby', purging
2023-05-27 07:02:34,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:34,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:34,468 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:34,468 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:34,491 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:34,491 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:34,691 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:34,691 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:35,653 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:35,687 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:35,721 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:35,877 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:37,050 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4r3vartl', purging
2023-05-27 07:02:37,050 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-51624dkd', purging
2023-05-27 07:02:37,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dlq_l8qj', purging
2023-05-27 07:02:37,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1bkrzclx', purging
2023-05-27 07:02:37,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:37,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:37,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:37,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:37,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:37,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:37,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:37,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:38,316 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:38,343 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:38,362 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:38,545 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:39,717 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i7ghosln', purging
2023-05-27 07:02:39,717 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y5qxpbgx', purging
2023-05-27 07:02:39,718 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2_77_nnx', purging
2023-05-27 07:02:39,718 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sfea0csm', purging
2023-05-27 07:02:39,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:39,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:39,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:39,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:39,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:39,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:39,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:39,946 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:41,023 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:41,069 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:41,109 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:41,264 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:42,412 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m6vw2sdi', purging
2023-05-27 07:02:42,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0tmlvcpa', purging
2023-05-27 07:02:42,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4yvbzp1m', purging
2023-05-27 07:02:42,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n5kavt2y', purging
2023-05-27 07:02:42,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:42,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:42,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:42,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:42,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:42,506 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:42,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:42,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:43,660 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:43,687 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:43,710 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:43,887 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:45,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lae4a6u2', purging
2023-05-27 07:02:45,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l14cklix', purging
2023-05-27 07:02:45,036 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w7dlm92_', purging
2023-05-27 07:02:45,036 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4x7zk2pa', purging
2023-05-27 07:02:45,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:45,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:45,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:45,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:45,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:45,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:45,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:45,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:46,280 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:46,325 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:46,351 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:46,505 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:47,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iwgd0_9e', purging
2023-05-27 07:02:47,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x_dzujs9', purging
2023-05-27 07:02:47,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zlh28jb5', purging
2023-05-27 07:02:47,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kq60tv79', purging
2023-05-27 07:02:47,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:47,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:47,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:47,731 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:47,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:47,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:47,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:47,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:48,875 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:48,906 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:48,931 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:49,096 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:50,258 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cc06rhjv', purging
2023-05-27 07:02:50,258 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ihem48n', purging
2023-05-27 07:02:50,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ovj0wpg', purging
2023-05-27 07:02:50,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-favw7rjb', purging
2023-05-27 07:02:50,259 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:50,259 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:50,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:50,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:50,309 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:50,309 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:50,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:50,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:51,514 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:51,550 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:51,568 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 07:02:52,907 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gmrgi8u0', purging
2023-05-27 07:02:52,907 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6d2j575z', purging
2023-05-27 07:02:52,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-02fkp2ge', purging
2023-05-27 07:02:52,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-62i3d9y2', purging
2023-05-27 07:02:52,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:52,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:52,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:52,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:52,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:52,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:53,970 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:53,994 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:54,162 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:55,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a7ex6uxh', purging
2023-05-27 07:02:55,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9zhrqpd2', purging
2023-05-27 07:02:55,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4pcotuh1', purging
2023-05-27 07:02:55,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:55,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:55,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:55,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:55,529 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:55,529 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 07:02:56,527 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:56,596 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:57,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n4f_a3r8', purging
2023-05-27 07:02:57,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bhfhs36b', purging
2023-05-27 07:02:57,920 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zp_qws37', purging
2023-05-27 07:02:57,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:57,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:02:57,930 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:02:57,930 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:02:58,745 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:02:58,909 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:00,082 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ekbhappl', purging
2023-05-27 07:03:00,082 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4jw9wnyc', purging
2023-05-27 07:03:00,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:00,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:00,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:00,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:00,916 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:01,088 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:02,300 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-met5_svp', purging
2023-05-27 07:03:02,301 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pmd1amy1', purging
2023-05-27 07:03:02,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:02,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:02,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:02,453 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:03,140 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:03,314 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:04,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4k14dkyj', purging
2023-05-27 07:03:04,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sk98yur4', purging
2023-05-27 07:03:04,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:04,479 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:04,648 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:04,648 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:05,304 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:05,471 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:06,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0_scr1mg', purging
2023-05-27 07:03:06,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-neiolber', purging
2023-05-27 07:03:06,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:06,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:06,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:06,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:07,508 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:07,671 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:08,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-47lk7jj1', purging
2023-05-27 07:03:08,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gvfv_9vc', purging
2023-05-27 07:03:08,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:08,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:09,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:09,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:09,705 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:09,871 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:11,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_rxdfyqj', purging
2023-05-27 07:03:11,085 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zlych2du', purging
2023-05-27 07:03:11,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:11,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:11,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:11,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:11,916 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:12,078 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:13,252 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_rak4nk_', purging
2023-05-27 07:03:13,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2kbkcx7b', purging
2023-05-27 07:03:13,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:13,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:13,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:13,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:14,076 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:14,243 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:15,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2i54vvlv', purging
2023-05-27 07:03:15,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_484gqni', purging
2023-05-27 07:03:15,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:15,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:15,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:15,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:16,251 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:16,415 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:17,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-foi_psl4', purging
2023-05-27 07:03:17,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s3jtn7j_', purging
2023-05-27 07:03:17,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:17,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:17,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:17,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:18,420 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:18,591 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:19,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dt0kp8j6', purging
2023-05-27 07:03:19,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oaj5qwzv', purging
2023-05-27 07:03:19,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:19,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:19,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:19,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:20,577 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:20,750 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:21,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xfmydqbq', purging
2023-05-27 07:03:21,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ny2m49kb', purging
2023-05-27 07:03:21,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:21,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:22,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:22,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:22,802 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:22,967 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:24,175 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yarogpkl', purging
2023-05-27 07:03:24,175 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z82ku553', purging
2023-05-27 07:03:24,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:24,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:24,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:24,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:25,007 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:25,180 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:26,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hv3tj4bv', purging
2023-05-27 07:03:26,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k61zihzb', purging
2023-05-27 07:03:26,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:26,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:26,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:26,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:27,179 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:27,343 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:28,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jqhismbp', purging
2023-05-27 07:03:28,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kopt0g_y', purging
2023-05-27 07:03:28,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:28,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:28,700 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:28,700 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:29,407 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:29,577 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:30,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qntht6ib', purging
2023-05-27 07:03:30,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x85p3yf3', purging
2023-05-27 07:03:30,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:30,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:30,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:30,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:31,618 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:31,802 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:32,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wb8w_07e', purging
2023-05-27 07:03:32,984 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n50ply6v', purging
2023-05-27 07:03:32,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:32,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:33,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:33,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:33,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:33,985 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:35,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l1vrbmwk', purging
2023-05-27 07:03:35,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s3d9_9jk', purging
2023-05-27 07:03:35,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:35,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:35,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:35,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:36,017 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:36,191 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:37,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5okc9z31', purging
2023-05-27 07:03:37,366 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yvjmxjjw', purging
2023-05-27 07:03:37,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:37,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:37,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:37,509 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:38,175 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:38,340 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:39,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_fx1woio', purging
2023-05-27 07:03:39,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7jm7l9e7', purging
2023-05-27 07:03:39,515 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:39,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:39,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:39,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:40,332 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:40,500 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:41,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e00yyls5', purging
2023-05-27 07:03:41,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l5e7ehzv', purging
2023-05-27 07:03:41,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:41,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:41,854 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:41,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:42,506 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:42,680 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:43,854 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xn3yojrp', purging
2023-05-27 07:03:43,855 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-erkjdne4', purging
2023-05-27 07:03:43,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:43,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:44,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:44,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:44,680 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:44,846 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:46,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-177gogjk', purging
2023-05-27 07:03:46,032 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z1g6ykqz', purging
2023-05-27 07:03:46,032 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:46,032 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:46,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:46,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:46,853 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:47,015 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:48,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-477a3gfx', purging
2023-05-27 07:03:48,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rhuz2121', purging
2023-05-27 07:03:48,195 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:48,195 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:48,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:48,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:49,021 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:49,184 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:50,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kmf8zk1k', purging
2023-05-27 07:03:50,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mu7kuw5m', purging
2023-05-27 07:03:50,356 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:50,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:50,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:50,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:51,177 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:51,351 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:52,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g37p_by8', purging
2023-05-27 07:03:52,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5w9myjn2', purging
2023-05-27 07:03:52,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:52,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:52,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:52,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:53,325 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:53,505 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:54,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yro6a5od', purging
2023-05-27 07:03:54,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bzb1vee6', purging
2023-05-27 07:03:54,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:54,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:54,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:54,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:55,500 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:55,671 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:56,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j07ktfav', purging
2023-05-27 07:03:56,813 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z5ves0yh', purging
2023-05-27 07:03:56,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:56,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:57,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:57,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:57,628 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:57,795 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:03:58,996 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o6nuiah0', purging
2023-05-27 07:03:58,997 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ocjzo4w', purging
2023-05-27 07:03:58,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:58,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:03:59,137 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:03:59,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:03:59,839 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:00,009 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:01,149 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9kks5mq_', purging
2023-05-27 07:04:01,149 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tuua01ty', purging
2023-05-27 07:04:01,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:01,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:01,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:01,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:01,971 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:02,128 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:03,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2wdl8ktq', purging
2023-05-27 07:04:03,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a3z8_nbu', purging
2023-05-27 07:04:03,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:03,320 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:03,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:03,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:04,160 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:04,334 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:05,547 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ys0_yfeo', purging
2023-05-27 07:04:05,547 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-co_la226', purging
2023-05-27 07:04:05,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:05,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:05,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:05,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:06,403 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:06,581 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:07,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-08bs9jfh', purging
2023-05-27 07:04:07,783 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9jpjx74c', purging
2023-05-27 07:04:07,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:07,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:07,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:07,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:08,603 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:08,772 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:09,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1q6orifp', purging
2023-05-27 07:04:09,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tge1uxw1', purging
2023-05-27 07:04:09,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:09,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:10,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:10,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:10,779 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:10,940 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:12,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1qucfkgt', purging
2023-05-27 07:04:12,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b0gri_3i', purging
2023-05-27 07:04:12,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:12,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:12,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:12,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:12,943 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:13,116 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:14,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pkb9yg_5', purging
2023-05-27 07:04:14,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gqobv2gn', purging
2023-05-27 07:04:14,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:14,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:14,437 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:14,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:15,127 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:15,295 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:16,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g1tq7o3o', purging
2023-05-27 07:04:16,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nifvm315', purging
2023-05-27 07:04:16,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:16,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:16,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:16,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:17,317 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:17,484 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:18,666 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wjuptkv6', purging
2023-05-27 07:04:18,666 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bifxz0ns', purging
2023-05-27 07:04:18,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:18,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:18,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:18,794 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:19,490 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:19,653 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:20,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h44nhwk2', purging
2023-05-27 07:04:20,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t389hy2q', purging
2023-05-27 07:04:20,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:20,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:21,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:21,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:21,699 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:21,867 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:23,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4t8aldux', purging
2023-05-27 07:04:23,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5sazkobh', purging
2023-05-27 07:04:23,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:23,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:23,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:23,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:23,873 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:24,040 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:25,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dbxt8j1_', purging
2023-05-27 07:04:25,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oo6id_zr', purging
2023-05-27 07:04:25,228 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:25,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:25,389 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:25,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:26,057 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:26,230 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:27,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ss1ps_mo', purging
2023-05-27 07:04:27,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jesdh7qc', purging
2023-05-27 07:04:27,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:27,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:27,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:27,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:28,228 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:28,403 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:29,577 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-texog_7q', purging
2023-05-27 07:04:29,577 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-waeqxx4g', purging
2023-05-27 07:04:29,577 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:29,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:29,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:29,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:30,424 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:30,586 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:31,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0itk2bid', purging
2023-05-27 07:04:31,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rp52tb76', purging
2023-05-27 07:04:31,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:31,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:31,907 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:31,907 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:32,689 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:32,860 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:34,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tloq0o5e', purging
2023-05-27 07:04:34,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5r3g0g57', purging
2023-05-27 07:04:34,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:34,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:34,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:34,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:34,873 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:35,046 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:36,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3mw59mb1', purging
2023-05-27 07:04:36,230 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jhv5zfa2', purging
2023-05-27 07:04:36,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:36,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:36,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:36,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:37,084 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:37,241 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:38,412 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nwpwna9g', purging
2023-05-27 07:04:38,412 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3zsid6xn', purging
2023-05-27 07:04:38,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:38,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:38,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:38,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:39,245 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:39,417 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:40,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1g3rh68i', purging
2023-05-27 07:04:40,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j8bh1r7_', purging
2023-05-27 07:04:40,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:40,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:40,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:40,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:41,399 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:41,573 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:42,762 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-76goxh_7', purging
2023-05-27 07:04:42,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9f48eb41', purging
2023-05-27 07:04:42,763 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:42,763 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:42,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:42,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:43,608 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:43,774 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:44,973 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9lyu1w52', purging
2023-05-27 07:04:44,973 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qmpzmmxi', purging
2023-05-27 07:04:44,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:44,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:45,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:45,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:45,798 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:45,953 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:47,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g04qwuev', purging
2023-05-27 07:04:47,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0rt5r8l', purging
2023-05-27 07:04:47,151 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:47,151 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:47,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:47,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:47,980 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:48,143 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:49,309 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aymyudth', purging
2023-05-27 07:04:49,309 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wkuq1jr1', purging
2023-05-27 07:04:49,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:49,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:49,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:49,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:50,148 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:50,309 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:51,500 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s6suu7a4', purging
2023-05-27 07:04:51,500 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sz4_7ooj', purging
2023-05-27 07:04:51,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:51,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:51,649 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:51,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:52,336 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:52,507 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:53,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-645pzq4u', purging
2023-05-27 07:04:53,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-74o2gace', purging
2023-05-27 07:04:53,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:53,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:53,829 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:53,829 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:54,540 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:54,717 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:55,871 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6r7bfmni', purging
2023-05-27 07:04:55,871 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cyyoray3', purging
2023-05-27 07:04:55,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:55,872 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:56,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:56,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:56,696 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:56,865 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:58,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qs_8mspv', purging
2023-05-27 07:04:58,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1w42ig20', purging
2023-05-27 07:04:58,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:58,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:04:58,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:04:58,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:04:58,908 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:04:59,076 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:00,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zc_z6gg0', purging
2023-05-27 07:05:00,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z48o86o1', purging
2023-05-27 07:05:00,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:00,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:00,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:00,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:01,140 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:01,309 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:02,509 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yydzde1e', purging
2023-05-27 07:05:02,510 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d5n_ja07', purging
2023-05-27 07:05:02,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:02,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:02,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:02,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:03,353 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:03,517 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:04,728 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l3m2p23t', purging
2023-05-27 07:05:04,728 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t7cq3ul1', purging
2023-05-27 07:05:04,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:04,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:04,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:04,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:05,565 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:05,743 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:06,934 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pcsv8mpv', purging
2023-05-27 07:05:06,934 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xarui8d8', purging
2023-05-27 07:05:06,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:06,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:07,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:07,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:07,778 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:07,943 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:09,177 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lh5ufklh', purging
2023-05-27 07:05:09,177 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zfzul4ye', purging
2023-05-27 07:05:09,178 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:09,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:09,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:09,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:10,019 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:10,200 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:11,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w8xll085', purging
2023-05-27 07:05:11,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fu51bywd', purging
2023-05-27 07:05:11,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:11,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:11,540 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:11,541 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:12,213 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:12,376 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:13,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n6rxnuyq', purging
2023-05-27 07:05:13,564 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r51obo2t', purging
2023-05-27 07:05:13,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:13,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:13,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:13,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:14,397 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:14,563 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:15,756 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yp9bavo3', purging
2023-05-27 07:05:15,756 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-csq9kk2s', purging
2023-05-27 07:05:15,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:15,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:15,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:15,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:16,587 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:16,749 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:17,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yu6u96h5', purging
2023-05-27 07:05:17,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ibiv5eje', purging
2023-05-27 07:05:17,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:17,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:18,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:18,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:18,805 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:18,980 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:20,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-up3spheh', purging
2023-05-27 07:05:20,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g9z8blvb', purging
2023-05-27 07:05:20,169 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:20,169 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:20,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:20,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:20,986 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:21,152 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:22,341 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qpbqp9vh', purging
2023-05-27 07:05:22,341 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ektpn056', purging
2023-05-27 07:05:22,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:22,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:22,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:22,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:23,167 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:23,339 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:24,561 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l2icxj0h', purging
2023-05-27 07:05:24,561 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_n2zj_wi', purging
2023-05-27 07:05:24,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:24,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:24,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:24,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:25,399 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:25,578 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:26,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5262blzp', purging
2023-05-27 07:05:26,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1qbwavmo', purging
2023-05-27 07:05:26,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:26,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 07:05:26,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:26,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 07:05:27,758 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:29,081 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wiyt2x5e', purging
2023-05-27 07:05:29,081 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uviv50bi', purging
2023-05-27 07:05:29,082 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:29,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:29,855 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:31,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1692482o', purging
2023-05-27 07:05:31,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:31,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:31,952 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:33,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hruj1wui', purging
2023-05-27 07:05:33,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:33,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:34,050 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:35,376 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hu1f5xqf', purging
2023-05-27 07:05:35,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:35,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:36,161 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:37,491 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_x8kqthl', purging
2023-05-27 07:05:37,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:37,492 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:38,276 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:39,583 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z22hq4_z', purging
2023-05-27 07:05:39,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:39,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:40,349 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:41,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r7t2xhrc', purging
2023-05-27 07:05:41,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:41,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:42,439 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:43,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nke_42ic', purging
2023-05-27 07:05:43,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:43,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:44,500 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:45,802 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2sf97use', purging
2023-05-27 07:05:45,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:45,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:46,567 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:47,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8_cff8g_', purging
2023-05-27 07:05:47,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:47,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:48,644 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:49,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d03qnsjf', purging
2023-05-27 07:05:49,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:49,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:50,711 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:52,014 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ovg8qr_l', purging
2023-05-27 07:05:52,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:52,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:52,791 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:54,088 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_94kovdt', purging
2023-05-27 07:05:54,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:54,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:54,850 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:56,146 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z46owch2', purging
2023-05-27 07:05:56,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:56,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:56,905 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:05:58,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7qssa14h', purging
2023-05-27 07:05:58,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:05:58,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:05:58,981 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:00,291 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-__ynufec', purging
2023-05-27 07:06:00,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:00,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:01,052 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:02,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yn5v9lm_', purging
2023-05-27 07:06:02,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:02,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:03,110 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:04,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xu3f72i6', purging
2023-05-27 07:06:04,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:04,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:05,174 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:06,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nwvg4jnv', purging
2023-05-27 07:06:06,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:06,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:07,239 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:08,532 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dx2ooli8', purging
2023-05-27 07:06:08,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:08,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:09,293 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:10,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-31nrlh0f', purging
2023-05-27 07:06:10,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:10,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:11,358 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:12,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t0ild3tr', purging
2023-05-27 07:06:12,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:12,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:13,431 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:14,740 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u0fdpfvi', purging
2023-05-27 07:06:14,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:14,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:15,504 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:16,804 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kcbzs_xv', purging
2023-05-27 07:06:16,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:16,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:17,569 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:18,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gp9triaf', purging
2023-05-27 07:06:18,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:18,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:19,622 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:20,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kwbu03e3', purging
2023-05-27 07:06:20,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:20,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:21,690 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:22,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rha3yexi', purging
2023-05-27 07:06:22,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:22,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:23,752 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:25,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zqq_1khy', purging
2023-05-27 07:06:25,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:25,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:25,814 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:27,109 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vfs3lbf7', purging
2023-05-27 07:06:27,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:27,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:27,881 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:29,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dhfcpxvu', purging
2023-05-27 07:06:29,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:29,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:30,004 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:31,308 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rfu95bfv', purging
2023-05-27 07:06:31,308 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:31,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:32,076 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:33,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-th06tp86', purging
2023-05-27 07:06:33,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:33,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:34,160 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:35,457 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ns9uhnh', purging
2023-05-27 07:06:35,458 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:35,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:36,224 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:37,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cgo45vua', purging
2023-05-27 07:06:37,515 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:37,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:38,279 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:39,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7rj98sn2', purging
2023-05-27 07:06:39,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:39,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:40,348 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:41,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ujprepq7', purging
2023-05-27 07:06:41,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:41,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:42,416 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:43,725 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8yee6ox2', purging
2023-05-27 07:06:43,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:43,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:44,495 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:45,809 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0z37ng41', purging
2023-05-27 07:06:45,810 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:45,810 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:46,575 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:47,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-awnzr8cq', purging
2023-05-27 07:06:47,869 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:47,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:48,631 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:49,926 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wbxvix6v', purging
2023-05-27 07:06:49,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:49,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:50,691 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:52,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bv6v_qor', purging
2023-05-27 07:06:52,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:52,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:52,768 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:54,062 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ns4f_lm_', purging
2023-05-27 07:06:54,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:54,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:54,823 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:56,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ec4ebhhj', purging
2023-05-27 07:06:56,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:56,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:56,905 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:06:58,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nke40fc_', purging
2023-05-27 07:06:58,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:06:58,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:06:58,981 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:00,279 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-igsthx6a', purging
2023-05-27 07:07:00,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:00,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:01,048 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:02,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xjipt0oo', purging
2023-05-27 07:07:02,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:02,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:03,122 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:04,434 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7gg_8ng8', purging
2023-05-27 07:07:04,434 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:04,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:05,201 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:06,505 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yypxmili', purging
2023-05-27 07:07:06,506 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:06,506 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:07,278 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:08,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tg7quf5n', purging
2023-05-27 07:07:08,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:08,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:09,365 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:10,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rssx13i0', purging
2023-05-27 07:07:10,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:10,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:11,441 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:12,745 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_eco6trv', purging
2023-05-27 07:07:12,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:12,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:13,504 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:14,807 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tc3q1gi1', purging
2023-05-27 07:07:14,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:14,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:15,569 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:16,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1sw5t8f_', purging
2023-05-27 07:07:16,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:16,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:17,628 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:18,928 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xt28lxl0', purging
2023-05-27 07:07:18,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:18,929 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:19,698 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:20,992 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6z1do8le', purging
2023-05-27 07:07:20,993 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:20,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:21,759 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:23,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dls0obue', purging
2023-05-27 07:07:23,068 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:23,068 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:23,832 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:25,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iwnipvpg', purging
2023-05-27 07:07:25,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:25,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:25,900 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:27,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6yw3d3ia', purging
2023-05-27 07:07:27,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:27,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:27,968 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:29,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2z7jo5wf', purging
2023-05-27 07:07:29,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:29,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:30,035 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:31,329 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-raes6s_a', purging
2023-05-27 07:07:31,330 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:31,330 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:32,104 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:33,407 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0s8ayj0p', purging
2023-05-27 07:07:33,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:33,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:34,173 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:35,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3n6uz0i4', purging
2023-05-27 07:07:35,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:35,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:36,244 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:37,554 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mt5z55si', purging
2023-05-27 07:07:37,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:37,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:38,320 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:39,621 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r7l4yw_h', purging
2023-05-27 07:07:39,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:39,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:40,384 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:41,680 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ga09v7e7', purging
2023-05-27 07:07:41,680 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:41,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:42,449 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:43,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-36lhsgd2', purging
2023-05-27 07:07:43,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:43,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:44,513 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:45,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e8d8t_f8', purging
2023-05-27 07:07:45,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:45,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:46,578 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:47,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-flwgqgul', purging
2023-05-27 07:07:47,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:47,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:48,650 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:49,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-asez9kyr', purging
2023-05-27 07:07:49,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:49,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:50,718 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:52,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-25ehgw4s', purging
2023-05-27 07:07:52,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:52,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:52,790 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:54,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0j9mh56k', purging
2023-05-27 07:07:54,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:54,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:54,865 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:56,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3806pn36', purging
2023-05-27 07:07:56,159 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:56,159 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:56,920 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:07:58,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-umu3m361', purging
2023-05-27 07:07:58,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:07:58,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:07:58,997 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:00,312 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-itbykqt6', purging
2023-05-27 07:08:00,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:00,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:01,075 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:02,366 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr2dbmdy', purging
2023-05-27 07:08:02,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:02,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:03,130 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:04,434 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-72u0sq7c', purging
2023-05-27 07:08:04,434 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:04,434 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:05,215 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:06,525 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v1707ldg', purging
2023-05-27 07:08:06,526 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:06,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:07,286 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:08,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-33yc22y1', purging
2023-05-27 07:08:08,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:08,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:09,356 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:10,653 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mk1testv', purging
2023-05-27 07:08:10,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:10,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:11,438 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:12,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wh9_2kb7', purging
2023-05-27 07:08:12,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:12,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:13,502 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:14,797 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6ablt9ug', purging
2023-05-27 07:08:14,797 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:14,797 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:15,560 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:16,862 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ippj4_4', purging
2023-05-27 07:08:16,863 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:16,863 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:17,626 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:18,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wiupmvs6', purging
2023-05-27 07:08:18,930 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:18,930 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:19,692 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:21,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wlwpqyu9', purging
2023-05-27 07:08:21,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:21,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:21,775 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:23,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j0aemo_g', purging
2023-05-27 07:08:23,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:23,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:23,839 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:25,147 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eq295cid', purging
2023-05-27 07:08:25,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:25,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:25,909 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:27,217 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7b1adpj', purging
2023-05-27 07:08:27,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:27,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:27,984 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:29,278 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t6pe2vsk', purging
2023-05-27 07:08:29,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:29,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:30,044 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:31,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-itz6v624', purging
2023-05-27 07:08:31,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:31,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:32,093 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:33,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7i38jx38', purging
2023-05-27 07:08:33,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:33,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:34,144 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:35,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yao1n32c', purging
2023-05-27 07:08:35,440 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:35,440 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:36,210 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:37,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wxn6oc8u', purging
2023-05-27 07:08:37,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:37,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:38,278 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:39,569 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0fds690e', purging
2023-05-27 07:08:39,569 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:39,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:40,329 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:41,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-arzzjtf5', purging
2023-05-27 07:08:41,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:41,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:42,398 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:43,698 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-czfksztj', purging
2023-05-27 07:08:43,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:43,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:44,459 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:45,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yz5vb1fa', purging
2023-05-27 07:08:45,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:45,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:46,519 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:47,825 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-68zg2q90', purging
2023-05-27 07:08:47,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:47,826 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:48,596 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:49,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ge16yary', purging
2023-05-27 07:08:49,903 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:49,903 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:50,672 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:51,977 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-joaj9ty9', purging
2023-05-27 07:08:51,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:51,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:52,744 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:54,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yypjynoj', purging
2023-05-27 07:08:54,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:54,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:54,818 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:56,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qdmq5a2r', purging
2023-05-27 07:08:56,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:56,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:56,884 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:08:58,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o0ugwosk', purging
2023-05-27 07:08:58,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:08:58,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:08:58,953 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:00,277 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4wikj3h9', purging
2023-05-27 07:09:00,278 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:00,278 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:01,042 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:02,340 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-52ze8b_1', purging
2023-05-27 07:09:02,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:02,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:03,104 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:04,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ybhvlzy', purging
2023-05-27 07:09:04,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:04,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:05,177 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:06,480 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f9trjaao', purging
2023-05-27 07:09:06,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:06,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:07,254 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:08,570 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c5uz_qhq', purging
2023-05-27 07:09:08,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:08,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:09,342 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:10,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ss3m5w_3', purging
2023-05-27 07:09:10,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:10,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:11,408 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:12,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ioxuyq8t', purging
2023-05-27 07:09:12,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:12,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:13,493 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:14,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t_aqfc4d', purging
2023-05-27 07:09:14,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:14,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:15,568 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:16,880 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-thlish2g', purging
2023-05-27 07:09:16,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:16,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:17,642 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:18,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lvey7f6d', purging
2023-05-27 07:09:18,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:18,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:19,715 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:21,017 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f7agg3sr', purging
2023-05-27 07:09:21,018 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:21,018 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:21,778 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:23,083 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6k6pyf7c', purging
2023-05-27 07:09:23,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:23,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:23,846 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:25,156 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vkg2_t5k', purging
2023-05-27 07:09:25,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:25,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:25,926 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:27,245 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-94z3g_a3', purging
2023-05-27 07:09:27,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:27,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:28,008 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:29,307 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wr8cq6ot', purging
2023-05-27 07:09:29,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:29,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:30,081 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:31,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uh99e3a6', purging
2023-05-27 07:09:31,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:31,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:32,161 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:33,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qt0ndcmg', purging
2023-05-27 07:09:33,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:33,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:34,240 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:35,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xdnmcw9j', purging
2023-05-27 07:09:35,537 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:35,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:36,310 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:37,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k6u9girf', purging
2023-05-27 07:09:37,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:37,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:38,371 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:39,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vy5d96mg', purging
2023-05-27 07:09:39,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:39,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:40,445 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:41,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-647nq_7w', purging
2023-05-27 07:09:41,742 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:41,742 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:42,519 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:43,820 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ww7caec', purging
2023-05-27 07:09:43,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:43,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:44,589 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:45,887 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7lbkw08h', purging
2023-05-27 07:09:45,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:45,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:46,647 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:47,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h8feaq9b', purging
2023-05-27 07:09:47,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:47,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:48,709 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:50,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0_p8tef8', purging
2023-05-27 07:09:50,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:50,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:50,773 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:52,071 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b15yi30c', purging
2023-05-27 07:09:52,072 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:52,072 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:52,843 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:54,149 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4bdf1hhh', purging
2023-05-27 07:09:54,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:54,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:54,924 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:56,235 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8u52c36s', purging
2023-05-27 07:09:56,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:56,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:57,001 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:09:58,309 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fka7siex', purging
2023-05-27 07:09:58,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:09:58,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:09:59,082 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:00,411 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jz3fxq3t', purging
2023-05-27 07:10:00,411 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:00,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:01,196 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:02,506 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hhy5bk6c', purging
2023-05-27 07:10:02,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:02,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:03,276 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:04,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dx_hb7at', purging
2023-05-27 07:10:04,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:04,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:05,346 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:06,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zm95uvf5', purging
2023-05-27 07:10:06,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:06,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:07,422 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:08,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2m1fbfu', purging
2023-05-27 07:10:08,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:08,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:09,498 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:10,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-61t_j4xd', purging
2023-05-27 07:10:10,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:10,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:11,577 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:12,880 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gohjnba6', purging
2023-05-27 07:10:12,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:12,881 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:13,647 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:14,945 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iqcbc9tc', purging
2023-05-27 07:10:14,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:14,946 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:15,715 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:17,015 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ch8eaxwr', purging
2023-05-27 07:10:17,016 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:17,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:17,788 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:19,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j3c_plc5', purging
2023-05-27 07:10:19,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:19,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:19,866 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:21,164 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i2ft7n2u', purging
2023-05-27 07:10:21,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:21,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:21,927 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:23,240 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9yw4zs67', purging
2023-05-27 07:10:23,241 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:23,241 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:24,007 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:25,330 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-db7s_6r4', purging
2023-05-27 07:10:25,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:25,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:26,094 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:27,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oswjvx3g', purging
2023-05-27 07:10:27,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:27,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:28,169 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:29,483 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mha58zz7', purging
2023-05-27 07:10:29,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:29,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:30,263 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:31,590 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2qewvxbw', purging
2023-05-27 07:10:31,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:31,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:32,363 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:33,676 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nhwwhl5l', purging
2023-05-27 07:10:33,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:33,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:34,446 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:35,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tqqgfqit', purging
2023-05-27 07:10:35,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:35,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:36,528 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:37,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5sw280m', purging
2023-05-27 07:10:37,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:37,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:38,606 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:39,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ydt905v', purging
2023-05-27 07:10:39,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:39,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:40,687 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:41,996 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lnr1gozr', purging
2023-05-27 07:10:41,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:41,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:42,776 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:44,082 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4befug_n', purging
2023-05-27 07:10:44,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:44,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:44,848 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:46,156 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8h9nczcp', purging
2023-05-27 07:10:46,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:46,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:46,918 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:48,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rrucigsc', purging
2023-05-27 07:10:48,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:48,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:48,998 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:50,315 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o_aa1rk4', purging
2023-05-27 07:10:50,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:50,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:51,079 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:52,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cl9yq_z', purging
2023-05-27 07:10:52,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:52,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:53,160 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:54,469 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6mengpou', purging
2023-05-27 07:10:54,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:54,470 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:55,235 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:56,547 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7jbv0gn5', purging
2023-05-27 07:10:56,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:56,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:57,325 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:10:58,640 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oebbxl81', purging
2023-05-27 07:10:58,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:10:58,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:10:59,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:00,720 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lxxz9d87', purging
2023-05-27 07:11:00,721 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:00,721 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:01,502 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:02,805 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rmz6cril', purging
2023-05-27 07:11:02,805 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:02,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:03,573 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:04,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-icip_62f', purging
2023-05-27 07:11:04,869 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:04,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:05,652 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:06,968 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wwxlzi3u', purging
2023-05-27 07:11:06,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:06,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:07,737 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:09,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ny1kknyt', purging
2023-05-27 07:11:09,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:09,052 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:09,813 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:11,118 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9aa2hvly', purging
2023-05-27 07:11:11,119 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:11,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:11,894 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:13,209 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7unobe2x', purging
2023-05-27 07:11:13,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:13,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:13,980 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:15,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r3jpba81', purging
2023-05-27 07:11:15,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:15,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:16,061 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:17,362 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9f34zzhl', purging
2023-05-27 07:11:17,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:17,362 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:18,129 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:19,431 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2oriy56q', purging
2023-05-27 07:11:19,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:19,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:20,202 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:21,501 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d1qtmn0p', purging
2023-05-27 07:11:21,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:21,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:22,266 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:23,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oipc3jqv', purging
2023-05-27 07:11:23,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:23,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:24,335 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:25,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jsuzv01z', purging
2023-05-27 07:11:25,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:25,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:26,413 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:27,724 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wa8tqexf', purging
2023-05-27 07:11:27,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:27,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:28,494 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:29,823 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-di8f2ihb', purging
2023-05-27 07:11:29,824 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:29,824 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:30,599 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:31,916 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-62ky5z1v', purging
2023-05-27 07:11:31,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:31,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:32,680 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:33,994 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tsupbv2h', purging
2023-05-27 07:11:33,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:33,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:34,770 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:36,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-09wypfkr', purging
2023-05-27 07:11:36,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:36,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:36,850 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:38,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sjdr4gdv', purging
2023-05-27 07:11:38,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:38,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:38,941 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:40,240 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eda_czvb', purging
2023-05-27 07:11:40,241 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:40,241 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:41,005 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:42,311 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ywhzbega', purging
2023-05-27 07:11:42,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:42,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:43,079 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:44,404 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2yjh02eh', purging
2023-05-27 07:11:44,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:44,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:45,179 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:46,493 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n6a_crmk', purging
2023-05-27 07:11:46,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:46,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:47,257 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:48,556 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-58oau_5d', purging
2023-05-27 07:11:48,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:48,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:49,321 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:50,623 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dnch_2vt', purging
2023-05-27 07:11:50,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:50,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:51,396 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:52,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wgk59sco', purging
2023-05-27 07:11:52,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:52,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:53,471 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:54,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v8hpnxe_', purging
2023-05-27 07:11:54,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:54,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:55,557 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:56,864 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7_pr_4l5', purging
2023-05-27 07:11:56,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:56,865 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:57,630 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:11:58,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fyh2fugz', purging
2023-05-27 07:11:58,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:11:58,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:11:59,712 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:01,014 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2vaj1tyc', purging
2023-05-27 07:12:01,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:01,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:01,800 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:03,119 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d9ubff9m', purging
2023-05-27 07:12:03,119 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:03,120 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:03,894 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:05,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z_6dqtvd', purging
2023-05-27 07:12:05,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:05,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:05,983 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:07,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g2zt_vjm', purging
2023-05-27 07:12:07,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:07,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:08,083 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:09,388 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jaefwufw', purging
2023-05-27 07:12:09,389 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:09,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:10,157 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:11,472 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wpknbhby', purging
2023-05-27 07:12:11,473 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:11,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:12,246 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:13,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9coxq0my', purging
2023-05-27 07:12:13,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:13,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:14,331 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:15,643 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7220g1t1', purging
2023-05-27 07:12:15,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:15,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:16,408 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:17,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wqs3wj2t', purging
2023-05-27 07:12:17,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:17,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:18,509 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:19,837 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2v0lljy0', purging
2023-05-27 07:12:19,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:19,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:20,607 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:21,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yqmqqp_4', purging
2023-05-27 07:12:21,928 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:21,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:22,698 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:24,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0fi0vjdh', purging
2023-05-27 07:12:24,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:24,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:24,793 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:26,105 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7niz0lez', purging
2023-05-27 07:12:26,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:26,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:26,880 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:28,191 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1fnde21b', purging
2023-05-27 07:12:28,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:28,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:28,953 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:30,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-timdrfsd', purging
2023-05-27 07:12:30,264 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:30,264 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:31,039 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:32,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ueg_vpm', purging
2023-05-27 07:12:32,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:32,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:33,145 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:34,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-roeob9_z', purging
2023-05-27 07:12:34,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:34,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:35,237 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:36,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-17ab4f7u', purging
2023-05-27 07:12:36,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:36,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:37,328 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:38,680 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2gotir9q', purging
2023-05-27 07:12:38,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:38,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:39,462 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:40,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pjmhtjf9', purging
2023-05-27 07:12:40,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:40,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:41,537 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:42,848 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0l4kdrs8', purging
2023-05-27 07:12:42,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:42,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:43,613 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:44,918 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rvugkttd', purging
2023-05-27 07:12:44,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:44,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:45,682 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:47,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-97_6m4nm', purging
2023-05-27 07:12:47,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:47,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:47,790 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:49,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-db9nfz5x', purging
2023-05-27 07:12:49,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:49,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:49,869 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:51,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-je__p9_d', purging
2023-05-27 07:12:51,188 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:51,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:51,952 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:53,284 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-92zxs866', purging
2023-05-27 07:12:53,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:53,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:54,061 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:55,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-28mxsb0v', purging
2023-05-27 07:12:55,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:55,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:56,151 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:57,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z0qm_cj4', purging
2023-05-27 07:12:57,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:57,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:12:58,220 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:12:59,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5p8358_0', purging
2023-05-27 07:12:59,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:12:59,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:13:00,287 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:13:01,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t4003hd0', purging
2023-05-27 07:13:01,602 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:13:01,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:13:02,388 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:13:03,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mv4142z7', purging
2023-05-27 07:13:03,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:13:03,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:13:04,464 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:13:05,766 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_logq6k', purging
2023-05-27 07:13:05,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:13:05,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:13:06,545 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:13:07,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mjxg_rjh', purging
2023-05-27 07:13:07,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:13:07,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 07:13:08,627 - distributed.nanny - WARNING - Restarting worker
2023-05-27 07:13:09,973 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cswwyqhu', purging
2023-05-27 07:13:09,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 07:13:09,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 939 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
