[dgx13:84331:0:84331] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  84331) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fa634865f1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7fa634866114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7fa6348662da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fa6c79a5420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fa6348df5d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fa634904859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7fa63482142f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7fa634824798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fa63486e989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fa63482362d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fa6348dcc4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7fa63498e06a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b17d6716fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b17d66d094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b17d67e519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b17d66e5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b17d67e7c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55b17d68be83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55b17d796b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55b17d628d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55b17d6757f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55b17d673929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b17d67e7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b17d66e5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b17d67e7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b17d66e5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b17d67e7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b17d66e5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b17d67e7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b17d66e5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b17d66d094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b17d67e519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55b17d66f128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b17d66d094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55b17d68bccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55b17d68c44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55b17d74f10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55b17d67677c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b17d6716fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b17d67e7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55b17d68bdac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b17d6716fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b17d67e7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b17d66e5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b17d66d094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b17d67e519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b17d66e5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b17d67e7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55b17d66e312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b17d66d094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b17d67e519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55b17d66f128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b17d66d094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55b17d66cd68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55b17d66cd19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55b17d71a07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55b17d746fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55b17d743353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55b17d73b16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55b17d73b05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55b17d73a297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55b17d70df07]
=================================
[dgx13:84327:0:84327] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  84327) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fd8bcce6f1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7fd8bcce7114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7fd8bcce72da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fd94fe2a420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fd8bcd605d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fd8bcd85859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7fd8bcca242f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7fd8bcca5798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fd8bccef989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fd8bcca462d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fd8bcd5dc4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7fd8bce0f06a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ca915d36fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ca915cf094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ca915e0519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ca915d05c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55ca91683162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fd8cffb31e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55ca915d877c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55ca9158ad05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55ca915d77f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55ca915d5929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ca915e07c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ca915d05c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ca915e07c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ca915d05c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ca915e07c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ca915d05c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ca915e07c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ca915d05c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ca915cf094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ca915e0519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55ca915d1128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ca915cf094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55ca915edccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55ca915ee44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55ca916b110e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55ca915d877c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ca915d36fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ca915e07c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55ca915eddac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ca915d36fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ca915e07c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ca915d05c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ca915cf094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ca915e0519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ca915d05c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ca915e07c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55ca915d0312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ca915cf094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ca915e0519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55ca915d1128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ca915cf094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55ca915ced68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55ca915ced19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55ca9167c07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55ca916a8fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55ca916a5353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55ca9169d16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55ca9169d05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55ca9169c297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55ca9166ff07]
=================================
[dgx13:84319:0:84319] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  84319) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fcbf7832f1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7fcbf7833114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7fcbf78332da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fcc9c997420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fcbf78ac5d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fcbf78d1859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7fcbf77ee42f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7fcbf77f1798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fcbf783b989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fcbf77f062d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fcbf78a9c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7fcbf795b06a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x5651f14f46fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5651f14f0094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5651f1501519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5651f14f15c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5651f15017c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x5651f150ee83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x5651f1619b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x5651f14abd05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x5651f14f87f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x5651f14f6929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5651f15017c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5651f14f15c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5651f15017c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5651f14f15c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5651f15017c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5651f14f15c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5651f15017c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5651f14f15c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5651f14f0094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5651f1501519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x5651f14f2128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5651f14f0094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x5651f150eccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x5651f150f44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x5651f15d210e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5651f14f977c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x5651f14f46fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5651f15017c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x5651f150edac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x5651f14f46fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5651f15017c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5651f14f15c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5651f14f0094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5651f1501519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5651f14f15c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5651f15017c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x5651f14f1312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5651f14f0094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5651f1501519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x5651f14f2128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5651f14f0094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x5651f14efd68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5651f14efd19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5651f159d07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x5651f15c9fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x5651f15c6353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x5651f15be16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x5651f15be05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x5651f15bd297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x5651f1590f07]
=================================
[dgx13:84323:0:84323] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  84323) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fc719292f1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7fc719293114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7fc7192932da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fc7be2a4420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fc71930c5d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fc719331859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7fc71924e42f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7fc719251798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fc71929b989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fc71925062d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fc719309c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7fc7193bb06a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55a8a8ec56fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a8a8ec1094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a8a8ed2519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a8a8ec25c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55a8a8f75162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fc73e42d1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55a8a8eca77c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55a8a8e7cd05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55a8a8ec97f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55a8a8ec7929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a8a8ed27c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a8a8ec25c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a8a8ed27c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a8a8ec25c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a8a8ed27c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a8a8ec25c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a8a8ed27c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a8a8ec25c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a8a8ec1094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a8a8ed2519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55a8a8ec3128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a8a8ec1094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55a8a8edfccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55a8a8ee044c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55a8a8fa310e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55a8a8eca77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55a8a8ec56fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a8a8ed27c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55a8a8edfdac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55a8a8ec56fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a8a8ed27c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a8a8ec25c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a8a8ec1094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a8a8ed2519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a8a8ec25c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a8a8ed27c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55a8a8ec2312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a8a8ec1094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a8a8ed2519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55a8a8ec3128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a8a8ec1094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55a8a8ec0d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55a8a8ec0d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55a8a8f6e07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55a8a8f9afca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55a8a8f97353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55a8a8f8f16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55a8a8f8f05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55a8a8f8e297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55a8a8f61f07]
=================================
2023-10-28 06:06:09,850 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33777 -> ucx://127.0.0.1:45581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f474d61d340, tag: 0x9da63878411286e9, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-28 06:06:09,850 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f783c200280, tag: 0x2ea99827620a349a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f783c200280, tag: 0x2ea99827620a349a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-28 06:06:09,850 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f59df187140, tag: 0xfb8912e6a67926df, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f59df187140, tag: 0xfb8912e6a67926df, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-28 06:06:09,850 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7fc31566d140, tag: 0x7c5e12797017df0a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7fc31566d140, tag: 0x7c5e12797017df0a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-10-28 06:06:09,852 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f474d61d140, tag: 0xd9c0c5f6dd285196, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f474d61d140, tag: 0xd9c0c5f6dd285196, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-28 06:06:09,882 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f59df187240, tag: 0xea171d0a6064d326, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f59df187240, tag: 0xea171d0a6064d326, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-28 06:06:09,882 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fc31566d2c0, tag: 0x2a7a78713dca9fcc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fc31566d2c0, tag: 0x2a7a78713dca9fcc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-10-28 06:06:09,891 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f59df1871c0, tag: 0x171c172c977b54e5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f59df1871c0, tag: 0x171c172c977b54e5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-28 06:06:09,896 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33777 -> ucx://127.0.0.1:50179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f474d61d440, tag: 0xd8d00887055a1e19, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-28 06:06:09,902 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f474d61d280, tag: 0x763fcd7ddec4380, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f474d61d280, tag: 0x763fcd7ddec4380, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-10-28 06:06:09,904 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33777 -> ucx://127.0.0.1:48559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f474d61d380, tag: 0x88de09c480523194, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-28 06:06:09,902 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37325 -> ucx://127.0.0.1:48559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc31566d380, tag: 0x25110b015392ecc1, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-28 06:06:09,931 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35031 -> ucx://127.0.0.1:48559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f783c2003c0, tag: 0x6d011236008a86f8, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-28 06:06:09,904 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f474d61d1c0, tag: 0x2357c2a95543ef12, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f474d61d1c0, tag: 0x2357c2a95543ef12, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-10-28 06:06:09,932 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f783c2001c0, tag: 0x426acbd271d9bab8, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f783c2001c0, tag: 0x426acbd271d9bab8, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-10-28 06:06:09,932 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f783c200300, tag: 0x17eef1416351433a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f783c200300, tag: 0x17eef1416351433a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-28 06:06:10,011 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc31566d280, tag: 0xee4c1e9745db20b, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc31566d280, tag: 0xee4c1e9745db20b, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-28 06:06:10,668 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51381
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7f474d61d240, tag: 0xc2acf7da5203ea54, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7f474d61d240, tag: 0xc2acf7da5203ea54, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-10-28 06:06:10,668 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51381
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fc31566d1c0, tag: 0x739c1cfe4a9eda2, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fc31566d1c0, tag: 0x739c1cfe4a9eda2, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-10-28 06:06:10,669 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37797 -> ucx://127.0.0.1:51381
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f59df1873c0, tag: 0x55c9d036c848e0a1, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-28 06:06:10,669 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51381
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f783c200340, tag: 0x99cf598e4541dddf, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f783c200340, tag: 0x99cf598e4541dddf, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-10-28 06:06:10,669 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37325 -> ucx://127.0.0.1:51381
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc31566d400, tag: 0x852dc46c636e9cc4, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-28 06:06:10,669 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51381
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f59df187180, tag: 0x8adbcc1c7cf32780, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f59df187180, tag: 0x8adbcc1c7cf32780, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-10-28 06:06:12,096 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-adccb87e3fee0e0ff9c5206a34e9fe09', 2)
Function:  subgraph_callable-d1006a9e-0505-4f9a-8b65-7b79b092
args:      (               key   payload
shuffle                     
0           244713  49852690
0           159078  80063288
0           200563  71194187
0           224711  38357187
0          1065600  13496440
...            ...       ...
7        799992869  17745170
7        799929594  16973761
7        799959679  77445993
7        799992888  52899130
7        799986764  25380767

[99996471 rows x 2 columns],                  key   payload
40612      302631301  66368767
11392      828407171  99047905
40621      825223410  85507463
11394      311455332  66327578
40626      826813712  34969294
...              ...       ...
99977712  1518339455  12488106
99977722  1549031668  29057969
99977611   790669062  74118535
99977619  1509114138   5202794
99977622  1541875708  45800568

[100013945 rows x 2 columns], 'simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 'simple-shuffle-84a0276e6a854cf0d6c4324869a61d39')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-10-28 06:06:12,140 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 0)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           182546  56496915
0           234309  24596991
0           171463  72396377
0          1011664  55851833
0           307734  31974049
...            ...       ...
0        799966710  76251288
0        799897302  94084437
0        799997931   2393859
0        799931017  84235530
0        799880715   6749788

[12505522 rows x 2 columns],                key   payload
shuffle                     
1            40755  38167139
1           188580  52834002
1            89158  63381433
1           199395  26974962
1            77560  93388033
...            ...       ...
1        799917118  60909718
1        799956668  64810041
1        799904709  61625278
1        799969929  68057011
1        799901718   7730613

[12497568 rows x 2 columns],                key   payload
shuffle                     
2           323592   2958157
2           315040  70991932
2           698707  94744473
2           378855  49982365
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-10-28 06:06:12,159 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 5)
Function:  _concat
args:      ([                key   payload
40611     822161042  71736114
11396     837834306  55123412
40619     860869306  47442195
11404     805235652  53774876
40627     831418146  49965977
...             ...       ...
99986806  510089946  73224132
99996042  840899736  29207520
99986809  827500433  86346907
99986874  819864631  57221121
99986875  508626671  51078458

[12498923 rows x 2 columns],                 key   payload
39046     937660761   7558208
39049     905691664  65976020
39071     946577672  56745799
11906     901295647  59219396
11917     965614086  48749189
...             ...       ...
99989377  960730244   2872732
99989472  925168110  76658376
99989491  622537669  96304003
99989492   12650802  64766871
99989494  905711654  14539226

[12501128 rows x 2 columns],                  key   payload
11297     1032726923  31666013
11307     1034733304  17039084
11266     1044298396  49449314
19062     1043827877  51532075
11274     1035702216  45158139
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-10-28 06:06:12,166 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
2023-10-28 06:06:12,166 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
2023-10-28 06:06:12,276 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 3)
Function:  _concat
args:      ([                key   payload
40614     857201754  24228236
11393     203056959  83208818
40615     506190647  68006059
11400     863809893  55002864
40617     832040685  24109248
...             ...       ...
99986689  106262197  71162104
99986690  829286282  71675785
99986698  846933600  32396742
99986705  849897462  81743442
99986708  859620515  88182187

[12498632 rows x 2 columns],                 key   payload
39041      20335891  32705750
39048     965926888  88622994
39053     945992430   3291337
11913     952689605  79803566
59490     123007072  41377047
...             ...       ...
99989477  519832775  92519252
99989480  921703955  61522574
99989485  907813462  86647968
99989487  951010339  78234204
99989488  221759547  80872181

[12502237 rows x 2 columns],                  key   payload
11313     1048029235  82369261
11315     1048933847  55022722
11322      536811353  55566363
11269      428849043  62696029
19040     1055657050  58258327
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-10-28 06:06:12,277 - distributed.worker - ERROR - 'int' object is not subscriptable
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2861, in get_data_from_worker
    status = response["status"]
TypeError: 'int' object is not subscriptable
2023-10-28 06:06:12,286 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1069, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1784, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 3, 6)}, 'who': 'ucx://127.0.0.1:35031', 'reply': True}
2023-10-28 06:06:12,289 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33777
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 364, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #107] ep: 0x7f783c200240, tag: 0x9e4db58e19cea3fc, nbytes: 6432, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #107] ep: 0x7f783c200240, tag: 0x9e4db58e19cea3fc, nbytes: 6432, type: <class 'numpy.ndarray'>>: Message truncated")
2023-10-28 06:06:12,289 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33777 -> ucx://127.0.0.1:35031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #090] ep: 0x7f474d61d400, tag: 0x463e2e06ee132b36, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1783, in get_data
    response = await comm.read(deserializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #090] ep: 0x7f474d61d400, tag: 0x463e2e06ee132b36, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-28 06:06:12,296 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6)
Function:  _concat
args:      ([                key   payload
40624     834760176  52093750
11398     858724324  10460308
40629     505126725   5860925
11413     102238064  62793926
11423     843505181  58797833
...             ...       ...
99986877  858118125  44573859
99986692  843798723  78533457
99986697  861294386  99535190
99986712  829421859  25846196
99986718  847127710  25365312

[12497796 rows x 2 columns],                 key   payload
39050     916549622  80014687
39052     963841567  43722048
39055     919694167  12444672
11904     955350019  65860337
39061      18961884  44410714
...             ...       ...
99989402  224884232  26537511
99989404  917088907  66261341
99989478  916438948  15489612
99989490  317111114  20025707
99989497  969840573  79780312

[12497151 rows x 2 columns],                  key   payload
11296      532242372  39896459
11303     1036502244    312247
11304     1011611488  79901366
11316     1009969952  90316150
11318      631265252  19661780
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-10-28 06:06:12,468 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-adccb87e3fee0e0ff9c5206a34e9fe09', 4)
Function:  subgraph_callable-d1006a9e-0505-4f9a-8b65-7b79b092
args:      (               key   payload
shuffle                     
0           141131  65645439
0            85276  26696094
0           168416  66960289
0            95557  80296044
0           226718  34340532
...            ...       ...
7        799825512  11746974
7        799915452  58214965
7        799972960  44492441
7        799936062  48998298
7        799948904  72175064

[100023899 rows x 2 columns],                  key   payload
40618      863258831  74618196
11395      845617013  95241158
40625      819683680  76073241
11399      703563997  56006970
40632        9008000  41876903
...              ...       ...
99985691  1527848705  75535813
99985692   497390587  27995806
99977708  1562721946  43298198
99977711    97959525  52978619
99977725   794372138  17364861

[99980499 rows x 2 columns], 'simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 'simple-shuffle-84a0276e6a854cf0d6c4324869a61d39')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-10-28 06:06:12,520 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 7)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           140085  52132310
0           292766  81789281
0           204136  51795909
0           160082  12437881
0           237981  82804349
...            ...       ...
0        799899261  85493747
0        799895759  55467467
0        799993743  22566749
0        799874123  48565993
0        799952463  94608006

[12498151 rows x 2 columns],                key   payload
shuffle                     
1           101032  22022086
1            50738  60578818
1           143506  28840857
1           140805  73810854
1           101035  69841550
...            ...       ...
1        799967828  86774207
1        799991927  33527893
1        799880823  18424186
1        799964542  60614112
1        799981319  80999939

[12498591 rows x 2 columns],                key   payload
shuffle                     
2           324269  32258059
2            53165  31988429
2           296994  21358586
2           323595  16710693
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-10-28 06:06:23,944 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 24 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
