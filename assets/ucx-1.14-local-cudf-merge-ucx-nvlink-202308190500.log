/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40387 instead
  warnings.warn(
[dgx13:79690:0:79690] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79690) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f10202bbf1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7f10202bc114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7f10202bc2da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f10c08fb420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f10203355d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f102035a859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7f102027742f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7f102027a798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f10202c4989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f102027962d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f1020332c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7f10203e9aaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x563e374e93d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563e374e3f94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x563e374f53f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563e374e54c6]
16  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563e374f56a2]
17  /opt/conda/envs/gdf/bin/python(+0x14ca43) [0x563e37502a43]
18  /opt/conda/envs/gdf/bin/python(+0x2580fc) [0x563e3760e0fc]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x563e374a848b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x563e374ec6f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x563e374ea6e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563e374f56a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563e374e54c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563e374f56a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563e374e54c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563e374f56a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563e374e54c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563e374f56a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563e374e54c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563e374e3f94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x563e374f53f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x563e374e6022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563e374e3f94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x563e3750288b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x563e3750300c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x563e375c673e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x563e374ed67c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x563e374e93d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563e374f56a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x563e3750296c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x563e374e93d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563e374f56a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563e374e54c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563e374e3f94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x563e374f53f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563e374e54c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563e374f56a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x563e374e5212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563e374e3f94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x563e374f53f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x563e374e6022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563e374e3f94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x563e374e3c68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x563e374e3c19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x563e3759120b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x563e375be5fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x563e375ba983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x563e375b279a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x563e375b268c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x563e375b18c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x563e37585047]
=================================
2023-08-19 05:53:14,580 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34209 -> ucx://127.0.0.1:57997
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6f92df9100, tag: 0x775278b3dae8ffd3, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-752' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-761' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-08-19 05:53:14,667 - distributed.nanny - WARNING - Restarting worker
[dgx13:79681:0:79681] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79681) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f8240a8ff1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7f8240a90114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7f8240a902da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f82e10b7420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f8240b095d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f8240b2e859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7f8240a4b42f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7f8240a4e798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f8240a98989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f8240a4d62d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f8240b06c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7f8240bbdaaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56401c1413d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56401c13bf94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56401c14d3f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56401c13d4c6]
16  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56401c14d6a2]
17  /opt/conda/envs/gdf/bin/python(+0x14ca43) [0x56401c15aa43]
18  /opt/conda/envs/gdf/bin/python(+0x2580fc) [0x56401c2660fc]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x56401c10048b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x56401c1446f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x56401c1426e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56401c14d6a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56401c13d4c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56401c14d6a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56401c13d4c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56401c14d6a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56401c13d4c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56401c14d6a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56401c13d4c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56401c13bf94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56401c14d3f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x56401c13e022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56401c13bf94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x56401c15a88b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x56401c15b00c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x56401c21e73e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56401c14567c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56401c1413d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56401c14d6a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x56401c15a96c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56401c1413d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56401c14d6a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56401c13d4c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56401c13bf94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56401c14d3f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56401c13d4c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56401c14d6a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x56401c13d212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56401c13bf94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56401c14d3f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x56401c13e022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56401c13bf94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x56401c13bc68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56401c13bc19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56401c1e920b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x56401c2165fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x56401c212983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x56401c20a79a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x56401c20a68c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x56401c2098c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x56401c1dd047]
=================================
[dgx13:79684:0:79684] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79684) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f3478cbbf1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7f3478cbc114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7f3478cbc2da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f35191a9420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f3478d355d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f3478d5a859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7f3478c7742f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7f3478c7a798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f3478cc4989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f3478c7962d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f3478d32c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7f3478de9aaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55a7d93953d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55a7d938ff94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a7d93a13f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7d93914c6]
16  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55a7d93a16a2]
17  /opt/conda/envs/gdf/bin/python(+0x14ca43) [0x55a7d93aea43]
18  /opt/conda/envs/gdf/bin/python(+0x2580fc) [0x55a7d94ba0fc]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x55a7d935448b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x55a7d93986f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x55a7d93966e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55a7d93a16a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7d93914c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55a7d93a16a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7d93914c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55a7d93a16a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7d93914c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55a7d93a16a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7d93914c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55a7d938ff94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a7d93a13f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55a7d9392022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55a7d938ff94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55a7d93ae88b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55a7d93af00c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x55a7d947273e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55a7d939967c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55a7d93953d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55a7d93a16a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55a7d93ae96c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55a7d93953d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55a7d93a16a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7d93914c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55a7d938ff94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a7d93a13f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7d93914c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55a7d93a16a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55a7d9391212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55a7d938ff94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a7d93a13f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55a7d9392022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55a7d938ff94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55a7d938fc68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55a7d938fc19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55a7d943d20b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x55a7d946a5fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x55a7d9466983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55a7d945e79a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55a7d945e68c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55a7d945d8c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55a7d9431047]
=================================
2023-08-19 05:53:15,260 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59897 -> ucx://127.0.0.1:37467
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc3f1cf8140, tag: 0x633d7fc6900d04c0, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:53:15,260 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37467
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fbf7136e200, tag: 0x7e666ca6c2e96780, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fbf7136e200, tag: 0x7e666ca6c2e96780, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-19 05:53:15,264 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37467
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 355, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 379, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1562, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-19 05:53:15,265 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37467
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 355, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 379, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1562, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-19 05:53:15,267 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34209 -> ucx://127.0.0.1:44999
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6f92df9180, tag: 0x3f84dab4fcd61c3, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-933' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-08-19 05:53:15,271 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44999
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 355, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 379, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1562, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-19 05:53:15,289 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37467
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1533, in _connect
    async def _connect(self, addr: str, timeout: float | None = None) -> Comm:
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
asyncio.exceptions.CancelledError
2023-08-19 05:53:15,291 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44999
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 355, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1562, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-19 05:53:15,289 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44999
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7fbf7136e180, tag: 0x1396ed9770d0fcec, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7fbf7136e180, tag: 0x1396ed9770d0fcec, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-19 05:53:15,265 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37467
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 355, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 379, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1562, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-19 05:53:15,348 - distributed.nanny - WARNING - Restarting worker
2023-08-19 05:53:15,271 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44999
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 355, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 379, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1562, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-19 05:53:15,399 - distributed.nanny - WARNING - Restarting worker
[dgx13:79687:0:79687] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79687) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fcae5c14f1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7fcae5c15114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7fcae5c152da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fcba02d2420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fcae5c8e5d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fcae5cb3859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7fcae5bd042f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7fcae5bd3798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fcae5c1d989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fcae5bd262d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fcae5c8bc4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7fcae5d42aaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x563ab81233d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563ab811df94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x563ab812f3f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563ab811f4c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x563ab81d2612]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fcb20e4e1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x563ab812767c]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x563ab80e248b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x563ab81266f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x563ab81246e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563ab812f6a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563ab811f4c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563ab812f6a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563ab811f4c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563ab812f6a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563ab811f4c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563ab812f6a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563ab811f4c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563ab811df94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x563ab812f3f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x563ab8120022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563ab811df94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x563ab813c88b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x563ab813d00c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x563ab820073e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x563ab812767c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x563ab81233d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563ab812f6a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x563ab813c96c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x563ab81233d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563ab812f6a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563ab811f4c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563ab811df94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x563ab812f3f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x563ab811f4c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x563ab812f6a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x563ab811f212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563ab811df94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x563ab812f3f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x563ab8120022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x563ab811df94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x563ab811dc68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x563ab811dc19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x563ab81cb20b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x563ab81f85fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x563ab81f4983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x563ab81ec79a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x563ab81ec68c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x563ab81eb8c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x563ab81bf047]
=================================
2023-08-19 05:53:15,707 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34209 -> ucx://127.0.0.1:51743
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6f92df9180, tag: 0xe708f3636fd1ebd2, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:53:15,707 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51743
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7efdb9855280, tag: 0x5d7c7ca32d84d93e, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7efdb9855280, tag: 0x5d7c7ca32d84d93e, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-19 05:53:15,707 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51743
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fbf7136e140, tag: 0x7d4603b04befd9d5, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fbf7136e140, tag: 0x7d4603b04befd9d5, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-19 05:53:15,707 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51743
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f6f92df9280, tag: 0x61e2a53d7f086734, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f6f92df9280, tag: 0x61e2a53d7f086734, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-19 05:53:15,707 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51743
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc3f1cf8340, tag: 0xaa5c22b64b4df169, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc3f1cf8340, tag: 0xaa5c22b64b4df169, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-19 05:53:15,773 - distributed.nanny - WARNING - Restarting worker
2023-08-19 05:53:44,966 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44999
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 355, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 381, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:44999 after 30 s
[dgx13:79851:0:79851] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79851) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fe91d890f1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7fe91d891114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7fe91d8912da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fe9c1da4420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fe91d90a5d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fe91d92f859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7fe91d84c42f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7fe91d84f798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fe91d899989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fe91d84e62d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fe91d907c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7fe91d9beaaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x559c2d5f63d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559c2d5f0f94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559c2d6023f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559c2d5f24c6]
16  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x559c2d6026a2]
17  /opt/conda/envs/gdf/bin/python(+0x14ca43) [0x559c2d60fa43]
18  /opt/conda/envs/gdf/bin/python(+0x2580fc) [0x559c2d71b0fc]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x559c2d5b548b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x559c2d5f96f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x559c2d5f76e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x559c2d6026a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559c2d5f24c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x559c2d6026a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559c2d5f24c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x559c2d6026a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559c2d5f24c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x559c2d6026a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559c2d5f24c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559c2d5f0f94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559c2d6023f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x559c2d5f3022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559c2d5f0f94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x559c2d60f88b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x559c2d61000c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x559c2d6d373e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x559c2d5fa67c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x559c2d5f63d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x559c2d6026a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x559c2d60f96c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x559c2d5f63d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x559c2d6026a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559c2d5f24c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559c2d5f0f94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559c2d6023f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559c2d5f24c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x559c2d6026a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x559c2d5f2212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559c2d5f0f94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559c2d6023f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x559c2d5f3022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559c2d5f0f94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x559c2d5f0c68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x559c2d5f0c19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x559c2d69e20b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x559c2d6cb5fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x559c2d6c7983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x559c2d6bf79a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x559c2d6bf68c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x559c2d6be8c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x559c2d692047]
=================================
2023-08-19 05:53:45,730 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:53329 -> ucx://127.0.0.1:43505
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fbf7136e280, tag: 0x4859623db543337, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:53:45,778 - distributed.nanny - WARNING - Restarting worker
2023-08-19 05:53:46,144 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:53:46,145 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:53:46,154 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:53:46,155 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:53:46,163 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 5)
Function:  shuffle_group
args:      (                 key   payload
0         1318863339  99051695
1         1352208751  78953234
2          664778035  81293845
3         1353618300  74974697
4         1302090160  62919800
...              ...       ...
99999995    62713713  72068972
99999996  1349206659  33160153
99999997  1359655348  40095643
99999998  1352540937  33956372
99999999  1312812172  90324512

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-19 05:53:46,247 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-054f65580a5efedc40c26858beb83d02', 4)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           764292  14052060
0           937089  72351131
0           891999  99419372
0           913425  99088963
0           922687  13466979
...            ...       ...
0        799960740  45171576
0        799875180  60019744
0        799874098  26547495
0        799953350  24355533
0        799914265  90353863

[12503392 rows x 2 columns],                key   payload
shuffle                     
1           787946  38746636
1           926309  62870621
1           770875  81257408
1           708300  26119425
1           911504  99474245
...            ...       ...
1        799683795  48675293
1        799722715  66467467
1        799829804  78100826
1        799703120  20233708
1        799783003  68565915

[12500389 rows x 2 columns],                key   payload
shuffle                     
2           606315  38409100
2           624809  63089775
2           397259  92281495
2           372694  76587972
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-19 05:53:46,273 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-054f65580a5efedc40c26858beb83d02', 1)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           774060  14290777
0           768319  61052894
0           829356   1640618
0           952009  23154072
0           948984   7993221
...            ...       ...
0        799836843  31996061
0        799965128  85795418
0        799882295    275290
0        799969670  11960445
0        799952587  14649868

[12497508 rows x 2 columns],                key   payload
shuffle                     
1           681775  55889763
1           790387  13096583
1           830333    981084
1           615216  57921659
1           946204   3168867
...            ...       ...
1        799749329  11764533
1        799742160  98326923
1        799847858  17812259
1        799763049  67272402
1        799871428  46843753

[12503907 rows x 2 columns],                key   payload
shuffle                     
2           616627  58589169
2           510292  73703601
2           404343  59816231
2           614096  99295032
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-19 05:53:46,311 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-054f65580a5efedc40c26858beb83d02', 2)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           914438  36072567
0           917151  62546407
0           922425  89887519
0           925498  91683813
0           944927  29401826
...            ...       ...
0        799989082  39199167
0        799975196  57808297
0        799870553  47298614
0        799988142  75394328
0        799852599  60915989

[12497244 rows x 2 columns],                key   payload
shuffle                     
1           710643  32217788
1           756712  88934932
1           720075  50867560
1           455432  22182923
1           486553  37152368
...            ...       ...
1        799721650  45072233
1        799868840   2446686
1        799823183  35135752
1        799705654  53727974
1        799719530  67636110

[12500558 rows x 2 columns],                key   payload
shuffle                     
2           492360  14128445
2           634097  13737428
2           606321  22876336
2           682718  34128423
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-19 05:53:49,528 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2023-08-19 05:53:49,538 - distributed.core - ERROR - unpack(b) received extra data.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2023-08-19 05:53:49,538 - distributed.worker - ERROR - unpack(b) received extra data.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2023-08-19 05:53:49,546 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:53:49,547 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:53:49,563 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33329
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 364, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #092] ep: 0x7f6f92df9380, tag: 0x15831ee08896cb8b, nbytes: 0, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #092] ep: 0x7f6f92df9380, tag: 0x15831ee08896cb8b, nbytes: 0, type: <class 'numpy.ndarray'>>: Message truncated")
2023-08-19 05:53:49,563 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 930, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1099, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': {"('split-simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 4, 1)"}, 'who': 'ucx://127.0.0.1:34209', 'max_connections': None, 'reply': True}
Task exception was never retrieved
future: <Task finished name='Task-1006' coro=<Server._handle_comm() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py:836> exception=AssertionError({'op': 'get_data', 'keys': {"('split-simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 4, 1)"}, 'who': 'ucx://127.0.0.1:34209', 'max_connections': None, 'reply': True})>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 930, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1099, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': {"('split-simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 4, 1)"}, 'who': 'ucx://127.0.0.1:34209', 'max_connections': None, 'reply': True}
2023-08-19 05:53:49,570 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33329
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 364, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #104] ep: 0x7fbf7136e100, tag: 0x2887fa637b4e91c8, nbytes: 0, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #104] ep: 0x7fbf7136e100, tag: 0x2887fa637b4e91c8, nbytes: 0, type: <class 'numpy.ndarray'>>: Message truncated")
[dgx13:79854:0:79854] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79854) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f631402ff1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7f6314030114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7f63140302da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f63b404b420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f6311b6b5d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f6311b90859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7f6311b0942f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7f6311b0c798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f6314038989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f6311b0b62d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f6311b68c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7f6311c1faaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55ea318223d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ea3181cf94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ea3182e3f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ea3181e4c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55ea318d1612]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f6334bc91e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55ea3182667c]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x55ea317e148b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x55ea318256f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x55ea318236e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ea3182e6a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ea3181e4c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ea3182e6a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ea3181e4c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ea3182e6a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ea3181e4c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ea3182e6a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ea3181e4c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ea3181cf94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ea3182e3f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55ea3181f022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ea3181cf94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55ea3183b88b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55ea3183c00c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x55ea318ff73e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55ea3182667c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55ea318223d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ea3182e6a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55ea3183b96c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55ea318223d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ea3182e6a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ea3181e4c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ea3181cf94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ea3182e3f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ea3181e4c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ea3182e6a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55ea3181e212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ea3181cf94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ea3182e3f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55ea3181f022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ea3181cf94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55ea3181cc68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55ea3181cc19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55ea318ca20b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x55ea318f75fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x55ea318f3983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55ea318eb79a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55ea318eb68c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55ea318ea8c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55ea318be047]
=================================
[dgx13:79859:0:79859] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79859) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fc9e0634f1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7fc9e0635114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7fc9e06352da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fca72b47420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fc9e06ae5d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fc9e06d3859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7fc9e05f042f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7fc9e05f3798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fc9e063d989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fc9e05f262d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fc9e06abc4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7fc9e0762aaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x556cc8aba3d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x556cc8ab4f94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x556cc8ac63f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc8ab64c6]
16  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x556cc8ac66a2]
17  /opt/conda/envs/gdf/bin/python(+0x14ca43) [0x556cc8ad3a43]
18  /opt/conda/envs/gdf/bin/python(+0x2580fc) [0x556cc8bdf0fc]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x556cc8a7948b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x556cc8abd6f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x556cc8abb6e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x556cc8ac66a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc8ab64c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x556cc8ac66a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc8ab64c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x556cc8ac66a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc8ab64c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x556cc8ac66a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc8ab64c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x556cc8ab4f94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x556cc8ac63f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x556cc8ab7022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x556cc8ab4f94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x556cc8ad388b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x556cc8ad400c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x556cc8b9773e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x556cc8abe67c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x556cc8aba3d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x556cc8ac66a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x556cc8ad396c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x556cc8aba3d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x556cc8ac66a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc8ab64c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x556cc8ab4f94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x556cc8ac63f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc8ab64c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x556cc8ac66a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x556cc8ab6212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x556cc8ab4f94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x556cc8ac63f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x556cc8ab7022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x556cc8ab4f94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x556cc8ab4c68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x556cc8ab4c19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x556cc8b6220b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x556cc8b8f5fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x556cc8b8b983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x556cc8b8379a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x556cc8b8368c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x556cc8b828c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x556cc8b56047]
=================================
[1692424429.645965] [dgx13:79674:0]    cuda_copy_md.c:208  UCX  ERROR   cuMemAlloc_v2((CUdeviceptr*)address_p, *length_p)() failed: out of memory
[1692424429.645988] [dgx13:79674:0]         uct_mem.c:155  UCX  ERROR   failed to allocate 536870912 bytes using md cuda_cpy for ucp_rndv_frags: Input/output error
[1692424429.645993] [dgx13:79674:0]           mpool.c:269  UCX  ERROR Failed to allocate memory pool (name=ucp_rndv_frags) chunk: Out of memory
[dgx13:79674:0:79674]        rndv.c:1369 Fatal: failed to allocate fragment memory buffer
==== backtrace (tid:  79674) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7efdb9af1f1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7efdb9aefad1]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x26c6c) [0x7efdb9aefc6c]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x6f48a) [0x7efdb9b9448a]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_recv_nbx+0xb68) [0x7efdb9ba7738]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_recv_nb+0x57) [0x7efdb9ba7917]
 6  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x639d9) [0x7efdb9c4b9d9]
 7  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55ee91dc000c]
 8  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55ee91da63d6]
 9  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ee91da0f94]
10  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ee91db23f9]
11  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55ee91da3022]
12  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ee91da0f94]
13  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ee91db23f9]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55ee91da3022]
15  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55ee91e55612]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55ee91da824d]
17  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55ee91e55612]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55ee91da824d]
19  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55ee91e55612]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55ee91da824d]
21  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55ee91e55612]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55ee91da824d]
23  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55ee91e55612]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55ee91da824d]
25  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55ee91e55612]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55ee91da824d]
27  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55ee91e55612]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55ee91da824d]
29  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55ee91e55612]
30  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7efddece21e9]
31  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7efddece2aa6]
32  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55ee91daa67c]
33  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x55ee91d6548b]
34  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x55ee91da96f3]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x55ee91da76e4]
36  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ee91db26a2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ee91da24c6]
38  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ee91db26a2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ee91da24c6]
40  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ee91db26a2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ee91da24c6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ee91db26a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ee91da24c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ee91da0f94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ee91db23f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55ee91da3022]
47  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ee91da0f94]
48  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55ee91dbf88b]
49  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55ee91dc000c]
50  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x55ee91e8373e]
51  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55ee91daa67c]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55ee91da63d6]
53  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ee91db26a2]
54  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55ee91dbf96c]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55ee91da63d6]
56  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ee91db26a2]
57  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ee91da24c6]
58  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ee91da0f94]
59  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ee91db23f9]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ee91da24c6]
61  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ee91db26a2]
=================================
2023-08-19 05:53:49,887 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34209 -> ucx://127.0.0.1:45153
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6f92df9400, tag: 0x53f9afbd827a3d39, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:53:49,887 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45153
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fbf7136e400, tag: 0xf1f66ed6803c08b1, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fbf7136e400, tag: 0xf1f66ed6803c08b1, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-19 05:53:49,887 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59897 -> ucx://127.0.0.1:45153
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc3f1cf8180, tag: 0x2dc7fdaff0c60cd9, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:53:49,888 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45153
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f6f92df9180, tag: 0x3619dbda1a3fab16, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f6f92df9180, tag: 0x3619dbda1a3fab16, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-19 05:53:49,888 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45153
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fc3f1cf83c0, tag: 0xbf48fa38eb0f05d1, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fc3f1cf83c0, tag: 0xbf48fa38eb0f05d1, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-19 05:53:49,889 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34209 -> ucx://127.0.0.1:54463
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6f92df9480, tag: 0xd64509a19f3ec58a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:53:49,889 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54463
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc3f1cf8140, tag: 0xd2796b1ac9ff23b0, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc3f1cf8140, tag: 0xd2796b1ac9ff23b0, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-19 05:53:49,889 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54463
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f6f92df93c0, tag: 0x60a78875c5f7178f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f6f92df93c0, tag: 0x60a78875c5f7178f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-19 05:53:49,899 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54463
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 355, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 379, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1562, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-19 05:53:49,913 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33329
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #083] ep: 0x7fc3f1cf82c0, tag: 0xfeeb7b339cb920ce, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #083] ep: 0x7fc3f1cf82c0, tag: 0xfeeb7b339cb920ce, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-19 05:53:49,914 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:53329 -> ucx://127.0.0.1:33329
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #096] ep: 0x7fbf7136e300, tag: 0xf0a45d45f033c061, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1778, in get_data
    response = await comm.read(deserializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #096] ep: 0x7fbf7136e300, tag: 0xf0a45d45f033c061, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
[dgx13:79842:0:79842] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79842) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f563c24ef1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7f563c24f114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7f563c24f2da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f56dc74d420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f563c2c85d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f563c2ed859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7f563c20a42f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7f563c20d798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f563c257989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f563c20c62d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f563c2c5c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7f563c37caaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55f0d00c03d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f0d00baf94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f0d00cc3f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f0d00bc4c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55f0d016f612]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f56d00161e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55f0d00c467c]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x55f0d007f48b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x55f0d00c36f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x55f0d00c16e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f0d00cc6a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f0d00bc4c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f0d00cc6a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f0d00bc4c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f0d00cc6a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f0d00bc4c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f0d00cc6a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f0d00bc4c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f0d00baf94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f0d00cc3f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55f0d00bd022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f0d00baf94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55f0d00d988b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55f0d00da00c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x55f0d019d73e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55f0d00c467c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55f0d00c03d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f0d00cc6a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55f0d00d996c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55f0d00c03d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f0d00cc6a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f0d00bc4c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f0d00baf94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f0d00cc3f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f0d00bc4c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f0d00cc6a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55f0d00bc212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f0d00baf94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f0d00cc3f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55f0d00bd022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f0d00baf94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55f0d00bac68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55f0d00bac19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55f0d016820b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x55f0d01955fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x55f0d0191983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55f0d018979a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55f0d018968c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55f0d01888c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55f0d015c047]
=================================
2023-08-19 05:53:49,916 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33329
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 355, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 379, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1562, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-19 05:53:49,966 - distributed.nanny - WARNING - Restarting worker
2023-08-19 05:53:49,917 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33329
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 355, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 379, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1562, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-19 05:53:50,021 - distributed.nanny - WARNING - Restarting worker
2023-08-19 05:53:50,089 - distributed.nanny - WARNING - Restarting worker
2023-08-19 05:53:50,178 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52399
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fbf7136e200, tag: 0x9bbd1ef11128ceb6, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fbf7136e200, tag: 0x9bbd1ef11128ceb6, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-19 05:53:50,178 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52399
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7fc3f1cf8340, tag: 0xf10280b6633b7da7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7fc3f1cf8340, tag: 0xf10280b6633b7da7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-19 05:53:50,179 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34209 -> ucx://127.0.0.1:52399
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6f92df9440, tag: 0x4c9300026b92d452, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:53:50,179 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52399
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f6f92df9280, tag: 0x70b6ef4824fc6ff9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f6f92df9280, tag: 0x70b6ef4824fc6ff9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-19 05:53:50,245 - distributed.nanny - WARNING - Restarting worker
[dgx13:79915:0:79915] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79915) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fa4e4aeff1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7fa4e4af0114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7fa4e4af02da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fa585020420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fa4e4b695d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fa4e4b8e859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7fa4f802742f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7fa4f802a798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fa4e4af8989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fa4f802962d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fa4e4b66c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7fa4e4c1daaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x558cbe8193d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x558cbe813f94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558cbe8253f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558cbe8154c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x558cbe8c8612]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fa57800b1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x558cbe81d67c]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x558cbe7d848b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x558cbe81c6f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x558cbe81a6e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x558cbe8256a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558cbe8154c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x558cbe8256a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558cbe8154c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x558cbe8256a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558cbe8154c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x558cbe8256a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558cbe8154c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x558cbe813f94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558cbe8253f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x558cbe816022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x558cbe813f94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x558cbe83288b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x558cbe83300c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x558cbe8f673e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x558cbe81d67c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x558cbe8193d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x558cbe8256a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x558cbe83296c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x558cbe8193d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x558cbe8256a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558cbe8154c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x558cbe813f94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558cbe8253f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558cbe8154c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x558cbe8256a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x558cbe815212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x558cbe813f94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558cbe8253f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x558cbe816022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x558cbe813f94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x558cbe813c68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x558cbe813c19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x558cbe8c120b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x558cbe8ee5fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x558cbe8ea983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x558cbe8e279a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x558cbe8e268c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x558cbe8e18c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x558cbe8b5047]
=================================
2023-08-19 05:53:53,653 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59081
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fbf7136e200, tag: 0x94b792f8f983a459, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fbf7136e200, tag: 0x94b792f8f983a459, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-19 05:53:53,653 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59081
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f6f92df9280, tag: 0x6669dfffcccf3789, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f6f92df9280, tag: 0x6669dfffcccf3789, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-19 05:53:53,653 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59081
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc3f1cf8340, tag: 0xcec8449792c75720, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc3f1cf8340, tag: 0xcec8449792c75720, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-19 05:53:53,654 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:53329 -> ucx://127.0.0.1:59081
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fbf7136e300, tag: 0x846310d5919c8451, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:53:53,721 - distributed.nanny - WARNING - Restarting worker
[dgx13:79950:0:79950] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79950) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f2d50bfcf1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7f2d50bfd114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7f2d50bfd2da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f2df1225420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f2d50c765d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f2d50c9b859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7f2d50bb842f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7f2d50bbb798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f2d50c05989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f2d50bba62d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f2d50c73c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7f2d50d2aaaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x561b1cb293d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x561b1cb23f94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x561b1cb353f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x561b1cb254c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x561b1cbd8612]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f2de411f1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x561b1cb2d67c]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x561b1cae848b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x561b1cb2c6f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x561b1cb2a6e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x561b1cb356a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x561b1cb254c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x561b1cb356a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x561b1cb254c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x561b1cb356a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x561b1cb254c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x561b1cb356a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x561b1cb254c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x561b1cb23f94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x561b1cb353f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x561b1cb26022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x561b1cb23f94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x561b1cb4288b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x561b1cb4300c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x561b1cc0673e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x561b1cb2d67c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x561b1cb293d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x561b1cb356a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x561b1cb4296c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x561b1cb293d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x561b1cb356a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x561b1cb254c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x561b1cb23f94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x561b1cb353f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x561b1cb254c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x561b1cb356a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x561b1cb25212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x561b1cb23f94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x561b1cb353f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x561b1cb26022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x561b1cb23f94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x561b1cb23c68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x561b1cb23c19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x561b1cbd120b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x561b1cbfe5fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x561b1cbfa983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x561b1cbf279a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x561b1cbf268c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x561b1cbf18c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x561b1cbc5047]
=================================
2023-08-19 05:53:57,081 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60687
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fc3f1cf8340, tag: 0x1361607857d7cea5, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fc3f1cf8340, tag: 0x1361607857d7cea5, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-19 05:53:57,081 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34209 -> ucx://127.0.0.1:60687
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6f92df93c0, tag: 0x672efdfcbf451245, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:53:57,081 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60687
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7fbf7136e300, tag: 0x35574fa9c293dd31, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7fbf7136e300, tag: 0x35574fa9c293dd31, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-19 05:53:57,081 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60687
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f6f92df9280, tag: 0xa1939a7b9a856c70, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f6f92df9280, tag: 0xa1939a7b9a856c70, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-19 05:53:57,147 - distributed.nanny - WARNING - Restarting worker
[dgx13:79678:0:79678] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79678) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fc3f1fccf1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7fc3f1fcd114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7fc3f1fcd2da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fc49a5fb420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fc40804f5d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fc408074859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7fc3f1f8842f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7fc3f1f8b798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fc3f1fd5989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fc3f1f8a62d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fc40804cc4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7fc408103aaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5578902ea3d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5578902e4f94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5578902f63f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5578902e64c6]
16  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5578902f66a2]
17  /opt/conda/envs/gdf/bin/python(+0x14ca43) [0x557890303a43]
18  /opt/conda/envs/gdf/bin/python(+0x2580fc) [0x55789040f0fc]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x5578902a948b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x5578902ed6f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x5578902eb6e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5578902f66a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5578902e64c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5578902f66a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5578902e64c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5578902f66a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5578902e64c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5578902f66a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5578902e64c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5578902e4f94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5578902f63f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5578902e7022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5578902e4f94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55789030388b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55789030400c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x5578903c773e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5578902ee67c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5578902ea3d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5578902f66a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55789030396c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5578902ea3d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5578902f66a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5578902e64c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5578902e4f94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5578902f63f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5578902e64c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5578902f66a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x5578902e6212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5578902e4f94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5578902f63f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5578902e7022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5578902e4f94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x5578902e4c68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5578902e4c19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55789039220b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x5578903bf5fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x5578903bb983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x5578903b379a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x5578903b368c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x5578903b28c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x557890386047]
=================================
2023-08-19 05:54:00,209 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:54:00,209 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:54:00,272 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:58677 -> ucx://127.0.0.1:59897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f9eaceb9180, tag: 0x6dbcf3aab9d682c9, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:54:00,275 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-5366301a596b755bb8c33997d3ce7726', 1)
Function:  generate_chunk
args:      (1, 100000000, 8, 'build', 0.3, True)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-19 05:54:00,337 - distributed.nanny - WARNING - Restarting worker
2023-08-19 05:54:00,479 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 1)
Function:  _concat
args:      ([               key  shuffle   payload  _partitions
0           104523        1  84245569            1
1           104528        1  44309097            1
2           104531        1  25113951            1
3            41506        1  21770125            1
4            41514        1  53122355            1
...            ...      ...       ...          ...
12499995  99960755        1  63867576            1
12499996  99996126        1  98792445            1
12499997  99996079        1  70911908            1
12499998  99996080        1  59551028            1
12499999  99996089        1   5287881            1

[12500000 rows x 4 columns],                 key  shuffle   payload  _partitions
0         100022769        1  54817007            1
1         100022783        1  72678468            1
2         100063692        1  30523302            1
3         100063704        1   1964435            1
4         100022734        1  52855690            1
...             ...      ...       ...      
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-19 05:54:00,504 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:54:00,505 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:54:00,516 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:54:00,516 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:54:00,533 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:58677
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 364, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #016] ep: 0x7f6f92df9280, tag: 0x744049b6cfa0857a, nbytes: 1368, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #016] ep: 0x7f6f92df9280, tag: 0x744049b6cfa0857a, nbytes: 1368, type: <class 'numpy.ndarray'>>: Message truncated")
2023-08-19 05:54:00,535 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:58677 -> ucx://127.0.0.1:34209
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7f9eaceb9100 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-19 05:54:00,711 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:54:00,711 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-19 05:54:03,326 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-5366301a596b755bb8c33997d3ce7726', 6)
Function:  generate_chunk
args:      (6, 100000000, 8, 'build', 0.3, True)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

2023-08-19 05:54:03,338 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-3393696d3757f92da87d0dddd0c6ae01', 2)
Function:  generate_chunk
args:      (2, 100000000, 8, 'other', 0.3, True)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
