2023-05-26 07:13:30,333 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-udn26b6r', purging
2023-05-26 07:13:30,334 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:30,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:30,380 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:30,380 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:30,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:30,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:30,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:30,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:30,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:30,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:30,390 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:30,390 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:30,390 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:30,390 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:30,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:30,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:32,637 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:32,638 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:32,706 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:32,729 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:32,754 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:32,778 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:32,801 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:32,969 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:34,205 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0k5ukdja', purging
2023-05-26 07:13:34,205 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mpf_r6nq', purging
2023-05-26 07:13:34,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hr31c6g4', purging
2023-05-26 07:13:34,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vn7qbr7g', purging
2023-05-26 07:13:34,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pfuaz2z6', purging
2023-05-26 07:13:34,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3cu10yt4', purging
2023-05-26 07:13:34,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0rb0iqek', purging
2023-05-26 07:13:34,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wp95poui', purging
2023-05-26 07:13:34,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:34,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:34,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:34,243 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:34,288 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:34,288 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:34,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:34,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:34,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:34,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:34,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:34,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:34,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:34,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:34,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:34,603 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:36,468 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:36,533 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:36,559 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:36,585 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:36,611 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:36,635 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:36,661 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:36,833 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:38,020 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zzzf_s1s', purging
2023-05-26 07:13:38,020 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1_o3q6cr', purging
2023-05-26 07:13:38,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8vfm4va2', purging
2023-05-26 07:13:38,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bsjyx72f', purging
2023-05-26 07:13:38,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-htjkrnxy', purging
2023-05-26 07:13:38,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6xk2g2ue', purging
2023-05-26 07:13:38,022 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jyesilm1', purging
2023-05-26 07:13:38,022 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-21bkldma', purging
2023-05-26 07:13:38,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:38,023 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:38,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:38,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:38,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:38,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:38,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:38,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:38,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:38,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:38,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:38,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:38,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:38,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:38,361 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:38,361 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:40,340 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:40,362 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:40,425 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:40,457 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:40,482 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:40,506 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:40,530 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:40,692 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:41,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wme6jvy4', purging
2023-05-26 07:13:41,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sju1s33f', purging
2023-05-26 07:13:41,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fgwp9dmi', purging
2023-05-26 07:13:41,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w99vav0z', purging
2023-05-26 07:13:41,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i3xexach', purging
2023-05-26 07:13:41,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7kcq6a1o', purging
2023-05-26 07:13:41,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-041q534b', purging
2023-05-26 07:13:41,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6t7pec4p', purging
2023-05-26 07:13:41,894 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:41,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:41,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:41,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:42,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:42,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:42,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:42,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:42,070 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:42,070 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:42,072 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:42,072 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:42,082 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:42,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:42,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:42,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:44,173 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:44,251 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:44,280 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:44,304 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:44,331 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:44,357 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:44,387 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:44,557 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:45,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8q_byvei', purging
2023-05-26 07:13:45,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2pdq6vk0', purging
2023-05-26 07:13:45,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gcr7d4de', purging
2023-05-26 07:13:45,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xi84e4ws', purging
2023-05-26 07:13:45,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3tpyam5r', purging
2023-05-26 07:13:45,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kyuxy_9a', purging
2023-05-26 07:13:45,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k6hq0nkf', purging
2023-05-26 07:13:45,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n65tqrc8', purging
2023-05-26 07:13:45,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:45,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:45,839 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:45,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:45,894 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:45,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:45,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:45,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:45,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:45,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:45,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:45,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:45,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:45,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:46,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:46,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:48,000 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:48,022 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:48,046 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:48,132 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:48,133 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:48,157 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:48,182 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:48,341 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:49,586 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7vre7awf', purging
2023-05-26 07:13:49,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7____8nw', purging
2023-05-26 07:13:49,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jwz3am5v', purging
2023-05-26 07:13:49,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-smz7u6sq', purging
2023-05-26 07:13:49,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j2gf_gu_', purging
2023-05-26 07:13:49,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jju7p3mx', purging
2023-05-26 07:13:49,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n6faibp_', purging
2023-05-26 07:13:49,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nmwzgagx', purging
2023-05-26 07:13:49,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:49,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:49,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:49,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:49,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:49,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:49,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:49,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:49,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:49,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:49,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:49,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:49,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:49,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:49,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:49,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:51,889 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:51,917 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:51,941 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:51,969 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:51,999 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:52,029 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:52,065 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:52,232 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:53,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h96vdk2s', purging
2023-05-26 07:13:53,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uu0vzyu4', purging
2023-05-26 07:13:53,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s80s9mi8', purging
2023-05-26 07:13:53,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6dvpyxyg', purging
2023-05-26 07:13:53,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-77gxzi66', purging
2023-05-26 07:13:53,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cv9jmj44', purging
2023-05-26 07:13:53,449 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0i75oiou', purging
2023-05-26 07:13:53,449 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6t4stzp9', purging
2023-05-26 07:13:53,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:53,450 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:53,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:53,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:53,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:53,485 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:53,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:53,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:53,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:53,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:53,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:53,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:53,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:53,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:53,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:53,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:55,828 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:55,852 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:55,880 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:55,910 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:55,933 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:55,960 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:55,995 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:56,159 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:57,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-99xbvrcb', purging
2023-05-26 07:13:57,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wshzz9__', purging
2023-05-26 07:13:57,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1onjezle', purging
2023-05-26 07:13:57,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cqlv3beh', purging
2023-05-26 07:13:57,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w6g_5ogk', purging
2023-05-26 07:13:57,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2pqqfy1e', purging
2023-05-26 07:13:57,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4b352b39', purging
2023-05-26 07:13:57,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s9kakp3i', purging
2023-05-26 07:13:57,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:57,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:57,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:57,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:57,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:57,487 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:57,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:57,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:57,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:57,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:57,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:57,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:57,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:57,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:13:57,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:13:57,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:59,682 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:59,717 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:13:59,778 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:59,802 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:59,828 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:59,853 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:13:59,887 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:00,066 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:01,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vklhxrkn', purging
2023-05-26 07:14:01,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o02l0pv1', purging
2023-05-26 07:14:01,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c9r0j8io', purging
2023-05-26 07:14:01,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jkoy8etu', purging
2023-05-26 07:14:01,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ryifpm6a', purging
2023-05-26 07:14:01,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qynmuhtt', purging
2023-05-26 07:14:01,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s6m9abmo', purging
2023-05-26 07:14:01,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n3od_v8m', purging
2023-05-26 07:14:01,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:01,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:01,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:01,300 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:01,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:01,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:01,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:01,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:01,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:01,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:01,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:01,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:01,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:01,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:01,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:01,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:03,577 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:03,634 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:03,671 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:03,698 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:03,727 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:03,751 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:03,780 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:03,942 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:05,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-spto2glg', purging
2023-05-26 07:14:05,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kcfzh3x8', purging
2023-05-26 07:14:05,172 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c3yd5l5n', purging
2023-05-26 07:14:05,172 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w2shyw8w', purging
2023-05-26 07:14:05,172 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tjar52_z', purging
2023-05-26 07:14:05,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_1zz6zju', purging
2023-05-26 07:14:05,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6xy0srcj', purging
2023-05-26 07:14:05,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0sw5gg1', purging
2023-05-26 07:14:05,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:05,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:05,189 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:05,189 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:05,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:05,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:05,276 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:05,276 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:05,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:05,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:05,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:05,322 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:05,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:05,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:05,568 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:05,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:07,490 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:07,516 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:07,546 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:07,587 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:07,615 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:07,644 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:07,673 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:07,855 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:09,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sohr_2ke', purging
2023-05-26 07:14:09,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jh9pp_sw', purging
2023-05-26 07:14:09,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qkh01_q3', purging
2023-05-26 07:14:09,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ez5qll7', purging
2023-05-26 07:14:09,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kjgiczua', purging
2023-05-26 07:14:09,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n6fj7qxa', purging
2023-05-26 07:14:09,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gikybwua', purging
2023-05-26 07:14:09,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-net51xt1', purging
2023-05-26 07:14:09,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:09,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:09,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:09,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:09,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:09,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:09,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:09,197 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:09,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:09,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:09,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:09,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:09,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:09,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:09,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:09,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:11,448 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:11,521 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:11,547 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:11,573 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:11,598 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:11,624 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:11,649 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:11,831 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:13,063 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pg07xve6', purging
2023-05-26 07:14:13,063 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mdso0sg4', purging
2023-05-26 07:14:13,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h7tnngcx', purging
2023-05-26 07:14:13,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ch3ggq1d', purging
2023-05-26 07:14:13,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mkc02cm6', purging
2023-05-26 07:14:13,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xr9262t3', purging
2023-05-26 07:14:13,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-94uthpsw', purging
2023-05-26 07:14:13,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nkgidt05', purging
2023-05-26 07:14:13,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:13,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:13,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:13,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:13,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:13,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:13,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:13,151 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:13,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:13,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:13,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:13,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:13,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:13,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:13,368 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:13,368 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:15,330 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:15,402 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:15,426 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:15,449 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:15,476 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:15,501 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:15,526 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:15,672 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:16,858 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-78nvxyj2', purging
2023-05-26 07:14:16,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nz905i_r', purging
2023-05-26 07:14:16,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p_ntn7vp', purging
2023-05-26 07:14:16,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-29nk_l4l', purging
2023-05-26 07:14:16,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-76_ux5kj', purging
2023-05-26 07:14:16,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5ef21c05', purging
2023-05-26 07:14:16,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-05rl8r06', purging
2023-05-26 07:14:16,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wwp7gv2c', purging
2023-05-26 07:14:16,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:16,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:16,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:16,929 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:16,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:16,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:16,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:16,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:16,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:16,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:17,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:17,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:17,151 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:17,151 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:17,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:17,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:19,089 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 07:14:19,284 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:19,285 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:19,296 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:19,305 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:19,314 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:19,429 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:20,636 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-acb88b1e', purging
2023-05-26 07:14:20,636 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ngglz3d3', purging
2023-05-26 07:14:20,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gw2bivp8', purging
2023-05-26 07:14:20,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2dcxqq1b', purging
2023-05-26 07:14:20,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cli68irb', purging
2023-05-26 07:14:20,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p5c9dfub', purging
2023-05-26 07:14:20,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04tfaeof', purging
2023-05-26 07:14:20,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0y0hgfyt', purging
2023-05-26 07:14:20,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:20,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:20,704 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:20,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:20,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:20,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:20,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:20,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:20,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:20,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:20,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:20,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:20,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:20,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:22,602 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:22,666 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:22,689 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:22,712 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:22,737 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:22,767 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:22,918 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:24,095 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-da9wqtbb', purging
2023-05-26 07:14:24,095 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-trgr_upm', purging
2023-05-26 07:14:24,096 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_4b9x353', purging
2023-05-26 07:14:24,096 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bzqstbq5', purging
2023-05-26 07:14:24,096 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gnwl88bp', purging
2023-05-26 07:14:24,097 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yp2mpmkl', purging
2023-05-26 07:14:24,097 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jfekes4s', purging
2023-05-26 07:14:24,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:24,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:24,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:24,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:24,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:24,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:24,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:24,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:24,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:24,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:24,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:24,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:24,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:24,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:26,053 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:26,165 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:26,166 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:26,193 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:26,213 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:26,373 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:27,517 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-re3vzti4', purging
2023-05-26 07:14:27,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n5ep444n', purging
2023-05-26 07:14:27,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2m9js2m7', purging
2023-05-26 07:14:27,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ue634m04', purging
2023-05-26 07:14:27,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_s09hyf5', purging
2023-05-26 07:14:27,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qoroqycm', purging
2023-05-26 07:14:27,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d1356kng', purging
2023-05-26 07:14:27,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:27,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:27,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:27,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:27,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:27,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:27,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:27,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:27,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:27,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:27,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:27,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:29,242 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:29,303 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:29,325 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:29,351 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:29,379 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:29,526 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:30,630 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g4317piu', purging
2023-05-26 07:14:30,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ikbsi75q', purging
2023-05-26 07:14:30,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wp4i33am', purging
2023-05-26 07:14:30,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-of6fta1p', purging
2023-05-26 07:14:30,632 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-chzgbmwj', purging
2023-05-26 07:14:30,632 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tt64qvhz', purging
2023-05-26 07:14:30,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:30,633 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:30,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:30,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:30,797 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:30,797 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:30,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:30,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:30,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:30,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:31,000 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:31,000 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:32,301 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:32,359 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:32,379 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:32,422 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:32,446 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:32,647 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:33,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kmnrts1j', purging
2023-05-26 07:14:33,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cp2uk1fq', purging
2023-05-26 07:14:33,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9k9uca0e', purging
2023-05-26 07:14:33,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mvnc97_n', purging
2023-05-26 07:14:33,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fe6dtciw', purging
2023-05-26 07:14:33,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7q8lle8i', purging
2023-05-26 07:14:33,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:33,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:33,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:33,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:33,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:33,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:33,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:33,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:33,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:33,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:34,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:34,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:35,406 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:35,453 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:35,486 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:35,512 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:35,538 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:35,785 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:36,817 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-klcu7ls4', purging
2023-05-26 07:14:36,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8gzhgm91', purging
2023-05-26 07:14:36,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-noi8yife', purging
2023-05-26 07:14:36,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wu3_58e6', purging
2023-05-26 07:14:36,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d69au9gs', purging
2023-05-26 07:14:36,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9qg6xhl', purging
2023-05-26 07:14:36,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:36,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:36,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:36,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:36,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:36,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:36,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:36,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:36,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:36,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:37,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:37,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:38,483 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:38,553 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:38,577 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:38,624 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:38,882 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:39,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mpyyren7', purging
2023-05-26 07:14:39,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q0mzaswh', purging
2023-05-26 07:14:39,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2u7ev4y8', purging
2023-05-26 07:14:39,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0wqu4xv_', purging
2023-05-26 07:14:39,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3myzx0p_', purging
2023-05-26 07:14:39,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-patyykbu', purging
2023-05-26 07:14:39,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:39,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:39,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:39,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:39,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:39,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:40,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:40,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:40,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:40,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:41,467 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:41,489 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:41,520 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:41,541 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:41,794 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:42,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7kemssqk', purging
2023-05-26 07:14:42,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lsgbfu19', purging
2023-05-26 07:14:42,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e7tu2wdj', purging
2023-05-26 07:14:42,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7z0ie2_q', purging
2023-05-26 07:14:42,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3d5le54w', purging
2023-05-26 07:14:42,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:42,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:42,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:42,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:42,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:42,953 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:42,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:42,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:43,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:43,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:44,339 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:44,395 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:44,423 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:44,449 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:44,674 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:45,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t_smivu6', purging
2023-05-26 07:14:45,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-09gaq2uz', purging
2023-05-26 07:14:45,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n2t84c97', purging
2023-05-26 07:14:45,854 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mu66gews', purging
2023-05-26 07:14:45,854 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7cnijjgt', purging
2023-05-26 07:14:45,854 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:45,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:45,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:45,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:45,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:45,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:45,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:45,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:46,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:46,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:47,360 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:47,382 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:47,406 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:47,444 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:47,608 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:48,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g4_enqqp', purging
2023-05-26 07:14:48,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2xl6c0r2', purging
2023-05-26 07:14:48,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c6q52tqm', purging
2023-05-26 07:14:48,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f1d4tufb', purging
2023-05-26 07:14:48,773 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-crqnuv_d', purging
2023-05-26 07:14:48,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:48,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:48,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:48,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:48,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:48,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:48,906 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:48,906 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:49,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:49,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:50,256 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:50,308 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:50,332 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:50,358 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:50,509 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:51,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8c86vu3q', purging
2023-05-26 07:14:51,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kzdecc1j', purging
2023-05-26 07:14:51,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zo3vamql', purging
2023-05-26 07:14:51,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sps3xlj5', purging
2023-05-26 07:14:51,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uy83988j', purging
2023-05-26 07:14:51,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:51,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:51,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:51,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:51,760 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:51,760 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:51,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:51,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:51,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:51,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:53,224 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:53,275 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:53,300 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:53,327 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:53,481 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:54,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3u145gqh', purging
2023-05-26 07:14:54,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-96lfhy5a', purging
2023-05-26 07:14:54,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqmjagm8', purging
2023-05-26 07:14:54,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cwt9ujkf', purging
2023-05-26 07:14:54,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-min95c_0', purging
2023-05-26 07:14:54,670 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:54,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:54,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:54,687 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:54,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:54,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:54,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:54,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:54,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:54,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:56,158 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:56,212 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:56,236 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:56,257 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:56,435 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:57,552 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b4qtidt2', purging
2023-05-26 07:14:57,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a439o918', purging
2023-05-26 07:14:57,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pakv_7zb', purging
2023-05-26 07:14:57,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9uub0b6v', purging
2023-05-26 07:14:57,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-666djn58', purging
2023-05-26 07:14:57,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:57,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:57,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:57,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:57,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:57,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:57,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:57,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:14:57,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:14:57,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:59,038 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:59,062 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:59,087 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:14:59,110 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:14:59,340 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:00,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h56r4khc', purging
2023-05-26 07:15:00,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_g6v3916', purging
2023-05-26 07:15:00,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r0kqsu3o', purging
2023-05-26 07:15:00,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zmzptwkt', purging
2023-05-26 07:15:00,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sqmr2w94', purging
2023-05-26 07:15:00,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:00,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:00,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:00,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:00,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:00,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:00,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:00,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:00,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:00,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:01,977 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:02,005 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:02,038 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:02,062 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:02,226 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:03,386 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9v0i5f99', purging
2023-05-26 07:15:03,386 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j8b2urd7', purging
2023-05-26 07:15:03,387 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ol31j7bd', purging
2023-05-26 07:15:03,387 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pl2lypx0', purging
2023-05-26 07:15:03,387 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-obs8jflg', purging
2023-05-26 07:15:03,388 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:03,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:03,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:03,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:03,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:03,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:03,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:03,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:03,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:03,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:04,886 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:04,924 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:04,960 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:04,984 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:05,140 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:06,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s81dvivu', purging
2023-05-26 07:15:06,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_jo6noy', purging
2023-05-26 07:15:06,322 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o6qkr9mn', purging
2023-05-26 07:15:06,322 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d5znzjlr', purging
2023-05-26 07:15:06,322 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5vlahek6', purging
2023-05-26 07:15:06,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:06,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:06,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:06,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:06,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:06,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:06,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:06,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:06,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:06,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:07,798 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:07,821 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:07,867 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:07,888 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:08,049 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:09,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gp9h8zf2', purging
2023-05-26 07:15:09,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vb7hawmc', purging
2023-05-26 07:15:09,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qnyr2den', purging
2023-05-26 07:15:09,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z64dh7z0', purging
2023-05-26 07:15:09,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cunk8lpr', purging
2023-05-26 07:15:09,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:09,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:09,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:09,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:09,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:09,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:09,324 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:09,324 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:09,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:09,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:10,695 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:10,731 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:10,751 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:10,775 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:10,947 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:12,120 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hppcevhc', purging
2023-05-26 07:15:12,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bfuhjlet', purging
2023-05-26 07:15:12,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oyr1cqvw', purging
2023-05-26 07:15:12,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5862ifk', purging
2023-05-26 07:15:12,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sqhn31zr', purging
2023-05-26 07:15:12,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:12,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:12,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:12,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:12,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:12,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:12,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:12,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:12,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:12,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:13,632 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:13,656 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:13,679 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:13,711 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:13,882 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:15,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:15,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hn19qi57', purging
2023-05-26 07:15:15,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:15,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eea_vg3i', purging
2023-05-26 07:15:15,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-anly43el', purging
2023-05-26 07:15:15,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n0s9o1q8', purging
2023-05-26 07:15:15,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-89ipfn5q', purging
2023-05-26 07:15:15,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:15,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:15,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:15,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:15,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:15,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:15,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:15,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:16,567 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:16,619 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:16,639 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:16,661 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:16,838 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:18,025 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vxaf2yra', purging
2023-05-26 07:15:18,025 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-15nvbvnd', purging
2023-05-26 07:15:18,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2iwu6pe', purging
2023-05-26 07:15:18,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wuzgs_se', purging
2023-05-26 07:15:18,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7iy3tegi', purging
2023-05-26 07:15:18,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:18,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:18,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:18,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:18,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:18,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:18,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:18,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:18,287 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:18,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:19,577 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:19,647 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:19,648 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:19,657 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:19,802 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:21,063 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9hn58b45', purging
2023-05-26 07:15:21,063 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rvj0bhco', purging
2023-05-26 07:15:21,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rbmkrxkl', purging
2023-05-26 07:15:21,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i73indao', purging
2023-05-26 07:15:21,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i6j9essq', purging
2023-05-26 07:15:21,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:21,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:21,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:21,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:21,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:21,117 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:21,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:21,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:21,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:21,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:22,574 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:22,621 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:22,651 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:22,680 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:22,849 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:23,998 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qg1kll4e', purging
2023-05-26 07:15:23,998 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2vuae22k', purging
2023-05-26 07:15:23,998 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ouzf9x27', purging
2023-05-26 07:15:23,999 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ldxb73rq', purging
2023-05-26 07:15:23,999 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nc4x4uv7', purging
2023-05-26 07:15:23,999 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:23,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:24,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:24,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:24,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:24,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:24,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:24,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:24,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:24,320 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:25,500 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:25,548 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:25,573 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:25,599 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:25,761 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:26,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dkv_hfnn', purging
2023-05-26 07:15:26,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tptighfb', purging
2023-05-26 07:15:26,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2s1js32f', purging
2023-05-26 07:15:26,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0mdwdo01', purging
2023-05-26 07:15:26,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l86qblri', purging
2023-05-26 07:15:26,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:26,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:26,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:26,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:26,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:26,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:27,024 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:27,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:27,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:27,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:28,441 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:28,490 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:28,517 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:28,543 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 07:15:29,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0jgccr08', purging
2023-05-26 07:15:29,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hu7nvbxq', purging
2023-05-26 07:15:29,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8w82hfr7', purging
2023-05-26 07:15:29,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-is69kocu', purging
2023-05-26 07:15:29,914 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0fm1azcy', purging
2023-05-26 07:15:29,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:29,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:29,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:29,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:29,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:29,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:29,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:29,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:31,185 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:31,208 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:31,247 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:31,410 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:32,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9bsyh9aw', purging
2023-05-26 07:15:32,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qylots5b', purging
2023-05-26 07:15:32,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yfpejzm0', purging
2023-05-26 07:15:32,607 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bz_g0jpb', purging
2023-05-26 07:15:32,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:32,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:32,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:32,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:32,638 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:32,638 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:32,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:32,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:33,944 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:33,971 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:33,997 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:34,154 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:35,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i_s_n1ve', purging
2023-05-26 07:15:35,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jea7cody', purging
2023-05-26 07:15:35,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0zt7n1zh', purging
2023-05-26 07:15:35,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-znffmbk2', purging
2023-05-26 07:15:35,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:35,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:35,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:35,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:35,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:35,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:35,549 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:35,549 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:36,612 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:36,641 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:36,666 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:36,829 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:38,012 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ucg1np2_', purging
2023-05-26 07:15:38,013 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3q1hn79u', purging
2023-05-26 07:15:38,013 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-if5hma09', purging
2023-05-26 07:15:38,013 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-erdkypqq', purging
2023-05-26 07:15:38,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:38,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:38,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:38,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:38,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:38,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:38,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:38,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:39,255 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:39,299 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:39,327 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:39,492 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:40,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i376f0yk', purging
2023-05-26 07:15:40,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0xyr52a6', purging
2023-05-26 07:15:40,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8vstdj4d', purging
2023-05-26 07:15:40,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v4v3rptt', purging
2023-05-26 07:15:40,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:40,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:40,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:40,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:40,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:40,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:40,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:40,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:41,922 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:41,952 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:41,969 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:42,151 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:43,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e_owjshp', purging
2023-05-26 07:15:43,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-46tt50v2', purging
2023-05-26 07:15:43,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8zg9vgdi', purging
2023-05-26 07:15:43,322 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a7opf2e0', purging
2023-05-26 07:15:43,322 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:43,322 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:43,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:43,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:43,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:43,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:43,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:43,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:44,581 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:44,645 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:44,813 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:45,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ao97ec63', purging
2023-05-26 07:15:45,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-99ssngen', purging
2023-05-26 07:15:45,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qhuchi66', purging
2023-05-26 07:15:45,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fga_djy7', purging
2023-05-26 07:15:45,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:45,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:46,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:46,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:46,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:46,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:46,961 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:46,999 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:47,166 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:48,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_nlyzcpj', purging
2023-05-26 07:15:48,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fmurd5tj', purging
2023-05-26 07:15:48,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-emz1p3iy', purging
2023-05-26 07:15:48,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:48,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:48,380 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:48,380 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:48,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:48,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:49,404 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:49,429 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:49,597 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:50,756 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xyp_7yuq', purging
2023-05-26 07:15:50,756 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pf0n2xva', purging
2023-05-26 07:15:50,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wn3psmem', purging
2023-05-26 07:15:50,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:50,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:50,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:50,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:50,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:50,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:51,768 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:51,806 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:51,971 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:53,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-18cbftbi', purging
2023-05-26 07:15:53,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7533w_o', purging
2023-05-26 07:15:53,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kkbeeelg', purging
2023-05-26 07:15:53,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:53,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:53,173 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:53,173 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:53,343 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:53,343 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:54,259 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:54,281 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:54,452 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:55,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kbm9nrfw', purging
2023-05-26 07:15:55,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-72bhhp3u', purging
2023-05-26 07:15:55,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4k9l9kcn', purging
2023-05-26 07:15:55,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:55,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:55,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:55,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:55,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:55,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:56,685 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:56,713 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:56,886 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:58,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rbljed28', purging
2023-05-26 07:15:58,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nislnz9t', purging
2023-05-26 07:15:58,054 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n4vs2zxi', purging
2023-05-26 07:15:58,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:58,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:58,082 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:58,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:15:58,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:15:58,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:15:59,143 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:59,167 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:15:59,332 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:00,499 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0j15nng1', purging
2023-05-26 07:16:00,499 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-py29jlfu', purging
2023-05-26 07:16:00,499 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kd7pp1lt', purging
2023-05-26 07:16:00,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:00,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:00,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:00,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:00,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:00,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:01,527 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:01,554 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:01,735 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:02,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hb_o8do0', purging
2023-05-26 07:16:02,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rixtb6oi', purging
2023-05-26 07:16:02,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gihpbyyq', purging
2023-05-26 07:16:02,894 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:02,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:02,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:02,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:03,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:03,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:03,948 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:03,973 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:04,140 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:05,318 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eo540xtr', purging
2023-05-26 07:16:05,318 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5mxhj1me', purging
2023-05-26 07:16:05,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9o517xd4', purging
2023-05-26 07:16:05,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:05,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:05,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:05,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:05,506 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:05,506 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:06,370 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:06,393 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:06,558 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:07,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-16dbp8ig', purging
2023-05-26 07:16:07,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b34_3ap5', purging
2023-05-26 07:16:07,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-01ywp2y7', purging
2023-05-26 07:16:07,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:07,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:07,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:07,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:07,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:07,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:08,789 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:08,828 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:09,000 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:10,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-78hc6sl6', purging
2023-05-26 07:16:10,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-488rwwuv', purging
2023-05-26 07:16:10,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xuuskbf1', purging
2023-05-26 07:16:10,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:10,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:10,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:10,197 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:10,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:10,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:11,207 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:11,232 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:11,406 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:12,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zgpnkx21', purging
2023-05-26 07:16:12,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ti_t2cg', purging
2023-05-26 07:16:12,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gy0m7whf', purging
2023-05-26 07:16:12,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:12,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:12,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:12,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:12,790 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:12,790 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:13,603 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:13,641 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:13,817 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:14,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-79fa3d7d', purging
2023-05-26 07:16:14,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n7gl0314', purging
2023-05-26 07:16:14,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4e5jozm2', purging
2023-05-26 07:16:14,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:14,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:14,994 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:14,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:15,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:15,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:16,057 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:16,080 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:16,240 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:17,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gwnsnuwb', purging
2023-05-26 07:16:17,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-azqljpii', purging
2023-05-26 07:16:17,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-picc64a5', purging
2023-05-26 07:16:17,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:17,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:17,389 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:17,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:17,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:17,603 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:18,412 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:18,451 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:18,618 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:19,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sz0ki3wu', purging
2023-05-26 07:16:19,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gh5tdxvg', purging
2023-05-26 07:16:19,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cr6s0zij', purging
2023-05-26 07:16:19,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:19,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:19,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:19,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:19,972 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:19,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:20,843 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:20,866 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:21,028 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:22,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pk74x0ds', purging
2023-05-26 07:16:22,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tlv8y24w', purging
2023-05-26 07:16:22,209 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3h5wur8_', purging
2023-05-26 07:16:22,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:22,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:22,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:22,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:22,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:22,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:23,252 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:23,280 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:23,444 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:24,634 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d9nzw7zn', purging
2023-05-26 07:16:24,634 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f6sql_3i', purging
2023-05-26 07:16:24,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ucagg0i7', purging
2023-05-26 07:16:24,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:24,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:24,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:24,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:24,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:24,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:25,672 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:25,712 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:25,878 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:27,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b2bb0kzn', purging
2023-05-26 07:16:27,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7mkz36g0', purging
2023-05-26 07:16:27,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rm7mszal', purging
2023-05-26 07:16:27,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:27,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:27,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:27,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:27,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:27,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:28,120 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:28,149 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:28,326 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:29,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ns9vkd40', purging
2023-05-26 07:16:29,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ktrxykon', purging
2023-05-26 07:16:29,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-do1gfg5u', purging
2023-05-26 07:16:29,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:29,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:29,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:29,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:29,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:29,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:30,512 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:30,556 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:30,722 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:31,877 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-20zyy7b1', purging
2023-05-26 07:16:31,877 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f2xc7iy3', purging
2023-05-26 07:16:31,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z0aciomz', purging
2023-05-26 07:16:31,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:31,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:31,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:31,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:32,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:32,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:32,914 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:32,944 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:33,129 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:34,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u4n156w4', purging
2023-05-26 07:16:34,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4z_5mhk5', purging
2023-05-26 07:16:34,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-peg1y1n2', purging
2023-05-26 07:16:34,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:34,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:34,322 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:34,322 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:34,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:34,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:35,342 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:35,370 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:35,543 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:36,710 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q5d583q6', purging
2023-05-26 07:16:36,710 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vrizqtiq', purging
2023-05-26 07:16:36,711 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wgwwi3no', purging
2023-05-26 07:16:36,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:36,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:36,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:36,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:36,894 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:36,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:37,759 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:37,799 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:37,967 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:39,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hbxvpcns', purging
2023-05-26 07:16:39,153 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-862mgxqk', purging
2023-05-26 07:16:39,153 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0vk0alcw', purging
2023-05-26 07:16:39,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:39,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:39,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:39,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:39,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:39,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:40,221 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:40,244 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:40,413 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:41,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dj9crf08', purging
2023-05-26 07:16:41,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-08_egw4k', purging
2023-05-26 07:16:41,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-je_j4ijs', purging
2023-05-26 07:16:41,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:41,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:41,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:41,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:41,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:41,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:42,639 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:42,669 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:42,842 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:43,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xy9fm_el', purging
2023-05-26 07:16:43,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xn90nskv', purging
2023-05-26 07:16:43,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j2yrejfs', purging
2023-05-26 07:16:43,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:43,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:44,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:44,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:44,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:44,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:45,009 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:45,044 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:45,220 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:46,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2v10xc8m', purging
2023-05-26 07:16:46,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_pat5bxp', purging
2023-05-26 07:16:46,392 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bar6yoo7', purging
2023-05-26 07:16:46,392 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:46,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:46,443 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:46,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:46,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:46,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:47,420 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:47,449 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:47,613 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:48,810 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rb3fysf7', purging
2023-05-26 07:16:48,811 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z2fsnfp5', purging
2023-05-26 07:16:48,811 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rw459dis', purging
2023-05-26 07:16:48,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:48,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:48,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:48,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:48,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:48,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:49,836 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:49,875 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:50,042 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:51,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5yr31dx7', purging
2023-05-26 07:16:51,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jw6f208q', purging
2023-05-26 07:16:51,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a2zry03w', purging
2023-05-26 07:16:51,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:51,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:51,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:51,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:51,379 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:51,379 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:52,283 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:52,306 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:52,469 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:53,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:53,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j_xqidd7', purging
2023-05-26 07:16:53,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:53,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-75f_u7sl', purging
2023-05-26 07:16:53,682 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_7f95xxc', purging
2023-05-26 07:16:53,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:53,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:53,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:53,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:54,737 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:54,760 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:54,926 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:56,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:56,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lcigde1e', purging
2023-05-26 07:16:56,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:56,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6rrtxyyz', purging
2023-05-26 07:16:56,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5ry46bwk', purging
2023-05-26 07:16:56,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:56,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:56,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:56,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:57,186 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:57,226 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:57,396 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:58,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xuuq8cax', purging
2023-05-26 07:16:58,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kpip1dvl', purging
2023-05-26 07:16:58,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9pf9rnyr', purging
2023-05-26 07:16:58,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:58,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:58,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:58,597 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:16:58,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:16:58,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:16:59,727 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:59,749 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:16:59,923 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:01,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:01,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ju7a7iqs', purging
2023-05-26 07:17:01,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:01,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wj63qzdn', purging
2023-05-26 07:17:01,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s572kswl', purging
2023-05-26 07:17:01,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:01,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:01,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:01,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:02,204 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:02,227 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:02,391 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:03,598 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hnu_44jf', purging
2023-05-26 07:17:03,599 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr7btcb0', purging
2023-05-26 07:17:03,599 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_008bwjg', purging
2023-05-26 07:17:03,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:03,600 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:03,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:03,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:03,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:03,753 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:04,657 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:04,678 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:04,848 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:06,098 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vi4mkdf_', purging
2023-05-26 07:17:06,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sajp9p04', purging
2023-05-26 07:17:06,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hz2wgnqm', purging
2023-05-26 07:17:06,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:06,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:06,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:06,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:06,228 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:06,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:07,173 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:07,195 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:07,357 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:08,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_6pk1go', purging
2023-05-26 07:17:08,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cl2p6oc_', purging
2023-05-26 07:17:08,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6m5xvipi', purging
2023-05-26 07:17:08,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:08,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:08,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:08,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:08,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:08,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:09,637 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:09,657 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:09,827 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:10,998 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_jrm5skg', purging
2023-05-26 07:17:10,999 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wmbgfoih', purging
2023-05-26 07:17:10,999 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-32prgeqf', purging
2023-05-26 07:17:10,999 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:10,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:11,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:11,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:11,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:11,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:12,047 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:12,077 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:12,238 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:13,443 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ux090z77', purging
2023-05-26 07:17:13,444 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lfbppon0', purging
2023-05-26 07:17:13,444 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hd4qqckm', purging
2023-05-26 07:17:13,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:13,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:13,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:13,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:13,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:13,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:14,499 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:14,517 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:14,682 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:15,916 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yh0s2e9p', purging
2023-05-26 07:17:15,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pbi9065k', purging
2023-05-26 07:17:15,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lbfu9t3p', purging
2023-05-26 07:17:15,918 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:15,918 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:15,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:15,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:16,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:16,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:16,975 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:17,000 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:17,165 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:18,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:18,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a2f0h3lp', purging
2023-05-26 07:17:18,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:18,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_21jau_q', purging
2023-05-26 07:17:18,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-feiczkq3', purging
2023-05-26 07:17:18,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:18,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:18,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:18,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:19,419 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:19,447 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:19,617 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:20,805 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jfc9t77g', purging
2023-05-26 07:17:20,805 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4s8i4bol', purging
2023-05-26 07:17:20,806 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-noqt2j88', purging
2023-05-26 07:17:20,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:20,806 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:20,808 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:20,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:21,020 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:21,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:21,846 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:21,876 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:22,053 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:23,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-09p1qan8', purging
2023-05-26 07:17:23,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-di8mcx_5', purging
2023-05-26 07:17:23,234 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ykjqrkr', purging
2023-05-26 07:17:23,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:23,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:23,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:23,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:23,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:23,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:24,261 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:24,301 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:24,465 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:25,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-id7zqu4r', purging
2023-05-26 07:17:25,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gh5mkxye', purging
2023-05-26 07:17:25,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m9br53ee', purging
2023-05-26 07:17:25,674 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:25,674 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:25,697 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:25,697 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:25,854 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:25,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:26,733 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:26,762 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:26,928 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:28,136 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b1og5ypg', purging
2023-05-26 07:17:28,136 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vz_fm0nr', purging
2023-05-26 07:17:28,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u79tz921', purging
2023-05-26 07:17:28,137 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:28,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:28,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:28,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:28,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:28,304 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:29,192 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:29,205 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:29,372 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:30,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kazl4yti', purging
2023-05-26 07:17:30,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zwbfup_5', purging
2023-05-26 07:17:30,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_x9xdifk', purging
2023-05-26 07:17:30,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:30,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:30,594 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:30,594 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:30,784 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:30,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:31,667 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:31,687 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:31,857 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:33,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e_spdsx3', purging
2023-05-26 07:17:33,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m4tj_ywb', purging
2023-05-26 07:17:33,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-20x0876y', purging
2023-05-26 07:17:33,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:33,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:33,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:33,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:33,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:33,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 07:17:34,172 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:34,287 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:35,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zvtrc0id', purging
2023-05-26 07:17:35,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qfv3gk9x', purging
2023-05-26 07:17:35,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p5yg5e1e', purging
2023-05-26 07:17:35,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:35,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:35,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:35,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:36,369 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:36,541 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:37,728 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-edioz62w', purging
2023-05-26 07:17:37,728 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cc35m8ma', purging
2023-05-26 07:17:37,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:37,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:37,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:37,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:38,561 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:38,724 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:39,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c87hssz1', purging
2023-05-26 07:17:39,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tplx8sn4', purging
2023-05-26 07:17:39,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:39,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:40,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:40,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:40,763 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:40,933 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:42,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qd67seow', purging
2023-05-26 07:17:42,126 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pcfqde_t', purging
2023-05-26 07:17:42,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:42,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:42,298 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:42,298 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:42,964 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:43,138 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:44,334 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ynrozdbp', purging
2023-05-26 07:17:44,335 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c9n5dopu', purging
2023-05-26 07:17:44,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:44,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:44,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:44,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:45,191 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:45,351 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:46,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wucihv5d', purging
2023-05-26 07:17:46,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6rx4wpxp', purging
2023-05-26 07:17:46,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:46,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:46,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:46,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:47,407 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:47,581 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:48,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wo5hpn0n', purging
2023-05-26 07:17:48,773 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ikx73y9u', purging
2023-05-26 07:17:48,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:48,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:48,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:48,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:49,621 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:49,786 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:50,977 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cmm67aw4', purging
2023-05-26 07:17:50,977 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mjce45z7', purging
2023-05-26 07:17:50,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:50,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:51,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:51,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:51,796 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:51,963 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:53,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-370pn14p', purging
2023-05-26 07:17:53,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o90divvk', purging
2023-05-26 07:17:53,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:53,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:53,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:53,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:53,970 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:54,142 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:55,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4kfig3ni', purging
2023-05-26 07:17:55,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ba825c4e', purging
2023-05-26 07:17:55,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:55,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:55,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:55,485 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:56,159 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:56,319 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:57,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y6znqng5', purging
2023-05-26 07:17:57,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_s8qgp3r', purging
2023-05-26 07:17:57,517 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:57,517 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:57,662 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:57,662 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:17:58,353 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:58,526 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:17:59,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6ykepuoy', purging
2023-05-26 07:17:59,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-npha5d60', purging
2023-05-26 07:17:59,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:59,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:17:59,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:17:59,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:00,556 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:00,723 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:01,901 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kxdzeovi', purging
2023-05-26 07:18:01,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ifmnp5ix', purging
2023-05-26 07:18:01,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:01,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:02,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:02,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:02,755 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:02,922 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:04,110 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nrc5sx1a', purging
2023-05-26 07:18:04,110 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c6k94h1s', purging
2023-05-26 07:18:04,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:04,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:04,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:04,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:04,952 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:05,111 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:06,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q4jbmu_n', purging
2023-05-26 07:18:06,303 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nfqcgt5g', purging
2023-05-26 07:18:06,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:06,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:06,445 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:06,445 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:07,129 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:07,290 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:08,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v8tzzyn0', purging
2023-05-26 07:18:08,485 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g_8kmtuo', purging
2023-05-26 07:18:08,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:08,485 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:08,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:08,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:09,308 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:09,472 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:10,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3adwopid', purging
2023-05-26 07:18:10,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-as3p_94v', purging
2023-05-26 07:18:10,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:10,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:10,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:10,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:11,535 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:11,703 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:12,881 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ns88nmxl', purging
2023-05-26 07:18:12,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kxn6kqt1', purging
2023-05-26 07:18:12,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:12,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:13,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:13,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:13,710 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:13,872 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:15,056 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aor3elg2', purging
2023-05-26 07:18:15,056 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zfwfqjp9', purging
2023-05-26 07:18:15,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:15,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:15,205 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:15,205 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:15,909 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:16,083 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:17,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z9yr5f7q', purging
2023-05-26 07:18:17,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k6xing3b', purging
2023-05-26 07:18:17,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:17,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:17,442 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:17,442 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:18,106 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:18,280 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:19,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lyq7sohg', purging
2023-05-26 07:18:19,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ib4wohqf', purging
2023-05-26 07:18:19,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:19,485 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:19,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:19,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:20,329 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:20,497 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:21,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xg_xxh5m', purging
2023-05-26 07:18:21,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wizyv_70', purging
2023-05-26 07:18:21,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:21,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:21,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:21,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:22,506 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:22,673 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:23,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y4mtjz6q', purging
2023-05-26 07:18:23,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ad4s7r7', purging
2023-05-26 07:18:23,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:23,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:24,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:24,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:24,800 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:24,958 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:26,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-me58w8w2', purging
2023-05-26 07:18:26,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wfeqwyjx', purging
2023-05-26 07:18:26,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:26,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:26,334 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:26,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:27,012 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:27,178 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 633 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
