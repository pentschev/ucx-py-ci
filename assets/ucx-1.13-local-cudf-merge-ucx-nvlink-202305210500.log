2023-05-21 06:26:25,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:25,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:25,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:25,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:25,597 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:25,597 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:25,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:25,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:25,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:25,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:25,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:25,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:25,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:25,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:25,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:25,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:60759:0:60759] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  60759) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f6f080dd11c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7f6f080dd2ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7f6f080dd634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f6f993ac420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7f6f0815e28b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f6f081880b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7f6f0808f6a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7f6f0808fc28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7f6f080920fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f6f080e7639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f6f080921ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f6f0815af1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f6f0820a6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x56317ec77b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x56317ec68112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56317ec6127a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56317ec72c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56317ec6281b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56317ec72ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x56317ec80a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x56317ed909b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x56317ec1e817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x56317ec69f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x56317ec67d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56317ec72ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56317ec6281b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56317ec72ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56317ec6281b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56317ec72ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56317ec6281b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56317ec72ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56317ec6281b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56317ec6127a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56317ec72c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x56317ec66fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56317ec6127a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x56317ec80935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x56317ec81104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x56317ed47fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56317ec6b2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56317ec661bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56317ec72ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x56317ec80c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56317ec661bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56317ec72ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56317ec6281b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56317ec6127a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56317ec72c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56317ec6281b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56317ec72ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x56317ec62568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56317ec6127a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56317ec72c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x56317ec633cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56317ec6127a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x56317ec60f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56317ec60eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56317ed118bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x56317ed3fadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x56317ed3bc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x56317ed337ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x56317ed336bd]
=================================
2023-05-21 06:26:33,783 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:42307 -> ucx://127.0.0.1:37925
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f17e91ff100, tag: 0xa323795fef9ef024, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-21 06:26:33,858 - distributed.nanny - WARNING - Restarting worker
[dgx13:60762:0:60762] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  60762) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fbdb90e011c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7fbdb90e02ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7fbdb90e0634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fbe5c38e420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7fbdb916128b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fbdb918b0b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7fbdb90926a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7fbdb9092c28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7fbdb90950fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fbdb90ea639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fbdb90951ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fbdb915df1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fbdb920d6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55899ff2eb08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55899ff1f112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55899ff1827a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55899ff29c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55899ff1981b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55899ff3e70e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fbddbdfc2fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55899ff222bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55899fed5817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55899ff20f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55899ff1ed36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55899ff29ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55899ff1981b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55899ff29ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55899ff1981b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55899ff29ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55899ff1981b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55899ff29ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55899ff1981b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55899ff1827a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55899ff29c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55899ff1dfa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55899ff1827a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55899ff37935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55899ff38104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55899fffefc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55899ff222bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55899ff1d1bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55899ff29ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55899ff37c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55899ff1d1bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55899ff29ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55899ff1981b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55899ff1827a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55899ff29c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55899ff1981b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55899ff29ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55899ff19568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55899ff1827a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55899ff29c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55899ff1a3cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55899ff1827a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55899ff17f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55899ff17eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55899ffc88bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55899fff6adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55899fff2c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55899ffea7ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55899ffea6bd]
=================================
[dgx13:60756:0:60756] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  60756) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fa53c49311c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7fa53c4932ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7fa53c493634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fa5cd742420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7fa53c51428b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fa53c53e0b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7fa53c4456a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7fa53c445c28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7fa53c4480fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fa53c49d639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fa53c4481ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fa53c510f1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fa53c5c06e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x556b257d2b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x556b257c3112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556b257bc27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556b257cdc05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556b257bd81b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x556b257e270e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fa54d1a92fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x556b257c62bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x556b25779817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x556b257c4f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x556b257c2d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556b257cdef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556b257bd81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556b257cdef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556b257bd81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556b257cdef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556b257bd81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556b257cdef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556b257bd81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556b257bc27a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556b257cdc05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x556b257c1fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556b257bc27a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x556b257db935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x556b257dc104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x556b258a2fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x556b257c62bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x556b257c11bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556b257cdef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x556b257dbc72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x556b257c11bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556b257cdef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556b257bd81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556b257bc27a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556b257cdc05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556b257bd81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556b257cdef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x556b257bd568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556b257bc27a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556b257cdc05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x556b257be3cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556b257bc27a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x556b257bbf07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x556b257bbeb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x556b2586c8bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x556b2589aadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x556b25896c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x556b2588e7ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x556b2588e6bd]
=================================
2023-05-21 06:26:34,370 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:42307 -> ucx://127.0.0.1:34389
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f17e91ff140, tag: 0x2b3392d3275bee63, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-21 06:26:34,370 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34389
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f18c4ea6280, tag: 0x63f62b807ce09d35, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f18c4ea6280, tag: 0x63f62b807ce09d35, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-21 06:26:34,370 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34389
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7feaa310d280, tag: 0xbbfeaee57dc7e167, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7feaa310d280, tag: 0xbbfeaee57dc7e167, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-21 06:26:34,371 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34389
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f17e91ff300, tag: 0x87121da10adc3d64, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f17e91ff300, tag: 0x87121da10adc3d64, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-21 06:26:34,371 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48029 -> ucx://127.0.0.1:34389
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f0c929302c0, tag: 0x2e8a307adf2f0731, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-21 06:26:34,373 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34389
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f0c92930280, tag: 0x38e342d8a73b2d1d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f0c92930280, tag: 0x38e342d8a73b2d1d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-05-21 06:26:34,432 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37385 -> ucx://127.0.0.1:34389
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 289, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message
2023-05-21 06:26:34,446 - distributed.nanny - WARNING - Restarting worker
2023-05-21 06:26:34,451 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34389
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
[dgx13:60742:0:60742] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  60742) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f0c934a211c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7f0c934a22ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7f0c934a2634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f0d32759420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7f0c9352328b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f0c9354d0b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7f0c934546a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7f0c93454c28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7f0c934570fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f0c934ac639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f0c934571ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f0c9351ff1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f0c935cf6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55922b8fcb08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55922b8ed112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55922b8e627a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55922b8f7c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55922b8e781b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55922b90c70e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f0cb21c22fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55922b8f02bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55922b8a3817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55922b8eef83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55922b8ecd36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55922b8f7ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55922b8e781b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55922b8f7ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55922b8e781b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55922b8f7ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55922b8e781b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55922b8f7ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55922b8e781b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55922b8e627a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55922b8f7c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55922b8ebfa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55922b8e627a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55922b905935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55922b906104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55922b9ccfc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55922b8f02bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55922b8eb1bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55922b8f7ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55922b905c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55922b8eb1bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55922b8f7ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55922b8e781b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55922b8e627a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55922b8f7c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55922b8e781b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55922b8f7ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55922b8e7568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55922b8e627a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55922b8f7c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55922b8e83cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55922b8e627a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55922b8e5f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55922b8e5eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55922b9968bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55922b9c4adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55922b9c0c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55922b9b87ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55922b9b86bd]
=================================
2023-05-21 06:26:34,455 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44817
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f18c4ea6140, tag: 0xff5f33f9440055b8, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f18c4ea6140, tag: 0xff5f33f9440055b8, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-21 06:26:34,455 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:51509 -> ucx://127.0.0.1:44817
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f18c4ea6340, tag: 0x777b3ac500fd92ac, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
[dgx13:60753:0:60753] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  60753) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fb37406211c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7fb3740622ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7fb374062634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fb405241420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7fb361f7c28b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fb361fa60b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7fb361f126a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7fb361f12c28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7fb361f150fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fb37406c639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fb361f151ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fb361f78f1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fb3740bf6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x56006c228b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x56006c219112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56006c21227a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56006c223c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56006c21381b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x56006c23870e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fb3f80182fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56006c21c2bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x56006c1cf817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x56006c21af83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x56006c218d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56006c223ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56006c21381b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56006c223ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56006c21381b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56006c223ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56006c21381b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56006c223ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56006c21381b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56006c21227a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56006c223c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x56006c217fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56006c21227a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x56006c231935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x56006c232104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x56006c2f8fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56006c21c2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56006c2171bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56006c223ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x56006c231c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56006c2171bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56006c223ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56006c21381b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56006c21227a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56006c223c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56006c21381b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56006c223ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x56006c213568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56006c21227a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56006c223c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x56006c2143cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56006c21227a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x56006c211f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56006c211eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56006c2c28bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x56006c2f0adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x56006c2ecc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x56006c2e47ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x56006c2e46bd]
=================================
2023-05-21 06:26:34,529 - distributed.nanny - WARNING - Restarting worker
2023-05-21 06:26:34,530 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44817
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7feaa310d140, tag: 0x5c68292d07feafcd, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7feaa310d140, tag: 0x5c68292d07feafcd, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-21 06:26:34,560 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:42307 -> ucx://127.0.0.1:44817
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f17e91ff1c0, tag: 0xfa215f9cfdcfce4d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-21 06:26:34,561 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44817
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f17e91ff240, tag: 0x699f0d31bf75412e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f17e91ff240, tag: 0x699f0d31bf75412e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-1263' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Endpoint timeout
Task exception was never retrieved
future: <Task finished name='Task-1035' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-05-21 06:26:34,781 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37385
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7feaa310d1c0, tag: 0xffe7d5a1e0bfa837, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7feaa310d1c0, tag: 0xffe7d5a1e0bfa837, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-05-21 06:26:34,831 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:51509 -> ucx://127.0.0.1:37385
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f18c4ea6300, tag: 0xa73260abb1bdaab3, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-21 06:26:34,831 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37385
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f18c4ea61c0, tag: 0x9e3e27020ba63f3e, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f18c4ea61c0, tag: 0x9e3e27020ba63f3e, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-05-21 06:26:34,838 - distributed.nanny - WARNING - Restarting worker
2023-05-21 06:26:34,868 - distributed.nanny - WARNING - Restarting worker
2023-05-21 06:26:34,831 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37385
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-21 06:26:35,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:35,445 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:36,039 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:36,039 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:36,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:36,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:36,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:36,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:36,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:36,450 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:61264:0:61264] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  61264) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f9b41fcb11c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7f9b41fcb2ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7f9b41fcb634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f9be3119420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7f9b4406828b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f9b440920b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7f9b41f7d6a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7f9b41f7dc28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7f9b41f800fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f9b41fd5639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f9b41f801ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f9b44064f1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f9b441146e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55f73733fb08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55f737330112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f73732927a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f73733ac05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f73732a81b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f73733aef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55f737348a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55f7374589b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55f7372e6817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55f737331f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55f73732fd36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f73733aef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f73732a81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f73733aef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f73732a81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f73733aef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f73732a81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f73733aef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f73732a81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f73732927a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f73733ac05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55f73732efa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f73732927a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55f737348935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55f737349104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55f73740ffc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55f7373332bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f73732e1bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f73733aef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55f737348c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f73732e1bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f73733aef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f73732a81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f73732927a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f73733ac05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f73732a81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f73733aef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55f73732a568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f73732927a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f73733ac05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55f73732b3cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f73732927a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55f737328f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55f737328eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55f7373d98bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55f737407adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55f737403c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55f7373fb7ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55f7373fb6bd]
=================================
2023-05-21 06:26:36,694 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-d92840edec611999275787f93067a3f4', 1)
Function:  <dask.layers.CallableLazyImport object at 0x7fe557
args:      (               key   payload
shuffle                     
1            52448   8756114
1            31941  44889211
1            52457  50448230
1            31955  87481438
1            52461  52580283
...            ...       ...
1        799996619  61748559
1        799996620  36652948
1        799996660  57082908
1        799996667  38363460
1        799996671  22440876

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-21 06:26:36,709 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-d92840edec611999275787f93067a3f4', 5)
Function:  <dask.layers.CallableLazyImport object at 0x7f129b
args:      (               key   payload
shuffle                     
5            52449  90074687
5            31936  50885180
5            31948  71238054
5            31956  23760321
5           162528  45404539
...            ...       ...
5        799996635  17657835
5        799996636   5850430
5        799996649  99684933
5        799996657  57360342
5        799996666    641234

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-21 06:26:36,869 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-d92840edec611999275787f93067a3f4', 7)
Function:  <dask.layers.CallableLazyImport object at 0x7f142c
args:      (               key   payload
shuffle                     
7            52459  23956606
7            31937  74910701
7            52464  54235734
7            31944  58659154
7            52468  59826782
...            ...       ...
7        799996651  10976072
7        799996652  81644390
7        799996656  54078858
7        799996668  90124551
7        799996669  63737276

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-21 06:26:36,922 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:42307 -> ucx://127.0.0.1:52273
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f17e91ff300, tag: 0x2b5d85ae40ee49b4, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-21 06:26:37,019 - distributed.nanny - WARNING - Restarting worker
2023-05-21 06:26:38,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:38,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[1684650400.638815] [dgx13:60738:0]    cuda_copy_md.c:172  UCX  ERROR   cuMemAlloc_v2((CUdeviceptr*)address_p, *length_p)() failed: out of memory
[1684650400.638837] [dgx13:60738:0]         uct_mem.c:155  UCX  ERROR   failed to allocate 536870912 bytes using md cuda_cpy for ucp_rndv_frags: Input/output error
[1684650400.638843] [dgx13:60738:0]           mpool.c:226  UCX  ERROR Failed to allocate memory pool (name=ucp_rndv_frags) chunk: Out of memory
[dgx13:60738:0:60738]        rndv.c:1332 Fatal: failed to allocate fragment memory buffer
==== backtrace (tid:  60738) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f17e9d8e11c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0xb8) [0x7f17e9d8b058]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_format+0x114) [0x7f17e9d8b174]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x70ee4) [0x7f17e9e33ee4]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_receive+0x46c) [0x7f17e9e34a3c]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_recv_nbx+0xc0a) [0x7f17e9e4d9ca]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_recv_nb+0x5a) [0x7f17e9e4cd9a]
 7  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x51f0d) [0x7f17e9ee4f0d]
 8  /opt/conda/envs/gdf/bin/python(+0x149dc7) [0x563a64ed4dc7]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0x158) [0x563a64ed31a8]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x563a64eb9d36]
11  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563a64eb327a]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563a64ec4c05]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x563a64eb53cb]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563a64eb327a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563a64ec4c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x563a64eb53cb]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x563a64ed970e]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x563a64eba923]
19  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x563a64ed970e]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x563a64eba923]
21  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x563a64ed970e]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x563a64eba923]
23  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x563a64ed970e]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x563a64eba923]
25  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x563a64ed970e]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x563a64eba923]
27  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x563a64ed970e]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x563a64eba923]
29  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x563a64ed970e]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x563a64eba923]
31  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x563a64ed970e]
32  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f18803d02fe]
33  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8b4e) [0x7f18803d0b4e]
34  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x563a64ebd2bc]
35  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x563a64e70817]
36  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x563a64ebbf83]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x563a64eb9d36]
38  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563a64ec4ef3]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563a64eb481b]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563a64ec4ef3]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563a64eb481b]
42  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563a64ec4ef3]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563a64eb481b]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563a64ec4ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563a64eb481b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563a64eb327a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563a64ec4c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x563a64eb8fa7]
49  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563a64eb327a]
50  /opt/conda/envs/gdf/bin/python(+0x147935) [0x563a64ed2935]
51  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x563a64ed3104]
52  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x563a64f99fc8]
53  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x563a64ebd2bc]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x563a64eb81bb]
55  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563a64ec4ef3]
56  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x563a64ed2c72]
57  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x563a64eb81bb]
58  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563a64ec4ef3]
59  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563a64eb481b]
60  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563a64eb327a]
61  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563a64ec4c05]
=================================
2023-05-21 06:26:40,885 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:42307
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f9102bf31c0, tag: 0x2a6bb782355fffd5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f9102bf31c0, tag: 0x2a6bb782355fffd5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-21 06:26:40,885 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:42307
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fdf741d1180, tag: 0x488afe5230d90ec3, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fdf741d1180, tag: 0x488afe5230d90ec3, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-21 06:26:40,885 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:42307
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f9cac28a140, tag: 0x7fb2e507825d84e5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f9cac28a140, tag: 0x7fb2e507825d84e5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-21 06:26:40,920 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:42307
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 708, in recv
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 355, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXError: Endpoint 0x7feaa310d180 error: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError('Endpoint 0x7feaa310d180 error: Endpoint timeout')
2023-05-21 06:26:40,921 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40011 -> ucx://127.0.0.1:42307
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7feaa310d3c0 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-21 06:26:40,927 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:42307
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 708, in recv
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 355, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXError: Endpoint 0x7f18c4ea6240 error: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError('Endpoint 0x7f18c4ea6240 error: Endpoint timeout')
2023-05-21 06:26:40,930 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:51509 -> ucx://127.0.0.1:42307
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7f18c4ea63c0 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-21 06:26:40,938 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:42307
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-21 06:26:40,964 - distributed.nanny - WARNING - Restarting worker
[dgx13:61272:0:61272] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  61272) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f9cace3c11c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7f9cace3c2ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7f9cace3c634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f9d4bf6d420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7f9cacebd28b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f9cacee70b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7f9cacdee6a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7f9cacdeec28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7f9cacdf10fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f9cace46639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f9cacdf11ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f9caceb9f1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f9cacf696e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55e9ae395b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55e9ae386112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e9ae37f27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e9ae390c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e9ae38081b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e9ae390ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55e9ae39ea16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55e9ae4ae9b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55e9ae33c817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55e9ae387f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55e9ae385d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e9ae390ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e9ae38081b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e9ae390ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e9ae38081b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e9ae390ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e9ae38081b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e9ae390ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e9ae38081b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e9ae37f27a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e9ae390c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55e9ae384fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e9ae37f27a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55e9ae39e935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55e9ae39f104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55e9ae465fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55e9ae3892bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55e9ae3841bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e9ae390ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55e9ae39ec72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55e9ae3841bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e9ae390ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e9ae38081b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e9ae37f27a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e9ae390c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e9ae38081b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e9ae390ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55e9ae380568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e9ae37f27a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e9ae390c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55e9ae3813cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e9ae37f27a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55e9ae37ef07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55e9ae37eeb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55e9ae42f8bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55e9ae45dadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55e9ae459c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55e9ae4517ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55e9ae4516bd]
=================================
2023-05-21 06:26:41,287 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52209 -> ucx://127.0.0.1:52863
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 355, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXError: Endpoint 0x7fdf741d1340 error: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-21 06:26:41,348 - distributed.nanny - WARNING - Restarting worker
2023-05-21 06:26:41,550 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:51509 -> ucx://127.0.0.1:52863
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f18c4ea6280, tag: 0xc3bd201f59f00317, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
[dgx13:61283:0:61283] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  61283) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f91037aa11c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7f91037aa2ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7f91037aa634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f91a28de420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7f910382b28b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f91038550b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7f910375c6a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7f910375cc28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7f910375f0fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f91037b4639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f910375f1ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f9103827f1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f91038d76e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x555fb79f6b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x555fb79e7112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555fb79e027a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555fb79f1c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555fb79e181b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555fb79f1ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x555fb79ffa16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x555fb7b0f9b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x555fb799d817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x555fb79e8f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x555fb79e6d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555fb79f1ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555fb79e181b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555fb79f1ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555fb79e181b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555fb79f1ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555fb79e181b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555fb79f1ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555fb79e181b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555fb79e027a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555fb79f1c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x555fb79e5fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555fb79e027a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x555fb79ff935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x555fb7a00104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x555fb7ac6fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x555fb79ea2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x555fb79e51bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555fb79f1ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x555fb79ffc72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x555fb79e51bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555fb79f1ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555fb79e181b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555fb79e027a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555fb79f1c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555fb79e181b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555fb79f1ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x555fb79e1568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555fb79e027a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555fb79f1c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x555fb79e23cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555fb79e027a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x555fb79dff07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x555fb79dfeb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x555fb7a908bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x555fb7abeadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x555fb7abac24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x555fb7ab27ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x555fb7ab26bd]
=================================
2023-05-21 06:26:41,876 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45499
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f18c4ea61c0, tag: 0xcc61a5031a4777be, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f18c4ea61c0, tag: 0xcc61a5031a4777be, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-05-21 06:26:41,876 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45499
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7feaa310d200, tag: 0x893f31d54f9ebc2c, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7feaa310d200, tag: 0x893f31d54f9ebc2c, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-05-21 06:26:41,877 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34901 -> ucx://127.0.0.1:45499
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc3bc123100, tag: 0x96b3abacc160fe99, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-21 06:26:41,881 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45499
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-21 06:26:41,944 - distributed.nanny - WARNING - Restarting worker
2023-05-21 06:26:41,978 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45499
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #011] ep: 0x7fdf741d11c0, tag: 0xd6e21c04b0981990, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #011] ep: 0x7fdf741d11c0, tag: 0xd6e21c04b0981990, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-21 06:26:42,581 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45499
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2907, in get_data_from_worker
    await comm.write("OK")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 289, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message
2023-05-21 06:26:42,602 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:42,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:42,770 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34901
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #032] ep: 0x7fdf741d1340, tag: 0x7833667324f52e71, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #032] ep: 0x7fdf741d1340, tag: 0x7833667324f52e71, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-21 06:26:42,877 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34901
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #034] ep: 0x7f18c4ea6280, tag: 0xb684a887a6a40f09, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #034] ep: 0x7f18c4ea6280, tag: 0xb684a887a6a40f09, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-21 06:26:42,943 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r0xh8qfr', purging
2023-05-21 06:26:42,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:42,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:42,994 - distributed.nanny - WARNING - Restarting worker
Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Exception ignored in: 'cupy.cuda.thrust.cupy_malloc'
Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-21 06:26:43,205 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-5366301a596b755bb8c33997d3ce7726', 6)
Function:  generate_chunk
args:      (6, 100000000, 8, 'build', 0.3, True)
kwargs:    {}
Exception: "RuntimeError('transform: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered')"

2023-05-21 06:26:43,215 - distributed.worker - WARNING - Compute Failed
Key:       ('assign-4b4ba4ec2b5fbf7b0eb9abb76062f4ab', 1)
Function:  subgraph_callable-feb21b01-4e95-4a6c-aa50-872e2f18
args:      (< could not convert arg to str >)
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/include/cudf/table/table_device_view.cuh:269: 700 cudaErrorIllegalAddress an illegal memory access was encountered')"

2023-05-21 06:26:43,218 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-5366301a596b755bb8c33997d3ce7726', 7)
Function:  generate_chunk
args:      (7, 100000000, 8, 'build', 0.3, True)
kwargs:    {}
Exception: "CUDADriverError('CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered')"

2023-05-21 06:26:43,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:43,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:43,542 - distributed.worker - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-21 06:26:43,543 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 830, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 987, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-21 06:26:43,616 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2023-05-21 06:26:43,620 - distributed.core - ERROR - unpack(b) received extra data.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = await offload(_from_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1442, in run_in_executor_with_context
    return await loop.run_in_executor(
  File "/opt/conda/envs/gdf/lib/python3.9/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1443, in <lambda>
    executor, lambda: context.run(func, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2023-05-21 06:26:43,620 - distributed.worker - ERROR - unpack(b) received extra data.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = await offload(_from_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1442, in run_in_executor_with_context
    return await loop.run_in_executor(
  File "/opt/conda/envs/gdf/lib/python3.9/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1443, in <lambda>
    executor, lambda: context.run(func, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2023-05-21 06:26:43,690 - distributed.worker - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-21 06:26:43,690 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 830, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 987, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-21 06:26:43,855 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2023-05-21 06:26:43,862 - distributed.worker - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-21 06:26:43,862 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 830, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 987, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-21 06:26:43,868 - distributed.core - ERROR - unpack(b) received extra data.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2023-05-21 06:26:43,868 - distributed.worker - ERROR - unpack(b) received extra data.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2023-05-21 06:26:43,873 - distributed.worker - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1049, in send_recv
    raise exc.with_traceback(tb)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 830, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 987, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-21 06:26:43,879 - distributed.worker - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-21 06:26:43,879 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 830, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 987, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-21 06:26:44,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:44,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:26:45,723 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-21 06:26:45,724 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
[1684650405.733720] [dgx13:61586:0]    cuda_copy_md.c:172  UCX  ERROR   cuMemAlloc_v2((CUdeviceptr*)address_p, *length_p)() failed: out of memory
[1684650405.733736] [dgx13:61586:0]         uct_mem.c:155  UCX  ERROR   failed to allocate 536870912 bytes using md cuda_cpy for ucp_rndv_frags: Input/output error
[1684650405.733741] [dgx13:61586:0]           mpool.c:226  UCX  ERROR Failed to allocate memory pool (name=ucp_rndv_frags) chunk: Out of memory
[dgx13:61586:0:61586]        rndv.c:1332 Fatal: failed to allocate fragment memory buffer
==== backtrace (tid:  61586) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f55d1deb11c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0xb8) [0x7f55d1de8058]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_format+0x114) [0x7f55d1de8174]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x70ee4) [0x7f55d1e90ee4]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_receive+0x46c) [0x7f55d1e91a3c]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_recv_nbx+0xc0a) [0x7f55d1eaa9ca]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_recv_nb+0x5a) [0x7f55d1ea9d9a]
 7  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x51f0d) [0x7f55d1f41f0d]
 8  /opt/conda/envs/gdf/bin/python(+0x149dc7) [0x558a5eed3dc7]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0x158) [0x558a5eed21a8]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x558a5eeb8d36]
11  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x558a5eeb227a]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x558a5eec3c05]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x558a5eeb43cb]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x558a5eeb227a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x558a5eec3c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x558a5eeb43cb]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558a5eed870e]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558a5eeb9923]
19  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558a5eed870e]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558a5eeb9923]
21  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558a5eed870e]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558a5eeb9923]
23  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558a5eed870e]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558a5eeb9923]
25  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558a5eed870e]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558a5eeb9923]
27  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558a5eed870e]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558a5eeb9923]
29  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558a5eed870e]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558a5eeb9923]
31  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558a5eed870e]
32  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f56684582fe]
33  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8b4e) [0x7f5668458b4e]
34  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x558a5eebc2bc]
35  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x558a5ee6f817]
36  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x558a5eebaf83]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x558a5eeb8d36]
38  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558a5eec3ef3]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558a5eeb381b]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558a5eec3ef3]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558a5eeb381b]
42  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558a5eec3ef3]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558a5eeb381b]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558a5eec3ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558a5eeb381b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x558a5eeb227a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x558a5eec3c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x558a5eeb7fa7]
49  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x558a5eeb227a]
50  /opt/conda/envs/gdf/bin/python(+0x147935) [0x558a5eed1935]
51  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x558a5eed2104]
52  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x558a5ef98fc8]
53  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x558a5eebc2bc]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x558a5eeb71bb]
55  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558a5eec3ef3]
56  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x558a5eed1c72]
57  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x558a5eeb71bb]
58  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558a5eec3ef3]
59  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558a5eeb381b]
60  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x558a5eeb227a]
61  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x558a5eec3c05]
=================================
2023-05-21 06:26:46,033 - distributed.nanny - WARNING - Restarting worker
2023-05-21 06:26:47,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-21 06:26:47,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-21 06:27:12,896 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34901
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:34901 after 30 s
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
