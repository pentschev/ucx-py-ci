2022-12-01 00:49:03,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-12-01 00:49:03,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-12-01 00:49:03,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-12-01 00:49:03,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-12-01 00:49:03,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-12-01 00:49:03,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-12-01 00:49:03,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-12-01 00:49:03,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-12-01 00:49:03,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-12-01 00:49:03,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-12-01 00:49:03,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-12-01 00:49:03,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-12-01 00:49:03,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-12-01 00:49:03,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2022-12-01 00:49:03,433 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-12-01 00:49:03,433 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:16641:0:16641] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  16641) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2d4) [0x7fe9c49b4014]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2e1ef) [0x7fe9c49b41ef]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2e514) [0x7fe9c49b4514]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7fea6356f980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fe9c4c39d44]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fe9c4c6a7d8]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x207bf) [0x7fe9c47697bf]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x20d94) [0x7fe9c4769d94]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x231e8) [0x7fe9c476c1e8]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fe9c49be6e9]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fe9c476c28b]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fe9c4c3659a]
12  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272b9) [0x7fe9c4ef02b9]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x132417) [0x561e7ba09417]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d2) [0x561e7ba16212]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x200d) [0x561e7b9f581d]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x9f6) [0x561e7b9f2c66]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x18c) [0x561e7ba043fc]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x67d) [0x561e7b9f3e8d]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0xf6) [0x561e7ba04366]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13cafb) [0x561e7ba13afb]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x24575a) [0x561e7bb1c75a]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xdb5b4) [0x561e7b9b25b4]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1241a6) [0x561e7b9fb1a6]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x6f) [0x561e7ba1417f]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5964) [0x561e7b9f9174]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0xf6) [0x561e7ba04366]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x67d) [0x561e7b9f3e8d]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0xf6) [0x561e7ba04366]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x67d) [0x561e7b9f3e8d]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0xf6) [0x561e7ba04366]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x67d) [0x561e7b9f3e8d]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0xf6) [0x561e7ba04366]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x67d) [0x561e7b9f3e8d]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x9f6) [0x561e7b9f2c66]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x18c) [0x561e7ba043fc]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4870) [0x561e7b9f8080]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x9f6) [0x561e7b9f2c66]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x18c) [0x561e7ba043fc]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13cd32) [0x561e7ba13d32]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x25a) [0x561e7b9fbd1a]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1fdd49) [0x561e7bad4d49]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x35b) [0x561e7ba1629b]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x200d) [0x561e7b9f581d]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0xf6) [0x561e7ba04366]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13cd32) [0x561e7ba13d32]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d2) [0x561e7ba16212]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x200d) [0x561e7b9f581d]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0xf6) [0x561e7ba04366]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x67d) [0x561e7b9f3e8d]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2e1) [0x561e7b9f2551]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x18c) [0x561e7ba043fc]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x67d) [0x561e7b9f3e8d]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0xf6) [0x561e7ba04366]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x38b) [0x561e7b9f3b9b]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2e1) [0x561e7b9f2551]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x18c) [0x561e7ba043fc]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x10e8) [0x561e7b9f48f8]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2e1) [0x561e7b9f2551]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x561e7bab1909]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x561e7bab18cb]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1fb4a3) [0x561e7bad24a3]
=================================
2022-12-01 00:49:12,400 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40715 -> ucx://127.0.0.1:34421
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fdd6c3db380, tag: 0x7659700d226a6fcf, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1755, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 742, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2022-12-01 00:49:12,401 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:43083 -> ucx://127.0.0.1:34421
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f3111ae2400, tag: 0xd0ef4c847357685d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1755, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 742, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2022-12-01 00:49:12,401 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34421
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7f8cc8000180, tag: 0x8343efe2d6307ee7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2049, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2854, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 400, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 385, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2834, in _get_data
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 969, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 742, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7f8cc8000180, tag: 0x8343efe2d6307ee7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2022-12-01 00:49:12,401 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34421
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f16e457b180, tag: 0x9545c52e27aa34d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2049, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2854, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 400, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 385, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2834, in _get_data
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 969, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 742, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f16e457b180, tag: 0x9545c52e27aa34d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2022-12-01 00:49:12,403 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44341 -> ucx://127.0.0.1:34421
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f16e457b300, tag: 0x34bc294629a6f177, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1755, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 742, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2022-12-01 00:49:12,403 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34421
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fdd6c3db100, tag: 0xa2e68c3682ffcae, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2049, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2854, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 400, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 385, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2834, in _get_data
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 969, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 742, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fdd6c3db100, tag: 0xa2e68c3682ffcae, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2022-12-01 00:49:12,404 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34421
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f3111ae2280, tag: 0x59de7b70b002f1ca, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2049, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2854, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 400, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 385, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2834, in _get_data
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 969, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 742, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f3111ae2280, tag: 0x59de7b70b002f1ca, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2022-12-01 00:49:12,468 - distributed.nanny - WARNING - Restarting worker
2022-12-01 00:49:14,334 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2022-12-01 00:49:14,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
