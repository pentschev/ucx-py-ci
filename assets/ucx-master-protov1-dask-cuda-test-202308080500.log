============================= test session starts ==============================
platform linux -- Python 3.9.16, pytest-7.4.0, pluggy-1.2.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1181 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-08-08 05:37:11,614 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:11,618 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38307 instead
  warnings.warn(
2023-08-08 05:37:11,622 - distributed.scheduler - INFO - State start
2023-08-08 05:37:11,641 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:11,642 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-08-08 05:37:11,642 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38307/status
2023-08-08 05:37:11,697 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39497'
2023-08-08 05:37:11,713 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38709'
2023-08-08 05:37:11,715 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41251'
2023-08-08 05:37:11,722 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34675'
2023-08-08 05:37:13,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:13,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:13,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:13,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:13,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:13,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:13,237 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:13,239 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:13,240 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:13,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:13,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:13,274 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-08-08 05:37:13,292 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34517
2023-08-08 05:37:13,292 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34517
2023-08-08 05:37:13,292 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43887
2023-08-08 05:37:13,292 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-08 05:37:13,292 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:13,292 - distributed.worker - INFO -               Threads:                          4
2023-08-08 05:37:13,292 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-08 05:37:13,292 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ail7u6d2
2023-08-08 05:37:13,292 - distributed.worker - INFO - Starting Worker plugin PreImport-d807a40b-5109-46e8-9aa2-12c7ef91d88d
2023-08-08 05:37:13,293 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a7954fb0-1503-45c6-9795-7a3df69d8daa
2023-08-08 05:37:13,293 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b5ebf674-8764-4c66-8844-aa51f122555a
2023-08-08 05:37:13,293 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:13,307 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34517', status: init, memory: 0, processing: 0>
2023-08-08 05:37:13,319 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34517
2023-08-08 05:37:13,320 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44620
2023-08-08 05:37:13,320 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-08 05:37:13,320 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:13,322 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-08 05:37:14,504 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35755
2023-08-08 05:37:14,504 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35755
2023-08-08 05:37:14,504 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42071
2023-08-08 05:37:14,504 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-08 05:37:14,504 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:14,504 - distributed.worker - INFO -               Threads:                          4
2023-08-08 05:37:14,504 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-08 05:37:14,505 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sdc4_410
2023-08-08 05:37:14,505 - distributed.worker - INFO - Starting Worker plugin PreImport-78b56f00-90e4-4a97-be7c-378783aa69ec
2023-08-08 05:37:14,505 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c3f925c2-6264-4646-ad27-14cb60834d5f
2023-08-08 05:37:14,505 - distributed.worker - INFO - Starting Worker plugin RMMSetup-40b6b542-c6b2-4ada-a0f3-9e25bb0c2fbb
2023-08-08 05:37:14,506 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:14,507 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40161
2023-08-08 05:37:14,508 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40161
2023-08-08 05:37:14,508 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46801
2023-08-08 05:37:14,508 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-08 05:37:14,508 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:14,508 - distributed.worker - INFO -               Threads:                          4
2023-08-08 05:37:14,508 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-08 05:37:14,508 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9nh8871a
2023-08-08 05:37:14,508 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33457
2023-08-08 05:37:14,508 - distributed.worker - INFO - Starting Worker plugin PreImport-f27fe023-330e-4396-8a7d-ba143d41cc84
2023-08-08 05:37:14,508 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33457
2023-08-08 05:37:14,509 - distributed.worker - INFO - Starting Worker plugin RMMSetup-57dda028-137d-4150-902f-7d4edb6334c2
2023-08-08 05:37:14,509 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40045
2023-08-08 05:37:14,509 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-08 05:37:14,509 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cbcfe1f4-8f41-4351-87cf-aa3ca3b8cdff
2023-08-08 05:37:14,509 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:14,509 - distributed.worker - INFO -               Threads:                          4
2023-08-08 05:37:14,509 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-08 05:37:14,509 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-cqq85_7a
2023-08-08 05:37:14,509 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:14,509 - distributed.worker - INFO - Starting Worker plugin PreImport-ad7ebf31-d41e-4db5-ac7e-0ac7009133f7
2023-08-08 05:37:14,509 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-24ce532b-f22a-4b14-bdb3-7ecc79dbcf1f
2023-08-08 05:37:14,509 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cf24d090-5589-47cd-9437-0ebdcb6f5b95
2023-08-08 05:37:14,510 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:14,531 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35755', status: init, memory: 0, processing: 0>
2023-08-08 05:37:14,531 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35755
2023-08-08 05:37:14,531 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44638
2023-08-08 05:37:14,532 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-08 05:37:14,532 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33457', status: init, memory: 0, processing: 0>
2023-08-08 05:37:14,532 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:14,533 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33457
2023-08-08 05:37:14,533 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44656
2023-08-08 05:37:14,533 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-08 05:37:14,534 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:14,534 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40161', status: init, memory: 0, processing: 0>
2023-08-08 05:37:14,534 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40161
2023-08-08 05:37:14,534 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44646
2023-08-08 05:37:14,535 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-08 05:37:14,535 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:14,535 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-08 05:37:14,536 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-08 05:37:14,538 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-08 05:37:15,444 - distributed.scheduler - INFO - Receive client connection: Client-9e8459c0-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:15,445 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55390
2023-08-08 05:37:15,454 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-08 05:37:15,454 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-08 05:37:15,455 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-08 05:37:15,455 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-08 05:37:15,459 - distributed.scheduler - INFO - Remove client Client-9e8459c0-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:15,459 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55390; closing.
2023-08-08 05:37:15,459 - distributed.scheduler - INFO - Remove client Client-9e8459c0-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:15,460 - distributed.scheduler - INFO - Close client connection: Client-9e8459c0-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:15,460 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39497'. Reason: nanny-close
2023-08-08 05:37:15,461 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:15,461 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38709'. Reason: nanny-close
2023-08-08 05:37:15,462 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:15,462 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41251'. Reason: nanny-close
2023-08-08 05:37:15,462 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40161. Reason: nanny-close
2023-08-08 05:37:15,462 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:15,463 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33457. Reason: nanny-close
2023-08-08 05:37:15,463 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34675'. Reason: nanny-close
2023-08-08 05:37:15,463 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:15,464 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35755. Reason: nanny-close
2023-08-08 05:37:15,464 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-08 05:37:15,464 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34517. Reason: nanny-close
2023-08-08 05:37:15,464 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44646; closing.
2023-08-08 05:37:15,465 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-08 05:37:15,465 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40161', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:15,465 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40161
2023-08-08 05:37:15,465 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-08 05:37:15,466 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:15,466 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:15,466 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44656; closing.
2023-08-08 05:37:15,466 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-08 05:37:15,467 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:15,467 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33457', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:15,467 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33457
2023-08-08 05:37:15,467 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44638; closing.
2023-08-08 05:37:15,468 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:15,468 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35755', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:15,468 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35755
2023-08-08 05:37:15,469 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44620; closing.
2023-08-08 05:37:15,470 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34517', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:15,470 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34517
2023-08-08 05:37:15,470 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:37:16,477 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:37:16,477 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:37:16,478 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:37:16,478 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-08-08 05:37:16,479 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-08-08 05:37:18,363 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:18,367 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35239 instead
  warnings.warn(
2023-08-08 05:37:18,371 - distributed.scheduler - INFO - State start
2023-08-08 05:37:18,390 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:18,391 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-08 05:37:18,392 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35239/status
2023-08-08 05:37:18,516 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38717'
2023-08-08 05:37:18,535 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34223'
2023-08-08 05:37:18,536 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34915'
2023-08-08 05:37:18,543 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42047'
2023-08-08 05:37:18,552 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45341'
2023-08-08 05:37:18,560 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42807'
2023-08-08 05:37:18,568 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39111'
2023-08-08 05:37:18,575 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34355'
2023-08-08 05:37:18,743 - distributed.scheduler - INFO - Receive client connection: Client-a2949811-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:18,756 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47984
2023-08-08 05:37:20,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:20,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:20,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:20,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:20,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:20,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:20,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:20,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:20,227 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:20,227 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:20,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:20,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:20,236 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:20,241 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:20,241 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:20,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:20,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:20,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:20,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:20,256 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:20,271 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:20,277 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:20,280 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:20,289 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:22,887 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37595
2023-08-08 05:37:22,887 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37595
2023-08-08 05:37:22,887 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39323
2023-08-08 05:37:22,887 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:22,888 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:22,888 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:22,888 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:22,888 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sry7s63a
2023-08-08 05:37:22,888 - distributed.worker - INFO - Starting Worker plugin RMMSetup-07053015-972f-4655-9478-72b84997ec79
2023-08-08 05:37:23,024 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41409
2023-08-08 05:37:23,025 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41409
2023-08-08 05:37:23,025 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45069
2023-08-08 05:37:23,025 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,026 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,026 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:23,026 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:23,026 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5ozmphnx
2023-08-08 05:37:23,027 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3d3c4afe-003b-4f38-af36-4eac4aba124d
2023-08-08 05:37:23,033 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42405
2023-08-08 05:37:23,034 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42405
2023-08-08 05:37:23,033 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42555
2023-08-08 05:37:23,034 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43121
2023-08-08 05:37:23,034 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42555
2023-08-08 05:37:23,034 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,033 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35071
2023-08-08 05:37:23,034 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43197
2023-08-08 05:37:23,034 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,034 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35071
2023-08-08 05:37:23,034 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,034 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,034 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46809
2023-08-08 05:37:23,034 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:23,034 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,034 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:23,034 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,034 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:23,034 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-w01xeviu
2023-08-08 05:37:23,034 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:23,034 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-uhyool4i
2023-08-08 05:37:23,034 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:23,034 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:23,034 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ekj9iwsu
2023-08-08 05:37:23,034 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1d453af1-9cdb-45ef-b5b5-694d9b551d11
2023-08-08 05:37:23,035 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d100933b-34fa-47ff-bbb5-6ee67f456704
2023-08-08 05:37:23,035 - distributed.worker - INFO - Starting Worker plugin RMMSetup-df1821bb-8f9b-4aed-a7f8-09f70fe2382e
2023-08-08 05:37:23,068 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e5ef2ab0-8bf2-4afd-9cec-8077a587838b
2023-08-08 05:37:23,069 - distributed.worker - INFO - Starting Worker plugin PreImport-5c920767-67a0-4482-86be-eb5b83c9272a
2023-08-08 05:37:23,069 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,080 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46539
2023-08-08 05:37:23,081 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46539
2023-08-08 05:37:23,081 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41743
2023-08-08 05:37:23,080 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40253
2023-08-08 05:37:23,081 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,081 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40253
2023-08-08 05:37:23,081 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,081 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42943
2023-08-08 05:37:23,081 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,081 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,081 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:23,081 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:23,081 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-cm0h2x0g
2023-08-08 05:37:23,081 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:23,081 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:23,081 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mwiusofs
2023-08-08 05:37:23,081 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4a7ecf11-5441-4f77-ace1-ec80f8e15c0b
2023-08-08 05:37:23,082 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a7be4f49-7952-4277-8e0f-a02a3c7f60ad
2023-08-08 05:37:23,082 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44471
2023-08-08 05:37:23,083 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44471
2023-08-08 05:37:23,083 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45673
2023-08-08 05:37:23,083 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,083 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,083 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:23,083 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:23,083 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wh9uioz7
2023-08-08 05:37:23,084 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c994a4df-f214-4d2f-a7b0-cef2d10c94c8
2023-08-08 05:37:23,097 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37595', status: init, memory: 0, processing: 0>
2023-08-08 05:37:23,099 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37595
2023-08-08 05:37:23,099 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47998
2023-08-08 05:37:23,099 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,099 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,101 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:23,194 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-10742d1b-35b0-41ba-b3bf-93c6037b1749
2023-08-08 05:37:23,202 - distributed.worker - INFO - Starting Worker plugin PreImport-13c678d8-0cea-4820-b7b6-aa7d21d6178b
2023-08-08 05:37:23,203 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,205 - distributed.worker - INFO - Starting Worker plugin PreImport-95c44abe-bad0-4100-ac6a-a3ff6bd1a2b6
2023-08-08 05:37:23,205 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-115c52f4-c6d4-4225-97f8-3636a45c789a
2023-08-08 05:37:23,206 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,206 - distributed.worker - INFO - Starting Worker plugin PreImport-5b4448d8-4878-42d4-998d-ccf6f43ada15
2023-08-08 05:37:23,206 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-38cf7c8e-1dac-42f7-8e2c-95a37c0b4015
2023-08-08 05:37:23,206 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,212 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f2cb3f35-407b-4c69-b690-610d74a7d8f3
2023-08-08 05:37:23,214 - distributed.worker - INFO - Starting Worker plugin PreImport-aa753092-6455-452d-b40a-e3eccdb52101
2023-08-08 05:37:23,215 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,228 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bfa41277-2d80-455d-b07a-573a8eef891f
2023-08-08 05:37:23,228 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d741c964-2f9a-4cef-8c47-437a2958ae59
2023-08-08 05:37:23,228 - distributed.worker - INFO - Starting Worker plugin PreImport-c222a62a-d9f5-46c2-a303-d0db62df732e
2023-08-08 05:37:23,229 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,229 - distributed.worker - INFO - Starting Worker plugin PreImport-a2e8fcbf-fb49-43c2-a01a-b86a7a0d0ed7
2023-08-08 05:37:23,229 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,232 - distributed.worker - INFO - Starting Worker plugin PreImport-54bb5375-7690-4872-85db-bb95c0853e75
2023-08-08 05:37:23,232 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3fbfdd64-bac3-4b16-90ed-510f191c95bd
2023-08-08 05:37:23,233 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,237 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42555', status: init, memory: 0, processing: 0>
2023-08-08 05:37:23,237 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42555
2023-08-08 05:37:23,237 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48014
2023-08-08 05:37:23,238 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,238 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,241 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:23,243 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41409', status: init, memory: 0, processing: 0>
2023-08-08 05:37:23,244 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41409
2023-08-08 05:37:23,244 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48008
2023-08-08 05:37:23,245 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,245 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,246 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35071', status: init, memory: 0, processing: 0>
2023-08-08 05:37:23,246 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35071
2023-08-08 05:37:23,246 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48018
2023-08-08 05:37:23,247 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,247 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,247 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:23,250 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:23,255 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40253', status: init, memory: 0, processing: 0>
2023-08-08 05:37:23,256 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40253
2023-08-08 05:37:23,256 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48038
2023-08-08 05:37:23,256 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,256 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,257 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42405', status: init, memory: 0, processing: 0>
2023-08-08 05:37:23,257 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42405
2023-08-08 05:37:23,257 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48032
2023-08-08 05:37:23,258 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:23,258 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,258 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,261 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:23,268 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46539', status: init, memory: 0, processing: 0>
2023-08-08 05:37:23,268 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46539
2023-08-08 05:37:23,268 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48050
2023-08-08 05:37:23,269 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,269 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,270 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44471', status: init, memory: 0, processing: 0>
2023-08-08 05:37:23,270 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44471
2023-08-08 05:37:23,270 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48052
2023-08-08 05:37:23,271 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:23,271 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:23,272 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:23,274 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:23,381 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:23,381 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:23,381 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:23,381 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:23,381 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:23,382 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:23,382 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:23,382 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:23,386 - distributed.scheduler - INFO - Remove client Client-a2949811-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:23,386 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47984; closing.
2023-08-08 05:37:23,387 - distributed.scheduler - INFO - Remove client Client-a2949811-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:23,387 - distributed.scheduler - INFO - Close client connection: Client-a2949811-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:23,388 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42047'. Reason: nanny-close
2023-08-08 05:37:23,388 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:23,389 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38717'. Reason: nanny-close
2023-08-08 05:37:23,389 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:23,390 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44471. Reason: nanny-close
2023-08-08 05:37:23,390 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34223'. Reason: nanny-close
2023-08-08 05:37:23,390 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:23,390 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46539. Reason: nanny-close
2023-08-08 05:37:23,390 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34915'. Reason: nanny-close
2023-08-08 05:37:23,391 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:23,391 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37595. Reason: nanny-close
2023-08-08 05:37:23,391 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45341'. Reason: nanny-close
2023-08-08 05:37:23,392 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:23,392 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42555. Reason: nanny-close
2023-08-08 05:37:23,392 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48052; closing.
2023-08-08 05:37:23,392 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:23,392 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42807'. Reason: nanny-close
2023-08-08 05:37:23,392 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44471', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:23,392 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:23,392 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44471
2023-08-08 05:37:23,392 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:23,393 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35071. Reason: nanny-close
2023-08-08 05:37:23,393 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39111'. Reason: nanny-close
2023-08-08 05:37:23,393 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:23,393 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:23,394 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:23,394 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34355'. Reason: nanny-close
2023-08-08 05:37:23,394 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42405. Reason: nanny-close
2023-08-08 05:37:23,394 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:23,394 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:23,394 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41409. Reason: nanny-close
2023-08-08 05:37:23,394 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:23,395 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:23,395 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:23,395 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:23,395 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40253. Reason: nanny-close
2023-08-08 05:37:23,396 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:23,396 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:23,397 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48050; closing.
2023-08-08 05:37:23,397 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47998; closing.
2023-08-08 05:37:23,397 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44471
2023-08-08 05:37:23,397 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44471
2023-08-08 05:37:23,397 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:23,398 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:23,398 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46539', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:23,398 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46539
2023-08-08 05:37:23,398 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:23,398 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37595', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:23,398 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37595
2023-08-08 05:37:23,399 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:23,399 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48014; closing.
2023-08-08 05:37:23,399 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48018; closing.
2023-08-08 05:37:23,399 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:23,399 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48008; closing.
2023-08-08 05:37:23,400 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42555', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:23,400 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42555
2023-08-08 05:37:23,400 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35071', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:23,400 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35071
2023-08-08 05:37:23,401 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41409', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:23,401 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41409
2023-08-08 05:37:23,401 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48032; closing.
2023-08-08 05:37:23,402 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48038; closing.
2023-08-08 05:37:23,402 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42405', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:23,402 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42405
2023-08-08 05:37:23,403 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40253', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:23,403 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40253
2023-08-08 05:37:23,403 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:37:24,855 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:37:24,856 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:37:24,856 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:37:24,857 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-08 05:37:24,858 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-08-08 05:37:26,745 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:26,749 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34245 instead
  warnings.warn(
2023-08-08 05:37:26,753 - distributed.scheduler - INFO - State start
2023-08-08 05:37:26,773 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:26,774 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-08 05:37:26,774 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34245/status
2023-08-08 05:37:26,818 - distributed.scheduler - INFO - Receive client connection: Client-a793941f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:26,830 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49502
2023-08-08 05:37:26,845 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40627'
2023-08-08 05:37:26,861 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39977'
2023-08-08 05:37:26,863 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46547'
2023-08-08 05:37:26,870 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33593'
2023-08-08 05:37:26,879 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42451'
2023-08-08 05:37:26,887 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35349'
2023-08-08 05:37:26,895 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38987'
2023-08-08 05:37:26,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35233'
2023-08-08 05:37:28,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:28,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:28,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:28,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:28,537 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:28,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:28,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:28,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:28,543 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:28,543 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:28,564 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:28,564 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:28,565 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:28,567 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:28,569 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:28,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:28,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:28,582 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:28,582 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:28,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:28,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:28,625 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:28,627 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:28,630 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:31,356 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34405
2023-08-08 05:37:31,356 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34405
2023-08-08 05:37:31,356 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36281
2023-08-08 05:37:31,356 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,356 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,357 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:31,357 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:31,357 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qm3ymykh
2023-08-08 05:37:31,357 - distributed.worker - INFO - Starting Worker plugin PreImport-56fd7358-86ef-47ce-b94d-081f1d55e44e
2023-08-08 05:37:31,357 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0c63e582-dc6f-4f97-9c36-2e0ccedd0791
2023-08-08 05:37:31,358 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2c590947-fb99-4fb9-b9a9-5412fe2d4ea5
2023-08-08 05:37:31,358 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39551
2023-08-08 05:37:31,358 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39551
2023-08-08 05:37:31,359 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34831
2023-08-08 05:37:31,359 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,359 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,359 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:31,359 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:31,359 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pqbc892s
2023-08-08 05:37:31,360 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fa8b5124-c4dd-4034-ba27-4bdbe76e0c6a
2023-08-08 05:37:31,409 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38283
2023-08-08 05:37:31,409 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38283
2023-08-08 05:37:31,410 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44981
2023-08-08 05:37:31,410 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,410 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,410 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:31,410 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:31,410 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pwt4bzlr
2023-08-08 05:37:31,410 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44901
2023-08-08 05:37:31,410 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1c52a1fa-1ba5-4cc7-ab8d-cc2b57240975
2023-08-08 05:37:31,410 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44901
2023-08-08 05:37:31,411 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45043
2023-08-08 05:37:31,411 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,411 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,411 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:31,411 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:31,411 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-s7jnz83k
2023-08-08 05:37:31,411 - distributed.worker - INFO - Starting Worker plugin RMMSetup-15aa32c2-f103-4a1e-8cc2-9a69e61cbd11
2023-08-08 05:37:31,423 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,425 - distributed.worker - INFO - Starting Worker plugin PreImport-ce971479-5b45-43a9-afff-555f501c92a7
2023-08-08 05:37:31,425 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1c52690f-cef2-460b-9e1b-d5e988d97ea7
2023-08-08 05:37:31,425 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,427 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38299
2023-08-08 05:37:31,427 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38299
2023-08-08 05:37:31,427 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37639
2023-08-08 05:37:31,428 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,428 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,428 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:31,428 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:31,428 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bi58m0ky
2023-08-08 05:37:31,428 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4dfb6693-745b-43e8-a1ff-7f5644b66d80
2023-08-08 05:37:31,437 - distributed.worker - INFO - Starting Worker plugin PreImport-e2ca3aa4-a776-49f2-abe1-64d0a3307f9a
2023-08-08 05:37:31,437 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8865cdf5-a3b6-4f80-980a-e9bbe0d7b5e3
2023-08-08 05:37:31,438 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,440 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5377efef-805e-49a5-a3cd-aac54234e83d
2023-08-08 05:37:31,441 - distributed.worker - INFO - Starting Worker plugin PreImport-36060776-fc48-4fae-8454-a67175facbf4
2023-08-08 05:37:31,441 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-970f21a9-5265-4360-8a68-8fe67485ecf1
2023-08-08 05:37:31,441 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,441 - distributed.worker - INFO - Starting Worker plugin PreImport-3b2c1e40-d99b-4840-87e6-7c05e4131de7
2023-08-08 05:37:31,441 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,451 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39551', status: init, memory: 0, processing: 0>
2023-08-08 05:37:31,452 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39551
2023-08-08 05:37:31,452 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49600
2023-08-08 05:37:31,452 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,453 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,453 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34405', status: init, memory: 0, processing: 0>
2023-08-08 05:37:31,453 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34405
2023-08-08 05:37:31,453 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49588
2023-08-08 05:37:31,454 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,454 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,455 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:31,457 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:31,467 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38299', status: init, memory: 0, processing: 0>
2023-08-08 05:37:31,468 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38299
2023-08-08 05:37:31,468 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49618
2023-08-08 05:37:31,468 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,468 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,471 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:31,475 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44901', status: init, memory: 0, processing: 0>
2023-08-08 05:37:31,475 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44901
2023-08-08 05:37:31,475 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49628
2023-08-08 05:37:31,476 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,476 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,479 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:31,480 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38283', status: init, memory: 0, processing: 0>
2023-08-08 05:37:31,481 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38283
2023-08-08 05:37:31,481 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49612
2023-08-08 05:37:31,482 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,482 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,484 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:31,520 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38149
2023-08-08 05:37:31,520 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38149
2023-08-08 05:37:31,521 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41599
2023-08-08 05:37:31,521 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,521 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,521 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:31,521 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:31,521 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-p0f909v4
2023-08-08 05:37:31,521 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c7b26902-cd1a-42c0-8e18-e24b48581c34
2023-08-08 05:37:31,522 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34695
2023-08-08 05:37:31,523 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34695
2023-08-08 05:37:31,523 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36475
2023-08-08 05:37:31,523 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45479
2023-08-08 05:37:31,523 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36475
2023-08-08 05:37:31,523 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,523 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,523 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37317
2023-08-08 05:37:31,523 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,524 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,523 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:31,524 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:31,524 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8bg7skl4
2023-08-08 05:37:31,524 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:31,524 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:31,524 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wskusmf6
2023-08-08 05:37:31,524 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ae7be855-5e29-44ac-bf38-d86d5ae16ecd
2023-08-08 05:37:31,524 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a05dc19c-22b8-4d25-afc2-a6d04103e8ad
2023-08-08 05:37:31,530 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fd11f08e-5746-4b6f-8366-fba25df0aeee
2023-08-08 05:37:31,530 - distributed.worker - INFO - Starting Worker plugin PreImport-2b7c44ef-c2ec-4714-be60-221dbf78f708
2023-08-08 05:37:31,530 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,533 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a67a6d14-aa25-4d9e-a924-c544e33ce24d
2023-08-08 05:37:31,533 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-26b9c9bb-a0e5-4b6b-92b4-52a0c2406292
2023-08-08 05:37:31,533 - distributed.worker - INFO - Starting Worker plugin PreImport-99bebf49-bdc2-4f45-a27c-3daecb31e40f
2023-08-08 05:37:31,534 - distributed.worker - INFO - Starting Worker plugin PreImport-be250c81-5c14-4c73-8830-f3ee5f6f8c65
2023-08-08 05:37:31,534 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,534 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,556 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36475', status: init, memory: 0, processing: 0>
2023-08-08 05:37:31,556 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36475
2023-08-08 05:37:31,556 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49648
2023-08-08 05:37:31,557 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,557 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,557 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34695', status: init, memory: 0, processing: 0>
2023-08-08 05:37:31,558 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34695
2023-08-08 05:37:31,558 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49638
2023-08-08 05:37:31,558 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,558 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,558 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38149', status: init, memory: 0, processing: 0>
2023-08-08 05:37:31,559 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:31,559 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38149
2023-08-08 05:37:31,559 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49632
2023-08-08 05:37:31,560 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:31,560 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:31,560 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:31,562 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:31,610 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:31,610 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:31,610 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:31,610 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:31,610 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:31,610 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:31,611 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:31,611 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:31,615 - distributed.scheduler - INFO - Remove client Client-a793941f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:31,615 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49502; closing.
2023-08-08 05:37:31,615 - distributed.scheduler - INFO - Remove client Client-a793941f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:31,616 - distributed.scheduler - INFO - Close client connection: Client-a793941f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:31,617 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39977'. Reason: nanny-close
2023-08-08 05:37:31,617 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:31,617 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42451'. Reason: nanny-close
2023-08-08 05:37:31,618 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:31,618 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34405. Reason: nanny-close
2023-08-08 05:37:31,618 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40627'. Reason: nanny-close
2023-08-08 05:37:31,618 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:31,619 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44901. Reason: nanny-close
2023-08-08 05:37:31,619 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46547'. Reason: nanny-close
2023-08-08 05:37:31,619 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:31,620 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38299. Reason: nanny-close
2023-08-08 05:37:31,620 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33593'. Reason: nanny-close
2023-08-08 05:37:31,620 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:31,620 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39551. Reason: nanny-close
2023-08-08 05:37:31,620 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49588; closing.
2023-08-08 05:37:31,620 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35349'. Reason: nanny-close
2023-08-08 05:37:31,621 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:31,621 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:31,621 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34405', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:31,621 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34405
2023-08-08 05:37:31,621 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:31,621 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38283. Reason: nanny-close
2023-08-08 05:37:31,621 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38987'. Reason: nanny-close
2023-08-08 05:37:31,621 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:31,621 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:31,622 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35233'. Reason: nanny-close
2023-08-08 05:37:31,622 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38149. Reason: nanny-close
2023-08-08 05:37:31,622 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:31,622 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:31,622 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:31,622 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34405
2023-08-08 05:37:31,622 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36475. Reason: nanny-close
2023-08-08 05:37:31,622 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49628; closing.
2023-08-08 05:37:31,622 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:31,623 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:31,623 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49618; closing.
2023-08-08 05:37:31,623 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34405
2023-08-08 05:37:31,623 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34695. Reason: nanny-close
2023-08-08 05:37:31,623 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:31,623 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34405
2023-08-08 05:37:31,623 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44901', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:31,623 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44901
2023-08-08 05:37:31,624 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34405
2023-08-08 05:37:31,624 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:31,624 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38299', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:31,624 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38299
2023-08-08 05:37:31,624 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:31,624 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:31,624 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49600; closing.
2023-08-08 05:37:31,625 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:31,625 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39551', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:31,625 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39551
2023-08-08 05:37:31,625 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:31,625 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49612; closing.
2023-08-08 05:37:31,625 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:31,626 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49632; closing.
2023-08-08 05:37:31,626 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:31,626 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49648; closing.
2023-08-08 05:37:31,626 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:31,626 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38283', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:31,626 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38283
2023-08-08 05:37:31,627 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38149', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:31,627 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38149
2023-08-08 05:37:31,627 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36475', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:31,627 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36475
2023-08-08 05:37:31,628 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49638; closing.
2023-08-08 05:37:31,628 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34695', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:31,628 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34695
2023-08-08 05:37:31,629 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:37:33,034 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:37:33,034 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:37:33,034 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:37:33,035 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-08 05:37:33,036 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-08-08 05:37:34,968 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:34,973 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46631 instead
  warnings.warn(
2023-08-08 05:37:34,976 - distributed.scheduler - INFO - State start
2023-08-08 05:37:34,996 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:34,997 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-08 05:37:34,998 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46631/status
2023-08-08 05:37:35,044 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36845'
2023-08-08 05:37:35,058 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46647'
2023-08-08 05:37:35,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42153'
2023-08-08 05:37:35,069 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45129'
2023-08-08 05:37:35,077 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43179'
2023-08-08 05:37:35,086 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32917'
2023-08-08 05:37:35,093 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41753'
2023-08-08 05:37:35,102 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40045'
2023-08-08 05:37:35,289 - distributed.scheduler - INFO - Receive client connection: Client-ac73186d-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:35,303 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44468
2023-08-08 05:37:36,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:36,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:36,688 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:36,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:36,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:36,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:36,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:36,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:36,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:36,737 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:36,737 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:36,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:36,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:36,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:36,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:36,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:36,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:36,749 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:36,749 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:36,749 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:36,773 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:36,773 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:36,788 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:36,788 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:39,194 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41803
2023-08-08 05:37:39,196 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41803
2023-08-08 05:37:39,197 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34167
2023-08-08 05:37:39,197 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,197 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,197 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:39,197 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:39,197 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-fmhphh5c
2023-08-08 05:37:39,198 - distributed.worker - INFO - Starting Worker plugin PreImport-eb4899ee-909c-4827-9ad3-8e0f6d40225d
2023-08-08 05:37:39,198 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2255a059-bf0c-4306-ae30-872890abee18
2023-08-08 05:37:39,198 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8e4ee69b-2996-4ca5-890b-cecf5c0a4b2b
2023-08-08 05:37:39,413 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33389
2023-08-08 05:37:39,414 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33389
2023-08-08 05:37:39,414 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33961
2023-08-08 05:37:39,414 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,414 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,414 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:39,414 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:39,414 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-aos1yle3
2023-08-08 05:37:39,415 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fcdd3b30-a04a-4363-8cbd-c8febf35e481
2023-08-08 05:37:39,415 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34027
2023-08-08 05:37:39,416 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34027
2023-08-08 05:37:39,416 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38817
2023-08-08 05:37:39,416 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,416 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,416 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:39,416 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:39,416 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-n_69s82_
2023-08-08 05:37:39,416 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9f548d37-37bd-40b0-b894-a19d06ecfb38
2023-08-08 05:37:39,422 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45797
2023-08-08 05:37:39,423 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45797
2023-08-08 05:37:39,423 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46473
2023-08-08 05:37:39,423 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,423 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,423 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:39,423 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:39,423 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-c3znq45h
2023-08-08 05:37:39,424 - distributed.worker - INFO - Starting Worker plugin PreImport-bbcd733b-36df-4d0c-8d59-972c859d3099
2023-08-08 05:37:39,424 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-48c4bbac-3eb2-4153-b3dd-6d21ec470777
2023-08-08 05:37:39,424 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8e8274cf-3813-493a-92ec-2e6b7811803a
2023-08-08 05:37:39,450 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41131
2023-08-08 05:37:39,451 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41131
2023-08-08 05:37:39,451 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44161
2023-08-08 05:37:39,451 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,451 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,451 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:39,451 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:39,451 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pwmhxy_v
2023-08-08 05:37:39,452 - distributed.worker - INFO - Starting Worker plugin PreImport-499d8045-f635-4212-b619-c23994d6f8fb
2023-08-08 05:37:39,452 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2d13493f-5fd6-433d-b937-046b3622d153
2023-08-08 05:37:39,452 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7479e60f-bd3a-4f07-866a-e8bcec6ef479
2023-08-08 05:37:39,480 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46085
2023-08-08 05:37:39,480 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46085
2023-08-08 05:37:39,480 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41599
2023-08-08 05:37:39,480 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,481 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,481 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:39,481 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:39,481 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jh_8o1i3
2023-08-08 05:37:39,481 - distributed.worker - INFO - Starting Worker plugin PreImport-f583e93a-af0e-4b90-a76e-889c3e8d4655
2023-08-08 05:37:39,481 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a2e5b5de-8255-4588-a786-ea2b9bb04759
2023-08-08 05:37:39,482 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c561df7f-8752-4bee-9d66-4d1beb3e3b8f
2023-08-08 05:37:39,488 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33425
2023-08-08 05:37:39,489 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33425
2023-08-08 05:37:39,489 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44865
2023-08-08 05:37:39,489 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,489 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,489 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:39,490 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:39,490 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-u0oha6u9
2023-08-08 05:37:39,490 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d1404ca1-741d-4ac8-99e3-d212c46f24eb
2023-08-08 05:37:39,490 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44187
2023-08-08 05:37:39,491 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44187
2023-08-08 05:37:39,491 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32997
2023-08-08 05:37:39,491 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,491 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,491 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:39,491 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:39,491 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nd6il51v
2023-08-08 05:37:39,492 - distributed.worker - INFO - Starting Worker plugin RMMSetup-31af874c-3ffe-449f-8fa9-a6e4ac4108f5
2023-08-08 05:37:39,497 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,535 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41803', status: init, memory: 0, processing: 0>
2023-08-08 05:37:39,537 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41803
2023-08-08 05:37:39,537 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44492
2023-08-08 05:37:39,537 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,538 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,540 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:39,603 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-763ac405-a0d6-48eb-adfd-b595110a15bd
2023-08-08 05:37:39,603 - distributed.worker - INFO - Starting Worker plugin PreImport-c7fca7d8-1c4e-4042-a84c-e97deb568052
2023-08-08 05:37:39,604 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,612 - distributed.worker - INFO - Starting Worker plugin PreImport-24bddb78-3c9f-4b9a-a6f0-48ad23c6e8cc
2023-08-08 05:37:39,612 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d1a6b1e2-bf9f-4378-b518-12dc61a99193
2023-08-08 05:37:39,613 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,641 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33389', status: init, memory: 0, processing: 0>
2023-08-08 05:37:39,641 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33389
2023-08-08 05:37:39,642 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44518
2023-08-08 05:37:39,642 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,642 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,644 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:39,645 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34027', status: init, memory: 0, processing: 0>
2023-08-08 05:37:39,645 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34027
2023-08-08 05:37:39,646 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44504
2023-08-08 05:37:39,646 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,646 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,649 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:39,666 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,671 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,685 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-458079f1-6194-4d32-a292-b994e0aa39a4
2023-08-08 05:37:39,685 - distributed.worker - INFO - Starting Worker plugin PreImport-6d321790-0bf5-493a-8b7e-18bba66b3832
2023-08-08 05:37:39,685 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,686 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e4324861-53d0-45be-8326-bf59f29caf6b
2023-08-08 05:37:39,687 - distributed.worker - INFO - Starting Worker plugin PreImport-73be9876-2dcb-4586-ab30-a500ca330961
2023-08-08 05:37:39,687 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,688 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,691 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41131', status: init, memory: 0, processing: 0>
2023-08-08 05:37:39,691 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41131
2023-08-08 05:37:39,691 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44532
2023-08-08 05:37:39,692 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,692 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,694 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:39,705 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45797', status: init, memory: 0, processing: 0>
2023-08-08 05:37:39,705 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45797
2023-08-08 05:37:39,705 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44540
2023-08-08 05:37:39,706 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,706 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,709 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:39,710 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44187', status: init, memory: 0, processing: 0>
2023-08-08 05:37:39,710 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44187
2023-08-08 05:37:39,711 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44552
2023-08-08 05:37:39,711 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,711 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:39,720 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46085', status: init, memory: 0, processing: 0>
2023-08-08 05:37:39,721 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46085
2023-08-08 05:37:39,721 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44570
2023-08-08 05:37:39,721 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,722 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,723 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33425', status: init, memory: 0, processing: 0>
2023-08-08 05:37:39,724 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33425
2023-08-08 05:37:39,724 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44554
2023-08-08 05:37:39,724 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:39,725 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:39,725 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:39,727 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:39,817 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:39,817 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:39,817 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:39,817 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:39,817 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:39,817 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:39,818 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:39,818 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:39,832 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-08 05:37:39,832 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-08 05:37:39,833 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-08 05:37:39,833 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-08 05:37:39,833 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-08 05:37:39,833 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-08 05:37:39,833 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-08 05:37:39,833 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-08 05:37:39,839 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:37:39,840 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:37:39,843 - distributed.scheduler - INFO - Remove client Client-ac73186d-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:39,843 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44468; closing.
2023-08-08 05:37:39,843 - distributed.scheduler - INFO - Remove client Client-ac73186d-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:39,843 - distributed.scheduler - INFO - Close client connection: Client-ac73186d-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:39,844 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45129'. Reason: nanny-close
2023-08-08 05:37:39,845 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:39,845 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36845'. Reason: nanny-close
2023-08-08 05:37:39,846 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:39,846 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34027. Reason: nanny-close
2023-08-08 05:37:39,846 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46647'. Reason: nanny-close
2023-08-08 05:37:39,847 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:39,847 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46085. Reason: nanny-close
2023-08-08 05:37:39,847 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42153'. Reason: nanny-close
2023-08-08 05:37:39,848 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:39,848 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41803. Reason: nanny-close
2023-08-08 05:37:39,848 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43179'. Reason: nanny-close
2023-08-08 05:37:39,848 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:39,848 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44187. Reason: nanny-close
2023-08-08 05:37:39,849 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32917'. Reason: nanny-close
2023-08-08 05:37:39,849 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:39,849 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44504; closing.
2023-08-08 05:37:39,849 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:39,849 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34027', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:39,849 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41753'. Reason: nanny-close
2023-08-08 05:37:39,849 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33425. Reason: nanny-close
2023-08-08 05:37:39,849 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34027
2023-08-08 05:37:39,850 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:39,850 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:39,850 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40045'. Reason: nanny-close
2023-08-08 05:37:39,850 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45797. Reason: nanny-close
2023-08-08 05:37:39,850 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:39,850 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:39,850 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:39,851 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41131. Reason: nanny-close
2023-08-08 05:37:39,851 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34027
2023-08-08 05:37:39,851 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:39,851 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:39,851 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44570; closing.
2023-08-08 05:37:39,851 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:39,852 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33389. Reason: nanny-close
2023-08-08 05:37:39,852 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34027
2023-08-08 05:37:39,852 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46085', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:39,852 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:39,852 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34027
2023-08-08 05:37:39,852 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46085
2023-08-08 05:37:39,853 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:39,853 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44552; closing.
2023-08-08 05:37:39,853 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44492; closing.
2023-08-08 05:37:39,853 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:39,853 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34027
2023-08-08 05:37:39,853 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44187', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:39,853 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:39,853 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44187
2023-08-08 05:37:39,854 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41803', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:39,854 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:39,854 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41803
2023-08-08 05:37:39,854 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:39,855 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44532; closing.
2023-08-08 05:37:39,855 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:39,855 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44554; closing.
2023-08-08 05:37:39,855 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:39,855 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44540; closing.
2023-08-08 05:37:39,855 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44518; closing.
2023-08-08 05:37:39,856 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41131', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:39,856 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:39,856 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41131
2023-08-08 05:37:39,856 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33425', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:39,856 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33425
2023-08-08 05:37:39,857 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45797', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:39,857 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45797
2023-08-08 05:37:39,857 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33389', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:39,857 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33389
2023-08-08 05:37:39,857 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:37:41,362 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:37:41,362 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:37:41,363 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:37:41,364 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-08 05:37:41,364 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-08-08 05:37:43,269 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:43,273 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43823 instead
  warnings.warn(
2023-08-08 05:37:43,277 - distributed.scheduler - INFO - State start
2023-08-08 05:37:43,296 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:43,297 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-08 05:37:43,298 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43823/status
2023-08-08 05:37:43,345 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36593'
2023-08-08 05:37:43,361 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40431'
2023-08-08 05:37:43,363 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35245'
2023-08-08 05:37:43,369 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35209'
2023-08-08 05:37:43,378 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33561'
2023-08-08 05:37:43,386 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39641'
2023-08-08 05:37:43,394 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42101'
2023-08-08 05:37:43,402 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37079'
2023-08-08 05:37:43,432 - distributed.scheduler - INFO - Receive client connection: Client-b16a4be7-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:43,445 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44708
2023-08-08 05:37:45,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:45,052 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:45,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:45,052 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:45,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:45,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:45,052 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:45,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:45,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:45,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:45,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:45,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:45,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:45,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:45,083 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:45,084 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:45,085 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:45,085 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:45,086 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:45,091 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:45,093 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:45,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:45,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:37:45,181 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:47,630 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33235
2023-08-08 05:37:47,631 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33235
2023-08-08 05:37:47,631 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45603
2023-08-08 05:37:47,632 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,632 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,632 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:47,632 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:47,632 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mfg8xek6
2023-08-08 05:37:47,633 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f87b69bc-a775-4392-98c8-76a34cc64488
2023-08-08 05:37:47,709 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40407
2023-08-08 05:37:47,710 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40407
2023-08-08 05:37:47,710 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41781
2023-08-08 05:37:47,710 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,710 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,710 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:47,710 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:47,710 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-w019vg9f
2023-08-08 05:37:47,711 - distributed.worker - INFO - Starting Worker plugin PreImport-92789ccd-f979-4fa7-a6ea-70a7a14fea5c
2023-08-08 05:37:47,711 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7794303b-125d-4b0a-b5ba-752230be929e
2023-08-08 05:37:47,711 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f773ae11-925f-485c-a374-736d3100eec3
2023-08-08 05:37:47,711 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46251
2023-08-08 05:37:47,712 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46251
2023-08-08 05:37:47,712 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40845
2023-08-08 05:37:47,712 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,712 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,712 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:47,712 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:47,712 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kgqccgdr
2023-08-08 05:37:47,713 - distributed.worker - INFO - Starting Worker plugin RMMSetup-10cf7ef0-7b81-41b2-96f3-15a6a2fcd1fc
2023-08-08 05:37:47,737 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42731
2023-08-08 05:37:47,738 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42731
2023-08-08 05:37:47,738 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37587
2023-08-08 05:37:47,738 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,738 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,738 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:47,739 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:47,739 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-yfljjcms
2023-08-08 05:37:47,739 - distributed.worker - INFO - Starting Worker plugin PreImport-98bf08b1-9294-4b34-80a4-234cfeb454c9
2023-08-08 05:37:47,739 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-367591ae-f89c-4177-974b-c83d7f41f5ea
2023-08-08 05:37:47,740 - distributed.worker - INFO - Starting Worker plugin RMMSetup-449327fa-b8aa-4943-925a-173baffae715
2023-08-08 05:37:47,803 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-920bd367-110f-4ac5-a093-379e827a0006
2023-08-08 05:37:47,803 - distributed.worker - INFO - Starting Worker plugin PreImport-f743d8a1-5344-4900-8c4d-8901623ce797
2023-08-08 05:37:47,803 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,836 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39055
2023-08-08 05:37:47,837 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39055
2023-08-08 05:37:47,837 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34461
2023-08-08 05:37:47,837 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,837 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,837 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:47,837 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:47,837 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-yy1vri2s
2023-08-08 05:37:47,838 - distributed.worker - INFO - Starting Worker plugin PreImport-9319835f-085a-4183-bbba-815fe24e8969
2023-08-08 05:37:47,838 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1b15e911-58a7-4278-af88-9243216138e8
2023-08-08 05:37:47,838 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff6bb2e5-146b-4042-b127-5f7c710879e4
2023-08-08 05:37:47,843 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33235', status: init, memory: 0, processing: 0>
2023-08-08 05:37:47,845 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33235
2023-08-08 05:37:47,845 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54366
2023-08-08 05:37:47,845 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,845 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,847 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:47,851 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44193
2023-08-08 05:37:47,852 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44193
2023-08-08 05:37:47,852 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37927
2023-08-08 05:37:47,852 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,852 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,853 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:47,853 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:47,853 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1o72lhh8
2023-08-08 05:37:47,853 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b640fedd-9fc5-4301-94bb-5c9d131e08cf
2023-08-08 05:37:47,863 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44009
2023-08-08 05:37:47,864 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44009
2023-08-08 05:37:47,864 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41639
2023-08-08 05:37:47,864 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,864 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,864 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:47,864 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:47,864 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-t20oyquc
2023-08-08 05:37:47,865 - distributed.worker - INFO - Starting Worker plugin RMMSetup-27d44810-bb11-4335-9c3c-3279c91852d1
2023-08-08 05:37:47,869 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32931
2023-08-08 05:37:47,870 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32931
2023-08-08 05:37:47,870 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43607
2023-08-08 05:37:47,870 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,870 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,870 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:47,870 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:37:47,870 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-d1sn33_k
2023-08-08 05:37:47,871 - distributed.worker - INFO - Starting Worker plugin PreImport-49c5169a-4a07-4885-a0a8-1c8402601b48
2023-08-08 05:37:47,871 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0272edb3-09b0-4e88-9af9-02106a1071d6
2023-08-08 05:37:47,871 - distributed.worker - INFO - Starting Worker plugin RMMSetup-34cde1ab-d858-476f-b51b-2ce2feb4ec12
2023-08-08 05:37:47,879 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,882 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,889 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-21368b4d-853a-4471-8840-442984582b83
2023-08-08 05:37:47,889 - distributed.worker - INFO - Starting Worker plugin PreImport-2f841b4a-d492-4fa0-8dbb-0149704847b9
2023-08-08 05:37:47,890 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,912 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40407', status: init, memory: 0, processing: 0>
2023-08-08 05:37:47,913 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40407
2023-08-08 05:37:47,913 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54384
2023-08-08 05:37:47,913 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,914 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,915 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42731', status: init, memory: 0, processing: 0>
2023-08-08 05:37:47,915 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:47,916 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42731
2023-08-08 05:37:47,916 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54368
2023-08-08 05:37:47,917 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,917 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,922 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:47,927 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46251', status: init, memory: 0, processing: 0>
2023-08-08 05:37:47,927 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46251
2023-08-08 05:37:47,928 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54392
2023-08-08 05:37:47,928 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:47,928 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,931 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:47,990 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,994 - distributed.worker - INFO - Starting Worker plugin PreImport-4ddcdc78-bbb1-45ba-bc15-780f1f208a0c
2023-08-08 05:37:47,994 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3748c6e0-7960-43e3-8623-571981f63d4b
2023-08-08 05:37:47,994 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:47,998 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5297a135-b03a-48e6-85e6-7f03d507fe54
2023-08-08 05:37:47,998 - distributed.worker - INFO - Starting Worker plugin PreImport-cbf87dbb-b4ee-4c06-9bbb-64374811ab0d
2023-08-08 05:37:47,998 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:48,000 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:48,019 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44193', status: init, memory: 0, processing: 0>
2023-08-08 05:37:48,021 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44193
2023-08-08 05:37:48,021 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54422
2023-08-08 05:37:48,021 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:48,021 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:48,023 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:48,025 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39055', status: init, memory: 0, processing: 0>
2023-08-08 05:37:48,025 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39055
2023-08-08 05:37:48,026 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54408
2023-08-08 05:37:48,026 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:48,026 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:48,027 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32931', status: init, memory: 0, processing: 0>
2023-08-08 05:37:48,027 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32931
2023-08-08 05:37:48,028 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54434
2023-08-08 05:37:48,028 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:48,028 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:48,029 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:48,029 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:48,036 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44009', status: init, memory: 0, processing: 0>
2023-08-08 05:37:48,036 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44009
2023-08-08 05:37:48,037 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54428
2023-08-08 05:37:48,037 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:48,037 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:48,040 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:48,051 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:48,052 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:48,052 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:48,052 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:48,052 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:48,052 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:48,053 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:48,053 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:37:48,058 - distributed.scheduler - INFO - Remove client Client-b16a4be7-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:48,058 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44708; closing.
2023-08-08 05:37:48,058 - distributed.scheduler - INFO - Remove client Client-b16a4be7-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:48,059 - distributed.scheduler - INFO - Close client connection: Client-b16a4be7-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:48,059 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35209'. Reason: nanny-close
2023-08-08 05:37:48,060 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:48,060 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36593'. Reason: nanny-close
2023-08-08 05:37:48,061 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:48,061 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40431'. Reason: nanny-close
2023-08-08 05:37:48,061 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46251. Reason: nanny-close
2023-08-08 05:37:48,062 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:48,062 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35245'. Reason: nanny-close
2023-08-08 05:37:48,062 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39055. Reason: nanny-close
2023-08-08 05:37:48,062 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:48,062 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40407. Reason: nanny-close
2023-08-08 05:37:48,062 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33561'. Reason: nanny-close
2023-08-08 05:37:48,063 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39641'. Reason: nanny-close
2023-08-08 05:37:48,063 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:48,063 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33235. Reason: nanny-close
2023-08-08 05:37:48,063 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42101'. Reason: nanny-close
2023-08-08 05:37:48,064 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:48,064 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54392; closing.
2023-08-08 05:37:48,064 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:48,064 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37079'. Reason: nanny-close
2023-08-08 05:37:48,064 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42731. Reason: nanny-close
2023-08-08 05:37:48,064 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:48,064 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46251', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:48,064 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:48,064 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46251
2023-08-08 05:37:48,064 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:48,065 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32931. Reason: nanny-close
2023-08-08 05:37:48,065 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:48,065 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:48,066 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:48,066 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44193. Reason: nanny-close
2023-08-08 05:37:48,066 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54408; closing.
2023-08-08 05:37:48,066 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:48,066 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:48,066 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:48,066 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46251
2023-08-08 05:37:48,067 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46251
2023-08-08 05:37:48,067 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:48,067 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39055', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:48,067 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46251
2023-08-08 05:37:48,067 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39055
2023-08-08 05:37:48,068 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:48,068 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54384; closing.
2023-08-08 05:37:48,068 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:48,068 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:48,068 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54366; closing.
2023-08-08 05:37:48,069 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:48,069 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40407', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:48,069 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40407
2023-08-08 05:37:48,070 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33235', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:48,070 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33235
2023-08-08 05:37:48,071 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54434; closing.
2023-08-08 05:37:48,071 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54368; closing.
2023-08-08 05:37:48,071 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54422; closing.
2023-08-08 05:37:48,072 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32931', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:48,072 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:32931
2023-08-08 05:37:48,073 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42731', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:48,073 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42731
2023-08-08 05:37:48,073 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44193', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:48,073 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44193
2023-08-08 05:37:48,074 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39055
2023-08-08 05:37:48,075 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40407
2023-08-08 05:37:48,075 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33235
2023-08-08 05:37:48,075 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:32931
2023-08-08 05:37:48,075 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42731
2023-08-08 05:37:48,075 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44193
2023-08-08 05:37:48,083 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:48,084 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44009. Reason: nanny-close
2023-08-08 05:37:48,086 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:48,086 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54428; closing.
2023-08-08 05:37:48,086 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44009', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:48,086 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44009
2023-08-08 05:37:48,087 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:37:48,087 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:49,527 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:37:49,527 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:37:49,528 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:37:49,529 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-08 05:37:49,529 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-08-08 05:37:51,308 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:51,312 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38961 instead
  warnings.warn(
2023-08-08 05:37:51,315 - distributed.scheduler - INFO - State start
2023-08-08 05:37:51,333 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:51,334 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-08 05:37:51,335 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38961/status
2023-08-08 05:37:51,388 - distributed.scheduler - INFO - Receive client connection: Client-b6468208-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:51,399 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54520
2023-08-08 05:37:51,492 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40283'
2023-08-08 05:37:52,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:37:52,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-08-08 05:37:53,430 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:37:54,411 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33451
2023-08-08 05:37:54,412 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33451
2023-08-08 05:37:54,412 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-08-08 05:37:54,412 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:37:54,412 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:54,412 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:37:54,412 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-08 05:37:54,412 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xoo2bs0y
2023-08-08 05:37:54,412 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8d31f012-a732-4aac-b4b8-64bc0516f859
2023-08-08 05:37:54,413 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-472b2c1b-e910-451a-95f2-00aa00a82c49
2023-08-08 05:37:54,413 - distributed.worker - INFO - Starting Worker plugin PreImport-fe7c936c-0dc3-4985-b7a5-f21df98a14ce
2023-08-08 05:37:54,413 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:54,436 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33451', status: init, memory: 0, processing: 0>
2023-08-08 05:37:54,437 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33451
2023-08-08 05:37:54,437 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54542
2023-08-08 05:37:54,437 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:37:54,437 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:37:54,439 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:37:54,444 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:37:54,446 - distributed.scheduler - INFO - Remove client Client-b6468208-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:54,446 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54520; closing.
2023-08-08 05:37:54,447 - distributed.scheduler - INFO - Remove client Client-b6468208-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:54,447 - distributed.scheduler - INFO - Close client connection: Client-b6468208-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:54,448 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40283'. Reason: nanny-close
2023-08-08 05:37:54,476 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:37:54,477 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33451. Reason: nanny-close
2023-08-08 05:37:54,479 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54542; closing.
2023-08-08 05:37:54,479 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:37:54,479 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33451', status: closing, memory: 0, processing: 0>
2023-08-08 05:37:54,480 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33451
2023-08-08 05:37:54,480 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:37:54,481 - distributed.nanny - INFO - Worker closed
2023-08-08 05:37:55,414 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:37:55,414 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:37:55,414 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:37:55,415 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-08 05:37:55,415 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-08-08 05:37:58,769 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:58,773 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33117 instead
  warnings.warn(
2023-08-08 05:37:58,776 - distributed.scheduler - INFO - State start
2023-08-08 05:37:58,809 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:37:58,809 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-08 05:37:58,810 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33117/status
2023-08-08 05:37:58,814 - distributed.scheduler - INFO - Receive client connection: Client-bab1b13d-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:37:58,825 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44064
2023-08-08 05:37:58,883 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45699'
2023-08-08 05:38:00,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:00,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-08-08 05:38:00,702 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:01,762 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41209
2023-08-08 05:38:01,762 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41209
2023-08-08 05:38:01,762 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43037
2023-08-08 05:38:01,762 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:01,762 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:01,762 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:01,763 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-08 05:38:01,763 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lg943ukr
2023-08-08 05:38:01,763 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e14a0fca-2f98-4473-bee4-48b2448491f8
2023-08-08 05:38:01,763 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bd8f9cd8-c8fc-438c-88b3-f48a15610868
2023-08-08 05:38:01,763 - distributed.worker - INFO - Starting Worker plugin PreImport-38d79f1c-c031-48cc-ac70-e2ba343296dc
2023-08-08 05:38:01,765 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:01,794 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41209', status: init, memory: 0, processing: 0>
2023-08-08 05:38:01,795 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41209
2023-08-08 05:38:01,795 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44072
2023-08-08 05:38:01,795 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:01,795 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:01,798 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:01,869 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:01,872 - distributed.scheduler - INFO - Remove client Client-bab1b13d-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:01,872 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44064; closing.
2023-08-08 05:38:01,872 - distributed.scheduler - INFO - Remove client Client-bab1b13d-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:01,873 - distributed.scheduler - INFO - Close client connection: Client-bab1b13d-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:01,873 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45699'. Reason: nanny-close
2023-08-08 05:38:01,874 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:01,875 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41209. Reason: nanny-close
2023-08-08 05:38:01,876 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44072; closing.
2023-08-08 05:38:01,876 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:01,877 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41209', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:01,877 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41209
2023-08-08 05:38:01,877 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:38:01,878 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:02,890 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:38:02,890 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:38:02,890 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:38:02,891 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-08 05:38:02,891 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-08-08 05:38:04,607 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:38:04,611 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38373 instead
  warnings.warn(
2023-08-08 05:38:04,615 - distributed.scheduler - INFO - State start
2023-08-08 05:38:04,644 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:38:04,645 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-08 05:38:04,645 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38373/status
2023-08-08 05:38:08,552 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:38:08,552 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:38:08,553 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:38:08,553 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-08 05:38:08,553 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-08-08 05:38:10,505 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:38:10,509 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42929 instead
  warnings.warn(
2023-08-08 05:38:10,513 - distributed.scheduler - INFO - State start
2023-08-08 05:38:10,533 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:38:10,534 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-08-08 05:38:10,535 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42929/status
2023-08-08 05:38:10,727 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39545'
2023-08-08 05:38:12,048 - distributed.scheduler - INFO - Receive client connection: Client-c1a0495f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:12,062 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41384
2023-08-08 05:38:12,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:12,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:12,141 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:13,030 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43107
2023-08-08 05:38:13,030 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43107
2023-08-08 05:38:13,030 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44655
2023-08-08 05:38:13,031 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-08 05:38:13,031 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:13,031 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:13,031 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-08 05:38:13,031 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3ww796e9
2023-08-08 05:38:13,031 - distributed.worker - INFO - Starting Worker plugin RMMSetup-147cd67b-ded7-43bd-9d85-76a88060848a
2023-08-08 05:38:13,031 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fdaa7841-c2ad-4a64-88a3-a467b89e9ac2
2023-08-08 05:38:13,031 - distributed.worker - INFO - Starting Worker plugin PreImport-f436f0e0-9789-4f5d-a283-4c5fb6c610bb
2023-08-08 05:38:13,032 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:13,056 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43107', status: init, memory: 0, processing: 0>
2023-08-08 05:38:13,057 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43107
2023-08-08 05:38:13,057 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41398
2023-08-08 05:38:13,058 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-08 05:38:13,058 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:13,060 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-08 05:38:13,081 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:13,083 - distributed.scheduler - INFO - Remove client Client-c1a0495f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:13,083 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41384; closing.
2023-08-08 05:38:13,083 - distributed.scheduler - INFO - Remove client Client-c1a0495f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:13,084 - distributed.scheduler - INFO - Close client connection: Client-c1a0495f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:13,085 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39545'. Reason: nanny-close
2023-08-08 05:38:13,109 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:13,110 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43107. Reason: nanny-close
2023-08-08 05:38:13,111 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-08 05:38:13,111 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41398; closing.
2023-08-08 05:38:13,112 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43107', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:13,112 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43107
2023-08-08 05:38:13,112 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:38:13,112 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:14,050 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:38:14,051 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:38:14,051 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:38:14,052 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-08-08 05:38:14,052 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-08-08 05:38:15,820 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:38:15,825 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45715 instead
  warnings.warn(
2023-08-08 05:38:15,828 - distributed.scheduler - INFO - State start
2023-08-08 05:38:15,849 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:38:15,850 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-08 05:38:15,851 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45715/status
2023-08-08 05:38:16,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36387'
2023-08-08 05:38:16,176 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42919'
2023-08-08 05:38:16,177 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35761'
2023-08-08 05:38:16,185 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35619'
2023-08-08 05:38:16,195 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44557'
2023-08-08 05:38:16,203 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36273'
2023-08-08 05:38:16,211 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33047'
2023-08-08 05:38:16,220 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44929'
2023-08-08 05:38:16,638 - distributed.scheduler - INFO - Receive client connection: Client-c4e2cd26-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:16,652 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54340
2023-08-08 05:38:17,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:17,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:17,755 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:17,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:17,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:17,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:17,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:17,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:17,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:17,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:17,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:17,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:17,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:17,850 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:17,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:17,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:17,860 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:17,866 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:17,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:17,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:18,009 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:18,040 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:18,044 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:18,047 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:19,680 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43209
2023-08-08 05:38:19,680 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43209
2023-08-08 05:38:19,680 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38319
2023-08-08 05:38:19,680 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:19,680 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:19,680 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:19,681 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:38:19,681 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-d_8p076y
2023-08-08 05:38:19,681 - distributed.worker - INFO - Starting Worker plugin PreImport-32871336-d87c-4412-9dfb-c156e723c1f0
2023-08-08 05:38:19,681 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-73146ad2-d9aa-4ef6-8b04-a803e378af7a
2023-08-08 05:38:19,681 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1a32341d-7af0-44bd-8e0c-d5e2ebebedcd
2023-08-08 05:38:19,894 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:19,921 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43209', status: init, memory: 0, processing: 0>
2023-08-08 05:38:19,923 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43209
2023-08-08 05:38:19,923 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54346
2023-08-08 05:38:19,923 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:19,924 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:19,925 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:20,668 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39125
2023-08-08 05:38:20,669 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39125
2023-08-08 05:38:20,669 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44431
2023-08-08 05:38:20,669 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,669 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,669 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:20,669 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:38:20,670 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-s3795zr3
2023-08-08 05:38:20,670 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fb16d0ed-62f3-403e-96a3-1dd0ceeca56b
2023-08-08 05:38:20,671 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43747
2023-08-08 05:38:20,672 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43747
2023-08-08 05:38:20,672 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36835
2023-08-08 05:38:20,672 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,672 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,672 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:20,672 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:38:20,673 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8dr1i3fw
2023-08-08 05:38:20,673 - distributed.worker - INFO - Starting Worker plugin PreImport-d5bbcf89-e084-47bc-9f41-da554bb2b24a
2023-08-08 05:38:20,673 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d9a20729-43e1-46c4-a4f9-8e5a5acadcc7
2023-08-08 05:38:20,673 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9d2375f3-962a-41d5-bf7b-8b11ae662398
2023-08-08 05:38:20,682 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45763
2023-08-08 05:38:20,682 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45763
2023-08-08 05:38:20,682 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37979
2023-08-08 05:38:20,682 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,682 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,682 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:20,683 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:38:20,683 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-w32mww5m
2023-08-08 05:38:20,683 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5e3e6e34-7e8a-421e-a73c-d6ca7f9b3327
2023-08-08 05:38:20,683 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33943
2023-08-08 05:38:20,684 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33943
2023-08-08 05:38:20,684 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36755
2023-08-08 05:38:20,684 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,684 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,684 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:20,684 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:38:20,684 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9jyjvssi
2023-08-08 05:38:20,685 - distributed.worker - INFO - Starting Worker plugin RMMSetup-76d667b4-82da-4839-9bae-3681cf651129
2023-08-08 05:38:20,686 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38503
2023-08-08 05:38:20,687 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38503
2023-08-08 05:38:20,687 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46087
2023-08-08 05:38:20,687 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,687 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,687 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:20,688 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:38:20,688 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3aiuk_fl
2023-08-08 05:38:20,688 - distributed.worker - INFO - Starting Worker plugin PreImport-be6669c7-e97a-458a-8e57-6617c4642dbf
2023-08-08 05:38:20,688 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-677026d8-fdd6-4074-a38a-2c33bee59222
2023-08-08 05:38:20,688 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2db82c73-bed4-4cb3-a3e1-eb45826dca38
2023-08-08 05:38:20,709 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33563
2023-08-08 05:38:20,710 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33563
2023-08-08 05:38:20,710 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37941
2023-08-08 05:38:20,709 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43169
2023-08-08 05:38:20,710 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,710 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43169
2023-08-08 05:38:20,710 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,710 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39929
2023-08-08 05:38:20,710 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,710 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:20,710 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,710 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:38:20,710 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zopqggtk
2023-08-08 05:38:20,710 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:20,711 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-08 05:38:20,711 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-a0bgn3ot
2023-08-08 05:38:20,711 - distributed.worker - INFO - Starting Worker plugin PreImport-bd0a1426-c462-482f-8146-1ebead7bd432
2023-08-08 05:38:20,711 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e0500abc-bc0a-4536-b448-665bbeee06d6
2023-08-08 05:38:20,711 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4101120c-b6e6-4eb1-96f7-5ba0ae2cc701
2023-08-08 05:38:20,711 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dd17ce65-8dd0-493e-b2f6-7d661f93ac93
2023-08-08 05:38:20,831 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,844 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-38f0d3b9-909f-4630-9048-503e16563271
2023-08-08 05:38:20,846 - distributed.worker - INFO - Starting Worker plugin PreImport-14307ca2-b7d4-4a8b-9cce-43d9b9670a3f
2023-08-08 05:38:20,847 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,855 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bc7112f3-1280-4711-b74e-1173e111338e
2023-08-08 05:38:20,856 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,856 - distributed.worker - INFO - Starting Worker plugin PreImport-a65264f3-c49b-4b6e-a0be-079f93ef1013
2023-08-08 05:38:20,856 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2e5b59e9-e94e-4da1-81f4-c761b06c7f42
2023-08-08 05:38:20,856 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,856 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e44af785-c29b-4a1f-a8a7-50f4bcbca641
2023-08-08 05:38:20,856 - distributed.worker - INFO - Starting Worker plugin PreImport-2247d178-d88d-46d0-9c94-6a26a47bd54e
2023-08-08 05:38:20,856 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,856 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,858 - distributed.worker - INFO - Starting Worker plugin PreImport-0a28bc73-e2a9-4acd-8f02-c35790da5c77
2023-08-08 05:38:20,859 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,863 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38503', status: init, memory: 0, processing: 0>
2023-08-08 05:38:20,864 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38503
2023-08-08 05:38:20,864 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54350
2023-08-08 05:38:20,864 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,864 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,869 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:20,883 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39125', status: init, memory: 0, processing: 0>
2023-08-08 05:38:20,884 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39125
2023-08-08 05:38:20,884 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54352
2023-08-08 05:38:20,885 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,885 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,885 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33563', status: init, memory: 0, processing: 0>
2023-08-08 05:38:20,886 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33563
2023-08-08 05:38:20,887 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54388
2023-08-08 05:38:20,887 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,887 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,888 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43169', status: init, memory: 0, processing: 0>
2023-08-08 05:38:20,888 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:20,888 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43169
2023-08-08 05:38:20,889 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54402
2023-08-08 05:38:20,889 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,889 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,889 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:20,889 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43747', status: init, memory: 0, processing: 0>
2023-08-08 05:38:20,890 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43747
2023-08-08 05:38:20,890 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54366
2023-08-08 05:38:20,890 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,891 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,891 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:20,891 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33943', status: init, memory: 0, processing: 0>
2023-08-08 05:38:20,892 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33943
2023-08-08 05:38:20,892 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54376
2023-08-08 05:38:20,893 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:20,893 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,893 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,895 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:20,900 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45763', status: init, memory: 0, processing: 0>
2023-08-08 05:38:20,901 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45763
2023-08-08 05:38:20,901 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54404
2023-08-08 05:38:20,901 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:20,901 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:20,904 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:21,003 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:38:21,004 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:38:21,004 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:38:21,004 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:38:21,004 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:38:21,004 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:38:21,004 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:38:21,005 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-08 05:38:21,016 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:21,017 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:21,017 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:21,017 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:21,017 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:21,017 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:21,017 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:21,018 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:21,023 - distributed.scheduler - INFO - Remove client Client-c4e2cd26-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:21,024 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54340; closing.
2023-08-08 05:38:21,024 - distributed.scheduler - INFO - Remove client Client-c4e2cd26-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:21,025 - distributed.scheduler - INFO - Close client connection: Client-c4e2cd26-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:21,025 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35619'. Reason: nanny-close
2023-08-08 05:38:21,026 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:21,026 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44557'. Reason: nanny-close
2023-08-08 05:38:21,027 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:21,027 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45763. Reason: nanny-close
2023-08-08 05:38:21,027 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36387'. Reason: nanny-close
2023-08-08 05:38:21,028 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:21,028 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42919'. Reason: nanny-close
2023-08-08 05:38:21,028 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38503. Reason: nanny-close
2023-08-08 05:38:21,028 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:21,029 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33563. Reason: nanny-close
2023-08-08 05:38:21,029 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35761'. Reason: nanny-close
2023-08-08 05:38:21,029 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:21,029 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43169. Reason: nanny-close
2023-08-08 05:38:21,029 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36273'. Reason: nanny-close
2023-08-08 05:38:21,029 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:21,029 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54404; closing.
2023-08-08 05:38:21,030 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:21,030 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45763', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:21,030 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33047'. Reason: nanny-close
2023-08-08 05:38:21,030 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39125. Reason: nanny-close
2023-08-08 05:38:21,030 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45763
2023-08-08 05:38:21,030 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:21,030 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:21,030 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:21,030 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44929'. Reason: nanny-close
2023-08-08 05:38:21,030 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43209. Reason: nanny-close
2023-08-08 05:38:21,031 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:21,031 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:21,031 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:21,031 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43747. Reason: nanny-close
2023-08-08 05:38:21,031 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45763
2023-08-08 05:38:21,031 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:21,032 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:21,032 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54350; closing.
2023-08-08 05:38:21,032 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:21,032 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54388; closing.
2023-08-08 05:38:21,032 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33943. Reason: nanny-close
2023-08-08 05:38:21,032 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45763
2023-08-08 05:38:21,032 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45763
2023-08-08 05:38:21,032 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45763
2023-08-08 05:38:21,033 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:21,033 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38503', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:21,033 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:21,033 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38503
2023-08-08 05:38:21,033 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:21,033 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33563', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:21,033 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33563
2023-08-08 05:38:21,033 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:21,033 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54402; closing.
2023-08-08 05:38:21,034 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:21,034 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:21,034 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43169', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:21,034 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:21,034 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43169
2023-08-08 05:38:21,034 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54352; closing.
2023-08-08 05:38:21,034 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:21,035 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54346; closing.
2023-08-08 05:38:21,035 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39125', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:21,036 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39125
2023-08-08 05:38:21,036 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43209', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:21,036 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43209
2023-08-08 05:38:21,036 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54366; closing.
2023-08-08 05:38:21,037 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54376; closing.
2023-08-08 05:38:21,037 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43747', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:21,037 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43747
2023-08-08 05:38:21,038 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33943', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:21,038 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33943
2023-08-08 05:38:21,038 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:38:22,492 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:38:22,493 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:38:22,493 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:38:22,494 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-08 05:38:22,495 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-08-08 05:38:24,352 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:38:24,355 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39953 instead
  warnings.warn(
2023-08-08 05:38:24,359 - distributed.scheduler - INFO - State start
2023-08-08 05:38:24,377 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:38:24,378 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-08 05:38:24,378 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39953/status
2023-08-08 05:38:24,408 - distributed.scheduler - INFO - Receive client connection: Client-c9eae61f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:24,420 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54494
2023-08-08 05:38:24,557 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34795'
2023-08-08 05:38:25,981 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:25,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:26,004 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:27,027 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35413
2023-08-08 05:38:27,028 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35413
2023-08-08 05:38:27,028 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36369
2023-08-08 05:38:27,028 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:27,028 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:27,028 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:27,029 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-08 05:38:27,029 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5eyzrtqt
2023-08-08 05:38:27,029 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2ea29c6e-52b1-4789-90b4-dd174369ea44
2023-08-08 05:38:27,121 - distributed.worker - INFO - Starting Worker plugin PreImport-3199ada9-cacc-453e-88b5-639904dfce1a
2023-08-08 05:38:27,122 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2f65e1c2-6b00-443f-ba21-30f8167555df
2023-08-08 05:38:27,122 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:27,149 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35413', status: init, memory: 0, processing: 0>
2023-08-08 05:38:27,150 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35413
2023-08-08 05:38:27,150 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37540
2023-08-08 05:38:27,151 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:27,151 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:27,155 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:27,167 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-08 05:38:27,170 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:27,171 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:27,173 - distributed.scheduler - INFO - Remove client Client-c9eae61f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:27,173 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54494; closing.
2023-08-08 05:38:27,174 - distributed.scheduler - INFO - Remove client Client-c9eae61f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:27,174 - distributed.scheduler - INFO - Close client connection: Client-c9eae61f-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:27,175 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34795'. Reason: nanny-close
2023-08-08 05:38:27,187 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:27,188 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35413. Reason: nanny-close
2023-08-08 05:38:27,190 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37540; closing.
2023-08-08 05:38:27,190 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:27,190 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35413', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:27,190 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35413
2023-08-08 05:38:27,190 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:38:27,191 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:28,041 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:38:28,041 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:38:28,041 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:38:28,042 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-08 05:38:28,042 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-08-08 05:38:29,905 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:38:29,909 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32933 instead
  warnings.warn(
2023-08-08 05:38:29,912 - distributed.scheduler - INFO - State start
2023-08-08 05:38:29,931 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-08 05:38:29,931 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-08 05:38:29,932 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:32933/status
2023-08-08 05:38:30,166 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35799'
2023-08-08 05:38:31,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:31,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:31,543 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-08 05:38:32,164 - distributed.scheduler - INFO - Receive client connection: Client-cd440313-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:32,177 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37638
2023-08-08 05:38:32,421 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34689
2023-08-08 05:38:32,421 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34689
2023-08-08 05:38:32,421 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40465
2023-08-08 05:38:32,421 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-08 05:38:32,422 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:32,422 - distributed.worker - INFO -               Threads:                          1
2023-08-08 05:38:32,422 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-08 05:38:32,422 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-90ep07no
2023-08-08 05:38:32,422 - distributed.worker - INFO - Starting Worker plugin RMMSetup-28c53e7d-f752-45c0-b0ea-c14782191f33
2023-08-08 05:38:32,529 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e83aa55b-80a1-4390-b797-b49ba7d65236
2023-08-08 05:38:32,529 - distributed.worker - INFO - Starting Worker plugin PreImport-77226128-f77e-41c0-9d5f-cfcf52ace23d
2023-08-08 05:38:32,530 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:32,559 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34689', status: init, memory: 0, processing: 0>
2023-08-08 05:38:32,560 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34689
2023-08-08 05:38:32,560 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37660
2023-08-08 05:38:32,561 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-08 05:38:32,561 - distributed.worker - INFO - -------------------------------------------------
2023-08-08 05:38:32,563 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-08 05:38:32,591 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-08-08 05:38:32,709 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-08 05:38:32,712 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:32,713 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-08 05:38:32,715 - distributed.scheduler - INFO - Remove client Client-cd440313-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:32,716 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37638; closing.
2023-08-08 05:38:32,716 - distributed.scheduler - INFO - Remove client Client-cd440313-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:32,716 - distributed.scheduler - INFO - Close client connection: Client-cd440313-35ad-11ee-870d-d8c49764f6bb
2023-08-08 05:38:32,717 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35799'. Reason: nanny-close
2023-08-08 05:38:32,718 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-08 05:38:32,719 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34689. Reason: nanny-close
2023-08-08 05:38:32,720 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-08 05:38:32,720 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37660; closing.
2023-08-08 05:38:32,721 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34689', status: closing, memory: 0, processing: 0>
2023-08-08 05:38:32,721 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34689
2023-08-08 05:38:32,721 - distributed.scheduler - INFO - Lost all workers
2023-08-08 05:38:32,721 - distributed.nanny - INFO - Worker closed
2023-08-08 05:38:33,683 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-08 05:38:33,684 - distributed.scheduler - INFO - Scheduler closing...
2023-08-08 05:38:33,684 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-08 05:38:33,685 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-08 05:38:33,685 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41789 instead
  warnings.warn(
2023-08-08 05:38:42,742 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:42,742 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:42,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:42,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:42,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:42,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:42,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:42,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:42,790 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:42,791 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:42,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:42,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:42,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:42,829 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:42,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:42,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45323 instead
  warnings.warn(
2023-08-08 05:38:52,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:52,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:52,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:52,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:52,815 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:52,815 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:52,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:52,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:52,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:52,826 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:52,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:52,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:52,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:52,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:38:52,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:38:52,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33911 instead
  warnings.warn(
2023-08-08 05:39:01,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:01,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:01,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:01,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:01,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:01,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:01,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:01,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:01,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:01,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:01,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:01,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:01,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:01,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:02,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:02,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40899 instead
  warnings.warn(
2023-08-08 05:39:12,474 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:12,474 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:12,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:12,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:12,486 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:12,486 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:12,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:12,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:12,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:12,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:12,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:12,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:12,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:12,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:12,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:12,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41443 instead
  warnings.warn(
2023-08-08 05:39:23,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:23,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:23,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:23,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:23,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:23,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:23,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:23,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:23,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:23,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:23,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:23,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:23,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:23,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:23,808 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:23,808 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39583 instead
  warnings.warn(
2023-08-08 05:39:34,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:34,735 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:34,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:34,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:34,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:34,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:34,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:34,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:34,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:34,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:34,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:34,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:34,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:34,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:34,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:34,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35275 instead
  warnings.warn(
2023-08-08 05:39:47,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:47,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:47,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:47,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:47,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:47,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:47,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:47,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:47,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:47,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:47,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:47,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:47,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:47,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:47,346 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:47,346 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44257 instead
  warnings.warn(
2023-08-08 05:39:58,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:58,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:58,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:58,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:58,592 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:58,592 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:58,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:58,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:58,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:58,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:58,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:58,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:58,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:58,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-08 05:39:58,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-08 05:39:58,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41817 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44623 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34649 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35583 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35821 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41087 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42243 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44571 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37117 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45829 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46403 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42741 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33455 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45715 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37743 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44177 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39749 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35183 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40997 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35717 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36373 instead
  warnings.warn(
std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-08 05:45:29,587 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-08 05:45:29,589 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-08 05:45:29,594 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-08 05:45:29,596 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f97d6793b20>>, <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-08 05:45:29,597 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2808a8eaf0>>, <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-08 05:45:29,601 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fc7c3228be0>>, <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-08 05:45:29,623 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-08 05:45:29,631 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f4a87a90a30>>, <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-08 05:45:31,599 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-08-08 05:45:31,601 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-08-08 05:45:31,603 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-08-08 05:45:31,634 - distributed.nanny - ERROR - Worker process died unexpectedly
