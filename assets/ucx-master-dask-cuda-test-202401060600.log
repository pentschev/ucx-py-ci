============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-06 06:31:26,452 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:31:26,457 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34963 instead
  warnings.warn(
2024-01-06 06:31:26,461 - distributed.scheduler - INFO - State start
2024-01-06 06:31:26,585 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:31:26,586 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-06 06:31:26,587 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34963/status
2024-01-06 06:31:26,588 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:31:27,349 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41207'
2024-01-06 06:31:27,368 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42535'
2024-01-06 06:31:27,371 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37799'
2024-01-06 06:31:27,379 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42329'
2024-01-06 06:31:28,151 - distributed.scheduler - INFO - Receive client connection: Client-36be9af9-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:31:28,165 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39106
2024-01-06 06:31:29,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:29,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:29,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:29,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:29,237 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:29,237 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:29,238 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35433
2024-01-06 06:31:29,238 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35433
2024-01-06 06:31:29,238 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45767
2024-01-06 06:31:29,238 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45767
2024-01-06 06:31:29,238 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40171
2024-01-06 06:31:29,238 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:31:29,238 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33811
2024-01-06 06:31:29,238 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,238 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:31:29,238 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:31:29,238 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,238 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:31:29,238 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:31:29,239 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-rjg8ldhs
2024-01-06 06:31:29,239 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:31:29,239 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-l_m1qvdu
2024-01-06 06:31:29,239 - distributed.worker - INFO - Starting Worker plugin PreImport-4650afef-0685-4144-95ba-38670650580a
2024-01-06 06:31:29,239 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-debbe3a2-6a0d-4330-b1c9-fb2aedbf8d7e
2024-01-06 06:31:29,239 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cb0f4991-5f4f-47dd-bd17-1839113cfd6a
2024-01-06 06:31:29,239 - distributed.worker - INFO - Starting Worker plugin PreImport-28ec7402-758d-448d-9f72-ef3d098a6fa3
2024-01-06 06:31:29,239 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4712ff7c-8f2f-4528-8462-d58271c8d528
2024-01-06 06:31:29,239 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fc45782d-3e25-4541-8b8e-5680cd3e7ce5
2024-01-06 06:31:29,239 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:29,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:29,239 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,243 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:29,244 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38601
2024-01-06 06:31:29,244 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38601
2024-01-06 06:31:29,244 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45339
2024-01-06 06:31:29,244 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:31:29,244 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,244 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:31:29,244 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:31:29,244 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-tkgyihwv
2024-01-06 06:31:29,245 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c133f3f3-577c-4cf9-bfa3-c71d41005882
2024-01-06 06:31:29,245 - distributed.worker - INFO - Starting Worker plugin PreImport-f72abb00-1c3f-49f6-bd00-592d50c39c99
2024-01-06 06:31:29,245 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f7d6ca4a-5ff8-4966-8da2-df4ec952b2b3
2024-01-06 06:31:29,245 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:29,278 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:29,282 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:29,283 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45887
2024-01-06 06:31:29,283 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45887
2024-01-06 06:31:29,283 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37011
2024-01-06 06:31:29,283 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:31:29,283 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,283 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:31:29,283 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:31:29,283 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-wrxygkxz
2024-01-06 06:31:29,283 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-51529753-4423-4e6f-8559-f44286b7bc67
2024-01-06 06:31:29,284 - distributed.worker - INFO - Starting Worker plugin PreImport-69c695c6-6fc5-4248-85f1-0183d4d050b3
2024-01-06 06:31:29,284 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cebda7fc-63dd-46cf-9de7-bb274bfe35e3
2024-01-06 06:31:29,284 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,349 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35433', status: init, memory: 0, processing: 0>
2024-01-06 06:31:29,350 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35433
2024-01-06 06:31:29,350 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39132
2024-01-06 06:31:29,351 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:29,352 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:31:29,352 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,353 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:31:29,357 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45767', status: init, memory: 0, processing: 0>
2024-01-06 06:31:29,357 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45767
2024-01-06 06:31:29,357 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39140
2024-01-06 06:31:29,358 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:29,359 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:31:29,359 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,360 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:31:29,365 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38601', status: init, memory: 0, processing: 0>
2024-01-06 06:31:29,365 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38601
2024-01-06 06:31:29,366 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39148
2024-01-06 06:31:29,367 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:29,367 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:31:29,367 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,369 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:31:29,379 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45887', status: init, memory: 0, processing: 0>
2024-01-06 06:31:29,380 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45887
2024-01-06 06:31:29,380 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39150
2024-01-06 06:31:29,381 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:29,382 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:31:29,382 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:29,383 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:31:29,397 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-06 06:31:29,397 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-06 06:31:29,397 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-06 06:31:29,398 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-06 06:31:29,402 - distributed.scheduler - INFO - Remove client Client-36be9af9-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:31:29,403 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39106; closing.
2024-01-06 06:31:29,403 - distributed.scheduler - INFO - Remove client Client-36be9af9-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:31:29,403 - distributed.scheduler - INFO - Close client connection: Client-36be9af9-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:31:29,405 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41207'. Reason: nanny-close
2024-01-06 06:31:29,405 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:29,405 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42535'. Reason: nanny-close
2024-01-06 06:31:29,406 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37799'. Reason: nanny-close
2024-01-06 06:31:29,406 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45767. Reason: nanny-close
2024-01-06 06:31:29,406 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:29,406 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42329'. Reason: nanny-close
2024-01-06 06:31:29,407 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35433. Reason: nanny-close
2024-01-06 06:31:29,408 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:31:29,408 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39140; closing.
2024-01-06 06:31:29,408 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45767', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522689.4088624')
2024-01-06 06:31:29,409 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:31:29,409 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:29,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39132; closing.
2024-01-06 06:31:29,410 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:29,410 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35433', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522689.4105313')
2024-01-06 06:31:29,411 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:29,411 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38601. Reason: nanny-close
2024-01-06 06:31:29,413 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:31:29,413 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39148; closing.
2024-01-06 06:31:29,413 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38601', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522689.4134781')
2024-01-06 06:31:29,414 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:29,433 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:29,434 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45887. Reason: nanny-close
2024-01-06 06:31:29,436 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:31:29,436 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39150; closing.
2024-01-06 06:31:29,437 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45887', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522689.4373577')
2024-01-06 06:31:29,437 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:31:29,438 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:30,170 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:31:30,170 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:31:30,171 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:31:30,172 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-06 06:31:30,172 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-06 06:31:32,491 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:31:32,496 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45993 instead
  warnings.warn(
2024-01-06 06:31:32,500 - distributed.scheduler - INFO - State start
2024-01-06 06:31:32,523 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:31:32,524 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-06 06:31:32,525 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:31:32,526 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-06 06:31:32,723 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37597'
2024-01-06 06:31:32,755 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37677'
2024-01-06 06:31:32,759 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44419'
2024-01-06 06:31:32,769 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33873'
2024-01-06 06:31:32,783 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39563'
2024-01-06 06:31:32,795 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44319'
2024-01-06 06:31:32,808 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33567'
2024-01-06 06:31:32,821 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39679'
2024-01-06 06:31:34,949 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:34,949 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:34,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:34,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:34,954 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:34,955 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44067
2024-01-06 06:31:34,955 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44067
2024-01-06 06:31:34,955 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36295
2024-01-06 06:31:34,955 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:34,955 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:34,955 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:34,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:34,955 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:34,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:34,955 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mjv08ezb
2024-01-06 06:31:34,955 - distributed.worker - INFO - Starting Worker plugin RMMSetup-550bcc0d-fe5b-4a4e-9f30-a3c207f97360
2024-01-06 06:31:34,956 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:34,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:34,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:34,957 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40621
2024-01-06 06:31:34,957 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40621
2024-01-06 06:31:34,957 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42967
2024-01-06 06:31:34,957 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:34,957 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:34,957 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:34,957 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:34,957 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cbeuyjeg
2024-01-06 06:31:34,958 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1f42fbb6-6e8a-4a4c-82dc-f3d21ce0fa96
2024-01-06 06:31:34,959 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:34,960 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:34,961 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:34,962 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:34,962 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42579
2024-01-06 06:31:34,962 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42579
2024-01-06 06:31:34,962 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37621
2024-01-06 06:31:34,962 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:34,962 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:34,962 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:34,962 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:34,962 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xj_0xr0n
2024-01-06 06:31:34,963 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40837
2024-01-06 06:31:34,963 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7d018f72-fef5-4c96-9d1e-ec0172c5b13a
2024-01-06 06:31:34,963 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40837
2024-01-06 06:31:34,963 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44411
2024-01-06 06:31:34,963 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:34,963 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:34,963 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:34,963 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:34,963 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k3_99gy7
2024-01-06 06:31:34,963 - distributed.worker - INFO - Starting Worker plugin RMMSetup-44f1fafa-ea6e-4eb0-b208-3c8649055a57
2024-01-06 06:31:34,964 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:34,965 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45289
2024-01-06 06:31:34,965 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45289
2024-01-06 06:31:34,965 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45571
2024-01-06 06:31:34,965 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:34,965 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:34,965 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:34,965 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:34,965 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mwwewpdz
2024-01-06 06:31:34,965 - distributed.worker - INFO - Starting Worker plugin PreImport-47547c2f-f528-45cb-9b0e-c1a14407ff11
2024-01-06 06:31:34,965 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-af3e8efe-9e46-4cae-8359-3c014b42eb44
2024-01-06 06:31:34,966 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c1ec5bec-cb9a-492a-9a9e-f87637fac2f1
2024-01-06 06:31:34,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:34,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:34,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:34,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:34,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:34,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:34,976 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:34,977 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36773
2024-01-06 06:31:34,977 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36773
2024-01-06 06:31:34,977 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34475
2024-01-06 06:31:34,977 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:34,977 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:34,977 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:34,977 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:34,977 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:34,977 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5gkjx_op
2024-01-06 06:31:34,978 - distributed.worker - INFO - Starting Worker plugin PreImport-fff68d99-7703-463d-98b7-539e4e98d9d8
2024-01-06 06:31:34,978 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4a9c0db9-ae22-4e90-a6a1-0844e9c56616
2024-01-06 06:31:34,978 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e0e5aac6-ddd1-4673-9a12-4e02540e418c
2024-01-06 06:31:34,978 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:34,978 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44769
2024-01-06 06:31:34,978 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44769
2024-01-06 06:31:34,978 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41975
2024-01-06 06:31:34,978 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:34,979 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:34,979 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:34,979 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:34,979 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yrtrtky6
2024-01-06 06:31:34,979 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4ee217df-9513-418a-b6d3-781b32ffe40a
2024-01-06 06:31:34,979 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45285
2024-01-06 06:31:34,979 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45285
2024-01-06 06:31:34,979 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38319
2024-01-06 06:31:34,979 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:34,979 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:34,979 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:34,979 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:34,979 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ypenqy3f
2024-01-06 06:31:34,980 - distributed.worker - INFO - Starting Worker plugin PreImport-1082bc36-726b-49c8-95a6-fa9916da2dda
2024-01-06 06:31:34,980 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a6541b9f-5ea2-48c1-8a2b-9207b3ded142
2024-01-06 06:31:34,980 - distributed.worker - INFO - Starting Worker plugin RMMSetup-be9d495f-55fa-4726-8a57-bac4b5d65bb7
2024-01-06 06:31:38,416 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39563'. Reason: nanny-close
2024-01-06 06:31:38,417 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44319'. Reason: nanny-close
2024-01-06 06:31:38,417 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33567'. Reason: nanny-close
2024-01-06 06:31:38,417 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39679'. Reason: nanny-close
2024-01-06 06:31:38,417 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37597'. Reason: nanny-close
2024-01-06 06:31:38,418 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37677'. Reason: nanny-close
2024-01-06 06:31:38,418 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44419'. Reason: nanny-close
2024-01-06 06:31:38,418 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33873'. Reason: nanny-close
2024-01-06 06:31:38,718 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,730 - distributed.worker - INFO - Starting Worker plugin PreImport-d5b0dd02-0cf3-4985-8abf-720004861293
2024-01-06 06:31:38,731 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7b86f037-6223-4e38-b83e-9d7f675ffd68
2024-01-06 06:31:38,732 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,745 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:38,746 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:38,746 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,748 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:31:38,768 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,776 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:38,776 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6dea1375-9d59-4a89-ae4d-fe4717086309
2024-01-06 06:31:38,777 - distributed.worker - INFO - Starting Worker plugin PreImport-df168a57-5e6d-486c-91f4-3c8dafab3539
2024-01-06 06:31:38,777 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:38,777 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,779 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,780 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:31:38,780 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:38,781 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40837. Reason: nanny-close
2024-01-06 06:31:38,784 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:31:38,786 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:38,786 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:38,786 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36773. Reason: nanny-close
2024-01-06 06:31:38,789 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:31:38,790 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:38,793 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:38,793 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:38,794 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,796 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:31:38,820 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:38,821 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:38,821 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,823 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:31:38,837 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:38,837 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:38,838 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44769. Reason: nanny-close
2024-01-06 06:31:38,838 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45289. Reason: nanny-close
2024-01-06 06:31:38,840 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:31:38,841 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:31:38,842 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:38,843 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:38,863 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-21623854-7d68-47ad-888c-9fe7fcd91e36
2024-01-06 06:31:38,864 - distributed.worker - INFO - Starting Worker plugin PreImport-3903bcef-85be-4bc4-a4b1-85b5abc5601b
2024-01-06 06:31:38,864 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,891 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:38,892 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:38,892 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,894 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:31:38,922 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:38,923 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40621. Reason: nanny-close
2024-01-06 06:31:38,925 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:31:38,926 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:38,979 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:38,981 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6b65ec88-7a65-4848-b8c1-18d81477615e
2024-01-06 06:31:38,982 - distributed.worker - INFO - Starting Worker plugin PreImport-3e41c39c-c40c-4f8b-9a8e-5dfd8e3af031
2024-01-06 06:31:38,983 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:39,010 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:39,011 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:39,011 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:39,013 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:31:39,024 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:39,026 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:39,026 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:39,028 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:31:39,041 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:39,042 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45285. Reason: nanny-close
2024-01-06 06:31:39,044 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:31:39,046 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:39,072 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:39,073 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44067. Reason: nanny-close
2024-01-06 06:31:39,075 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:31:39,077 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:39,129 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d702e6d8-5424-46d5-876f-f4375a1504d2
2024-01-06 06:31:39,130 - distributed.worker - INFO - Starting Worker plugin PreImport-130268b8-e0a5-4da5-bcf6-0ff3b1a60b69
2024-01-06 06:31:39,132 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:39,171 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:39,172 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:39,172 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:39,175 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:31:39,186 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:31:39,188 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42579. Reason: nanny-close
2024-01-06 06:31:39,190 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:31:39,192 - distributed.nanny - INFO - Worker closed
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-06 06:31:42,231 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:31:42,236 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36997 instead
  warnings.warn(
2024-01-06 06:31:42,240 - distributed.scheduler - INFO - State start
2024-01-06 06:31:42,757 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:31:42,758 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-06 06:31:42,759 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:31:42,760 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-06 06:31:42,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35479'
2024-01-06 06:31:43,008 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42381'
2024-01-06 06:31:43,019 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42523'
2024-01-06 06:31:43,033 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38217'
2024-01-06 06:31:43,036 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36307'
2024-01-06 06:31:43,046 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42889'
2024-01-06 06:31:43,057 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42079'
2024-01-06 06:31:43,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34331'
2024-01-06 06:31:44,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:44,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:44,859 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:44,860 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38501
2024-01-06 06:31:44,860 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38501
2024-01-06 06:31:44,860 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34429
2024-01-06 06:31:44,860 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:44,860 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:44,860 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:44,860 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:44,860 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_ktwd0lz
2024-01-06 06:31:44,860 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ce436b1d-e7c5-4797-b39e-557a66b9d370
2024-01-06 06:31:44,863 - distributed.worker - INFO - Starting Worker plugin PreImport-54c8d48f-105e-4452-88cb-6c3d5e369056
2024-01-06 06:31:44,864 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9f9d2ad6-4c17-4251-aa09-3bffb90ae686
2024-01-06 06:31:44,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:44,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:44,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:44,921 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:44,924 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:44,924 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37405
2024-01-06 06:31:44,924 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37405
2024-01-06 06:31:44,925 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41131
2024-01-06 06:31:44,925 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:44,925 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:44,925 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:44,925 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:44,925 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wkvxdx9b
2024-01-06 06:31:44,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:44,925 - distributed.worker - INFO - Starting Worker plugin PreImport-b68a87bf-4d33-421a-9b1e-516a06ea3855
2024-01-06 06:31:44,925 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:44,925 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:44,925 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3a8095a2-ad47-4af3-aa17-cb103e3f8e89
2024-01-06 06:31:44,925 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3259fb12-2804-4ff7-9706-9361ccf51656
2024-01-06 06:31:44,926 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34109
2024-01-06 06:31:44,926 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34109
2024-01-06 06:31:44,926 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43913
2024-01-06 06:31:44,926 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:44,926 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:44,926 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:44,926 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:44,926 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zurmfs91
2024-01-06 06:31:44,927 - distributed.worker - INFO - Starting Worker plugin RMMSetup-33e47389-a4c2-4e16-9e21-3dd58012bb6e
2024-01-06 06:31:44,929 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:44,930 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35247
2024-01-06 06:31:44,930 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35247
2024-01-06 06:31:44,930 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45759
2024-01-06 06:31:44,931 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:44,931 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:44,931 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:44,931 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:44,931 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9ng7rs1j
2024-01-06 06:31:44,931 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8b0ebedd-1e94-4f25-aba4-b911c7614963
2024-01-06 06:31:44,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:44,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:44,941 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:44,942 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36309
2024-01-06 06:31:44,942 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36309
2024-01-06 06:31:44,943 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34625
2024-01-06 06:31:44,943 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:44,943 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:44,943 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:44,943 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:44,943 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yddr7wiz
2024-01-06 06:31:44,943 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6ee2f3ae-17d7-4aec-8efd-750990d5d8d3
2024-01-06 06:31:45,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:45,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:45,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:45,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:45,137 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:45,138 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32787
2024-01-06 06:31:45,138 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32787
2024-01-06 06:31:45,138 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40981
2024-01-06 06:31:45,138 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:45,138 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:45,138 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:45,138 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:45,138 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-obqmaa0o
2024-01-06 06:31:45,138 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:45,138 - distributed.worker - INFO - Starting Worker plugin PreImport-31d5b6d1-d65d-4431-976f-ae1d11f38e1c
2024-01-06 06:31:45,138 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1f3748a0-6d70-4a87-b134-8ebd41a5bb20
2024-01-06 06:31:45,138 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b63f497-0e82-4dcf-a398-54d92405af1e
2024-01-06 06:31:45,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:31:45,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:31:45,139 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40129
2024-01-06 06:31:45,139 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40129
2024-01-06 06:31:45,139 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41951
2024-01-06 06:31:45,139 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:45,139 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:45,139 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:45,139 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:45,139 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jzej73hv
2024-01-06 06:31:45,139 - distributed.worker - INFO - Starting Worker plugin PreImport-726e4363-04be-4fe4-889d-1a37b88c0372
2024-01-06 06:31:45,140 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a743d1fb-4ec7-4b53-98c7-a0f6b2c03967
2024-01-06 06:31:45,140 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7865fab7-d08f-4172-a4cb-db67a4c7262c
2024-01-06 06:31:45,143 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:31:45,143 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42109
2024-01-06 06:31:45,143 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42109
2024-01-06 06:31:45,144 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39449
2024-01-06 06:31:45,144 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:31:45,144 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:45,144 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:31:45,144 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:31:45,144 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d0chnn32
2024-01-06 06:31:45,144 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4f876584-f3b5-4b78-b033-745091e0ead5
2024-01-06 06:31:45,950 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:46,872 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:46,983 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-85e6e021-21ab-4d16-9062-723f16abe81f
2024-01-06 06:31:46,983 - distributed.worker - INFO - Starting Worker plugin PreImport-f05ed135-b761-43dc-86a2-4be326becff0
2024-01-06 06:31:46,984 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:46,994 - distributed.worker - INFO - Starting Worker plugin PreImport-ae189acd-193c-4a5b-8738-e791f68f9c52
2024-01-06 06:31:46,995 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-825eeb71-8fcc-4485-8ab8-07866b7335a0
2024-01-06 06:31:46,996 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:47,026 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:47,029 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-54e0ccf6-b6f7-45f5-9dc6-69ad1fa22e5b
2024-01-06 06:31:47,030 - distributed.worker - INFO - Starting Worker plugin PreImport-c23c522e-31ca-43d2-9077-8355b63e5328
2024-01-06 06:31:47,031 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:47,045 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a4f165a3-d3c2-49c9-aee1-b4c928460fbb
2024-01-06 06:31:47,047 - distributed.worker - INFO - Starting Worker plugin PreImport-356ff7bd-06dc-4c63-aa63-fc236f4c1122
2024-01-06 06:31:47,048 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:47,053 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:50,487 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:50,488 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:50,488 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:50,490 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:31:50,517 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42381'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2024-01-06 06:31:50,518 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2024-01-06 06:31:50,520 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35247. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2024-01-06 06:31:50,522 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:31:50,524 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:50,781 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:50,782 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:50,782 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:50,784 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:31:50,822 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42523'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2024-01-06 06:31:50,822 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2024-01-06 06:31:50,823 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34109. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2024-01-06 06:31:50,825 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:31:50,827 - distributed.nanny - INFO - Worker closed
2024-01-06 06:31:50,929 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:31:50,929 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:31:50,929 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:31:50,931 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 383, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:55270 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 242, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2024-01-06 06:31:50,933 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=62946 parent=62754 started daemon>
2024-01-06 06:31:50,934 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=62942 parent=62754 started daemon>
2024-01-06 06:31:50,934 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=62938 parent=62754 started daemon>
2024-01-06 06:31:50,934 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=62935 parent=62754 started daemon>
2024-01-06 06:31:50,934 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=62931 parent=62754 started daemon>
2024-01-06 06:31:50,934 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=62927 parent=62754 started daemon>
2024-01-06 06:31:50,934 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=62920 parent=62754 started daemon>
2024-01-06 06:31:51,217 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 62938 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-06 06:32:00,645 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:00,650 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38635 instead
  warnings.warn(
2024-01-06 06:32:00,654 - distributed.scheduler - INFO - State start
2024-01-06 06:32:00,655 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-yddr7wiz', purging
2024-01-06 06:32:00,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-obqmaa0o', purging
2024-01-06 06:32:00,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-jzej73hv', purging
2024-01-06 06:32:00,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-d0chnn32', purging
2024-01-06 06:32:00,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-_ktwd0lz', purging
2024-01-06 06:32:00,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-wkvxdx9b', purging
2024-01-06 06:32:00,681 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:00,682 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:32:00,682 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38635/status
2024-01-06 06:32:00,683 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:32:00,783 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35437'
2024-01-06 06:32:00,807 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38225'
2024-01-06 06:32:00,823 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33055'
2024-01-06 06:32:00,826 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41829'
2024-01-06 06:32:00,835 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32915'
2024-01-06 06:32:00,844 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37365'
2024-01-06 06:32:00,854 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45681'
2024-01-06 06:32:00,863 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34215'
2024-01-06 06:32:01,173 - distributed.scheduler - INFO - Receive client connection: Client-4b1f14a2-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:01,188 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50678
2024-01-06 06:32:02,695 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:02,695 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:02,696 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:02,696 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:02,699 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:02,700 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34261
2024-01-06 06:32:02,700 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34261
2024-01-06 06:32:02,700 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37505
2024-01-06 06:32:02,700 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:02,700 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:02,700 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:02,700 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:02,700 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b330suvo
2024-01-06 06:32:02,701 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:02,701 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b4901dfd-50ae-443b-990c-c8e62229c4ff
2024-01-06 06:32:02,701 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45423
2024-01-06 06:32:02,702 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45423
2024-01-06 06:32:02,702 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36303
2024-01-06 06:32:02,702 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:02,702 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:02,702 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:02,702 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:02,702 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vezbx2gz
2024-01-06 06:32:02,702 - distributed.worker - INFO - Starting Worker plugin PreImport-876b1488-9dae-43e7-bc5e-f98f95fa76c1
2024-01-06 06:32:02,702 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-be225687-33a0-46cd-89c5-98648e53fd82
2024-01-06 06:32:02,702 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6214a764-b0c1-443a-84d8-a420335db13c
2024-01-06 06:32:02,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:02,706 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:02,710 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:02,711 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33545
2024-01-06 06:32:02,711 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33545
2024-01-06 06:32:02,711 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34157
2024-01-06 06:32:02,711 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:02,711 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:02,711 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:02,711 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:02,711 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ojadkewd
2024-01-06 06:32:02,711 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1e22877b-e72b-4637-a5dd-e57a924de0c4
2024-01-06 06:32:02,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:02,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:02,751 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:02,752 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37973
2024-01-06 06:32:02,752 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37973
2024-01-06 06:32:02,752 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45871
2024-01-06 06:32:02,753 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:02,753 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:02,753 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:02,753 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:02,753 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8cqk9ezb
2024-01-06 06:32:02,753 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c149065d-8224-483c-999e-a2f068146ba2
2024-01-06 06:32:02,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:02,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:02,780 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:02,781 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32989
2024-01-06 06:32:02,781 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32989
2024-01-06 06:32:02,781 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43929
2024-01-06 06:32:02,781 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:02,781 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:02,781 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:02,781 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:02,781 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d50zdrcc
2024-01-06 06:32:02,781 - distributed.worker - INFO - Starting Worker plugin PreImport-a1fbcbab-dfa3-4dcb-8a26-772e22348d17
2024-01-06 06:32:02,781 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-797c6fc4-fdb4-4ef5-90dc-97d3400ce9a4
2024-01-06 06:32:02,782 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2a530f96-964b-45c3-b233-1a38ca137a9d
2024-01-06 06:32:02,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:02,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:02,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:02,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:02,805 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:02,806 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39019
2024-01-06 06:32:02,806 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39019
2024-01-06 06:32:02,806 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35111
2024-01-06 06:32:02,806 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:02,806 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:02,806 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:02,806 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:02,806 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5wihmacx
2024-01-06 06:32:02,806 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fde3aa35-a2e6-4d80-98ba-42c69e4e608f
2024-01-06 06:32:02,808 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:02,808 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37209
2024-01-06 06:32:02,808 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37209
2024-01-06 06:32:02,809 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44599
2024-01-06 06:32:02,809 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:02,809 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:02,809 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:02,809 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:02,809 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3kv_etia
2024-01-06 06:32:02,809 - distributed.worker - INFO - Starting Worker plugin RMMSetup-213ffd0f-c65d-4cd8-bccb-517e6b5c25e0
2024-01-06 06:32:02,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:02,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:02,850 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:02,851 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40873
2024-01-06 06:32:02,852 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40873
2024-01-06 06:32:02,852 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46263
2024-01-06 06:32:02,852 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:02,852 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:02,852 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:02,852 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:02,852 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-979yq27s
2024-01-06 06:32:02,852 - distributed.worker - INFO - Starting Worker plugin PreImport-01f511b5-3368-4c1f-96bc-9787740afc78
2024-01-06 06:32:02,852 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-22048e87-1db2-46e9-8583-a9b1e7f279a8
2024-01-06 06:32:02,855 - distributed.worker - INFO - Starting Worker plugin RMMSetup-687aedcf-b7e3-440a-8b97-770b18785d0c
2024-01-06 06:32:04,830 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,845 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-898e9de2-e1d7-456b-a5a1-e61c30fc0c2e
2024-01-06 06:32:04,848 - distributed.worker - INFO - Starting Worker plugin PreImport-a11241ca-96bd-4463-a636-c40c69048720
2024-01-06 06:32:04,849 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,855 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45423', status: init, memory: 0, processing: 0>
2024-01-06 06:32:04,857 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45423
2024-01-06 06:32:04,857 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50688
2024-01-06 06:32:04,858 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:04,858 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:04,859 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,860 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:04,888 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34261', status: init, memory: 0, processing: 0>
2024-01-06 06:32:04,888 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34261
2024-01-06 06:32:04,889 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50694
2024-01-06 06:32:04,890 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:04,891 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:04,891 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,894 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:04,928 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b4f1feb6-d486-497d-b66b-98255821f0ac
2024-01-06 06:32:04,928 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,928 - distributed.worker - INFO - Starting Worker plugin PreImport-b4b8fe89-6bb9-43b0-8d27-3d5223400c8a
2024-01-06 06:32:04,930 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,931 - distributed.worker - INFO - Starting Worker plugin PreImport-f528f8a0-55a5-48e9-a5be-fd0e5801746e
2024-01-06 06:32:04,933 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d20a1be5-50d0-46c3-8d4c-c48825262e69
2024-01-06 06:32:04,934 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,951 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-41c7e24b-0917-456a-8402-251e9103e4e4
2024-01-06 06:32:04,952 - distributed.worker - INFO - Starting Worker plugin PreImport-68d6b69b-793e-4e15-b2c8-384de40d2a9c
2024-01-06 06:32:04,954 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,955 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32989', status: init, memory: 0, processing: 0>
2024-01-06 06:32:04,956 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32989
2024-01-06 06:32:04,956 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50702
2024-01-06 06:32:04,957 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:04,958 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:04,958 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,959 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:04,971 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33545', status: init, memory: 0, processing: 0>
2024-01-06 06:32:04,971 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33545
2024-01-06 06:32:04,971 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50714
2024-01-06 06:32:04,973 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:04,974 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37973', status: init, memory: 0, processing: 0>
2024-01-06 06:32:04,974 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:04,974 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,975 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37973
2024-01-06 06:32:04,975 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50720
2024-01-06 06:32:04,976 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:04,976 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:04,978 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:04,978 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,980 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:04,980 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-938c8ede-e48f-4bee-bd93-744ecb5fa41d
2024-01-06 06:32:04,981 - distributed.worker - INFO - Starting Worker plugin PreImport-882c1af0-c1ba-4403-8818-810f1bda9270
2024-01-06 06:32:04,981 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,982 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:04,998 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37209', status: init, memory: 0, processing: 0>
2024-01-06 06:32:04,998 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37209
2024-01-06 06:32:04,998 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50724
2024-01-06 06:32:05,000 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:05,001 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:05,001 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:05,003 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:05,007 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39019', status: init, memory: 0, processing: 0>
2024-01-06 06:32:05,007 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39019
2024-01-06 06:32:05,007 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50740
2024-01-06 06:32:05,008 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40873', status: init, memory: 0, processing: 0>
2024-01-06 06:32:05,008 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:05,009 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40873
2024-01-06 06:32:05,009 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50754
2024-01-06 06:32:05,009 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:05,009 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:05,010 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:05,011 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:05,011 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:05,011 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:05,012 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:05,087 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:05,088 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:05,088 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:05,088 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:05,088 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:05,089 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:05,089 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:05,089 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:05,100 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:05,100 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:05,101 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:05,101 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:05,101 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:05,101 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:05,101 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:05,101 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:05,111 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:05,113 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:05,116 - distributed.scheduler - INFO - Remove client Client-4b1f14a2-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:05,116 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50678; closing.
2024-01-06 06:32:05,116 - distributed.scheduler - INFO - Remove client Client-4b1f14a2-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:05,116 - distributed.scheduler - INFO - Close client connection: Client-4b1f14a2-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:05,118 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35437'. Reason: nanny-close
2024-01-06 06:32:05,118 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:05,118 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38225'. Reason: nanny-close
2024-01-06 06:32:05,119 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:05,119 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33055'. Reason: nanny-close
2024-01-06 06:32:05,119 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33545. Reason: nanny-close
2024-01-06 06:32:05,119 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:05,120 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41829'. Reason: nanny-close
2024-01-06 06:32:05,120 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34261. Reason: nanny-close
2024-01-06 06:32:05,120 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:05,120 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32915'. Reason: nanny-close
2024-01-06 06:32:05,120 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39019. Reason: nanny-close
2024-01-06 06:32:05,121 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:05,121 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37365'. Reason: nanny-close
2024-01-06 06:32:05,121 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45423. Reason: nanny-close
2024-01-06 06:32:05,121 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:05,121 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45681'. Reason: nanny-close
2024-01-06 06:32:05,122 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:05,122 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37209. Reason: nanny-close
2024-01-06 06:32:05,122 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34215'. Reason: nanny-close
2024-01-06 06:32:05,122 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:05,122 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:05,122 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50714; closing.
2024-01-06 06:32:05,122 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37973. Reason: nanny-close
2024-01-06 06:32:05,122 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32989. Reason: nanny-close
2024-01-06 06:32:05,122 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33545', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522725.1228662')
2024-01-06 06:32:05,122 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:05,122 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:05,123 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40873. Reason: nanny-close
2024-01-06 06:32:05,123 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:05,123 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50740; closing.
2024-01-06 06:32:05,124 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50694; closing.
2024-01-06 06:32:05,124 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:05,124 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:05,124 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:05,125 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:05,125 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:05,125 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39019', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522725.1250942')
2024-01-06 06:32:05,125 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:05,125 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34261', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522725.1254456')
2024-01-06 06:32:05,125 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50688; closing.
2024-01-06 06:32:05,126 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:05,126 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:05,126 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:05,126 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45423', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522725.126628')
2024-01-06 06:32:05,126 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:05,127 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50724; closing.
2024-01-06 06:32:05,127 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50702; closing.
2024-01-06 06:32:05,128 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50754; closing.
2024-01-06 06:32:05,128 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50720; closing.
2024-01-06 06:32:05,128 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37209', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522725.1284957')
2024-01-06 06:32:05,128 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:05,128 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:05,128 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32989', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522725.1288607')
2024-01-06 06:32:05,129 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40873', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522725.1291945')
2024-01-06 06:32:05,129 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37973', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522725.1294951')
2024-01-06 06:32:05,129 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:32:06,164 - distributed.scheduler - INFO - Receive client connection: Client-4f8bcbae-ac5d-11ee-b2c9-d8c49764f6bb
2024-01-06 06:32:06,164 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50768
2024-01-06 06:32:06,384 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:32:06,385 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:32:06,385 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:32:06,387 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:32:06,387 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-06 06:32:08,682 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:08,687 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38721 instead
  warnings.warn(
2024-01-06 06:32:08,691 - distributed.scheduler - INFO - State start
2024-01-06 06:32:08,715 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:08,715 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-06 06:32:08,716 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:32:08,717 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-06 06:32:08,848 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36087'
2024-01-06 06:32:08,881 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45803'
2024-01-06 06:32:08,885 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45813'
2024-01-06 06:32:08,896 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45861'
2024-01-06 06:32:08,908 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37711'
2024-01-06 06:32:08,921 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44621'
2024-01-06 06:32:08,933 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43833'
2024-01-06 06:32:08,946 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41947'
2024-01-06 06:32:10,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:10,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:10,902 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:10,902 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32933
2024-01-06 06:32:10,902 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32933
2024-01-06 06:32:10,902 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42885
2024-01-06 06:32:10,903 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:10,903 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:10,903 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:10,903 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:10,903 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-76ojoe6c
2024-01-06 06:32:10,903 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8177fc83-2e6b-48b1-aaf9-b5c6e0cbcd54
2024-01-06 06:32:10,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:10,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:10,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:10,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:10,909 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:10,909 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:10,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:10,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:10,910 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39531
2024-01-06 06:32:10,910 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45715
2024-01-06 06:32:10,910 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39531
2024-01-06 06:32:10,910 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45715
2024-01-06 06:32:10,910 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33823
2024-01-06 06:32:10,910 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34497
2024-01-06 06:32:10,910 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:10,910 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:10,910 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:10,910 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:10,910 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:10,910 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:10,910 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:10,910 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:10,910 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pb5fj2v7
2024-01-06 06:32:10,910 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ivygrsds
2024-01-06 06:32:10,911 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1fd8c909-0811-42ae-ada1-c74326d2fe84
2024-01-06 06:32:10,911 - distributed.worker - INFO - Starting Worker plugin PreImport-a45a5153-b8e2-4a37-b9f9-a1c530bd3d9c
2024-01-06 06:32:10,911 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1c60d098-feb3-4864-b985-62c918b401d6
2024-01-06 06:32:10,911 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c251bca9-d6d7-45c0-9070-bf1be9a11f10
2024-01-06 06:32:10,914 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:10,915 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46777
2024-01-06 06:32:10,915 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46777
2024-01-06 06:32:10,915 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43371
2024-01-06 06:32:10,915 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:10,915 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:10,915 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:10,915 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:10,915 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ivl16bha
2024-01-06 06:32:10,915 - distributed.worker - INFO - Starting Worker plugin RMMSetup-39b529d2-7a21-4490-b438-24a19669163f
2024-01-06 06:32:10,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:10,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:10,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:10,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:10,938 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:10,938 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:10,938 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33141
2024-01-06 06:32:10,939 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33141
2024-01-06 06:32:10,939 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43387
2024-01-06 06:32:10,939 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:10,939 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:10,939 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:10,939 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:10,939 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-45g46all
2024-01-06 06:32:10,939 - distributed.worker - INFO - Starting Worker plugin RMMSetup-918357f2-d6af-465c-a069-44c7871e626b
2024-01-06 06:32:10,939 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33407
2024-01-06 06:32:10,939 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33407
2024-01-06 06:32:10,940 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36817
2024-01-06 06:32:10,940 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:10,940 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:10,940 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:10,940 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:10,940 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o_pkbb7n
2024-01-06 06:32:10,940 - distributed.worker - INFO - Starting Worker plugin PreImport-518f1823-e657-42d3-aa2f-33b41c28290b
2024-01-06 06:32:10,940 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4c9bfea4-c500-4893-97c5-a755ed3798c1
2024-01-06 06:32:10,940 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c02fa7c7-f7db-4f93-ae0c-a3b872744aee
2024-01-06 06:32:10,943 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:10,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:10,948 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:10,948 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37357
2024-01-06 06:32:10,948 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37357
2024-01-06 06:32:10,948 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40947
2024-01-06 06:32:10,949 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:10,949 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:10,949 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:10,949 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:10,949 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gs3c7x14
2024-01-06 06:32:10,949 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1acc9afb-5bfd-48cc-bea5-7b6c2363623a
2024-01-06 06:32:10,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:10,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:10,956 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:10,957 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38521
2024-01-06 06:32:10,957 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38521
2024-01-06 06:32:10,957 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39971
2024-01-06 06:32:10,957 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:10,957 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:10,958 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:10,958 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:10,958 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-83wj05la
2024-01-06 06:32:10,958 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a31baf77-71b7-49a1-b01c-1046bc823277
2024-01-06 06:32:14,494 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,520 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:14,521 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:14,521 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,523 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:14,529 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fe695f93-785a-4888-964f-5ec81ecb6c5f
2024-01-06 06:32:14,529 - distributed.worker - INFO - Starting Worker plugin PreImport-d511dfbe-145e-41cb-a1ea-21c6222346ec
2024-01-06 06:32:14,531 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,564 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bd8e4812-1ab8-4ab1-bda6-769e452a513b
2024-01-06 06:32:14,564 - distributed.worker - INFO - Starting Worker plugin PreImport-0f643e6e-13ca-43c5-a301-fc076560b05b
2024-01-06 06:32:14,565 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,568 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:14,569 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:14,569 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,571 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:14,590 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:14,590 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:14,590 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,592 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:14,596 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cbe1c1d9-2aea-45d9-b1c0-02de274e82f2
2024-01-06 06:32:14,596 - distributed.worker - INFO - Starting Worker plugin PreImport-99974355-9402-4d47-ada6-4ec6601ce7eb
2024-01-06 06:32:14,597 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,607 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,608 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-96956e92-a614-417a-b614-248d9cdac870
2024-01-06 06:32:14,609 - distributed.worker - INFO - Starting Worker plugin PreImport-ec79b83a-cb49-4a6b-9b34-a25f513d49f4
2024-01-06 06:32:14,611 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,615 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-142b01e2-6d31-4ade-ab12-2edaeea28544
2024-01-06 06:32:14,616 - distributed.worker - INFO - Starting Worker plugin PreImport-af296037-9356-46a7-bf62-0dc6797732cb
2024-01-06 06:32:14,618 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,618 - distributed.worker - INFO - Starting Worker plugin PreImport-6a3df71d-5982-401c-8263-f422016df561
2024-01-06 06:32:14,618 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ca423cbb-e755-4d54-8839-7abd7f292196
2024-01-06 06:32:14,620 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,622 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:14,623 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:14,623 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,624 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:14,637 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:14,638 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:14,638 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,639 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:14,669 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:14,670 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:14,671 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:14,671 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,671 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:14,671 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,673 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:14,674 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:14,674 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:14,675 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:14,675 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:14,678 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:22,336 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:22,336 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:22,337 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:22,337 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:22,337 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:22,337 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:22,337 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:22,337 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:22,349 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:22,350 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:22,350 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:22,350 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:22,350 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:22,350 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:22,350 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:22,350 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:32:22,366 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36087'. Reason: nanny-close
2024-01-06 06:32:22,367 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:22,367 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45803'. Reason: nanny-close
2024-01-06 06:32:22,368 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:22,368 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45813'. Reason: nanny-close
2024-01-06 06:32:22,368 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:22,368 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45861'. Reason: nanny-close
2024-01-06 06:32:22,368 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46777. Reason: nanny-close
2024-01-06 06:32:22,369 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:22,369 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33407. Reason: nanny-close
2024-01-06 06:32:22,369 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37711'. Reason: nanny-close
2024-01-06 06:32:22,369 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45715. Reason: nanny-close
2024-01-06 06:32:22,369 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:22,369 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44621'. Reason: nanny-close
2024-01-06 06:32:22,369 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32933. Reason: nanny-close
2024-01-06 06:32:22,369 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:22,370 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43833'. Reason: nanny-close
2024-01-06 06:32:22,370 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:22,370 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41947'. Reason: nanny-close
2024-01-06 06:32:22,370 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33141. Reason: nanny-close
2024-01-06 06:32:22,370 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:22,371 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39531. Reason: nanny-close
2024-01-06 06:32:22,371 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:22,371 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:22,371 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38521. Reason: nanny-close
2024-01-06 06:32:22,371 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:22,371 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37357. Reason: nanny-close
2024-01-06 06:32:22,371 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:22,372 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:22,372 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:22,373 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:22,373 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:22,373 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:22,373 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:22,374 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:22,374 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:22,374 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:22,374 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:22,376 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:22,376 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-06 06:32:25,889 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:25,894 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45779 instead
  warnings.warn(
2024-01-06 06:32:25,901 - distributed.scheduler - INFO - State start
2024-01-06 06:32:25,927 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:25,928 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:32:25,929 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45779/status
2024-01-06 06:32:25,930 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:32:26,004 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37987'
2024-01-06 06:32:26,023 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45421'
2024-01-06 06:32:26,039 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39347'
2024-01-06 06:32:26,042 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38425'
2024-01-06 06:32:26,054 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37337'
2024-01-06 06:32:26,065 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37647'
2024-01-06 06:32:26,076 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35457'
2024-01-06 06:32:26,088 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43255'
2024-01-06 06:32:26,907 - distributed.scheduler - INFO - Receive client connection: Client-5a34cc60-ac5d-11ee-b2c9-d8c49764f6bb
2024-01-06 06:32:26,925 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53050
2024-01-06 06:32:28,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:28,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:28,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:28,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:28,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:28,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:28,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:28,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:28,178 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:28,178 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:28,179 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42105
2024-01-06 06:32:28,179 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42181
2024-01-06 06:32:28,179 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42105
2024-01-06 06:32:28,179 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42181
2024-01-06 06:32:28,179 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:28,179 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45929
2024-01-06 06:32:28,179 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40367
2024-01-06 06:32:28,179 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:28,179 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:28,179 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:28,179 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:28,179 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:28,179 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:28,180 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:28,180 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:28,180 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5fq6_mhr
2024-01-06 06:32:28,180 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6xzk41r5
2024-01-06 06:32:28,180 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f1264963-3a09-4b73-88e6-89389ec546fd
2024-01-06 06:32:28,180 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3a7a891d-31fd-4484-ba13-566748f57a9e
2024-01-06 06:32:28,180 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:28,180 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43701
2024-01-06 06:32:28,180 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43701
2024-01-06 06:32:28,180 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39757
2024-01-06 06:32:28,180 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:28,181 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:28,181 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:28,181 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:28,181 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gza9k9rh
2024-01-06 06:32:28,181 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ca0d4367-e3a2-47b0-b5f1-2f4d5b3a9f91
2024-01-06 06:32:28,181 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33633
2024-01-06 06:32:28,181 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33633
2024-01-06 06:32:28,181 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33777
2024-01-06 06:32:28,181 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:28,181 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:28,181 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:28,182 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:28,182 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b02hfj9g
2024-01-06 06:32:28,182 - distributed.worker - INFO - Starting Worker plugin PreImport-4d7c7aa3-3e27-43d0-a713-9e5bffc8acb4
2024-01-06 06:32:28,182 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ebfeaa8e-2511-45a0-abc4-01278d5d7a95
2024-01-06 06:32:28,182 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e55e5812-04b9-4d85-bdea-4c967c00bfb3
2024-01-06 06:32:28,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:28,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:28,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:28,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:28,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:28,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:28,189 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:28,190 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46291
2024-01-06 06:32:28,190 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46291
2024-01-06 06:32:28,190 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46063
2024-01-06 06:32:28,190 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:28,190 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:28,190 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:28,190 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:28,190 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s84_zl_c
2024-01-06 06:32:28,190 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f6eb0c1e-18c8-4912-9e84-aab2d6d3cfa6
2024-01-06 06:32:28,190 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:28,190 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:28,191 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46753
2024-01-06 06:32:28,191 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46753
2024-01-06 06:32:28,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:28,191 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43593
2024-01-06 06:32:28,191 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38187
2024-01-06 06:32:28,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:28,192 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43593
2024-01-06 06:32:28,192 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:28,192 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:28,192 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39073
2024-01-06 06:32:28,192 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:28,192 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:28,192 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:28,192 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:28,192 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b225ov0o
2024-01-06 06:32:28,192 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:28,192 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:28,192 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1u69vnoo
2024-01-06 06:32:28,192 - distributed.worker - INFO - Starting Worker plugin PreImport-c7065362-7e87-4a5c-9e27-873a2eeff74e
2024-01-06 06:32:28,192 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1cb89dea-949d-4b57-914a-52afc0c3de5d
2024-01-06 06:32:28,192 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e87eeaff-fa84-4b15-94cc-7de33e4946b8
2024-01-06 06:32:28,192 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6269f2cb-04e1-42f7-93b6-21bd7d0f47f0
2024-01-06 06:32:28,197 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:28,198 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46707
2024-01-06 06:32:28,198 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46707
2024-01-06 06:32:28,198 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33443
2024-01-06 06:32:28,198 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:28,198 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:28,198 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:28,198 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:32:28,198 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0skp7v4h
2024-01-06 06:32:28,198 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2409bcd6-469b-40a9-8953-9d7b3fe33ede
2024-01-06 06:32:28,706 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38941', status: init, memory: 0, processing: 0>
2024-01-06 06:32:28,708 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38941
2024-01-06 06:32:28,708 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53072
2024-01-06 06:32:28,787 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:28,789 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:28,792 - distributed.scheduler - INFO - Remove client Client-5a34cc60-ac5d-11ee-b2c9-d8c49764f6bb
2024-01-06 06:32:28,792 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53050; closing.
2024-01-06 06:32:28,792 - distributed.scheduler - INFO - Remove client Client-5a34cc60-ac5d-11ee-b2c9-d8c49764f6bb
2024-01-06 06:32:28,793 - distributed.scheduler - INFO - Close client connection: Client-5a34cc60-ac5d-11ee-b2c9-d8c49764f6bb
2024-01-06 06:32:28,798 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53072; closing.
2024-01-06 06:32:28,798 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38941', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522748.798523')
2024-01-06 06:32:28,798 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:32:30,420 - distributed.worker - INFO - Starting Worker plugin PreImport-49c5da7d-68ec-4ec3-b64d-cd8dbabe64d0
2024-01-06 06:32:30,420 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3d619c72-cfb1-4b07-ba2f-a4d3a8ffcd1f
2024-01-06 06:32:30,421 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,430 - distributed.scheduler - INFO - Receive client connection: Client-5e029067-ac5d-11ee-b2c9-d8c49764f6bb
2024-01-06 06:32:30,430 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59604
2024-01-06 06:32:30,433 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a726a7eb-3934-4555-b024-5886e56df0c8
2024-01-06 06:32:30,433 - distributed.worker - INFO - Starting Worker plugin PreImport-70ac0930-f499-4873-b75e-805f3beb5ade
2024-01-06 06:32:30,434 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,448 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,456 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42105', status: init, memory: 0, processing: 0>
2024-01-06 06:32:30,457 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42105
2024-01-06 06:32:30,457 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59600
2024-01-06 06:32:30,458 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43701', status: init, memory: 0, processing: 0>
2024-01-06 06:32:30,458 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:30,459 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43701
2024-01-06 06:32:30,459 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59620
2024-01-06 06:32:30,459 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:30,460 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,460 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:30,460 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:30,460 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,462 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:30,462 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:30,462 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-36cae37b-53cd-45ef-80e8-10fd392fc417
2024-01-06 06:32:30,462 - distributed.worker - INFO - Starting Worker plugin PreImport-bf544712-2e7a-4ada-a88a-a6cb8c7bd293
2024-01-06 06:32:30,463 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,467 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-47fb024a-4b17-4bf3-acaf-64c3615c1ba4
2024-01-06 06:32:30,467 - distributed.worker - INFO - Starting Worker plugin PreImport-a2b5f321-21c3-4846-b8cd-17893610e1d0
2024-01-06 06:32:30,468 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,471 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46753', status: init, memory: 0, processing: 0>
2024-01-06 06:32:30,471 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46753
2024-01-06 06:32:30,471 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59626
2024-01-06 06:32:30,472 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:30,473 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:30,473 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,475 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:30,476 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,478 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-61e15288-f063-4797-8716-629425bbf565
2024-01-06 06:32:30,479 - distributed.worker - INFO - Starting Worker plugin PreImport-405911d5-80dd-4f05-b33c-6001aa7e5fda
2024-01-06 06:32:30,480 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,481 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2bea7229-8782-4d42-893d-aa2db79af1dd
2024-01-06 06:32:30,482 - distributed.worker - INFO - Starting Worker plugin PreImport-bd6eba68-5b29-4f37-b19f-90b6a57f4e21
2024-01-06 06:32:30,482 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,491 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46291', status: init, memory: 0, processing: 0>
2024-01-06 06:32:30,491 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46291
2024-01-06 06:32:30,491 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59634
2024-01-06 06:32:30,492 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:30,493 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:30,493 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,495 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:30,503 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42181', status: init, memory: 0, processing: 0>
2024-01-06 06:32:30,504 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42181
2024-01-06 06:32:30,504 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59648
2024-01-06 06:32:30,505 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:30,506 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46707', status: init, memory: 0, processing: 0>
2024-01-06 06:32:30,506 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46707
2024-01-06 06:32:30,506 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59670
2024-01-06 06:32:30,506 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:30,506 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,507 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:30,508 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:30,508 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,508 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:30,509 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:30,514 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33633', status: init, memory: 0, processing: 0>
2024-01-06 06:32:30,515 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33633
2024-01-06 06:32:30,515 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59664
2024-01-06 06:32:30,516 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:30,517 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:30,518 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,519 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43593', status: init, memory: 0, processing: 0>
2024-01-06 06:32:30,519 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43593
2024-01-06 06:32:30,519 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59676
2024-01-06 06:32:30,520 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:30,521 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:30,522 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:30,522 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:30,524 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:33,983 - distributed.scheduler - INFO - Receive client connection: Client-5a1c83a5-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:33,983 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59770
2024-01-06 06:32:33,996 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:33,996 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:33,996 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:33,996 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:33,996 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:33,996 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:33,996 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:33,997 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:32:34,001 - distributed.scheduler - INFO - Remove client Client-5a1c83a5-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:34,001 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59770; closing.
2024-01-06 06:32:34,002 - distributed.scheduler - INFO - Remove client Client-5a1c83a5-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:34,002 - distributed.scheduler - INFO - Close client connection: Client-5a1c83a5-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:34,003 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37987'. Reason: nanny-close
2024-01-06 06:32:34,003 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:34,003 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45421'. Reason: nanny-close
2024-01-06 06:32:34,004 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:34,004 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39347'. Reason: nanny-close
2024-01-06 06:32:34,004 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42181. Reason: nanny-close
2024-01-06 06:32:34,004 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:34,005 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38425'. Reason: nanny-close
2024-01-06 06:32:34,005 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33633. Reason: nanny-close
2024-01-06 06:32:34,005 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:34,005 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37337'. Reason: nanny-close
2024-01-06 06:32:34,005 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46753. Reason: nanny-close
2024-01-06 06:32:34,005 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:34,006 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46291. Reason: nanny-close
2024-01-06 06:32:34,006 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37647'. Reason: nanny-close
2024-01-06 06:32:34,006 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:34,006 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35457'. Reason: nanny-close
2024-01-06 06:32:34,006 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42105. Reason: nanny-close
2024-01-06 06:32:34,006 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:34,007 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:34,007 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43255'. Reason: nanny-close
2024-01-06 06:32:34,007 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43593. Reason: nanny-close
2024-01-06 06:32:34,007 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:34,007 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:34,007 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59648; closing.
2024-01-06 06:32:34,007 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:34,007 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46707. Reason: nanny-close
2024-01-06 06:32:34,008 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42181', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522754.0080364')
2024-01-06 06:32:34,008 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:34,008 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43701. Reason: nanny-close
2024-01-06 06:32:34,008 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:34,009 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59664; closing.
2024-01-06 06:32:34,009 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:34,009 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59626; closing.
2024-01-06 06:32:34,009 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:34,009 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:34,009 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:34,009 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:34,009 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:34,010 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:34,010 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33633', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522754.0106275')
2024-01-06 06:32:34,011 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46753', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522754.0110424')
2024-01-06 06:32:34,011 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:34,011 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:34,011 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:34,011 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59600; closing.
2024-01-06 06:32:34,011 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59634; closing.
2024-01-06 06:32:34,011 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:34,012 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42105', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522754.0129254')
2024-01-06 06:32:34,013 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46291', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522754.0133746')
2024-01-06 06:32:34,013 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59676; closing.
2024-01-06 06:32:34,013 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59670; closing.
2024-01-06 06:32:34,014 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43593', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522754.0145447')
2024-01-06 06:32:34,014 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46707', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522754.0149188')
2024-01-06 06:32:34,015 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59620; closing.
2024-01-06 06:32:34,015 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43701', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522754.015733')
2024-01-06 06:32:34,015 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:32:34,558 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37031', status: init, memory: 0, processing: 0>
2024-01-06 06:32:34,559 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37031
2024-01-06 06:32:34,559 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59794
2024-01-06 06:32:34,656 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:34,657 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:34,660 - distributed.scheduler - INFO - Remove client Client-5e029067-ac5d-11ee-b2c9-d8c49764f6bb
2024-01-06 06:32:34,660 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59604; closing.
2024-01-06 06:32:34,661 - distributed.scheduler - INFO - Remove client Client-5e029067-ac5d-11ee-b2c9-d8c49764f6bb
2024-01-06 06:32:34,661 - distributed.scheduler - INFO - Close client connection: Client-5e029067-ac5d-11ee-b2c9-d8c49764f6bb
2024-01-06 06:32:34,665 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59794; closing.
2024-01-06 06:32:34,666 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37031', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522754.666134')
2024-01-06 06:32:34,666 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:32:34,969 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:32:34,969 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:32:34,970 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:32:34,971 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:32:34,971 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-06 06:32:37,352 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:37,356 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35829 instead
  warnings.warn(
2024-01-06 06:32:37,361 - distributed.scheduler - INFO - State start
2024-01-06 06:32:37,384 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:37,385 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:32:37,386 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35829/status
2024-01-06 06:32:37,386 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:32:37,468 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40573'
2024-01-06 06:32:37,642 - distributed.scheduler - INFO - Receive client connection: Client-61045494-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:37,658 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59904
2024-01-06 06:32:39,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:39,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:39,827 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:39,828 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40297
2024-01-06 06:32:39,828 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40297
2024-01-06 06:32:39,828 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-06 06:32:39,829 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:39,829 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:39,829 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:39,829 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:32:39,829 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mu_mcxyl
2024-01-06 06:32:39,829 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1e2029d7-1708-4ea9-b74a-a3e1d86aad07
2024-01-06 06:32:39,829 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-05ddaab9-3965-40c0-b7d9-234a6c02a28b
2024-01-06 06:32:39,829 - distributed.worker - INFO - Starting Worker plugin PreImport-51f7f739-de83-4a62-999c-a9d917b3a7b7
2024-01-06 06:32:39,830 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:39,890 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40297', status: init, memory: 0, processing: 0>
2024-01-06 06:32:39,891 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40297
2024-01-06 06:32:39,891 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59926
2024-01-06 06:32:39,892 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:39,893 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:39,893 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:39,894 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:39,965 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:39,968 - distributed.scheduler - INFO - Remove client Client-61045494-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:39,969 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59904; closing.
2024-01-06 06:32:39,969 - distributed.scheduler - INFO - Remove client Client-61045494-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:39,969 - distributed.scheduler - INFO - Close client connection: Client-61045494-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:39,970 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40573'. Reason: nanny-close
2024-01-06 06:32:39,971 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:39,972 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40297. Reason: nanny-close
2024-01-06 06:32:39,974 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:39,974 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59926; closing.
2024-01-06 06:32:39,974 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40297', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522759.974543')
2024-01-06 06:32:39,974 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:32:39,975 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:40,686 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:32:40,686 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:32:40,687 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:32:40,688 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:32:40,688 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-06 06:32:45,268 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:45,272 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40249 instead
  warnings.warn(
2024-01-06 06:32:45,277 - distributed.scheduler - INFO - State start
2024-01-06 06:32:45,299 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:45,300 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:32:45,301 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40249/status
2024-01-06 06:32:45,301 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:32:45,461 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35879'
2024-01-06 06:32:46,112 - distributed.scheduler - INFO - Receive client connection: Client-65ba16d3-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:46,136 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46482
2024-01-06 06:32:47,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:47,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:48,054 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:48,056 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42441
2024-01-06 06:32:48,056 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42441
2024-01-06 06:32:48,056 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43549
2024-01-06 06:32:48,056 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:32:48,056 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:48,056 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:48,056 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:32:48,056 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dcyej0v8
2024-01-06 06:32:48,056 - distributed.worker - INFO - Starting Worker plugin RMMSetup-65581a08-a380-4811-9abc-bef20461d38f
2024-01-06 06:32:48,057 - distributed.worker - INFO - Starting Worker plugin PreImport-04a7365e-f4ca-4346-850e-8944dae1e915
2024-01-06 06:32:48,058 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1949909f-ca3e-440f-a053-21247b24add7
2024-01-06 06:32:48,058 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:48,114 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42441', status: init, memory: 0, processing: 0>
2024-01-06 06:32:48,115 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42441
2024-01-06 06:32:48,115 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46510
2024-01-06 06:32:48,116 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:48,117 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:32:48,117 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:48,118 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:32:48,184 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:48,186 - distributed.scheduler - INFO - Remove client Client-65ba16d3-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:48,187 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46482; closing.
2024-01-06 06:32:48,187 - distributed.scheduler - INFO - Remove client Client-65ba16d3-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:48,188 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35879'. Reason: nanny-close
2024-01-06 06:32:48,189 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:48,190 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42441. Reason: nanny-close
2024-01-06 06:32:48,191 - distributed.scheduler - INFO - Close client connection: Client-65ba16d3-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:48,192 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:32:48,192 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46510; closing.
2024-01-06 06:32:48,193 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42441', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522768.1931105')
2024-01-06 06:32:48,193 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:32:48,194 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:48,854 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:32:48,854 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:32:48,855 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:32:48,856 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:32:48,857 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-06 06:32:51,108 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:51,112 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36347 instead
  warnings.warn(
2024-01-06 06:32:51,116 - distributed.scheduler - INFO - State start
2024-01-06 06:32:51,140 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:51,141 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:32:51,142 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36347/status
2024-01-06 06:32:51,142 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:32:53,826 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:58746'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 969, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4428, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:58746>: Stream is closed
2024-01-06 06:32:54,226 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:32:54,226 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:32:54,226 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:32:54,227 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:32:54,227 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-06 06:32:56,628 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:56,633 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33473 instead
  warnings.warn(
2024-01-06 06:32:56,638 - distributed.scheduler - INFO - State start
2024-01-06 06:32:56,662 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:32:56,664 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-06 06:32:56,665 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33473/status
2024-01-06 06:32:56,665 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:32:56,761 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33579'
2024-01-06 06:32:58,259 - distributed.scheduler - INFO - Receive client connection: Client-6c7fefa4-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:58,279 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58440
2024-01-06 06:32:58,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:32:58,637 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:32:58,641 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:32:58,642 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37807
2024-01-06 06:32:58,642 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37807
2024-01-06 06:32:58,642 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36549
2024-01-06 06:32:58,642 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:32:58,642 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:58,642 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:32:58,643 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:32:58,643 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-r3zukhuf
2024-01-06 06:32:58,643 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9a463f3d-c037-46ce-becc-3c37798fd33f
2024-01-06 06:32:58,643 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-07081b09-feb2-4d20-a194-52e288949b75
2024-01-06 06:32:58,643 - distributed.worker - INFO - Starting Worker plugin PreImport-8a08917d-da93-4b9c-8ac3-e69bb7f9a579
2024-01-06 06:32:58,643 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:58,709 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37807', status: init, memory: 0, processing: 0>
2024-01-06 06:32:58,710 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37807
2024-01-06 06:32:58,710 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58460
2024-01-06 06:32:58,711 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:32:58,712 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:32:58,712 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:32:58,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:32:58,797 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:32:58,800 - distributed.scheduler - INFO - Remove client Client-6c7fefa4-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:58,800 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58440; closing.
2024-01-06 06:32:58,800 - distributed.scheduler - INFO - Remove client Client-6c7fefa4-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:58,801 - distributed.scheduler - INFO - Close client connection: Client-6c7fefa4-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:32:58,802 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33579'. Reason: nanny-close
2024-01-06 06:32:58,802 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:32:58,803 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37807. Reason: nanny-close
2024-01-06 06:32:58,805 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:32:58,805 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58460; closing.
2024-01-06 06:32:58,805 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37807', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522778.8058212')
2024-01-06 06:32:58,806 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:32:58,807 - distributed.nanny - INFO - Worker closed
2024-01-06 06:32:59,518 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:32:59,518 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:32:59,519 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:32:59,520 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-06 06:32:59,520 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-06 06:33:01,883 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:33:01,887 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35717 instead
  warnings.warn(
2024-01-06 06:33:01,891 - distributed.scheduler - INFO - State start
2024-01-06 06:33:01,913 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:33:01,914 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:33:01,915 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35717/status
2024-01-06 06:33:01,915 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:33:02,139 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42511'
2024-01-06 06:33:02,160 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37255'
2024-01-06 06:33:02,172 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33767'
2024-01-06 06:33:02,188 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42575'
2024-01-06 06:33:02,192 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41319'
2024-01-06 06:33:02,203 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39711'
2024-01-06 06:33:02,216 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45751'
2024-01-06 06:33:02,231 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39351'
2024-01-06 06:33:02,671 - distributed.scheduler - INFO - Receive client connection: Client-6fa5589f-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:02,687 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41490
2024-01-06 06:33:04,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:33:04,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:33:04,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:33:04,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:33:04,149 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:33:04,150 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40537
2024-01-06 06:33:04,150 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40537
2024-01-06 06:33:04,150 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35661
2024-01-06 06:33:04,150 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:33:04,150 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:04,151 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:33:04,151 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:33:04,151 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yqjwp2pu
2024-01-06 06:33:04,151 - distributed.worker - INFO - Starting Worker plugin PreImport-acff34c8-ed0a-44a9-b814-263cedf97b87
2024-01-06 06:33:04,151 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f3462d2d-c02e-4b98-99cb-b18941f1f03c
2024-01-06 06:33:04,151 - distributed.worker - INFO - Starting Worker plugin RMMSetup-79bd3ae7-3a25-4967-8a84-6b06b0fa3812
2024-01-06 06:33:04,154 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:33:04,155 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36717
2024-01-06 06:33:04,155 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36717
2024-01-06 06:33:04,155 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36987
2024-01-06 06:33:04,155 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:33:04,155 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:04,155 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:33:04,155 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:33:04,155 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xwvbg10q
2024-01-06 06:33:04,155 - distributed.worker - INFO - Starting Worker plugin RMMSetup-db4c519e-9053-4a93-b709-5080953e3aaa
2024-01-06 06:33:04,218 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:33:04,218 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:33:04,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:33:04,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:33:04,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:33:04,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:33:04,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:33:04,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:33:04,223 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:33:04,224 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:33:04,224 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39851
2024-01-06 06:33:04,224 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39851
2024-01-06 06:33:04,224 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35321
2024-01-06 06:33:04,224 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:33:04,224 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:04,224 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:33:04,224 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:33:04,224 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pxrqf6g3
2024-01-06 06:33:04,225 - distributed.worker - INFO - Starting Worker plugin RMMSetup-48507c17-666c-49cc-a9a3-1473ca1bca6d
2024-01-06 06:33:04,225 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37761
2024-01-06 06:33:04,225 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37761
2024-01-06 06:33:04,225 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39913
2024-01-06 06:33:04,225 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:33:04,225 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:04,225 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:33:04,225 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:33:04,225 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f0h0j450
2024-01-06 06:33:04,225 - distributed.worker - INFO - Starting Worker plugin RMMSetup-36febb0e-aad3-422f-bd44-3b4a28c5462c
2024-01-06 06:33:04,226 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:33:04,226 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:33:04,227 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32819
2024-01-06 06:33:04,227 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32819
2024-01-06 06:33:04,227 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43695
2024-01-06 06:33:04,227 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:33:04,227 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:04,227 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:33:04,227 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34025
2024-01-06 06:33:04,227 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:33:04,227 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34025
2024-01-06 06:33:04,227 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ntez4fca
2024-01-06 06:33:04,227 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36945
2024-01-06 06:33:04,227 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:33:04,227 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:04,227 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:33:04,227 - distributed.worker - INFO - Starting Worker plugin PreImport-93e3b66c-b0e5-4f4d-bb2a-dcda53137690
2024-01-06 06:33:04,227 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:33:04,227 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kinfpzs8
2024-01-06 06:33:04,227 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eb065c84-c0b2-47c0-b6f3-109f36ed88c8
2024-01-06 06:33:04,228 - distributed.worker - INFO - Starting Worker plugin RMMSetup-226e3d23-f2a5-4d71-9419-c90149839925
2024-01-06 06:33:04,231 - distributed.worker - INFO - Starting Worker plugin RMMSetup-23224cf4-fea5-4acb-93bf-04aab6f252d8
2024-01-06 06:33:04,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:33:04,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:33:04,255 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:33:04,256 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44767
2024-01-06 06:33:04,256 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44767
2024-01-06 06:33:04,256 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44967
2024-01-06 06:33:04,256 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:33:04,256 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:04,256 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:33:04,256 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:33:04,256 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ernraruv
2024-01-06 06:33:04,257 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-92e2ce06-5795-45e1-90f3-cd6dd3abd459
2024-01-06 06:33:04,257 - distributed.worker - INFO - Starting Worker plugin PreImport-db5c2278-d422-46a8-917b-9771d1074139
2024-01-06 06:33:04,258 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7afc3aa6-1708-418a-804f-a38ec6889767
2024-01-06 06:33:04,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:33:04,280 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:33:04,287 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:33:04,288 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46275
2024-01-06 06:33:04,288 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46275
2024-01-06 06:33:04,288 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39543
2024-01-06 06:33:04,288 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:33:04,288 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:04,288 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:33:04,288 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:33:04,289 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yru205_9
2024-01-06 06:33:04,289 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aa6fb189-f532-4268-9233-1f3af0bad833
2024-01-06 06:33:08,009 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,037 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0ff521a2-063b-4c4d-b190-451609d35361
2024-01-06 06:33:08,039 - distributed.worker - INFO - Starting Worker plugin PreImport-ed01c361-3c76-466c-831e-e5c63bd8d7f0
2024-01-06 06:33:08,040 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,046 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44767', status: init, memory: 0, processing: 0>
2024-01-06 06:33:08,048 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44767
2024-01-06 06:33:08,048 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41502
2024-01-06 06:33:08,049 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:33:08,051 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:33:08,051 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,053 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:33:08,072 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39851', status: init, memory: 0, processing: 0>
2024-01-06 06:33:08,072 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39851
2024-01-06 06:33:08,072 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41514
2024-01-06 06:33:08,074 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:33:08,075 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:33:08,075 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,077 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:33:08,219 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,252 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32819', status: init, memory: 0, processing: 0>
2024-01-06 06:33:08,253 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32819
2024-01-06 06:33:08,253 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41516
2024-01-06 06:33:08,254 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:33:08,256 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:33:08,256 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,258 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:33:08,289 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d5f3d8c4-84dd-4dad-ad5d-ea08cf7072de
2024-01-06 06:33:08,290 - distributed.worker - INFO - Starting Worker plugin PreImport-9de21d33-8c1d-468f-aef7-1e111eb656b5
2024-01-06 06:33:08,291 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,299 - distributed.worker - INFO - Starting Worker plugin PreImport-3cb43d0d-ff7f-4a06-a767-a84a4cf5fe62
2024-01-06 06:33:08,300 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e1d9425a-deb9-405b-aa55-3c849265c397
2024-01-06 06:33:08,301 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,326 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37761', status: init, memory: 0, processing: 0>
2024-01-06 06:33:08,327 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37761
2024-01-06 06:33:08,327 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41528
2024-01-06 06:33:08,328 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36717', status: init, memory: 0, processing: 0>
2024-01-06 06:33:08,328 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36717
2024-01-06 06:33:08,328 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41540
2024-01-06 06:33:08,328 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:33:08,329 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:33:08,330 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:33:08,330 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,330 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:33:08,330 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,332 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:33:08,332 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:33:08,341 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,342 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1ac81766-eedc-40bb-890e-df945c3b1e0e
2024-01-06 06:33:08,343 - distributed.worker - INFO - Starting Worker plugin PreImport-322d82ce-0ecb-426e-98b1-63597b193aed
2024-01-06 06:33:08,344 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,348 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2282231c-62a0-4181-bba3-f4fbacbdca50
2024-01-06 06:33:08,348 - distributed.worker - INFO - Starting Worker plugin PreImport-90f449d0-9e41-458b-aef7-27d1324eb479
2024-01-06 06:33:08,349 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,364 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40537', status: init, memory: 0, processing: 0>
2024-01-06 06:33:08,365 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40537
2024-01-06 06:33:08,365 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41542
2024-01-06 06:33:08,366 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:33:08,367 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:33:08,367 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,369 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:33:08,370 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34025', status: init, memory: 0, processing: 0>
2024-01-06 06:33:08,370 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34025
2024-01-06 06:33:08,370 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41560
2024-01-06 06:33:08,371 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:33:08,372 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:33:08,372 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,373 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:33:08,376 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46275', status: init, memory: 0, processing: 0>
2024-01-06 06:33:08,376 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46275
2024-01-06 06:33:08,377 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41546
2024-01-06 06:33:08,379 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:33:08,380 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:33:08,380 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:08,382 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:33:08,479 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:33:08,479 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:33:08,479 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:33:08,479 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:33:08,479 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:33:08,480 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:33:08,480 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:33:08,480 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:33:08,493 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:08,493 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:08,494 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:08,494 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:08,494 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:08,494 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:08,494 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:08,494 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:08,498 - distributed.scheduler - INFO - Remove client Client-6fa5589f-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:08,499 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41490; closing.
2024-01-06 06:33:08,499 - distributed.scheduler - INFO - Remove client Client-6fa5589f-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:08,499 - distributed.scheduler - INFO - Close client connection: Client-6fa5589f-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:08,500 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42511'. Reason: nanny-close
2024-01-06 06:33:08,501 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:33:08,501 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37255'. Reason: nanny-close
2024-01-06 06:33:08,502 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:33:08,502 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34025. Reason: nanny-close
2024-01-06 06:33:08,502 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33767'. Reason: nanny-close
2024-01-06 06:33:08,502 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:33:08,502 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40537. Reason: nanny-close
2024-01-06 06:33:08,502 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42575'. Reason: nanny-close
2024-01-06 06:33:08,503 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:33:08,503 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41319'. Reason: nanny-close
2024-01-06 06:33:08,503 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32819. Reason: nanny-close
2024-01-06 06:33:08,503 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:33:08,504 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39711'. Reason: nanny-close
2024-01-06 06:33:08,504 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39851. Reason: nanny-close
2024-01-06 06:33:08,504 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:33:08,504 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45751'. Reason: nanny-close
2024-01-06 06:33:08,504 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36717. Reason: nanny-close
2024-01-06 06:33:08,504 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:33:08,504 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:33:08,504 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:33:08,504 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39351'. Reason: nanny-close
2024-01-06 06:33:08,505 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41560; closing.
2024-01-06 06:33:08,505 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37761. Reason: nanny-close
2024-01-06 06:33:08,505 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41542; closing.
2024-01-06 06:33:08,505 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:33:08,505 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34025', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522788.505417')
2024-01-06 06:33:08,505 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46275. Reason: nanny-close
2024-01-06 06:33:08,505 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:33:08,506 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40537', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522788.5059662')
2024-01-06 06:33:08,506 - distributed.nanny - INFO - Worker closed
2024-01-06 06:33:08,506 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44767. Reason: nanny-close
2024-01-06 06:33:08,506 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:33:08,506 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:33:08,506 - distributed.nanny - INFO - Worker closed
2024-01-06 06:33:08,507 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:33:08,507 - distributed.nanny - INFO - Worker closed
2024-01-06 06:33:08,507 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41514; closing.
2024-01-06 06:33:08,507 - distributed.nanny - INFO - Worker closed
2024-01-06 06:33:08,507 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:33:08,507 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41516; closing.
2024-01-06 06:33:08,508 - distributed.nanny - INFO - Worker closed
2024-01-06 06:33:08,508 - distributed.nanny - INFO - Worker closed
2024-01-06 06:33:08,508 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39851', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522788.5086207')
2024-01-06 06:33:08,509 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41540; closing.
2024-01-06 06:33:08,509 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:33:08,509 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32819', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522788.5091782')
2024-01-06 06:33:08,509 - distributed.nanny - INFO - Worker closed
2024-01-06 06:33:08,509 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41528; closing.
2024-01-06 06:33:08,510 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36717', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522788.5099645')
2024-01-06 06:33:08,510 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37761', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522788.5103662')
2024-01-06 06:33:08,510 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41546; closing.
2024-01-06 06:33:08,510 - distributed.nanny - INFO - Worker closed
2024-01-06 06:33:08,511 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46275', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522788.5111995')
2024-01-06 06:33:08,511 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41502; closing.
2024-01-06 06:33:08,511 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44767', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522788.511917')
2024-01-06 06:33:08,512 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:33:09,717 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:33:09,717 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:33:09,718 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:33:09,719 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:33:09,720 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-06 06:33:12,059 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:33:12,065 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:33:12,069 - distributed.scheduler - INFO - State start
2024-01-06 06:33:12,092 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:33:12,093 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:33:12,094 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:33:12,094 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:33:12,257 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38495'
2024-01-06 06:33:12,609 - distributed.scheduler - INFO - Receive client connection: Client-75b8129b-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:12,623 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40834
2024-01-06 06:33:14,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:33:14,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:33:14,064 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:33:14,065 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34395
2024-01-06 06:33:14,065 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34395
2024-01-06 06:33:14,065 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38531
2024-01-06 06:33:14,065 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:33:14,065 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:14,065 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:33:14,065 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:33:14,065 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1zxtvs81
2024-01-06 06:33:14,065 - distributed.worker - INFO - Starting Worker plugin RMMSetup-de251e99-4c76-4530-99b3-9b4408da3c97
2024-01-06 06:33:14,397 - distributed.worker - INFO - Starting Worker plugin PreImport-e57196a7-0a50-462b-80db-970360a98c2a
2024-01-06 06:33:14,398 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-347866c2-d5a1-479f-bc83-b7501332284d
2024-01-06 06:33:14,398 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:14,457 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34395', status: init, memory: 0, processing: 0>
2024-01-06 06:33:14,458 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34395
2024-01-06 06:33:14,458 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40850
2024-01-06 06:33:14,459 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:33:14,460 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:33:14,460 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:14,461 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:33:14,463 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:33:14,467 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:14,468 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:14,471 - distributed.scheduler - INFO - Remove client Client-75b8129b-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:14,471 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40834; closing.
2024-01-06 06:33:14,472 - distributed.scheduler - INFO - Remove client Client-75b8129b-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:14,472 - distributed.scheduler - INFO - Close client connection: Client-75b8129b-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:14,473 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38495'. Reason: nanny-close
2024-01-06 06:33:14,485 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:33:14,486 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34395. Reason: nanny-close
2024-01-06 06:33:14,488 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40850; closing.
2024-01-06 06:33:14,488 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:33:14,488 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34395', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522794.4884412')
2024-01-06 06:33:14,488 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:33:14,489 - distributed.nanny - INFO - Worker closed
2024-01-06 06:33:15,088 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:33:15,088 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:33:15,088 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:33:15,089 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:33:15,089 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-06 06:33:17,458 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:33:17,462 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42783 instead
  warnings.warn(
2024-01-06 06:33:17,466 - distributed.scheduler - INFO - State start
2024-01-06 06:33:17,488 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:33:17,489 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:33:17,490 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42783/status
2024-01-06 06:33:17,490 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:33:17,658 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35243'
2024-01-06 06:33:18,739 - distributed.scheduler - INFO - Receive client connection: Client-78ea8b13-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:18,753 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40950
2024-01-06 06:33:19,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:33:19,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:33:19,470 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:33:19,471 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45587
2024-01-06 06:33:19,471 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45587
2024-01-06 06:33:19,471 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36795
2024-01-06 06:33:19,471 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:33:19,471 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:19,471 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:33:19,471 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:33:19,471 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u5j7r194
2024-01-06 06:33:19,472 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1f196c5d-77e7-4779-b986-cd511a996657
2024-01-06 06:33:19,791 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3b452f70-6229-4762-8ceb-e60cc0c74149
2024-01-06 06:33:19,791 - distributed.worker - INFO - Starting Worker plugin PreImport-feca5c57-255e-4169-b549-4c2303fb10f7
2024-01-06 06:33:19,791 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:19,853 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45587', status: init, memory: 0, processing: 0>
2024-01-06 06:33:19,854 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45587
2024-01-06 06:33:19,854 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40966
2024-01-06 06:33:19,855 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:33:19,856 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:33:19,856 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:33:19,857 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:33:19,880 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-06 06:33:19,885 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:33:19,888 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:19,890 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:33:19,892 - distributed.scheduler - INFO - Remove client Client-78ea8b13-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:19,892 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40950; closing.
2024-01-06 06:33:19,893 - distributed.scheduler - INFO - Remove client Client-78ea8b13-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:19,894 - distributed.scheduler - INFO - Close client connection: Client-78ea8b13-ac5d-11ee-b277-d8c49764f6bb
2024-01-06 06:33:19,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35243'. Reason: nanny-close
2024-01-06 06:33:19,895 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:33:19,896 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45587. Reason: nanny-close
2024-01-06 06:33:19,897 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40966; closing.
2024-01-06 06:33:19,897 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:33:19,897 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45587', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522799.8978086')
2024-01-06 06:33:19,898 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:33:19,898 - distributed.nanny - INFO - Worker closed
2024-01-06 06:33:20,560 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:33:20,560 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:33:20,560 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:33:20,561 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:33:20,562 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45831 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32955 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33297 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34637 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39755 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38285 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44943 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38519 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34945 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42975 instead
  warnings.warn(
[1704522975.755471] [dgx13:68591:0]            sock.c:481  UCX  ERROR bind(fd=161 addr=0.0.0.0:33516) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32931 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43783 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40317 instead
  warnings.warn(
[1704523002.565620] [dgx13:69064:0]            sock.c:481  UCX  ERROR bind(fd=160 addr=0.0.0.0:49014) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46487 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39903 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44273 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35399 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38995 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36293 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44133 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35793 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43401 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40573 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33273 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44487 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38883 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44293 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40273 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35439 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40081 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36267 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45599 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42619 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43317 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36481 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33983 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42803 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34801 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38067 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38835 instead
  warnings.warn(
[1704523726.007768] [dgx13:80678:0]            sock.c:481  UCX  ERROR bind(fd=158 addr=0.0.0.0:44248) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40805 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35955 instead
  warnings.warn(
[1704523777.791756] [dgx13:81456:0]            sock.c:481  UCX  ERROR bind(fd=150 addr=0.0.0.0:33438) failed: Address already in use
[1704523777.791817] [dgx13:81456:0]            sock.c:481  UCX  ERROR bind(fd=150 addr=0.0.0.0:48396) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39589 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45559 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39305 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41101 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37867 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40147 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45315 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36643 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44787 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42829 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36827 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41505 instead
  warnings.warn(
[1704523985.576346] [dgx13:84325:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:46478) failed: Address already in use
[1704523985.576403] [dgx13:84325:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:56800) failed: Address already in use
[1704523985.576799] [dgx13:84320:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:33558) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46339 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38883 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44549 instead
  warnings.warn(
[1704524044.565897] [dgx13:85013:0]            sock.c:481  UCX  ERROR bind(fd=130 addr=0.0.0.0:50864) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39575 instead
  warnings.warn(
2024-01-06 06:54:22,013 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
[1704524062.874097] [dgx13:85117] UCXPY  WARNING Listener object is being destroyed, but 1 client handler(s) is(are) still alive. This usually indicates the Listener was prematurely destroyed.
[1704524062.874232] [dgx13:85117] UCXPY  WARNING Listener object is being destroyed, but 1 client handler(s) is(are) still alive. This usually indicates the Listener was prematurely destroyed.
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35407 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44851 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42461 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43911 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40015 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43691 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45897 instead
  warnings.warn(
[1704524180.271244] [dgx13:86649:0]            sock.c:481  UCX  ERROR bind(fd=172 addr=0.0.0.0:33746) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_lock_workers PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucx] [1704524213.889010] [dgx13:87201:0]            sock.c:481  UCX  ERROR bind(fd=162 addr=0.0.0.0:34036) failed: Address already in use
PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucxx] PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[tcp] PASSED
dask_cuda/tests/test_gds.py::test_gds[True-cupy] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-cudf] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-numba.cuda] SKIPPED (GDS ...)
dask_cuda/tests/test_gds.py::test_gds[False-cupy] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-cudf] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-numba.cuda] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucx] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucxx] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucx] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33717 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44031 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37039 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45391 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39707 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_local_cuda_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_with_subset_of_cuda_visible_devices PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucxx] [1704524304.707418] [dgx13:62071:0]            sock.c:481  UCX  ERROR bind(fd=251 addr=0.0.0.0:37618) failed: Address already in use
[1704524309.968273] [dgx13:88136:0]            sock.c:481  UCX  ERROR bind(fd=161 addr=0.0.0.0:38044) failed: Address already in use
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_n_workers PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_threads_per_worker_and_memory_limit PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cudaworker 2024-01-06 06:59:00,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:00,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:00,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:00,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:00,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:00,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:00,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:00,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:00,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:00,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:00,907 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:00,907 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:00,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:00,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:01,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:01,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:01,337 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:01,338 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41499
2024-01-06 06:59:01,338 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41499
2024-01-06 06:59:01,338 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34813
2024-01-06 06:59:01,339 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,339 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,339 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:01,339 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qjbc_09l
2024-01-06 06:59:01,339 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a2c66140-ba64-4a49-8ace-b1d180c91d2c
2024-01-06 06:59:01,339 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-77e34599-3569-4119-b0a7-b74d2123416a
2024-01-06 06:59:01,339 - distributed.worker - INFO - Starting Worker plugin PreImport-d5f02f7e-c4fa-42a1-9a41-7d361add22f6
2024-01-06 06:59:01,339 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,377 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:01,378 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44315
2024-01-06 06:59:01,378 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44315
2024-01-06 06:59:01,378 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38011
2024-01-06 06:59:01,378 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,379 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,379 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:01,379 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k36uhp9_
2024-01-06 06:59:01,379 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-77ca6896-d9b9-4d9e-95ce-44121796f788
2024-01-06 06:59:01,379 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a1c0e725-acdf-4e1c-a8d8-419e431f9dd1
2024-01-06 06:59:01,379 - distributed.worker - INFO - Starting Worker plugin PreImport-a16d16cd-e531-4305-9928-af31157503b7
2024-01-06 06:59:01,379 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,418 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:01,419 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,419 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,420 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37603
2024-01-06 06:59:01,437 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:01,438 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39405
2024-01-06 06:59:01,438 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39405
2024-01-06 06:59:01,438 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45339
2024-01-06 06:59:01,438 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,438 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,439 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:01,439 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-deu6w377
2024-01-06 06:59:01,439 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0c179f3b-ee8e-4580-93e5-7d26920e0a83
2024-01-06 06:59:01,439 - distributed.worker - INFO - Starting Worker plugin RMMSetup-22596483-e3ea-4bf2-aa40-a2a11f5faee8
2024-01-06 06:59:01,439 - distributed.worker - INFO - Starting Worker plugin PreImport-23fd5809-2650-4a75-a93b-c1e4d85fcfed
2024-01-06 06:59:01,440 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,464 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:01,465 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,465 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,466 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37603
2024-01-06 06:59:01,504 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:01,505 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,505 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,506 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37603
2024-01-06 06:59:01,559 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:01,559 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:01,560 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33031
2024-01-06 06:59:01,560 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33031
2024-01-06 06:59:01,560 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45571
2024-01-06 06:59:01,560 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,560 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,560 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43333
2024-01-06 06:59:01,560 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:01,560 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43333
2024-01-06 06:59:01,560 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2i6cj_ah
2024-01-06 06:59:01,560 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45603
2024-01-06 06:59:01,560 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,560 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,560 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:01,560 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7slro7hy
2024-01-06 06:59:01,560 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0598518d-504f-4e11-b506-a1d92e930e93
2024-01-06 06:59:01,560 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7dabb9e5-4988-4feb-a749-c3be723ba832
2024-01-06 06:59:01,561 - distributed.worker - INFO - Starting Worker plugin RMMSetup-45747acf-8795-4ce7-86bc-854aa5016f48
2024-01-06 06:59:01,561 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-db0b3d02-259b-4577-bf6c-0b61e13fd365
2024-01-06 06:59:01,561 - distributed.worker - INFO - Starting Worker plugin PreImport-e686e670-04f6-46a2-bc37-43497d2acd0f
2024-01-06 06:59:01,561 - distributed.worker - INFO - Starting Worker plugin PreImport-1321a5a3-cdcd-4472-b937-58ea50b87829
2024-01-06 06:59:01,561 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,561 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,604 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:01,605 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41883
2024-01-06 06:59:01,605 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41883
2024-01-06 06:59:01,605 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40625
2024-01-06 06:59:01,605 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,605 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,605 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:01,606 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wyfozqcj
2024-01-06 06:59:01,606 - distributed.worker - INFO - Starting Worker plugin PreImport-457ba443-636b-4f0b-abd6-0332bc03654f
2024-01-06 06:59:01,606 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7fe5d0e0-6df6-49bc-b8af-565aac31f046
2024-01-06 06:59:01,606 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ac4878d5-b426-4f2d-9b3e-8fbb902e9548
2024-01-06 06:59:01,606 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,608 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:01,609 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44745
2024-01-06 06:59:01,609 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44745
2024-01-06 06:59:01,609 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39981
2024-01-06 06:59:01,609 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,609 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,609 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:01,609 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fg4rh4ul
2024-01-06 06:59:01,610 - distributed.worker - INFO - Starting Worker plugin RMMSetup-095db48d-ee01-42d1-834b-5bbace82b167
2024-01-06 06:59:01,610 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d2a4aa81-67b5-45a3-80da-140cac196802
2024-01-06 06:59:01,610 - distributed.worker - INFO - Starting Worker plugin PreImport-8877e28e-8799-4852-b1fa-a38b8e3c1805
2024-01-06 06:59:01,610 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,694 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:01,695 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,695 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,696 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:01,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37603
2024-01-06 06:59:01,697 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,697 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,698 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37603
2024-01-06 06:59:01,742 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:01,743 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,743 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,744 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:01,744 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37603
2024-01-06 06:59:01,745 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,745 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,746 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37603
2024-01-06 06:59:01,785 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:01,786 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33365
2024-01-06 06:59:01,786 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33365
2024-01-06 06:59:01,786 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39447
2024-01-06 06:59:01,786 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,786 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,786 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:01,786 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a2hj_7xa
2024-01-06 06:59:01,786 - distributed.worker - INFO - Starting Worker plugin RMMSetup-24ba6128-d210-487d-b492-c0315cb4327a
2024-01-06 06:59:01,787 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-525834d2-7ba8-4515-9526-0a1bb2d8ae23
2024-01-06 06:59:01,787 - distributed.worker - INFO - Starting Worker plugin PreImport-c8d73387-b4b3-4ff5-b9ed-fb987eb9d68d
2024-01-06 06:59:01,787 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,859 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:01,860 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:37603
2024-01-06 06:59:01,860 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:01,862 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37603
2024-01-06 06:59:01,873 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:59:01,873 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:59:01,873 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:59:01,873 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:59:01,873 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:59:01,873 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:59:01,874 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:59:01,874 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:59:01,879 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41499. Reason: nanny-close
2024-01-06 06:59:01,880 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44315. Reason: nanny-close
2024-01-06 06:59:01,881 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39405. Reason: nanny-close
2024-01-06 06:59:01,881 - distributed.core - INFO - Connection to tcp://127.0.0.1:37603 has been closed.
2024-01-06 06:59:01,881 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33031. Reason: nanny-close
2024-01-06 06:59:01,882 - distributed.core - INFO - Connection to tcp://127.0.0.1:37603 has been closed.
2024-01-06 06:59:01,882 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41883. Reason: nanny-close
2024-01-06 06:59:01,882 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:01,882 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43333. Reason: nanny-close
2024-01-06 06:59:01,883 - distributed.core - INFO - Connection to tcp://127.0.0.1:37603 has been closed.
2024-01-06 06:59:01,883 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44745. Reason: nanny-close
2024-01-06 06:59:01,883 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:01,883 - distributed.core - INFO - Connection to tcp://127.0.0.1:37603 has been closed.
2024-01-06 06:59:01,883 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33365. Reason: nanny-close
2024-01-06 06:59:01,883 - distributed.core - INFO - Connection to tcp://127.0.0.1:37603 has been closed.
2024-01-06 06:59:01,884 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:01,884 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:01,885 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:01,885 - distributed.core - INFO - Connection to tcp://127.0.0.1:37603 has been closed.
2024-01-06 06:59:01,885 - distributed.core - INFO - Connection to tcp://127.0.0.1:37603 has been closed.
2024-01-06 06:59:01,885 - distributed.core - INFO - Connection to tcp://127.0.0.1:37603 has been closed.
2024-01-06 06:59:01,886 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:01,886 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:01,886 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_all_to_all PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_pool PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_maximum_poolsize_without_poolsize_error PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_managed PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async_with_maximum_pool_size PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_logging PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import_not_found 2024-01-06 06:59:37,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:37,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:37,864 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:37,865 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43145
2024-01-06 06:59:37,865 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43145
2024-01-06 06:59:37,865 - distributed.worker - INFO -           Worker name:                          0
2024-01-06 06:59:37,865 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43591
2024-01-06 06:59:37,865 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43473
2024-01-06 06:59:37,865 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:37,866 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:37,866 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:59:37,866 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-eynwul14
2024-01-06 06:59:37,866 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-16f93f7e-f4b2-4952-9a38-548ee8c55cd1
2024-01-06 06:59:37,866 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fcd27b51-a2b4-476b-8436-3ea797193f9a
2024-01-06 06:59:37,866 - distributed.worker - INFO - Starting Worker plugin PreImport-446da621-918c-482c-a127-6e13e43b3c40
2024-01-06 06:59:37,870 - distributed.worker - ERROR - No module named 'my_module'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'
2024-01-06 06:59:37,870 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43145. Reason: failure-to-start-<class 'ModuleNotFoundError'>
2024-01-06 06:59:37,870 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2024-01-06 06:59:37,872 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1473, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 967, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 677, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
XFAIL
dask_cuda/tests/test_local_cuda_cluster.py::test_cluster_worker 2024-01-06 06:59:42,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:42,516 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:42,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:42,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:42,577 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:42,577 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:42,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:42,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:42,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:42,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:42,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:42,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:42,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:42,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:42,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:42,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:43,174 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:43,174 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46455
2024-01-06 06:59:43,175 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46455
2024-01-06 06:59:43,175 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35153
2024-01-06 06:59:43,175 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,175 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,175 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:43,175 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:43,175 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q_erikz7
2024-01-06 06:59:43,175 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9147abff-a83b-421e-8345-863ffc387799
2024-01-06 06:59:43,175 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c94c378b-2b95-4582-926e-819f95fd6d35
2024-01-06 06:59:43,175 - distributed.worker - INFO - Starting Worker plugin PreImport-e162d4cc-b00e-4085-bbaf-39575baef549
2024-01-06 06:59:43,176 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,183 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:43,183 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43883
2024-01-06 06:59:43,184 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43883
2024-01-06 06:59:43,184 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36829
2024-01-06 06:59:43,184 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,184 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,184 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:43,184 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:43,184 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pnn64vbb
2024-01-06 06:59:43,184 - distributed.worker - INFO - Starting Worker plugin PreImport-3386fa60-c6a3-4f46-be67-03b6f7bfd2b5
2024-01-06 06:59:43,184 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3f675b4a-19d9-4f2a-8f18-abe920e0e252
2024-01-06 06:59:43,184 - distributed.worker - INFO - Starting Worker plugin RMMSetup-df5a70be-f090-4887-aa52-8a21681423ed
2024-01-06 06:59:43,185 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,230 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:43,231 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36997
2024-01-06 06:59:43,231 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36997
2024-01-06 06:59:43,231 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34057
2024-01-06 06:59:43,231 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,231 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,231 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:43,231 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:43,231 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6xn8to8s
2024-01-06 06:59:43,231 - distributed.worker - INFO - Starting Worker plugin PreImport-42351f7a-233a-4f97-89b7-3009d4210080
2024-01-06 06:59:43,231 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-69ffadff-8aa4-480d-bde4-de2846b6293a
2024-01-06 06:59:43,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ecd3e65e-1517-4fbf-af96-90f2a6da4e60
2024-01-06 06:59:43,232 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,243 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:43,244 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35963
2024-01-06 06:59:43,244 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35963
2024-01-06 06:59:43,244 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42015
2024-01-06 06:59:43,244 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,244 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,244 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:43,244 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:43,244 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yl0bh4ch
2024-01-06 06:59:43,245 - distributed.worker - INFO - Starting Worker plugin PreImport-23c3a1d8-4646-42b3-b620-afd3755492ca
2024-01-06 06:59:43,245 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-facdfd7f-f2ce-4ec4-b4f8-49042c97fbe7
2024-01-06 06:59:43,245 - distributed.worker - INFO - Starting Worker plugin RMMSetup-61f01b55-7c7c-4865-afe7-9d71e7aca870
2024-01-06 06:59:43,246 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,250 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:43,251 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40381
2024-01-06 06:59:43,251 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40381
2024-01-06 06:59:43,251 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37731
2024-01-06 06:59:43,251 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,251 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,251 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:43,251 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:43,251 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vpdt8ytt
2024-01-06 06:59:43,252 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-920bc45c-fad8-4c22-8606-57b6ca5e205f
2024-01-06 06:59:43,252 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b131ac07-175b-46a7-ac31-9f5439dd280e
2024-01-06 06:59:43,252 - distributed.worker - INFO - Starting Worker plugin PreImport-383eba75-ad62-4630-bcc7-57295f2d3526
2024-01-06 06:59:43,252 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,258 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:43,259 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,259 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,260 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44245
2024-01-06 06:59:43,270 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:43,271 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,271 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,272 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44245
2024-01-06 06:59:43,352 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:43,353 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,353 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,354 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:43,355 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44245
2024-01-06 06:59:43,355 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36015
2024-01-06 06:59:43,355 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36015
2024-01-06 06:59:43,355 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43927
2024-01-06 06:59:43,355 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,355 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,355 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:43,355 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:43,355 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z7wiylty
2024-01-06 06:59:43,356 - distributed.worker - INFO - Starting Worker plugin PreImport-364824df-c9b8-415c-8b8c-3c40f270d4d8
2024-01-06 06:59:43,356 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-04d78d46-35a1-462c-bd04-28128a2b3277
2024-01-06 06:59:43,356 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7967230f-9dca-45c0-b86f-5a8cd144d7ca
2024-01-06 06:59:43,356 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,366 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:43,367 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,367 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,368 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44245
2024-01-06 06:59:43,371 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:43,372 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,372 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,373 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44245
2024-01-06 06:59:43,419 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:43,420 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,420 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,421 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44245
2024-01-06 06:59:43,422 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:43,423 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36079
2024-01-06 06:59:43,423 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36079
2024-01-06 06:59:43,423 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41899
2024-01-06 06:59:43,423 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,423 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,423 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:43,423 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:43,423 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-79qi6aqq
2024-01-06 06:59:43,424 - distributed.worker - INFO - Starting Worker plugin RMMSetup-194b2345-465d-4827-817e-423ee8f5c46e
2024-01-06 06:59:43,424 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7e542cf4-6279-4d08-9b26-5a7f6fae25ea
2024-01-06 06:59:43,424 - distributed.worker - INFO - Starting Worker plugin PreImport-9c84d30b-df48-4c76-82ae-6c06df9e6e72
2024-01-06 06:59:43,424 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,481 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:43,482 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46489
2024-01-06 06:59:43,482 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46489
2024-01-06 06:59:43,483 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46799
2024-01-06 06:59:43,483 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,483 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,483 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:43,483 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:43,483 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_tbxm45b
2024-01-06 06:59:43,483 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4875f831-7dca-4add-8845-f4764fce1058
2024-01-06 06:59:43,484 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5784c85c-1c37-4816-ba2d-fa7e1b3eb9f9
2024-01-06 06:59:43,484 - distributed.worker - INFO - Starting Worker plugin PreImport-fa45c088-3b0f-4371-a7e1-20d5ca743c6d
2024-01-06 06:59:43,484 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,492 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:43,493 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,493 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,494 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44245
2024-01-06 06:59:43,559 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:43,560 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44245
2024-01-06 06:59:43,560 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:43,562 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44245
2024-01-06 06:59:43,578 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43883. Reason: nanny-close
2024-01-06 06:59:43,578 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46455. Reason: nanny-close
2024-01-06 06:59:43,579 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35963. Reason: nanny-close
2024-01-06 06:59:43,580 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36997. Reason: nanny-close
2024-01-06 06:59:43,580 - distributed.core - INFO - Connection to tcp://127.0.0.1:44245 has been closed.
2024-01-06 06:59:43,580 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40381. Reason: nanny-close
2024-01-06 06:59:43,581 - distributed.core - INFO - Connection to tcp://127.0.0.1:44245 has been closed.
2024-01-06 06:59:43,581 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36015. Reason: nanny-close
2024-01-06 06:59:43,581 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:43,581 - distributed.core - INFO - Connection to tcp://127.0.0.1:44245 has been closed.
2024-01-06 06:59:43,581 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36079. Reason: nanny-close
2024-01-06 06:59:43,582 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46489. Reason: nanny-close
2024-01-06 06:59:43,582 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:43,582 - distributed.core - INFO - Connection to tcp://127.0.0.1:44245 has been closed.
2024-01-06 06:59:43,582 - distributed.core - INFO - Connection to tcp://127.0.0.1:44245 has been closed.
2024-01-06 06:59:43,583 - distributed.core - INFO - Connection to tcp://127.0.0.1:44245 has been closed.
2024-01-06 06:59:43,583 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:43,584 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:43,584 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:43,584 - distributed.core - INFO - Connection to tcp://127.0.0.1:44245 has been closed.
2024-01-06 06:59:43,584 - distributed.core - INFO - Connection to tcp://127.0.0.1:44245 has been closed.
2024-01-06 06:59:43,584 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:43,586 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:43,586 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_available_mig_workers SKIPPED
dask_cuda/tests/test_local_cuda_cluster.py::test_gpu_uuid PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_track_allocations PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_get_cluster_configuration PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_worker_fraction_limits PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_death_timeout_raises XFAIL
dask_cuda/tests/test_proxify_host_file.py::test_one_dev_item_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_one_item_host_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_spill_on_demand FAILED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_dataframes_share_dev_mem PASSED
dask_cuda/tests/test_proxify_host_file.py::test_cudf_get_device_memory_objects PASSED
dask_cuda/tests/test_proxify_host_file.py::test_externals PASSED
dask_cuda/tests/test_proxify_host_file.py::test_incompatible_types PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_worker_force_spill_to_disk PASSED
dask_cuda/tests/test_proxify_host_file.py::test_on_demand_debug_info 2024-01-06 07:01:06,722 - distributed.worker - WARNING - RMM allocation of 1.00 MiB failed, spill-on-demand couldn't find any device memory to spill.
RMM allocs: 1.00 MiB, <ProxyManager dev_limit=25.60 GiB host_limit=0.98 TiB disk=0 B(0) host=0 B(0) dev=0 B(0)>, traceback:
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 937, in _bootstrap
    self._bootstrap_inner()
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/threadpoolexecutor.py", line 57, in _worker
    task.run()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/_concurrent_futures_thread.py", line 65, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1541, in <lambda>
    executor, lambda: context.run(func, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2954, in apply_function
    msg = apply_function_simple(function, args, kwargs, time_delay)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2990, in apply_function_simple
    result = function(*args, **kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_proxify_host_file.py", line 467, in task
    rmm.DeviceBuffer(size=rmm_pool_size),  # Trigger OOM
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/proxify_host_file.py", line 617, in oom
    traceback.print_stack(file=f)


2024-01-06 07:01:06,915 - distributed.worker - WARNING - Compute Failed
Key:       task-5c302f54392a5ca98adb3c55c8357b0e
Function:  task
args:      ()
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_serializer PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-None] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-None] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_length[numpy] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_length[cupy] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_name PASSED
dask_cuda/tests/test_proxy.py::test_spilling_local_cuda_cluster[True] /opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
            127.0.0.1:33387
2024-01-06 06:58:25,022 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:39225
2024-01-06 06:58:25,022 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:58:25,022 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:58:25,023 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_lt062q9
2024-01-06 06:58:25,023 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e58377b1-d44a-41cd-b333-351c124d9a19
2024-01-06 06:58:25,023 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7ad5fbfb-faeb-4245-80c3-03d03254dbdb
2024-01-06 06:58:25,023 - distributed.worker - INFO - Starting Worker plugin PreImport-2a7f9e1f-12be-4629-b089-9669b60302fe
2024-01-06 06:58:25,023 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:58:25,045 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:58:25,046 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40261
2024-01-06 06:58:25,046 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40261
2024-01-06 06:58:25,046 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39867
2024-01-06 06:58:25,046 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:39225
2024-01-06 06:58:25,046 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:58:25,046 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:58:25,046 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xmjir_by
2024-01-06 06:58:25,046 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-26146985-41d5-4e32-9e81-becc50fd2f2e
2024-01-06 06:58:25,047 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b160799f-8338-4d7a-a176-b4b7854e1af1
2024-01-06 06:58:25,047 - distributed.worker - INFO - Starting Worker plugin PreImport-014d1c83-0294-48ea-9fec-a351c66c0359
2024-01-06 06:58:25,047 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:58:25,095 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:58:25,097 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:39225
2024-01-06 06:58:25,097 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:58:25,098 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39225
2024-01-06 06:58:25,126 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:58:25,127 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:39225
2024-01-06 06:58:25,127 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:58:25,128 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39225
2024-01-06 06:58:25,165 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:58:25,165 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:58:25,166 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:58:25,166 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:58:25,166 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:58:25,166 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:58:25,166 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:58:25,166 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:58:25,172 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43169. Reason: nanny-close
2024-01-06 06:58:25,172 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44761. Reason: nanny-close
2024-01-06 06:58:25,173 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45945. Reason: nanny-close
2024-01-06 06:58:25,174 - distributed.core - INFO - Connection to tcp://127.0.0.1:39225 has been closed.
2024-01-06 06:58:25,174 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37211. Reason: nanny-close
2024-01-06 06:58:25,174 - distributed.core - INFO - Connection to tcp://127.0.0.1:39225 has been closed.
2024-01-06 06:58:25,175 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43337. Reason: nanny-close
2024-01-06 06:58:25,175 - distributed.core - INFO - Connection to tcp://127.0.0.1:39225 has been closed.
2024-01-06 06:58:25,175 - distributed.nanny - INFO - Worker closed
2024-01-06 06:58:25,175 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45307. Reason: nanny-close
2024-01-06 06:58:25,176 - distributed.core - INFO - Connection to tcp://127.0.0.1:39225 has been closed.
2024-01-06 06:58:25,176 - distributed.nanny - INFO - Worker closed
2024-01-06 06:58:25,176 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40261. Reason: nanny-close
2024-01-06 06:58:25,176 - distributed.nanny - INFO - Worker closed
2024-01-06 06:58:25,176 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37649. Reason: nanny-close
2024-01-06 06:58:25,177 - distributed.core - INFO - Connection to tcp://127.0.0.1:39225 has been closed.
2024-01-06 06:58:25,177 - distributed.nanny - INFO - Worker closed
2024-01-06 06:58:25,178 - distributed.core - INFO - Connection to tcp://127.0.0.1:39225 has been closed.
2024-01-06 06:58:25,178 - distributed.core - INFO - Connection to tcp://127.0.0.1:39225 has been closed.
2024-01-06 06:58:25,178 - distributed.nanny - INFO - Worker closed
2024-01-06 06:58:25,178 - distributed.core - INFO - Connection to tcp://127.0.0.1:39225 has been closed.
2024-01-06 06:58:25,179 - distributed.nanny - INFO - Worker closed
2024-01-06 06:58:25,179 - distributed.nanny - INFO - Worker closed
2024-01-06 06:58:25,180 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_all_to_all PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_pool PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_maximum_poolsize_without_poolsize_error PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_managed PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async_with_maximum_pool_size PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_logging PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import_not_found 2024-01-06 06:59:03,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:03,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:03,945 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:03,946 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46161
2024-01-06 06:59:03,946 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46161
2024-01-06 06:59:03,946 - distributed.worker - INFO -           Worker name:                          0
2024-01-06 06:59:03,946 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33259
2024-01-06 06:59:03,946 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38221
2024-01-06 06:59:03,946 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:03,946 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:03,946 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:59:03,946 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bnpf16tk
2024-01-06 06:59:03,947 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a43845ba-817c-488b-8690-3bdeb17a078c
2024-01-06 06:59:03,947 - distributed.worker - INFO - Starting Worker plugin RMMSetup-85575c10-2e5b-4d4e-b802-c80ef0e5ad19
2024-01-06 06:59:03,947 - distributed.worker - INFO - Starting Worker plugin PreImport-b8d68969-2697-418d-ad9b-355cb396e427
2024-01-06 06:59:03,967 - distributed.worker - ERROR - No module named 'my_module'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'
2024-01-06 06:59:03,968 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46161. Reason: failure-to-start-<class 'ModuleNotFoundError'>
2024-01-06 06:59:03,968 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2024-01-06 06:59:03,972 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1473, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 967, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 677, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
XFAIL
dask_cuda/tests/test_local_cuda_cluster.py::test_cluster_worker 2024-01-06 06:59:08,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:08,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:08,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:08,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:08,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:08,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:09,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:09,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:09,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:09,070 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:09,072 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:09,072 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:09,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:09,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:09,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:59:09,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:59:09,331 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:09,332 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35717
2024-01-06 06:59:09,332 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35717
2024-01-06 06:59:09,332 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45711
2024-01-06 06:59:09,332 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44359
2024-01-06 06:59:09,332 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,332 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:09,332 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:09,332 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wt4mfi4i
2024-01-06 06:59:09,333 - distributed.worker - INFO - Starting Worker plugin PreImport-0d6d5cfc-7ada-4260-a182-8bc8977cf3e0
2024-01-06 06:59:09,333 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0eac0f4b-38ff-4810-b12f-ca34a20c2000
2024-01-06 06:59:09,333 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f5fdbffb-341f-4a30-941b-ac9b709e6426
2024-01-06 06:59:09,334 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,535 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:09,535 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40297
2024-01-06 06:59:09,536 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40297
2024-01-06 06:59:09,536 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40525
2024-01-06 06:59:09,536 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44359
2024-01-06 06:59:09,536 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,536 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:09,536 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:09,536 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5tl88hcp
2024-01-06 06:59:09,536 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e3754e27-c373-4bfb-961f-e3cdd5e75d8c
2024-01-06 06:59:09,536 - distributed.worker - INFO - Starting Worker plugin PreImport-f3da6608-689a-4ae4-903f-30f644ad3fc4
2024-01-06 06:59:09,537 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8db41145-2654-46f2-b748-4981cae5baa1
2024-01-06 06:59:09,537 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,551 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:09,552 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39315
2024-01-06 06:59:09,552 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39315
2024-01-06 06:59:09,552 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42307
2024-01-06 06:59:09,552 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44359
2024-01-06 06:59:09,552 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,552 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:09,552 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:09,552 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-c07qh7c4
2024-01-06 06:59:09,553 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cc094ade-923e-49ec-8c20-dda8745388a6
2024-01-06 06:59:09,553 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-44328490-05c5-4f4a-89cd-2b4061c77c3a
2024-01-06 06:59:09,553 - distributed.worker - INFO - Starting Worker plugin PreImport-1fef46c2-d9f0-4494-8410-5286fe47c313
2024-01-06 06:59:09,553 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,701 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:09,702 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43725
2024-01-06 06:59:09,702 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43725
2024-01-06 06:59:09,702 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42975
2024-01-06 06:59:09,702 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44359
2024-01-06 06:59:09,702 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,702 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:09,703 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:09,703 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mpz30quj
2024-01-06 06:59:09,703 - distributed.worker - INFO - Starting Worker plugin PreImport-b1095c61-b718-4312-bc22-3c7498107e48
2024-01-06 06:59:09,703 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9134930e-e156-413e-a83d-dfa75faa9226
2024-01-06 06:59:09,703 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2e843053-d989-49c3-b234-a8e07d25c4e5
2024-01-06 06:59:09,703 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,708 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:09,709 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38447
2024-01-06 06:59:09,709 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38447
2024-01-06 06:59:09,709 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42651
2024-01-06 06:59:09,709 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44359
2024-01-06 06:59:09,709 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,709 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:09,710 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:09,710 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-de2vios3
2024-01-06 06:59:09,710 - distributed.worker - INFO - Starting Worker plugin PreImport-b0520244-f6fa-4bca-895c-d1e26b6b25ee
2024-01-06 06:59:09,710 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d33ed90c-5e26-45ec-93be-ddfe387ce954
2024-01-06 06:59:09,710 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0706d866-23f8-4fac-8dd8-b0bc91781865
2024-01-06 06:59:09,710 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,721 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:09,722 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45669
2024-01-06 06:59:09,722 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45669
2024-01-06 06:59:09,722 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40691
2024-01-06 06:59:09,722 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44359
2024-01-06 06:59:09,722 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,722 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:09,722 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:09,722 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ssefdivb
2024-01-06 06:59:09,723 - distributed.worker - INFO - Starting Worker plugin PreImport-62cbe929-467b-4865-b915-0865b28d29fc
2024-01-06 06:59:09,723 - distributed.worker - INFO - Starting Worker plugin RMMSetup-60eef723-f9da-4c25-b256-17ffa75e3946
2024-01-06 06:59:09,723 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bd6ca236-4c7b-4e5f-a90a-64021f6ae214
2024-01-06 06:59:09,723 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,738 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:09,739 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44811
2024-01-06 06:59:09,739 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44811
2024-01-06 06:59:09,739 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41675
2024-01-06 06:59:09,739 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44359
2024-01-06 06:59:09,739 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,739 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:09,739 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:09,739 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dc2rhs84
2024-01-06 06:59:09,740 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-25952003-e498-4f17-bd9d-1b441448a6b3
2024-01-06 06:59:09,740 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0ae4bf83-3b51-4aa0-9ed8-e8bee58f4162
2024-01-06 06:59:09,740 - distributed.worker - INFO - Starting Worker plugin PreImport-a113fbab-0dad-400e-bc15-4d58db606f20
2024-01-06 06:59:09,740 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,906 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:59:09,907 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39165
2024-01-06 06:59:09,907 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39165
2024-01-06 06:59:09,907 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36465
2024-01-06 06:59:09,907 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44359
2024-01-06 06:59:09,907 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,907 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:59:09,907 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:59:09,907 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2p_o7c_h
2024-01-06 06:59:09,908 - distributed.worker - INFO - Starting Worker plugin RMMSetup-95608ecb-93c6-4668-a41d-45d588a95cbb
2024-01-06 06:59:09,908 - distributed.worker - INFO - Starting Worker plugin PreImport-5d34c16a-30eb-4dc3-a98c-ad65b1605859
2024-01-06 06:59:09,908 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-37836b26-f41e-4cae-b092-fddf45f19fce
2024-01-06 06:59:09,908 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,986 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:09,987 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44359
2024-01-06 06:59:09,987 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:09,988 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44359
2024-01-06 06:59:10,006 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:10,007 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44359
2024-01-06 06:59:10,007 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:10,008 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44359
2024-01-06 06:59:10,021 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:10,022 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44359
2024-01-06 06:59:10,022 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:10,023 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44359
2024-01-06 06:59:10,085 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:10,086 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44359
2024-01-06 06:59:10,086 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:10,087 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44359
2024-01-06 06:59:10,089 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:10,090 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44359
2024-01-06 06:59:10,090 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:10,092 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44359
2024-01-06 06:59:10,100 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:10,101 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44359
2024-01-06 06:59:10,101 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:10,102 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:10,103 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44359
2024-01-06 06:59:10,103 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44359
2024-01-06 06:59:10,103 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:10,104 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44359
2024-01-06 06:59:10,109 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:59:10,109 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44359
2024-01-06 06:59:10,109 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:59:10,111 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44359
2024-01-06 06:59:10,162 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35717. Reason: nanny-close
2024-01-06 06:59:10,163 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38447. Reason: nanny-close
2024-01-06 06:59:10,163 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39315. Reason: nanny-close
2024-01-06 06:59:10,164 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43725. Reason: nanny-close
2024-01-06 06:59:10,165 - distributed.core - INFO - Connection to tcp://127.0.0.1:44359 has been closed.
2024-01-06 06:59:10,165 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45669. Reason: nanny-close
2024-01-06 06:59:10,165 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40297. Reason: nanny-close
2024-01-06 06:59:10,166 - distributed.core - INFO - Connection to tcp://127.0.0.1:44359 has been closed.
2024-01-06 06:59:10,166 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44811. Reason: nanny-close
2024-01-06 06:59:10,166 - distributed.core - INFO - Connection to tcp://127.0.0.1:44359 has been closed.
2024-01-06 06:59:10,166 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:10,167 - distributed.core - INFO - Connection to tcp://127.0.0.1:44359 has been closed.
2024-01-06 06:59:10,167 - distributed.core - INFO - Connection to tcp://127.0.0.1:44359 has been closed.
2024-01-06 06:59:10,167 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:10,167 - distributed.core - INFO - Connection to tcp://127.0.0.1:44359 has been closed.
2024-01-06 06:59:10,168 - distributed.core - INFO - Connection to tcp://127.0.0.1:44359 has been closed.
2024-01-06 06:59:10,168 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:10,168 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:10,168 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:10,168 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39165. Reason: nanny-close
2024-01-06 06:59:10,169 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:10,169 - distributed.nanny - INFO - Worker closed
2024-01-06 06:59:10,170 - distributed.core - INFO - Connection to tcp://127.0.0.1:44359 has been closed.
2024-01-06 06:59:10,172 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_available_mig_workers SKIPPED
dask_cuda/tests/test_local_cuda_cluster.py::test_gpu_uuid PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_track_allocations PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_get_cluster_configuration PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_worker_fraction_limits PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_death_timeout_raises XFAIL
dask_cuda/tests/test_proxify_host_file.py::test_one_dev_item_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_one_item_host_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_spill_on_demand FAILED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_dataframes_share_dev_mem PASSED
dask_cuda/tests/test_proxify_host_file.py::test_cudf_get_device_memory_objects PASSED
dask_cuda/tests/test_proxify_host_file.py::test_externals PASSED
dask_cuda/tests/test_proxify_host_file.py::test_incompatible_types PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_worker_force_spill_to_disk 2024-01-06 07:00:38,401 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56078 remote=tcp://127.0.0.1:34741>: Stream is closed
PASSED
dask_cuda/tests/test_proxify_host_file.py::test_on_demand_debug_info /opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
