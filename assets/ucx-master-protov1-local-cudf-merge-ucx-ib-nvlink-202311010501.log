[1698818421.849975] [dgx13:73532:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_1: LRU push returned Unsupported operation
[dgx13:73532:0:73532]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  73532) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7ff9c316706d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7ff9c3164c11]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dac) [0x7ff9c3164dac]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739e8) [0x7ff9c320e9e8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7ff9c31e5d7f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7ff9c3221aed]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7ff9c32269da]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7ff9c322771f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7ff9c32d56f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x564997fe244c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x564997fc76fb]
11  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x564997fc3094]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x564997fd4519]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x564997fc5128]
14  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x564997fc3094]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x564997fd4519]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x564997fc5128]
17  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x564998077162]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x564997fc9e64]
19  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x564998077162]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x564997fc9e64]
21  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x564998077162]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x564997fc9e64]
23  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x564998077162]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x564997fc9e64]
25  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x564998077162]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x564997fc9e64]
27  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x564998077162]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7ff9e84491e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7ff9e8449aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x564997fcc77c]
31  /opt/conda/envs/gdf/bin/python(+0xead05) [0x564997f7ed05]
32  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x564997fcb7f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x564997fc9929]
34  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x564997fd47c2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564997fc45c6]
36  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x564997fd47c2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564997fc45c6]
38  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x564997fd47c2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564997fc45c6]
40  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x564997fd47c2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564997fc45c6]
42  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x564997fc3094]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x564997fd4519]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x564997fc5128]
45  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x564997fc3094]
46  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x564997fe1ccb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x564997fe244c]
48  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x5649980a510e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x564997fcc77c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x564997fc76fb]
51  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x564997fd47c2]
52  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x564997fe1dac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x564997fc76fb]
54  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x564997fd47c2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564997fc45c6]
56  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x564997fc3094]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x564997fd4519]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564997fc45c6]
59  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x564997fd47c2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x564997fc4312]
61  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x564997fc3094]
=================================
2023-11-01 06:00:24,225 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56602
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f14bd062100, tag: 0x340bce635af980d6, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f14bd062100, tag: 0x340bce635af980d6, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-01 06:00:24,225 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56602
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #010] ep: 0x7efd8d4471c0, tag: 0x9a269070a2514a24, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #010] ep: 0x7efd8d4471c0, tag: 0x9a269070a2514a24, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-01 06:00:24,226 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56602
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f334c6c91c0, tag: 0x2e2ab6592ef7f09d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f334c6c91c0, tag: 0x2e2ab6592ef7f09d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-01 06:00:24,226 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56602
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7efeed017100, tag: 0x5d1be178400ef1c0, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7efeed017100, tag: 0x5d1be178400ef1c0, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-01 06:00:24,239 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56602
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-11-01 06:00:24,319 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56602
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
[1698818427.511340] [dgx13:73548:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:73548:0:73548]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  73548) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7efdbd2e406d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7efdbd2e1c11]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dac) [0x7efdbd2e1dac]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739e8) [0x7efdbd38b9e8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7efdbd362d7f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7efdbd39eaed]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7efdbd3a39da]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7efdbd3a471f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7efdbd4526f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x562b434c444c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x562b434a96fb]
11  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562b434a5094]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x562b434b6519]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x562b434a7128]
14  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562b434a5094]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x562b434b6519]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x562b434a7128]
17  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x562b43559162]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x562b434abe64]
19  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x562b43559162]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x562b434abe64]
21  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x562b43559162]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x562b434abe64]
23  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x562b43559162]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x562b434abe64]
25  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x562b43559162]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x562b434abe64]
27  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x562b43559162]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7efde25df1e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7efde25dfaa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x562b434ae77c]
31  /opt/conda/envs/gdf/bin/python(+0xead05) [0x562b43460d05]
32  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x562b434ad7f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x562b434ab929]
34  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562b434b67c2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562b434a65c6]
36  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562b434b67c2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562b434a65c6]
38  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562b434b67c2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562b434a65c6]
40  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562b434b67c2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562b434a65c6]
42  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562b434a5094]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x562b434b6519]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x562b434a7128]
45  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562b434a5094]
46  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x562b434c3ccb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x562b434c444c]
48  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x562b4358710e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x562b434ae77c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x562b434a96fb]
51  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562b434b67c2]
52  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x562b434c3dac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x562b434a96fb]
54  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562b434b67c2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562b434a65c6]
56  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562b434a5094]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x562b434b6519]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562b434a65c6]
59  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562b434b67c2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x562b434a6312]
61  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562b434a5094]
=================================
2023-11-01 06:00:29,476 - distributed.nanny - WARNING - Restarting worker
2023-11-01 06:00:29,790 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38614
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #045] ep: 0x7f9bfd574180, tag: 0x8660734fb3d5d445, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #045] ep: 0x7f9bfd574180, tag: 0x8660734fb3d5d445, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-01 06:00:29,790 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38614
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #050] ep: 0x7f14bd062140, tag: 0x9ef12ab669d4f48a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #050] ep: 0x7f14bd062140, tag: 0x9ef12ab669d4f48a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-01 06:00:29,791 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38614
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #052] ep: 0x7efeed017180, tag: 0x19e3ff62cdf33a2d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #052] ep: 0x7efeed017180, tag: 0x19e3ff62cdf33a2d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-01 06:00:29,791 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38614
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #038] ep: 0x7f334c6c9200, tag: 0xe3e750f43d420b50, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #038] ep: 0x7f334c6c9200, tag: 0xe3e750f43d420b50, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-01 06:00:29,792 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38614
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #058] ep: 0x7f73e1967200, tag: 0xc26df4311a97e2db, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #058] ep: 0x7f73e1967200, tag: 0xc26df4311a97e2db, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-01 06:00:29,792 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38614
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #031] ep: 0x7fcf90690180, tag: 0xa4c2e58db74e7b8f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #031] ep: 0x7fcf90690180, tag: 0xa4c2e58db74e7b8f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-01 06:00:31,315 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
2023-11-01 06:00:31,315 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
2023-11-01 06:00:31,425 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 5)
Function:  _concat
args:      ([                key   payload
32392     861473892  55017636
39487     828986132  75383577
32405     833038700  87716752
50720     307243128   5777302
31859     843576172  93561795
...             ...       ...
99995528  836142546  43445838
99995530  868141916    737166
99995541  839180515  85287619
99995545  862993155  68629477
99995548  818506257  47636428

[12498923 rows x 2 columns],                 key   payload
2785      956621536  85693109
2793      418269931  34134424
2753      916513075  83300320
2756      915091735   4458392
2761      922126459   6242992
...             ...       ...
99998644  908524622  78703913
99998568  315891850  22453171
99998570  215825212  85803188
99998587  955869160  57015204
99998588  939254651  50442436

[12501128 rows x 2 columns],                  key   payload
113761      25264210  53542201
123590    1067043370  64966503
113766     635919777  69126610
123602     434863185  62073983
113770    1001769011  50612547
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-11-01 06:00:31,599 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-adccb87e3fee0e0ff9c5206a34e9fe09', 0)
Function:  subgraph_callable-6d2356e8-a8c0-4a31-9f40-d65cbe65
args:      (               key   payload
shuffle                     
0            10971   1731578
0            23783  38057165
0            97961  78190864
0            14572  80188724
0           149747  50438155
...            ...       ...
7        799705117  97979006
7        799726680  66081766
7        799681212  56226395
7        799862241  46659790
7        799760537   9808850

[99999977 rows x 2 columns],                  key   payload
32386      807161904  54641893
39484      817928961  81031757
32387      506623305  15269314
50730      800685569  97024053
31849      711223281  18399507
...              ...       ...
99979532  1500760200  34633792
99985284  1503289313  86340304
99985287  1500662372  23452529
99985298  1552162752  64005242
99985307    93286669  59927918

[100005446 rows x 2 columns], 'simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 'simple-shuffle-84a0276e6a854cf0d6c4324869a61d39')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-11-01 06:00:31,670 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 6)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           186566  65940412
0            59490   3778845
0            56758  28340302
0          1158225  45104296
0           351969  26174909
...            ...       ...
0        799895755  79729464
0        799785638   5536479
0        799813764  98473638
0        799901744  78110337
0        799901751  72140052

[12498811 rows x 2 columns],                key   payload
shuffle                     
1            36136  48821755
1           323935  33435474
1            90408  88096186
1            73714  64727002
1            86846  76064997
...            ...       ...
1        799891055  78823131
1        799888060  11493837
1        799864518  97173438
1        799961401  93859036
1        799990270  77275010

[12498510 rows x 2 columns],                key   payload
shuffle                     
2           124060  31046854
2           150132  64722951
2            67637  43492793
2          1143440  31911334
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded')"

2023-11-01 06:00:34,915 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
