[1705908776.076321] [dgx13:91295:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:91295:0:91295]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  91295) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f7645c2707d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f7645c24c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f7645c24dbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7f7645ccf9f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f7645ca6d8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f7645ce2afd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f7645ce79ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f7645ce872f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7f7645d966f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55d427bd104c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55d427bb73f6]
11  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55d427bb1fb4]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d427bc3469]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55d427bb4042]
14  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55d427bb1fb4]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d427bc3469]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55d427bb4042]
17  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55d427c666d2]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55d427bb8c10]
19  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55d427c666d2]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55d427bb8c10]
21  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55d427c666d2]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55d427bb8c10]
23  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55d427c666d2]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55d427bb8c10]
25  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55d427c666d2]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55d427bb8c10]
27  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55d427c666d2]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f76e329f1e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f76e329faa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55d427bbb6ac]
31  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x55d427b763ff]
32  /opt/conda/envs/gdf/bin/python(+0x136723) [0x55d427bba723]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x55d427bb8929]
34  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55d427bc3712]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d427bb34e6]
36  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55d427bc3712]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d427bb34e6]
38  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55d427bc3712]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d427bb34e6]
40  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55d427bc3712]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d427bb34e6]
42  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55d427bb1fb4]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d427bc3469]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55d427bb4042]
45  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55d427bb1fb4]
46  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x55d427bd08cb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55d427bd104c]
48  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x55d427c9480e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55d427bbb6ac]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55d427bb73f6]
51  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55d427bc3712]
52  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x55d427bd09ac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55d427bb73f6]
54  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55d427bc3712]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d427bb34e6]
56  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55d427bb1fb4]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d427bc3469]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d427bb34e6]
59  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55d427bc3712]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55d427bb3232]
61  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55d427bb1fb4]
=================================
2024-01-22 07:32:58,268 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56857
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7f1971578100, tag: 0x321f3fd10e357404, nbytes: 800000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7f1971578100, tag: 0x321f3fd10e357404, nbytes: 800000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
[1705908779.043508] [dgx13:91268:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_0: LRU push returned Unsupported operation
[dgx13:91268:0:91268]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  91268) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f7f43ce407d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f7f43ce1c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f7f43ce1dbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7f7f43d8c9f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f7f43d63d8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f7f43d9fafd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f7f43da49ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f7f43da572f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7f7f43e536f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x5626e61b104c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5626e61973f6]
11  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5626e6191fb4]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5626e61a3469]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5626e6194042]
14  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5626e6191fb4]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5626e61a3469]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5626e6194042]
17  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x5626e62466d2]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x5626e6198c10]
19  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x5626e62466d2]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x5626e6198c10]
21  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x5626e62466d2]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x5626e6198c10]
23  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x5626e62466d2]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x5626e6198c10]
25  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x5626e62466d2]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x5626e6198c10]
27  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x5626e62466d2]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f7fe13851e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f7fe1385aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5626e619b6ac]
31  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x5626e61563ff]
32  /opt/conda/envs/gdf/bin/python(+0x136723) [0x5626e619a723]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x5626e6198929]
34  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5626e61a3712]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5626e61934e6]
36  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5626e61a3712]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5626e61934e6]
38  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5626e61a3712]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5626e61934e6]
40  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5626e61a3712]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5626e61934e6]
42  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5626e6191fb4]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5626e61a3469]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5626e6194042]
45  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5626e6191fb4]
46  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x5626e61b08cb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x5626e61b104c]
48  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x5626e627480e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5626e619b6ac]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5626e61973f6]
51  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5626e61a3712]
52  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x5626e61b09ac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5626e61973f6]
54  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5626e61a3712]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5626e61934e6]
56  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5626e6191fb4]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5626e61a3469]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5626e61934e6]
59  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5626e61a3712]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x5626e6193232]
61  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5626e6191fb4]
=================================
[1705908779.156457] [dgx13:91284:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_1: LRU push returned Unsupported operation
[dgx13:91284:0:91284]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  91284) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fb5d03a407d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7fb5d03a1c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7fb5d03a1dbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7fb5d044c9f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7fb5d0423d8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7fb5d045fafd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7fb5d04649ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7fb5d046572f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7fb5d05136f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55cb5fbce04c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55cb5fbb43f6]
11  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55cb5fbaefb4]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55cb5fbc0469]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55cb5fbb1042]
14  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55cb5fbaefb4]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55cb5fbc0469]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55cb5fbb1042]
17  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55cb5fc636d2]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55cb5fbb5c10]
19  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55cb5fc636d2]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55cb5fbb5c10]
21  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55cb5fc636d2]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55cb5fbb5c10]
23  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55cb5fc636d2]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55cb5fbb5c10]
25  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55cb5fc636d2]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55cb5fbb5c10]
27  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55cb5fc636d2]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fb6599df1e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7fb6599dfaa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55cb5fbb86ac]
31  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x55cb5fb733ff]
32  /opt/conda/envs/gdf/bin/python(+0x136723) [0x55cb5fbb7723]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x55cb5fbb5929]
34  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55cb5fbc0712]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cb5fbb04e6]
36  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55cb5fbc0712]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cb5fbb04e6]
38  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55cb5fbc0712]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cb5fbb04e6]
40  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55cb5fbc0712]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cb5fbb04e6]
42  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55cb5fbaefb4]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55cb5fbc0469]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55cb5fbb1042]
45  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55cb5fbaefb4]
46  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x55cb5fbcd8cb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55cb5fbce04c]
48  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x55cb5fc9180e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55cb5fbb86ac]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55cb5fbb43f6]
51  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55cb5fbc0712]
52  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x55cb5fbcd9ac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55cb5fbb43f6]
54  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55cb5fbc0712]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cb5fbb04e6]
56  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55cb5fbaefb4]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55cb5fbc0469]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55cb5fbb04e6]
59  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55cb5fbc0712]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55cb5fbb0232]
61  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55cb5fbaefb4]
=================================
Task exception was never retrieved
future: <Task finished name='Task-1277' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:140> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 155, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await asyncio.wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2024-01-22 07:33:01,322 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40714
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7fb5308ee1c0, tag: 0xbdf522fa84f17cc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7fb5308ee1c0, tag: 0xbdf522fa84f17cc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2024-01-22 07:33:01,324 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40714
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f7af0548200, tag: 0xf2993650309fede5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f7af0548200, tag: 0xf2993650309fede5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-22 07:33:01,324 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40714
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f19715781c0, tag: 0xdf7fce92e8ac0431, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f19715781c0, tag: 0xdf7fce92e8ac0431, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-22 07:33:01,323 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40714
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f2181bdd340, tag: 0x7c26a016545aba6a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f2181bdd340, tag: 0x7c26a016545aba6a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-22 07:33:01,330 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40714
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 467, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1016, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 328, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 60, in exchange_peer_info
    await asyncio.wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 469, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2024-01-22 07:33:01,425 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51240
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f7af0548100, tag: 0x726f42995015e423, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f7af0548100, tag: 0x726f42995015e423, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-22 07:33:01,425 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51240
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f2181bdd200, tag: 0x22b579ca3450c9c6, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f2181bdd200, tag: 0x22b579ca3450c9c6, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-22 07:33:01,426 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51240
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fb5308ee180, tag: 0xf8c27cc1884f5c63, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fb5308ee180, tag: 0xf8c27cc1884f5c63, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-22 07:33:01,433 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51240
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fb365abd100, tag: 0xeb75e125c3a38e9f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fb365abd100, tag: 0xeb75e125c3a38e9f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-22 07:33:01,459 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51240
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7f1971578100, tag: 0x2c284308c16ba864, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7f1971578100, tag: 0x2c284308c16ba864, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2024-01-22 07:33:03,128 - distributed.comm.ucx - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 374, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 167, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded
2024-01-22 07:33:03,129 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 374, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 167, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded
2024-01-22 07:33:03,505 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-54efe4e1c1ff02b405ca9dd1c57e206a', 5)
Function:  _concat
args:      ([               key   payload  _partitions
shuffle                                  
0           120116  99221438            5
0           135081  75479523            5
0           145780  48743088            5
0            99775    284181            5
0           332524  29758791            5
...            ...       ...          ...
0        799830554  98612240            5
0        799855236  56957928            5
0        799950243  32512763            5
0        799820451  35365474            5
0        799857204  15147951            5

[12507714 rows x 3 columns],                key   payload  _partitions
shuffle                                  
1           420886  61017504            5
1           340877  33060029            5
1           294330   8896774            5
1           139544  30050956            5
1           315357  43379003            5
...            ...       ...          ...
1        799905399   1327648            5
1        799941900  90379085            5
1 
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded')"

2024-01-22 07:33:03,541 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-54efe4e1c1ff02b405ca9dd1c57e206a', 3)
Function:  _concat
args:      ([               key   payload  _partitions
shuffle                                  
0            18931  53650001            3
0            13155  95329695            3
0           102273  83860444            3
0           297831  73100876            3
0           197916  23715623            3
...            ...       ...          ...
0        799969720  29073663            3
0        799856173  48524387            3
0        799890843  69539864            3
0        799979445  46291863            3
0        799951299  39621025            3

[12499485 rows x 3 columns],                key   payload  _partitions
shuffle                                  
1           249719  40050913            3
1           333241  79794305            3
1           321365  88579123            3
1           208145  96082463            3
1           262994  47692875            3
...            ...       ...          ...
1        799932432  17525857            3
1        799977952   2296117            3
1 
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded')"

2024-01-22 07:33:03,705 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b9e75a656c00804c86f03e519074f660', 5)
Function:  _concat
args:      ([                key   payload  _partitions
40961     865755638   7919523            5
40968     412348634  20051155            5
40970     865899902  27799522            5
40982     405760277  14628357            5
40987     506273811   3169898            5
...             ...       ...          ...
99991861  865534918  30741720            5
99991813  839132235  43705358            5
99991821  835084943  13505240            5
99991829  833616018  30208249            5
99991831  818701198   4167754            5

[12501172 rows x 3 columns],                 key   payload  _partitions
21153     224063861   7714013            5
21175     907561096  13660179            5
23169      20832485  58334877            5
23176     917122724  85335591            5
22196     935318400  97542308            5
...             ...       ...          ...
99985839   12909793  99005502            5
99985840  964233964  54652593            5
99985844  925528825  98107587            5
99985848  942041262  7
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded')"

2024-01-22 07:33:03,707 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:46306
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #096] ep: 0x7f1971578240, tag: 0x94a89e7f10ae6ea1, nbytes: 2210, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #096] ep: 0x7f1971578240, tag: 0x94a89e7f10ae6ea1, nbytes: 2210, type: <class 'numpy.ndarray'>>: Message truncated")
2024-01-22 07:33:03,714 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46306 -> ucx://127.0.0.1:37982
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 334, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 641, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7fb5308ee3c0 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2024-01-22 07:33:04,000 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-54efe4e1c1ff02b405ca9dd1c57e206a', 1)
Function:  _concat
args:      ([               key   payload  _partitions
shuffle                                  
0           114169  97312250            1
0            89394  41213017            1
0           299282  97346726            1
0           274270  19027388            1
0           282965  70220443            1
...            ...       ...          ...
0        799818463  15545203            1
0        799910832  95741882            1
0        799871054  53111711            1
0        799768699  24263048            1
0        799834741  42599187            1

[12502439 rows x 3 columns],                key   payload  _partitions
shuffle                                  
1              440  67542417            1
1           361909  63935903            1
1             1383  43965605            1
1           258406    239420            1
1           325493  23220046            1
...            ...       ...          ...
1        799796418    181457            1
1        799815883  96794461            1
1 
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded')"

2024-01-22 07:33:07,397 - distributed.nanny - WARNING - Restarting worker
2024-01-22 07:33:12,019 - distributed.nanny - WARNING - Restarting worker
2024-01-22 07:33:12,099 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
