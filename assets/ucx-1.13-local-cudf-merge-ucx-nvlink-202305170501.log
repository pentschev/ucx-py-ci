2023-05-17 05:49:45,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:45,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:45,024 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:45,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:45,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:45,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:45,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:45,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:45,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:45,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:45,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:45,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:45,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:45,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:45,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:45,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:80157:0:80157] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  80157) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fdfb874211c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7fdfb87422ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7fdfb8742634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fe0499eb420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7fdfb87c328b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fdfb87ed0b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7fdfb86f46a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7fdfb86f4c28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7fdfb86f70fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fdfb874c639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fdfb86f71ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fdfb87bff1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fdfb886f6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55a4ab3b1b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55a4ab3a2112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4ab39b27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a4ab3acc05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4ab39c81b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55a4ab3c170e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fdfc946f2fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55a4ab3a52bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55a4ab358817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55a4ab3a3f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55a4ab3a1d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4ab3acef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4ab39c81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4ab3acef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4ab39c81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4ab3acef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4ab39c81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4ab3acef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4ab39c81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4ab39b27a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a4ab3acc05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55a4ab3a0fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4ab39b27a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55a4ab3ba935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55a4ab3bb104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55a4ab481fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55a4ab3a52bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55a4ab3a01bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4ab3acef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55a4ab3bac72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55a4ab3a01bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4ab3acef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4ab39c81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4ab39b27a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a4ab3acc05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4ab39c81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4ab3acef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55a4ab39c568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4ab39b27a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a4ab3acc05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55a4ab39d3cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4ab39b27a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55a4ab39af07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55a4ab39aeb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55a4ab44b8bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55a4ab479adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55a4ab475c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55a4ab46d7ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55a4ab46d6bd]
=================================
[dgx13:80154:0:80154] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  80154) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fba810e011c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7fba810e02ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7fba810e0634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fbb2438a420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7fba8116128b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fba8118b0b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7fba810926a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7fba81092c28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7fba810950fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fba810ea639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fba810951ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fba8115df1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fba8120d6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5598abbd6b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5598abbc7112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5598abbc027a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5598abbd1c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5598abbc181b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5598abbd1ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x5598abbdfa16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x5598abcef9b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5598abb7d817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5598abbc8f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5598abbc6d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5598abbd1ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5598abbc181b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5598abbd1ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5598abbc181b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5598abbd1ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5598abbc181b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5598abbd1ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5598abbc181b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5598abbc027a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5598abbd1c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5598abbc5fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5598abbc027a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5598abbdf935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5598abbe0104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5598abca6fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5598abbca2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5598abbc51bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5598abbd1ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5598abbdfc72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5598abbc51bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5598abbd1ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5598abbc181b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5598abbc027a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5598abbd1c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5598abbc181b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5598abbd1ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5598abbc1568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5598abbc027a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5598abbd1c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5598abbc23cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5598abbc027a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5598abbbff07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5598abbbfeb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5598abc708bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5598abc9eadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5598abc9ac24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5598abc927ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5598abc926bd]
=================================
[dgx13:80148:0:80148] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  80148) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f80782e911c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7f80782e92ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7f80782e9634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f8109581420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7f807836a28b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f80783940b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7f807829b6a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7f807829bc28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7f807829e0fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f80782f3639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f807829e1ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f8078366f1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f80784166e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55e2190a4b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55e219095112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e21908e27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e21909fc05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e21908f81b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55e2190b470e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f80890012fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55e2190982bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55e21904b817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55e219096f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55e219094d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e21909fef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e21908f81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e21909fef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e21908f81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e21909fef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e21908f81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e21909fef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e21908f81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e21908e27a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e21909fc05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55e219093fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e21908e27a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55e2190ad935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55e2190ae104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55e219174fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55e2190982bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55e2190931bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e21909fef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55e2190adc72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55e2190931bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e21909fef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e21908f81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e21908e27a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e21909fc05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e21908f81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e21909fef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55e21908f568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e21908e27a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e21909fc05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55e2190903cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e21908e27a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55e21908df07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55e21908deb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55e21913e8bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55e21916cadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55e219168c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55e2191607ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55e2191606bd]
=================================
[dgx13:80151:0:80151] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  80151) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f8ca1fcb11c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7f8ca1fcb2ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7f8ca1fcb634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f8d492ab420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7f8cb809328b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f8cb80bd0b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7f8cb80296a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7f8cb8029c28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7f8cb802c0fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f8ca1fd5639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f8cb802c1ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f8cb808ff1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f8cb813f6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x56087f93db08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x56087f92e112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56087f92727a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56087f938c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56087f92881b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56087f938ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x56087f946a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x56087fa569b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x56087f8e4817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x56087f92ff83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x56087f92dd36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56087f938ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56087f92881b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56087f938ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56087f92881b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56087f938ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56087f92881b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56087f938ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56087f92881b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56087f92727a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56087f938c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x56087f92cfa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56087f92727a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x56087f946935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x56087f947104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x56087fa0dfc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56087f9312bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56087f92c1bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56087f938ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x56087f946c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56087f92c1bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56087f938ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56087f92881b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56087f92727a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56087f938c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56087f92881b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56087f938ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x56087f928568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56087f92727a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56087f938c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x56087f9293cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56087f92727a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x56087f926f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56087f926eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56087f9d78bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x56087fa05adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x56087fa01c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x56087f9f97ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x56087f9f96bd]
=================================
2023-05-17 05:49:52,976 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48447 -> ucx://127.0.0.1:34905
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fe1c2f3e100, tag: 0x248cc8162f39e3c5, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-826' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Endpoint timeout
2023-05-17 05:49:52,977 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34905
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f488c2191c0, tag: 0x417d64636c91a0b1, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f488c2191c0, tag: 0x417d64636c91a0b1, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:34905 after 30 s
2023-05-17 05:49:52,981 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34905
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-17 05:49:52,982 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34905
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
Task exception was never retrieved
future: <Task finished name='Task-849' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-05-17 05:49:52,988 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34905
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-17 05:49:52,992 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57387 -> ucx://127.0.0.1:48493
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f9cb1f97180, tag: 0x2270e4ad064b9d9d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-850' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Endpoint timeout
2023-05-17 05:49:52,995 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48493
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-17 05:49:52,995 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48493
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-17 05:49:52,995 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48493
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-17 05:49:53,058 - distributed.nanny - WARNING - Restarting worker
2023-05-17 05:49:53,121 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57387 -> ucx://127.0.0.1:46719
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f9cb1f97200, tag: 0xab2423e31882af5f, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-17 05:49:53,122 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:46719
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f9cb1f97240, tag: 0xa8a8e99cbcab8278, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f9cb1f97240, tag: 0xa8a8e99cbcab8278, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-17 05:49:53,126 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:46719
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #011] ep: 0x7f0080339100, tag: 0xa9fdcb03f2facc34, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #011] ep: 0x7f0080339100, tag: 0xa9fdcb03f2facc34, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-17 05:49:53,126 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44495 -> ucx://127.0.0.1:46719
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f488c219340, tag: 0x5f4ef858c0991837, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-17 05:49:53,127 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:46719
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f488c219100, tag: 0x470c949b0fc8c7e0, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f488c219100, tag: 0x470c949b0fc8c7e0, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-05-17 05:49:53,142 - distributed.nanny - WARNING - Restarting worker
2023-05-17 05:49:53,192 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:46719
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fe1c2f3e240, tag: 0xf09116b0e8c8aa1c, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fe1c2f3e240, tag: 0xf09116b0e8c8aa1c, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-05-17 05:49:53,208 - distributed.nanny - WARNING - Restarting worker
Task exception was never retrieved
future: <Task finished name='Task-953' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Endpoint timeout
2023-05-17 05:49:53,257 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60993 -> ucx://127.0.0.1:58843
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f0080339400, tag: 0x749188e16c91ed09, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-17 05:49:53,268 - distributed.nanny - WARNING - Restarting worker
2023-05-17 05:49:54,569 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:54,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:54,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:54,603 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:54,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:54,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:54,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:54,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:55,170 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 0)
Function:  <dask.layers.CallableLazyImport object at 0x7fdc85
args:      ([                key   payload
31906     853277924  49548919
31907     840785319  97156979
31920     842399018  94962175
19137     801805407   5823398
19140     831264488  67053160
...             ...       ...
99993535  806095554  32167554
99993487  827333254  31571780
99993490  837838902   2453326
99993502  712332340  20270677
99993503  869625704  92663297

[12497168 rows x 2 columns],                 key   payload
11395     945617013  95241158
11406     926442993  14911233
11418     522211455   2865487
11420     943400036  29008370
104641    951449864  82814904
...             ...       ...
99991899  946965329   4362390
99965336  926330737  99190132
99965208  967531797  82243012
99965213  958254452  88060930
99965214  718414913  66713618

[12502889 rows x 2 columns],                  key   payload
38049     1002616565  25230728
38052     1038779988  47335393
38056      627879126  84940423
32399     1009185486  81105569
32413      630375339  88840670
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-17 05:49:55,359 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 4)
Function:  <dask.layers.CallableLazyImport object at 0x7fdc85
args:      ([                key   payload
11429     813559065  87859800
11433     868329126  51749993
11436     804834137  15614818
11440     803858383  93810435
11442     510819889  52929828
...             ...       ...
99993473  204288797  53219988
99993476  834097664  44804133
99993480  816515936  49436731
99993481  828933357  64199641
99993499  611681302  43501386

[12500589 rows x 2 columns],                 key   payload
11419     957478795  69764899
104640    961948598  29823515
104663    916842997  71775956
104666    118260319  48456801
60134     937476211  47861056
...             ...       ...
99965334  934602414  26994886
99991895   13166556  69139396
99991896  417957810  42317661
99965184  937428344  76731405
99965186  918110309  30040727

[12501715 rows x 2 columns],                  key   payload
31813      228882689  99861949
38066     1053153896    290822
31814     1065942591  19036661
31838     1061911218  71273917
32390     1021992566  68519243
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-17 05:49:55,494 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6)
Function:  <dask.layers.CallableLazyImport object at 0x7fdc85
args:      ([                key   payload
11426     706431177  34416834
11438     849597869  29287560
11445     808918330  52993592
11446     303323426  23567619
11447     868175782  14125433
...             ...       ...
99993561  865489238  36846518
99993562  852047057  50911466
99993566  107341903  83483507
99993482  507438980  33471624
99993496  838189238  43068461

[12497796 rows x 2 columns],                 key   payload
11394     323955332  66327578
11401     322545504  28565297
11421     914048963  36519784
11422     956781831  17764812
104661    952166190  84499338
...             ...       ...
99965194  942767530  35510311
99965196  944703642   6806515
99965200  943375175  16166697
99965205  958416987  13504749
99965211  939334941  65937042

[12497151 rows x 2 columns],                  key   payload
31812     1065545958  93282087
38062      426862205  19573870
31817     1024989760  68872317
31820     1062867663   4182252
32387      531623305  15269314
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

[dgx13:80664:0:80664] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  80664) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7ff57c5c711c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7ff57c5c72ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7ff57c5c7634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7ff61b6fc420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7ff57c64828b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7ff57c6720b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7ff57c5796a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7ff57c579c28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7ff57c57c0fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7ff57c5d1639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7ff57c57c1ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7ff57c644f1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7ff57c6f46e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x556d3e697b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x556d3e688112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556d3e68127a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556d3e692c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556d3e68281b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556d3e692ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x556d3e6a0a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x556d3e7b09b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x556d3e63e817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x556d3e689f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x556d3e687d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556d3e692ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556d3e68281b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556d3e692ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556d3e68281b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556d3e692ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556d3e68281b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556d3e692ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556d3e68281b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556d3e68127a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556d3e692c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x556d3e686fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556d3e68127a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x556d3e6a0935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x556d3e6a1104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x556d3e767fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x556d3e68b2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x556d3e6861bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556d3e692ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x556d3e6a0c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x556d3e6861bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556d3e692ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556d3e68281b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556d3e68127a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556d3e692c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556d3e68281b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556d3e692ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x556d3e682568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556d3e68127a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556d3e692c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x556d3e6833cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556d3e68127a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x556d3e680f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x556d3e680eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x556d3e7318bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x556d3e75fadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x556d3e75bc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x556d3e7537ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x556d3e7536bd]
=================================
Task exception was never retrieved
future: <Task finished name='Task-1678' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Endpoint timeout
2023-05-17 05:49:55,636 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44495 -> ucx://127.0.0.1:49491
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f488c219300, tag: 0xa133a6196f54a691, nbytes: 99992920, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-17 05:49:55,685 - distributed.nanny - WARNING - Restarting worker
2023-05-17 05:49:55,698 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-252ad14fcb6b7fd7a96ffd96c0e2023d', 1)
Function:  subgraph_callable-6f9e8688-42ae-4204-82bf-9bbe1231
args:      (               key   payload
shuffle                     
0           538303  95423824
0           184755  94366716
0           184295  23085156
0           182263  16561835
0           897913  69947419
...            ...       ...
7        799941255  15835512
7        799977070  58294332
7        799894703   9039476
7        799935621  31907020
7        799997548  69623166

[100005187 rows x 2 columns],                  key   payload
11424      310549991  15367195
11428      867387233  55924324
11437      818974461  69729928
31905      705795044  58670149
31913      828535192  43479385
...              ...       ...
99965190  1500569836  34605603
99965207  1501427457  37042990
99965211  1539334941  65937042
99965282  1568183121  47943972
99965286  1549645038  14317204

[99996328 rows x 2 columns])
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-17 05:49:55,721 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-252ad14fcb6b7fd7a96ffd96c0e2023d', 2)
Function:  subgraph_callable-6f9e8688-42ae-4204-82bf-9bbe1231
args:      (               key   payload
shuffle                     
0           398194  97118020
0           526900  89781265
0           511649  24059008
0           194538  77852098
0           129915  80789874
...            ...       ...
7        799935624  68253091
7        799996091  55816645
7        799996094  13488803
7        799997552  87703134
7        799959058  77600320

[99996471 rows x 2 columns],                  key   payload
11430      816455952  78657584
11435      861118242  48509001
11441      862416429   4914051
11451      817086426  48538166
31924      810640982  82843337
...              ...       ...
99965199  1537835916  95496881
99965287  1503485378  42515198
99965301  1517878395  53136294
99965302   497254723   6080551
99965311  1537931097  91389042

[100013945 rows x 2 columns])
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-17 05:49:55,741 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-17 05:49:55,741 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-17 05:49:55,745 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60993 -> ucx://127.0.0.1:49491
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f0080339400, tag: 0x317dd02c186b90c9, nbytes: 99996680, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
[dgx13:80670:0:80670] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  80670) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fc8e9a2111c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x302ff) [0x7fc8e9a212ff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30634) [0x7fc8e9a21634]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fc98cb66420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x1b) [0x7fc8e9aa228b]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fc8e9acc0b8]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x216a7) [0x7fc8e99d36a7]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21c28) [0x7fc8e99d3c28]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x240fc) [0x7fc8e99d60fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fc8e9a2b639]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fc8e99d61ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fc8e9a9ef1a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fc8e9b4e6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55701d39ab08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55701d38b112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55701d38427a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55701d395c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55701d38581b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55701d395ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55701d3a3a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55701d4b39b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55701d341817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55701d38cf83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55701d38ad36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55701d395ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55701d38581b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55701d395ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55701d38581b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55701d395ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55701d38581b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55701d395ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55701d38581b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55701d38427a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55701d395c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55701d389fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55701d38427a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55701d3a3935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55701d3a4104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55701d46afc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55701d38e2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55701d3891bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55701d395ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55701d3a3c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55701d3891bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55701d395ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55701d38581b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55701d38427a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55701d395c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55701d38581b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55701d395ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55701d385568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55701d38427a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55701d395c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55701d3863cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55701d38427a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55701d383f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55701d383eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55701d4348bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55701d462adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55701d45ec24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55701d4567ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55701d4566bd]
=================================
2023-05-17 05:49:55,839 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-17 05:49:55,840 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-17 05:49:55,881 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-17 05:49:55,881 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-17 05:49:55,905 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48447 -> ucx://127.0.0.1:53409
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fe1c2f3e240, tag: 0xcffd7139e8eb9d69, nbytes: 99985648, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-17 05:49:55,905 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57387 -> ucx://127.0.0.1:53409
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f9cb1f97200, tag: 0x9a23156d6099ee53, nbytes: 100019112, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-1977' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Endpoint timeout
2023-05-17 05:49:55,942 - distributed.nanny - WARNING - Restarting worker
2023-05-17 05:49:56,053 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-ebc001d8cefba05cda02be96f011c653', 5)
Function:  <dask.layers.CallableLazyImport object at 0x7f4334
args:      ([               key   payload
shuffle                     
0           468077  55516466
0           516623  15267238
0           507082  98320982
0           274860  13039627
0           500476  40363401
...            ...       ...
0        799520321  47592599
0        799581382  58131756
0        799561918   5761074
0        799554161    474547
0        799532745  95261032

[12502296 rows x 2 columns],                key   payload
shuffle                     
1           800618  76237831
1           863048  56000641
1           865670  39682841
1           514770  76842355
1          1051573  62440493
...            ...       ...
1        799925358  54317561
1        799961711  22085507
1        799988834  43781236
1        799947403  70178891
1        799887385  36848684

[12499115 rows x 2 columns],                key   payload
shuffle                     
2           169621  64647365
2            86773  32823170
2           155651  29497967
2           172568  90766182
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-17 05:49:57,178 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:57,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:49:57,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-17 05:49:57,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-17 05:50:22,724 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48493
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:48493 after 30 s
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
