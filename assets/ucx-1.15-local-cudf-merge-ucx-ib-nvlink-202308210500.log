/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39873 instead
  warnings.warn(
[1692599184.456694] [dgx13:69757:0]    ib_mlx5dv_md.c:462  UCX  ERROR mlx5_0: LRU push returned Unsupported operation
[dgx13:69757:0:69757]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  69757) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f554c3960cd]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f554c393c71]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27e0c) [0x7f554c393e0c]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739b8) [0x7f554c43e9b8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f554c415d4f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f554c451aad]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f554c45699a]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f554c4576df]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x64ed7) [0x7f554c4fded7]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x5599729a000c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5599729863d6]
11  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559972980f94]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5599729923f9]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x559972983022]
14  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559972980f94]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5599729923f9]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x559972983022]
17  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x559972a35612]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55997298824d]
19  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x559972a35612]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55997298824d]
21  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x559972a35612]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55997298824d]
23  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x559972a35612]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55997298824d]
25  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x559972a35612]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55997298824d]
27  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x559972a35612]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f55e00191e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f55e0019aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55997298a67c]
31  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x55997294548b]
32  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x5599729896f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x5599729876e4]
34  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5599729926a2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5599729824c6]
36  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5599729926a2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5599729824c6]
38  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5599729926a2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5599729824c6]
40  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5599729926a2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5599729824c6]
42  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559972980f94]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5599729923f9]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x559972983022]
45  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559972980f94]
46  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55997299f88b]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x5599729a000c]
48  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x559972a6373e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55997298a67c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5599729863d6]
51  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5599729926a2]
52  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55997299f96c]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5599729863d6]
54  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5599729926a2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5599729824c6]
56  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559972980f94]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5599729923f9]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5599729824c6]
59  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5599729926a2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x559972982212]
61  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x559972980f94]
=================================
2023-08-21 06:26:24,753 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44020
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fe4903e2140, tag: 0x7f5db2948f7898bc, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fe4903e2140, tag: 0x7f5db2948f7898bc, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 06:26:24,752 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44020
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f4d5c77b200, tag: 0xa3345f6003cdad5a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 392, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1927, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f4d5c77b200, tag: 0xa3345f6003cdad5a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1620, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1539, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 397, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:44020 after 30 s
2023-08-21 06:26:24,754 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44020
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc3909dd180, tag: 0xf94a351b8e67c660, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc3909dd180, tag: 0xf94a351b8e67c660, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-1005' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-08-21 06:26:24,754 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44020
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f0285bb4240, tag: 0xb977bed0d520fbe8, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f0285bb4240, tag: 0xb977bed0d520fbe8, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 06:26:24,756 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44020
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fb6856e7200, tag: 0xa12c9307d7546ad8, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fb6856e7200, tag: 0xa12c9307d7546ad8, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 06:26:24,755 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44020
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f5c70a7d1c0, tag: 0x81a3fd91df855c50, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f5c70a7d1c0, tag: 0x81a3fd91df855c50, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 06:26:24,756 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44020
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7f253031c1c0, tag: 0x12fc9af489ae4a4b, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7f253031c1c0, tag: 0x12fc9af489ae4a4b, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-21 06:26:25,208 - distributed.nanny - WARNING - Restarting worker
2023-08-21 06:26:29,281 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-f1e9396f54451b9cde4495a9a287c08c', 3)
Function:  subgraph_callable-446bbc16-063e-49e8-8047-3666559f
args:      (               key   payload
shuffle                     
0           824938  42667259
0           688926  64622089
0           656868  13115042
0           165407  58559641
0             6034  41182728
...            ...       ...
7        799901115  81640567
7        799982890  44244216
7        799950833  40372593
7        799755391  30732604
7        799943050  73234134

[100002012 rows x 2 columns],                  key   payload
104994     840744542   5468312
104999     844154213  60298616
105002     110377739  94324482
105008     866310275  89427805
84552      841446496  11017976
...              ...       ...
99997614  1514176963   1896720
99997616   192250535  29330640
99997622  1562749601  92727686
99997624   394630887  87116639
99997667  1557933057  80242442

[100005738 rows x 2 columns], 'simple-shuffle-054f65580a5efedc40c26858beb83d02', 'simple-shuffle-84a0276e6a854cf0d6c4324869a61d39')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

[1692599193.054431] [dgx13:69763:0]    ib_mlx5dv_md.c:462  UCX  ERROR mlx5_1: LRU push returned Unsupported operation
[dgx13:69763:0:69763]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  69763) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f25331740cd]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f2533171c71]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27e0c) [0x7f2533171e0c]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739b8) [0x7f253321c9b8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f25331f3d4f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f253322faad]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f253323499a]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f25332356df]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x64ed7) [0x7f25332dbed7]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55f7ab05900c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55f7ab03f3d6]
11  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f7ab039f94]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f7ab04b3f9]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55f7ab03c022]
14  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f7ab039f94]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f7ab04b3f9]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55f7ab03c022]
17  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55f7ab0ee612]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55f7ab04124d]
19  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55f7ab0ee612]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55f7ab04124d]
21  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55f7ab0ee612]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55f7ab04124d]
23  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55f7ab0ee612]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55f7ab04124d]
25  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55f7ab0ee612]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x55f7ab04124d]
27  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55f7ab0ee612]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f25583601e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f2558360aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55f7ab04367c]
31  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x55f7aaffe48b]
32  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x55f7ab0426f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x55f7ab0406e4]
34  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f7ab04b6a2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f7ab03b4c6]
36  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f7ab04b6a2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f7ab03b4c6]
38  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f7ab04b6a2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f7ab03b4c6]
40  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f7ab04b6a2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f7ab03b4c6]
42  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f7ab039f94]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f7ab04b3f9]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55f7ab03c022]
45  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f7ab039f94]
46  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55f7ab05888b]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55f7ab05900c]
48  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x55f7ab11c73e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55f7ab04367c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55f7ab03f3d6]
51  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f7ab04b6a2]
52  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55f7ab05896c]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55f7ab03f3d6]
54  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f7ab04b6a2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f7ab03b4c6]
56  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f7ab039f94]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f7ab04b3f9]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f7ab03b4c6]
59  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55f7ab04b6a2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55f7ab03b212]
61  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55f7ab039f94]
=================================
2023-08-21 06:26:33,322 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39356
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #113] ep: 0x7f5c70a7d140, tag: 0xfa2e7e8015a80375, nbytes: 800043568, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #113] ep: 0x7f5c70a7d140, tag: 0xfa2e7e8015a80375, nbytes: 800043568, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-21 06:26:33,324 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39356
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #090] ep: 0x7fe4903e2100, tag: 0x13278333d5eef148, nbytes: 99935688, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #090] ep: 0x7fe4903e2100, tag: 0x13278333d5eef148, nbytes: 99935688, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-21 06:26:33,324 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39356
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #103] ep: 0x7f4d5c77b180, tag: 0x107915026c75fa98, nbytes: 99989016, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #103] ep: 0x7f4d5c77b180, tag: 0x107915026c75fa98, nbytes: 99989016, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-21 06:26:33,472 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39356
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #025] ep: 0x7f083d50d100, tag: 0xdd592666183c3e52, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #025] ep: 0x7f083d50d100, tag: 0xdd592666183c3e52, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 06:26:33,826 - distributed.nanny - WARNING - Restarting worker
[1692599196.018876] [dgx13:69748:0]    ib_mlx5dv_md.c:462  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:69748:0:69748]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  69748) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f02b4a0f0cd]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f02b4a0cc71]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27e0c) [0x7f02b4a0ce0c]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739b8) [0x7f02b4ab79b8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f02b4a8ed4f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f02b4acaaad]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f02b4acf99a]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f02b4ad06df]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x64ed7) [0x7f02b4b76ed7]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55686810600c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5568680ec3d6]
11  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5568680e6f94]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5568680f83f9]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5568680e9022]
14  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5568680e6f94]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5568680f83f9]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5568680e9022]
17  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55686819b612]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x5568680ee24d]
19  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55686819b612]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x5568680ee24d]
21  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55686819b612]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x5568680ee24d]
23  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55686819b612]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x5568680ee24d]
25  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55686819b612]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x641d) [0x5568680ee24d]
27  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55686819b612]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f02d5a8f1e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f02d5a8faa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5568680f067c]
31  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x5568680ab48b]
32  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x5568680ef6f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x5568680ed6e4]
34  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5568680f86a2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5568680e84c6]
36  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5568680f86a2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5568680e84c6]
38  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5568680f86a2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5568680e84c6]
40  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5568680f86a2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5568680e84c6]
42  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5568680e6f94]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5568680f83f9]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5568680e9022]
45  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5568680e6f94]
46  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55686810588b]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55686810600c]
48  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x5568681c973e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5568680f067c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5568680ec3d6]
51  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5568680f86a2]
52  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55686810596c]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5568680ec3d6]
54  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5568680f86a2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5568680e84c6]
56  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5568680e6f94]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5568680f83f9]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5568680e84c6]
59  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x5568680f86a2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x5568680e8212]
61  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x5568680e6f94]
=================================
2023-08-21 06:26:36,308 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50593
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #079] ep: 0x7fc3909dd240, tag: 0x49332af0b4395631, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #079] ep: 0x7fc3909dd240, tag: 0x49332af0b4395631, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 06:26:36,310 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50593
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #112] ep: 0x7f5c70a7d280, tag: 0xf5ce10192a970db2, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #112] ep: 0x7f5c70a7d280, tag: 0xf5ce10192a970db2, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-21 06:26:36,311 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50593
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #076] ep: 0x7fe4903e21c0, tag: 0xed9352fe433f05d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #076] ep: 0x7fe4903e21c0, tag: 0xed9352fe433f05d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 06:26:36,312 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50593
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #046] ep: 0x7f083d50d140, tag: 0x11a2bfbf729bfb35, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #046] ep: 0x7f083d50d140, tag: 0x11a2bfbf729bfb35, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 06:26:36,312 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50593
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #083] ep: 0x7fb6856e7140, tag: 0x13359bfdc30e504f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #083] ep: 0x7fb6856e7140, tag: 0x13359bfdc30e504f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 06:26:36,313 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50593
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #125] ep: 0x7f4d5c77b280, tag: 0xbfd46301b38d98d2, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #125] ep: 0x7f4d5c77b280, tag: 0xbfd46301b38d98d2, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 06:26:36,806 - distributed.nanny - WARNING - Restarting worker
2023-08-21 06:26:37,459 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-21 06:26:37,460 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-21 06:26:37,626 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 5)
Function:  _concat
args:      ([                key   payload
39054     843738267  82435858
39055     819694167  12444672
39057     856147800  78235400
39059     808355601  25830606
18561     811782141  36961381
...             ...       ...
99993068  107703439  76766442
99993074  833694879  75529757
99993080  850511615     50571
99993081  807422747  60195675
99993084  853285074  94598415

[12498923 rows x 2 columns],                 key   payload
75842     933178392  28164516
75865     967395415  82012349
113793    909780415   4091212
113813     20837146  83826053
21064     944747962  25378766
...             ...       ...
99998170  919427665  19517373
99998171   21400430  26635982
99998172  961195505  44449764
99998088  320443975  69000119
99998094  948840529  23012807

[12501128 rows x 2 columns],                  key   payload
73249      528797088  35296400
9728      1014907381  62363085
73252      236437564  53801678
12992     1012214427  70781135
15027     1022072008  27477279
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-21 06:26:37,786 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-054f65580a5efedc40c26858beb83d02', 6)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           258035  96401006
0           240053  55736951
0           146809  89181089
0            18696  45950830
0           581314  22723586
...            ...       ...
0        799863540  91949684
0        799933108   4489503
0        799964798  91955919
0        799957740  72397022
0        799941251  37799493

[12498811 rows x 2 columns],                key   payload
shuffle                     
1           171515  68216023
1           188886  91256379
1          1125491  93594449
1          1138377  54635717
1          1087158  31986383
...            ...       ...
1        799864518  97173438
1        799954732  78627191
1        799951799  83246605
1        799938837  50368032
1        799804156  20801653

[12498510 rows x 2 columns],                key   payload
shuffle                     
2           153937  70174885
2            50267  55188419
2           205135  88794404
2           118618  97998409
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
