[dgx13:85250:0:85250] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  85250) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fa9d006ff1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7fa9d0070114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7fa9d00702da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7faa711ad420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fa9b5b6a5d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fa9b5b8f859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7fa9d002b42f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7fa9d002e798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fa9d0078989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fa9d002d62d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fa9b5b67c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7fa9b5c1906a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55da1f8ac6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55da1f8a8094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55da1f8b9519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55da1f8a95c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55da1f8b97c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55da1f8c6e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55da1f9d1b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55da1f863d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55da1f8b07f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55da1f8ae929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55da1f8b97c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55da1f8a95c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55da1f8b97c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55da1f8a95c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55da1f8b97c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55da1f8a95c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55da1f8b97c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55da1f8a95c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55da1f8a8094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55da1f8b9519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55da1f8aa128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55da1f8a8094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55da1f8c6ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55da1f8c744c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55da1f98a10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55da1f8b177c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55da1f8ac6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55da1f8b97c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55da1f8c6dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55da1f8ac6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55da1f8b97c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55da1f8a95c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55da1f8a8094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55da1f8b9519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55da1f8a95c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55da1f8b97c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55da1f8a9312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55da1f8a8094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55da1f8b9519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55da1f8aa128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55da1f8a8094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55da1f8a7d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55da1f8a7d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55da1f95507b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55da1f981fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55da1f97e353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55da1f97616a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55da1f97605c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55da1f975297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55da1f948f07]
=================================
[dgx13:85253:0:85253] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  85253) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f920005ef1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7f920005f114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7f920005f2da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f92935cd420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f91edf835d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f91edfa8859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7f91edf2142f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7f91edf24798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f9200067989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f91edf2362d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f91edf80c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7f92000c406a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x562e47a106fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562e47a0c094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x562e47a1d519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562e47a0d5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x562e47ac0162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f92895901e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x562e47a1577c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x562e479c7d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x562e47a147f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x562e47a12929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562e47a1d7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562e47a0d5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562e47a1d7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562e47a0d5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562e47a1d7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562e47a0d5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562e47a1d7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562e47a0d5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562e47a0c094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x562e47a1d519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x562e47a0e128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562e47a0c094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x562e47a2accb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x562e47a2b44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x562e47aee10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x562e47a1577c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x562e47a106fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562e47a1d7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x562e47a2adac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x562e47a106fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562e47a1d7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562e47a0d5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562e47a0c094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x562e47a1d519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x562e47a0d5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x562e47a1d7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x562e47a0d312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562e47a0c094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x562e47a1d519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x562e47a0e128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x562e47a0c094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x562e47a0bd68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x562e47a0bd19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x562e47ab907b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x562e47ae5fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x562e47ae2353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x562e47ada16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x562e47ada05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x562e47ad9297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x562e47aacf07]
=================================
[dgx13:85237:0:85237] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
[dgx13:85242:0:85242] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  85237) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f957454ef1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7f957454f114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7f957454f2da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f9615b67420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f95745c85d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f95745ed859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7f957450a42f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7f957450d798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f9574557989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f957450c62d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f95745c5c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7f957467706a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x558f5f3c56fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558f5f3c1094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558f5f3d2519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558f5f3c25c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x558f5f475162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f960bb501e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x558f5f3ca77c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x558f5f37cd05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x558f5f3c97f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x558f5f3c7929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x558f5f3d27c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558f5f3c25c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x558f5f3d27c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558f5f3c25c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x558f5f3d27c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558f5f3c25c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x558f5f3d27c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558f5f3c25c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558f5f3c1094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558f5f3d2519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x558f5f3c3128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558f5f3c1094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x558f5f3dfccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x558f5f3e044c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x558f5f4a310e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x558f5f3ca77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x558f5f3c56fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x558f5f3d27c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x558f5f3dfdac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x558f5f3c56fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x558f5f3d27c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558f5f3c25c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558f5f3c1094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558f5f3d2519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x558f5f3c25c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x558f5f3d27c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x558f5f3c2312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558f5f3c1094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558f5f3d2519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x558f5f3c3128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558f5f3c1094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x558f5f3c0d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x558f5f3c0d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x558f5f46e07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x558f5f49afca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x558f5f497353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x558f5f48f16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x558f5f48f05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x558f5f48e297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x558f5f461f07]
=================================
==== backtrace (tid:  85242) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7ff3a3752f1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7ff3a3753114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7ff3a37532da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7ff448d8a420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7ff3a37cc5d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7ff3a37f1859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7ff3a370e42f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7ff3a3711798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7ff3a375b989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7ff3a371062d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7ff3a37c9c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7ff3a387b06a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55be935156fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55be93511094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55be93522519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55be935125c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55be935c5162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7ff43ed501e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55be9351a77c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55be934ccd05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55be935197f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55be93517929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55be935227c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55be935125c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55be935227c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55be935125c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55be935227c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55be935125c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55be935227c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55be935125c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55be93511094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55be93522519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55be93513128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55be93511094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55be9352fccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55be9353044c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55be935f310e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55be9351a77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55be935156fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55be935227c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55be9352fdac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55be935156fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55be935227c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55be935125c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55be93511094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55be93522519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55be935125c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55be935227c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55be93512312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55be93511094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55be93522519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55be93513128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55be93511094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55be93510d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55be93510d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55be935be07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55be935eafca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55be935e7353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55be935df16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55be935df05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55be935de297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55be935b1f07]
=================================
[dgx13:85244:0:85244] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  85244) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f038428df1d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29114) [0x7f038428e114]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x292da) [0x7f038428e2da]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f04258d7420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f03843075d4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f038432c859]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2042f) [0x7f038424942f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23798) [0x7f038424c798]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f0384296989]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f038424b62d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f0384304c4a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7f03843b606a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ce4272b6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ce42727094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ce42738519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ce427285c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ce427387c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55ce42745e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55ce42850b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55ce426e2d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55ce4272f7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55ce4272d929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ce427387c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ce427285c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ce427387c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ce427285c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ce427387c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ce427285c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ce427387c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ce427285c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ce42727094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ce42738519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55ce42729128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ce42727094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55ce42745ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55ce4274644c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55ce4280910e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55ce4273077c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ce4272b6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ce427387c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55ce42745dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ce4272b6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ce427387c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ce427285c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ce42727094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ce42738519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ce427285c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ce427387c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55ce42728312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ce42727094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ce42738519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55ce42729128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ce42727094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55ce42726d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55ce42726d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55ce427d407b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55ce42800fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55ce427fd353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55ce427f516a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55ce427f505c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55ce427f4297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55ce427c7f07]
=================================
2023-12-21 06:56:13,733 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:43059 -> ucx://127.0.0.1:50803
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fbb71ce7180, tag: 0x87a159e8b48e22b6, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-923' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-12-21 06:56:13,738 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50803
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-12-21 06:56:13,738 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50803
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-12-21 06:56:13,739 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50803
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-12-21 06:56:13,809 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33125
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f70315371c0, tag: 0x976d2c38f325b155, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f70315371c0, tag: 0x976d2c38f325b155, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-12-21 06:56:13,809 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33125
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f321c179380, tag: 0x82f153785691c4d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f321c179380, tag: 0x82f153785691c4d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-12-21 06:56:13,811 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:38309 -> ucx://127.0.0.1:33125
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f7031537100, tag: 0x586c263896e15c67, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-12-21 06:56:13,815 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33125
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-12-21 06:56:13,913 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:38755 -> ucx://127.0.0.1:49179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f321c179400, tag: 0x9a639e5fd68da378, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-939' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-974' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2023-12-21 06:56:13,941 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f7031537200, tag: 0xec5020861a55d6ef, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f7031537200, tag: 0xec5020861a55d6ef, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-12-21 06:56:13,973 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43401
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7fbb71ce7280, tag: 0x87215a85cbdc1034, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7fbb71ce7280, tag: 0x87215a85cbdc1034, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-12-21 06:56:13,988 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:38309 -> ucx://127.0.0.1:43401
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f7031537140, tag: 0x9deda7bcba887b5c, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-12-21 06:56:13,995 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:38755 -> ucx://127.0.0.1:55897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #006] ep: 0x7f321c179180, tag: 0xaef5ffb9c747aa55, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1783, in get_data
    response = await comm.read(deserializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #006] ep: 0x7f321c179180, tag: 0xaef5ffb9c747aa55, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-12-21 06:56:13,996 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43401
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f321c179240, tag: 0xa34dca6f82e8e450, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f321c179240, tag: 0xa34dca6f82e8e450, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-12-21 06:56:14,000 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43401
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f7031537180, tag: 0x299bc43a61ffe220, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f7031537180, tag: 0x299bc43a61ffe220, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-12-21 06:56:32,018 - distributed.nanny - WARNING - Worker process still alive after 3.1999995422363288 seconds, killing
2023-12-21 06:56:32,119 - distributed.nanny - WARNING - Worker process still alive after 3.1999995422363288 seconds, killing
2023-12-21 06:56:32,181 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing
2023-12-21 06:56:40,924 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:55897 after 30 s
2023-12-21 06:56:40,937 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:55897 after 30 s
2023-12-21 06:56:41,907 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 4)
Function:  shuffle_group
args:      (               key   payload
shuffle                     
4            32386  37161904
4            32394  95306370
4            32395  16256131
4            32402  91243323
4            32413  23128701
...            ...       ...
4        799995605  15146621
4        799995610  76117315
4        799995619  94500793
4        799995629  46829634
4        799995634  51259239

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-12-21 06:56:42,058 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2023-12-21 06:56:42,059 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2023-12-21 06:56:42,087 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 2)
Function:  shuffle_group
args:      (               key   payload
shuffle                     
2            32385  65668444
2            32398     64092
2            32401  87350680
2            32404  12969498
2            32409    399872
...            ...       ...
2        799995620  70630937
2        799995626  56776778
2        799995640  73373633
2        799995642  38545067
2        799995644    876310

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-12-21 06:56:42,160 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 1)
Function:  _concat
args:      ([                key   payload
43171     802582821  21027758
63624     835774867  63469281
43175     311463544  98996530
80610     202248449   8201183
43189     824486935  78084753
...             ...       ...
99994060    6490116  91158956
99994065  836090391  45184438
99993996  845950689  72550707
99994005  711300235  95617730
99994015  821105110  45103244

[12502120 rows x 2 columns],                 key   payload
145427    915970649  86718461
145430    515275523  10862812
145433    224743947  85138359
31942     927379439  62224902
31943     961949071   3238074
...             ...       ...
99998527  932078306  25012011
99998630  906866290  18101752
99998632  910033356  52272884
99998639  923253587  20430540
99998654  905652954  55099074

[12499414 rows x 2 columns],                  key   payload
23260     1004494998  10894117
73289     1022336168  19969669
29403     1000586605  53731444
23267      330033589  28824459
35558     1010730067   8499545
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-12-21 06:56:43,029 - distributed.worker - ERROR - ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 0, 3)}, 'who': 'ucx://127.0.0.1:38755', 'reply': True})
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2861, in get_data_from_worker
    status = response["status"]
KeyError: 'status'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2863, in get_data_from_worker
    raise ValueError("Unexpected response", response)
ValueError: ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 0, 3)}, 'who': 'ucx://127.0.0.1:38755', 'reply': True})
2023-12-21 06:56:43,033 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1069, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1784, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': {('split-simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 2, 4)}, 'who': 'ucx://127.0.0.1:38309', 'reply': True}
2023-12-21 06:56:43,037 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38755
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 364, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #105] ep: 0x7f7031537280, tag: 0xdc828f84218b6edd, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #105] ep: 0x7f7031537280, tag: 0xdc828f84218b6edd, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated")
2023-12-21 06:56:43,037 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:38755 -> ucx://127.0.0.1:38309
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 320, in write
    await self.ep.send(struct.pack("?Q", False, nframes))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7f321c1791c0 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-12-21 06:56:43,148 - distributed.worker - WARNING - Compute Failed
Key:       ('sort_index-86563d3c54ed11bf71e0c240596313fc', 0)
Function:  subgraph_callable-fd4870e7-d7cd-481d-8055-9c51f122
args:      ('set_index_post_scalar-ceb9308523ab39bbcf59f6dccd678d89',                 key  shuffle   payload  _partitions
0             31939        0  35748287            0
1             31943        0  91949071            0
2             31951        0  69043728            0
3             31954        0  47905428            0
4             31966        0   2608513            0
...             ...      ...       ...          ...
99999995  799964847        0  43201015            0
99999996  799964863        0  71184486            0
99999997  799964885        0  65514592            0
99999998  799964890        0  15758850            0
99999999  799964895        0  58761955            0

[100000000 rows x 4 columns], 'simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-12-21 06:56:43,258 - distributed.worker - WARNING - Compute Failed
Key:       ('sort_index-86563d3c54ed11bf71e0c240596313fc', 3)
Function:  subgraph_callable-fd4870e7-d7cd-481d-8055-9c51f122
args:      ('set_index_post_scalar-ceb9308523ab39bbcf59f6dccd678d89',                 key  shuffle   payload  _partitions
0             31942        3  57379439            3
1             31952        3   5707878            3
2             31960        3  33029669            3
3             31965        3  79805110            3
4            123590        3  97043370            3
...             ...      ...       ...          ...
99999995  799964842        3   3376371            3
99999996  799964859        3  98602621            3
99999997  799964869        3   2585193            3
99999998  799964887        3  96022168            3
99999999  799964891        3  95977452            3

[100000000 rows x 4 columns], 'simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-12-21 06:56:43,263 - distributed.worker - WARNING - Compute Failed
Key:       ('sort_index-86563d3c54ed11bf71e0c240596313fc', 4)
Function:  subgraph_callable-fd4870e7-d7cd-481d-8055-9c51f122
args:      ('set_index_post_scalar-ceb9308523ab39bbcf59f6dccd678d89',                 key  shuffle   payload  _partitions
0             31945        4  67461033            4
1             31946        4  24723696            4
2             31950        4  96448963            4
3            123585        4  16347698            4
4            123591        4  44594591            4
...             ...      ...       ...          ...
99999995  799964861        4  27716649            4
99999996  799964879        4  45939119            4
99999997  799964880        4  82491633            4
99999998  799964882        4  72504058            4
99999999  799964893        4  34670723            4

[100000000 rows x 4 columns], 'simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-12-21 06:56:43,458 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 7)
Function:  _concat
args:      ([               key  shuffle   payload  _partitions
0            31937        7  74910701            7
1            31944        7  58659154            7
2            31953        7  69281613            7
3            31957        7  56806874            7
4            31959        7  51718372            7
...            ...      ...       ...          ...
12499995  99999103        7  41752779            7
12499996  99998984        7  50610813            7
12499997  99999000        7  69540740            7
12499998  99999005        7  72201393            7
12499999  99999006        7  58942175            7

[12500000 rows x 4 columns],                 key  shuffle   payload  _partitions
0         100011883        7  44320104            7
1         100011884        7  50758105            7
2         100011903        7  10819814            7
3         100020068        7  70250732            7
4         100020075        7  41819008            7
...             ...      ...       ...      
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-12-21 06:56:43,462 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 6)
Function:  _concat
args:      ([               key  shuffle   payload  _partitions
0            31938        6   4423111            6
1            31949        6   5438113            6
2            31958        6   3434436            6
3            31961        6  85884183            6
4            31967        6  86523250            6
...            ...      ...       ...          ...
12499995  99998983        6  19505345            6
12499996  99998990        6   1476397            6
12499997  99998991        6    972745            6
12499998  99998996        6  62214388            6
12499999  99999004        6  33863714            6

[12500000 rows x 4 columns],                 key  shuffle   payload  _partitions
0         100011878        6  81119156            6
1         100011894        6  95408000            6
2         100011898        6  64835512            6
3         100020070        6  70456621            6
4         100020077        6  49666390            6
...             ...      ...       ...      
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 18 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
