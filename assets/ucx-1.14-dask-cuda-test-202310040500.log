============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.2, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-10-04 05:38:20,874 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:38:20,879 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40659 instead
  warnings.warn(
2023-10-04 05:38:20,882 - distributed.scheduler - INFO - State start
2023-10-04 05:38:20,904 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:38:20,905 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-04 05:38:20,906 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40659/status
2023-10-04 05:38:20,906 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-04 05:38:20,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44545'
2023-10-04 05:38:21,015 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42869'
2023-10-04 05:38:21,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41659'
2023-10-04 05:38:21,027 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46435'
2023-10-04 05:38:21,773 - distributed.scheduler - INFO - Receive client connection: Client-39321c4f-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:38:21,785 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51726
2023-10-04 05:38:22,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:22,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:22,671 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-10-04 05:38:22,683 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43023
2023-10-04 05:38:22,684 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43023
2023-10-04 05:38:22,684 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34837
2023-10-04 05:38:22,684 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-04 05:38:22,684 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:22,684 - distributed.worker - INFO -               Threads:                          4
2023-10-04 05:38:22,684 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-04 05:38:22,684 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-us05z57_
2023-10-04 05:38:22,684 - distributed.worker - INFO - Starting Worker plugin RMMSetup-becff8aa-abc9-42b4-8422-29624d52aa0b
2023-10-04 05:38:22,684 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4154a423-c392-44a1-9324-51277b34bc11
2023-10-04 05:38:22,685 - distributed.worker - INFO - Starting Worker plugin PreImport-07806393-fbfa-4e68-b865-05739d5fa61a
2023-10-04 05:38:22,685 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:22,735 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43023', status: init, memory: 0, processing: 0>
2023-10-04 05:38:22,736 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43023
2023-10-04 05:38:22,737 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51744
2023-10-04 05:38:22,737 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:22,738 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-04 05:38:22,738 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:22,739 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-04 05:38:22,777 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:22,778 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:22,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:22,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:22,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:22,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:22,782 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:22,783 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:22,785 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:24,015 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40317
2023-10-04 05:38:24,016 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40317
2023-10-04 05:38:24,016 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40133
2023-10-04 05:38:24,016 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40133
2023-10-04 05:38:24,016 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35979
2023-10-04 05:38:24,016 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-04 05:38:24,016 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37615
2023-10-04 05:38:24,016 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-04 05:38:24,016 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:24,016 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:24,016 - distributed.worker - INFO -               Threads:                          4
2023-10-04 05:38:24,016 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43649
2023-10-04 05:38:24,017 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-04 05:38:24,017 - distributed.worker - INFO -               Threads:                          4
2023-10-04 05:38:24,017 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43649
2023-10-04 05:38:24,017 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-nqauu7q4
2023-10-04 05:38:24,017 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-04 05:38:24,017 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-gu11fu6t
2023-10-04 05:38:24,017 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44677
2023-10-04 05:38:24,017 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-04 05:38:24,017 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:24,017 - distributed.worker - INFO -               Threads:                          4
2023-10-04 05:38:24,017 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e2a9e811-21dd-49fc-9157-75f2dc4fe91d
2023-10-04 05:38:24,017 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c802c28f-68ee-408f-9d14-5d9b6d851a10
2023-10-04 05:38:24,017 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-04 05:38:24,017 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-lj5zivm8
2023-10-04 05:38:24,017 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-12dca1b8-97e0-4ef4-b4c6-9c78cc10c17d
2023-10-04 05:38:24,017 - distributed.worker - INFO - Starting Worker plugin PreImport-33c0b235-9325-4fa2-bff0-2b3d46345c57
2023-10-04 05:38:24,018 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-48c36d70-da94-4a0f-b455-8e959d7e92fc
2023-10-04 05:38:24,018 - distributed.worker - INFO - Starting Worker plugin PreImport-2b553a41-ddd4-4c73-8086-b6cc08687c8e
2023-10-04 05:38:24,018 - distributed.worker - INFO - Starting Worker plugin RMMSetup-90ff20d3-eda8-41e1-b418-7ecc568f2d0c
2023-10-04 05:38:24,018 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:24,018 - distributed.worker - INFO - Starting Worker plugin PreImport-ffe90f7e-7cb1-4702-8aab-a883d8dae85a
2023-10-04 05:38:24,018 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6c52f67a-33c9-49d1-9975-98a47fccfdcd
2023-10-04 05:38:24,018 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:24,018 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:24,040 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40317', status: init, memory: 0, processing: 0>
2023-10-04 05:38:24,041 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40317
2023-10-04 05:38:24,041 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51768
2023-10-04 05:38:24,041 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:24,042 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-04 05:38:24,042 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:24,044 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-04 05:38:24,048 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43649', status: init, memory: 0, processing: 0>
2023-10-04 05:38:24,049 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43649
2023-10-04 05:38:24,049 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51780
2023-10-04 05:38:24,050 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40133', status: init, memory: 0, processing: 0>
2023-10-04 05:38:24,050 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:24,050 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40133
2023-10-04 05:38:24,050 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51776
2023-10-04 05:38:24,051 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-04 05:38:24,051 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:24,051 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:24,052 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-04 05:38:24,052 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:24,053 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-04 05:38:24,055 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-04 05:38:24,112 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-04 05:38:24,112 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-04 05:38:24,112 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-04 05:38:24,112 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-04 05:38:24,117 - distributed.scheduler - INFO - Remove client Client-39321c4f-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:38:24,117 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51726; closing.
2023-10-04 05:38:24,117 - distributed.scheduler - INFO - Remove client Client-39321c4f-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:38:24,117 - distributed.scheduler - INFO - Close client connection: Client-39321c4f-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:38:24,118 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44545'. Reason: nanny-close
2023-10-04 05:38:24,119 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:24,121 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42869'. Reason: nanny-close
2023-10-04 05:38:24,121 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:24,121 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40133. Reason: nanny-close
2023-10-04 05:38:24,121 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41659'. Reason: nanny-close
2023-10-04 05:38:24,121 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:24,121 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40317. Reason: nanny-close
2023-10-04 05:38:24,122 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46435'. Reason: nanny-close
2023-10-04 05:38:24,122 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:24,122 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43649. Reason: nanny-close
2023-10-04 05:38:24,123 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43023. Reason: nanny-close
2023-10-04 05:38:24,123 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-04 05:38:24,123 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51768; closing.
2023-10-04 05:38:24,123 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-04 05:38:24,123 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40317', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397904.123858')
2023-10-04 05:38:24,124 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51776; closing.
2023-10-04 05:38:24,124 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:24,124 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40133', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397904.124841')
2023-10-04 05:38:24,124 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-04 05:38:24,125 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-04 05:38:24,125 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:24,126 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:24,126 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:24,125 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:51776>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-04 05:38:24,127 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51780; closing.
2023-10-04 05:38:24,128 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51744; closing.
2023-10-04 05:38:24,128 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43649', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397904.128388')
2023-10-04 05:38:24,128 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43023', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397904.1287684')
2023-10-04 05:38:24,128 - distributed.scheduler - INFO - Lost all workers
2023-10-04 05:38:25,285 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-04 05:38:25,285 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-04 05:38:25,286 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:38:25,287 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-04 05:38:25,287 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-10-04 05:38:27,314 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:38:27,319 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37579 instead
  warnings.warn(
2023-10-04 05:38:27,323 - distributed.scheduler - INFO - State start
2023-10-04 05:38:27,345 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:38:27,346 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-10-04 05:38:27,347 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:38:27,348 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-10-04 05:38:27,552 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34267'
2023-10-04 05:38:27,567 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38347'
2023-10-04 05:38:27,583 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43589'
2023-10-04 05:38:27,585 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42427'
2023-10-04 05:38:27,595 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39143'
2023-10-04 05:38:27,603 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36767'
2023-10-04 05:38:27,612 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35195'
2023-10-04 05:38:27,624 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37225'
2023-10-04 05:38:29,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:29,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:29,242 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:29,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:29,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:29,329 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:29,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:29,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:29,543 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:29,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:29,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:29,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:29,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:29,558 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:29,558 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:29,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:29,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:29,574 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:29,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:29,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:29,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:29,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:29,579 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:29,581 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:31,212 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33701
2023-10-04 05:38:31,213 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33701
2023-10-04 05:38:31,213 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39583
2023-10-04 05:38:31,213 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:31,213 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:31,213 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:31,213 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:31,213 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_3exwqez
2023-10-04 05:38:31,214 - distributed.worker - INFO - Starting Worker plugin PreImport-0b821fcb-09bf-473e-a20b-0a5993883809
2023-10-04 05:38:31,214 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8519abda-32a8-48d4-84e0-2d4c01f3ffd5
2023-10-04 05:38:31,214 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f97fbe37-4163-4220-b2e2-c31fab19be05
2023-10-04 05:38:31,435 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,439 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45773
2023-10-04 05:38:32,440 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45773
2023-10-04 05:38:32,440 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44697
2023-10-04 05:38:32,440 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,440 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,440 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:32,440 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:32,440 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mutcw9eh
2023-10-04 05:38:32,440 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34283
2023-10-04 05:38:32,441 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34283
2023-10-04 05:38:32,441 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43861
2023-10-04 05:38:32,441 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a14b10d6-ef0a-4abf-9c97-15138f6fa7fb
2023-10-04 05:38:32,441 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,441 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,441 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:32,441 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:32,441 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dxn5x7b3
2023-10-04 05:38:32,442 - distributed.worker - INFO - Starting Worker plugin RMMSetup-13d7d43c-7221-417e-b1a1-ae377a92cf7a
2023-10-04 05:38:32,442 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39197
2023-10-04 05:38:32,444 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39197
2023-10-04 05:38:32,444 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44015
2023-10-04 05:38:32,444 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,444 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,444 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:32,444 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:32,444 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4r2rq8ja
2023-10-04 05:38:32,445 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4be7745c-bff0-4816-95a7-d224ecf5843d
2023-10-04 05:38:32,445 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33999
2023-10-04 05:38:32,446 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33999
2023-10-04 05:38:32,446 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46087
2023-10-04 05:38:32,446 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,446 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,446 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:32,446 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:32,446 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xwiyj6mb
2023-10-04 05:38:32,447 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b93e7290-6d08-4f28-85d7-ce4dec66fd6e
2023-10-04 05:38:32,447 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7b29da3e-eedd-4a5f-829f-b09a2f912641
2023-10-04 05:38:32,448 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40879
2023-10-04 05:38:32,449 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40879
2023-10-04 05:38:32,449 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40121
2023-10-04 05:38:32,449 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,448 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34367
2023-10-04 05:38:32,449 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,449 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34367
2023-10-04 05:38:32,449 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44111
2023-10-04 05:38:32,449 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:32,449 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,449 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,449 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:32,449 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-92bjz0os
2023-10-04 05:38:32,449 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:32,450 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:32,450 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t49v6wfe
2023-10-04 05:38:32,450 - distributed.worker - INFO - Starting Worker plugin PreImport-4fe1fd3c-a879-4799-bc55-070142d46333
2023-10-04 05:38:32,450 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8a95fdd6-21b4-44e2-85ab-a787db7e0385
2023-10-04 05:38:32,450 - distributed.worker - INFO - Starting Worker plugin RMMSetup-93a047c3-e353-407b-93f5-98b3ae54f77a
2023-10-04 05:38:32,450 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4e37e4b3-e1b6-4d9b-bbba-a2a1edd614b0
2023-10-04 05:38:32,453 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36081
2023-10-04 05:38:32,455 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36081
2023-10-04 05:38:32,455 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44261
2023-10-04 05:38:32,455 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,455 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,455 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:32,455 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:32,455 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ukfp_vgq
2023-10-04 05:38:32,457 - distributed.worker - INFO - Starting Worker plugin PreImport-ee7478c1-9a06-4b34-bb62-d433824fcae5
2023-10-04 05:38:32,457 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-248baa18-a750-4629-8a12-ef654b833f07
2023-10-04 05:38:32,457 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ad455131-a480-43b3-bb79-4397d4053e1e
2023-10-04 05:38:32,599 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,599 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e282f0b1-2937-4b16-b464-e1bdcd529432
2023-10-04 05:38:32,599 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b7d7d99c-c2a0-4a33-a535-286f1274a439
2023-10-04 05:38:32,599 - distributed.worker - INFO - Starting Worker plugin PreImport-c9a4d859-ebbc-4017-8be6-b86a5a357a71
2023-10-04 05:38:32,599 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,599 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5b56d9cb-6c62-4a67-bcd4-35bc4e912a12
2023-10-04 05:38:32,599 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-52b58783-414c-47e9-be39-5f9b0a309cbe
2023-10-04 05:38:32,599 - distributed.worker - INFO - Starting Worker plugin PreImport-c5d87788-a875-4187-bf70-167c0dd4ee99
2023-10-04 05:38:32,600 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,600 - distributed.worker - INFO - Starting Worker plugin PreImport-2e2e1f2f-8524-48f6-a5f2-7fceee203f3a
2023-10-04 05:38:32,600 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,600 - distributed.worker - INFO - Starting Worker plugin PreImport-c8d938f9-4f6c-4184-8a00-b1948366560a
2023-10-04 05:38:32,600 - distributed.worker - INFO - Starting Worker plugin PreImport-b60b5cca-03b1-428b-a63d-e0f1824b7124
2023-10-04 05:38:32,600 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,600 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,600 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,639 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:32,640 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,640 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,641 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:32,642 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:32,642 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:32,643 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,643 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,643 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,643 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,643 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:32,644 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,644 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,645 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:32,645 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:32,645 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:32,646 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:32,646 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,646 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,646 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:32,647 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:32,647 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:32,647 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,648 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,649 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,649 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,649 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:32,651 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:32,664 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38347'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,665 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,666 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43589'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,666 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,666 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36081. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,667 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42427'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,667 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,667 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39197. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,668 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39143'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,668 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33999. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,668 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,669 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36767'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,669 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:32,669 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,669 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34367. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,669 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35195'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,670 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:32,670 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,670 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45773. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,670 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:32,670 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34283. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,670 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37225'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,671 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,671 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:32,672 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:32,672 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40879. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,672 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:32,672 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:32,673 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:32,673 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:32,674 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:32,674 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:32,675 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:32,675 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:32,676 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:32,710 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:32,711 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:32,711 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:32,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:32,721 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34267'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,722 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,723 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33701. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:38:32,725 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:32,727 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 376, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:36046 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-10-04 05:38:33,437 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63486 parent=63300 started daemon>
2023-10-04 05:38:33,437 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63483 parent=63300 started daemon>
2023-10-04 05:38:33,437 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63481 parent=63300 started daemon>
2023-10-04 05:38:33,437 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63477 parent=63300 started daemon>
2023-10-04 05:38:33,438 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63472 parent=63300 started daemon>
2023-10-04 05:38:33,438 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63468 parent=63300 started daemon>
2023-10-04 05:38:33,438 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63465 parent=63300 started daemon>
2023-10-04 05:38:33,666 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 63483 exit status was already read will report exitcode 255
2023-10-04 05:38:33,690 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 63486 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-10-04 05:38:43,808 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:38:43,812 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33255 instead
  warnings.warn(
2023-10-04 05:38:43,816 - distributed.scheduler - INFO - State start
2023-10-04 05:38:43,839 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:38:43,840 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-04 05:38:43,841 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33255/status
2023-10-04 05:38:43,841 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-04 05:38:44,010 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41137'
2023-10-04 05:38:44,030 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33871'
2023-10-04 05:38:44,032 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38279'
2023-10-04 05:38:44,040 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39443'
2023-10-04 05:38:44,048 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38007'
2023-10-04 05:38:44,057 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42241'
2023-10-04 05:38:44,065 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42755'
2023-10-04 05:38:44,074 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39965'
2023-10-04 05:38:44,225 - distributed.scheduler - INFO - Receive client connection: Client-46eab9be-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:38:44,238 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34886
2023-10-04 05:38:45,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:45,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:45,895 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:45,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:45,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:45,905 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:45,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:45,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:45,956 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:45,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:45,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:45,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:45,973 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:45,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:45,977 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:45,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:45,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:45,993 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:46,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:46,002 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:46,006 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:46,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:46,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:46,016 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:50,256 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38147
2023-10-04 05:38:50,256 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38045
2023-10-04 05:38:50,257 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38147
2023-10-04 05:38:50,257 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38045
2023-10-04 05:38:50,257 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34271
2023-10-04 05:38:50,257 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43189
2023-10-04 05:38:50,257 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,257 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,257 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,258 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,258 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:50,258 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:50,258 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:50,258 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:50,258 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0zsa0uzu
2023-10-04 05:38:50,258 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aemsx6qu
2023-10-04 05:38:50,258 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a2d2c14a-07ee-4882-8702-d068e7d200f4
2023-10-04 05:38:50,258 - distributed.worker - INFO - Starting Worker plugin PreImport-620c61f9-cd57-41ba-8439-3e88225f296c
2023-10-04 05:38:50,258 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cc491a46-1d5d-4ef3-9cd8-a34a20373c4b
2023-10-04 05:38:50,259 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1a1afbf0-9416-4230-8534-5d69b582dc54
2023-10-04 05:38:50,260 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39101
2023-10-04 05:38:50,261 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39101
2023-10-04 05:38:50,261 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45729
2023-10-04 05:38:50,261 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,261 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,261 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:50,262 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:50,262 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ioooifzr
2023-10-04 05:38:50,262 - distributed.worker - INFO - Starting Worker plugin PreImport-fc82d997-5bd7-458b-8407-7dd72c6cb011
2023-10-04 05:38:50,262 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d3896470-7969-49a0-bde2-fcfda26b6fc6
2023-10-04 05:38:50,263 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d8464945-dd37-4684-a611-506db16b4b0e
2023-10-04 05:38:50,269 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,269 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b4f3c5ce-0afe-46d2-acf5-c71f77ac40ba
2023-10-04 05:38:50,271 - distributed.worker - INFO - Starting Worker plugin PreImport-8c070615-4384-4233-a692-4813e66a3c8a
2023-10-04 05:38:50,272 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,277 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,289 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38045', status: init, memory: 0, processing: 0>
2023-10-04 05:38:50,290 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38045
2023-10-04 05:38:50,290 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40956
2023-10-04 05:38:50,291 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:50,292 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,292 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,293 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:50,309 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38147', status: init, memory: 0, processing: 0>
2023-10-04 05:38:50,309 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38147
2023-10-04 05:38:50,309 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40962
2023-10-04 05:38:50,311 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39101', status: init, memory: 0, processing: 0>
2023-10-04 05:38:50,311 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:50,311 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39101
2023-10-04 05:38:50,311 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40974
2023-10-04 05:38:50,312 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,312 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,313 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:50,314 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,314 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,314 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:50,316 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:50,431 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32907
2023-10-04 05:38:50,432 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32907
2023-10-04 05:38:50,432 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33459
2023-10-04 05:38:50,432 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,433 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,433 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:50,433 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:50,433 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qixus6zw
2023-10-04 05:38:50,434 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b7989a4a-effb-40e7-ab54-932067bc1544
2023-10-04 05:38:50,435 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42461
2023-10-04 05:38:50,436 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42461
2023-10-04 05:38:50,436 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46105
2023-10-04 05:38:50,436 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,436 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,436 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:50,436 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:50,436 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g6wf2xdv
2023-10-04 05:38:50,437 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f9eee19f-c0e1-43c7-8b38-459e269ae34b
2023-10-04 05:38:50,437 - distributed.worker - INFO - Starting Worker plugin PreImport-1da9ea11-1e4e-4aac-8d70-3d32d1f1e799
2023-10-04 05:38:50,437 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ec6d07ec-87ad-42fa-82a7-8e4d800af590
2023-10-04 05:38:50,441 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33337
2023-10-04 05:38:50,442 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33337
2023-10-04 05:38:50,442 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44061
2023-10-04 05:38:50,442 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,442 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,442 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:50,443 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:50,443 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-x2f1758q
2023-10-04 05:38:50,443 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cdafc38e-2e31-4626-9129-aa7f0b3a31e4
2023-10-04 05:38:50,443 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36559
2023-10-04 05:38:50,444 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36559
2023-10-04 05:38:50,444 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38163
2023-10-04 05:38:50,444 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,444 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,444 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:50,445 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:50,445 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t0prvhul
2023-10-04 05:38:50,444 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36159
2023-10-04 05:38:50,445 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36159
2023-10-04 05:38:50,445 - distributed.worker - INFO - Starting Worker plugin RMMSetup-28575ee8-55a6-49a8-bf69-50dcc6c445f3
2023-10-04 05:38:50,445 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35301
2023-10-04 05:38:50,446 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,446 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,446 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:38:50,446 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:38:50,446 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rf2okfzg
2023-10-04 05:38:50,446 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5516354c-2ce7-4ceb-a887-ff2f42e88d01
2023-10-04 05:38:50,446 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a7054035-780b-400f-aead-c562fc87e2e1
2023-10-04 05:38:50,461 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-10755155-e23b-461a-ad23-8aae61993f77
2023-10-04 05:38:50,462 - distributed.worker - INFO - Starting Worker plugin PreImport-ab8c221c-3260-4422-969a-2877e9452faf
2023-10-04 05:38:50,462 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,462 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,463 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7df8aa9d-4f1c-40e9-8055-7d0ee6c50214
2023-10-04 05:38:50,463 - distributed.worker - INFO - Starting Worker plugin PreImport-5cde4948-aa6c-4755-a693-a0cc5d784911
2023-10-04 05:38:50,463 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,465 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a1455afe-3c40-4abd-9944-7fbe71108cc9
2023-10-04 05:38:50,465 - distributed.worker - INFO - Starting Worker plugin PreImport-cf475999-ae78-4e1c-9361-512d6c30b879
2023-10-04 05:38:50,465 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,467 - distributed.worker - INFO - Starting Worker plugin PreImport-0a11fdfc-799a-40c3-920b-e18b2b0d84e3
2023-10-04 05:38:50,468 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,486 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32907', status: init, memory: 0, processing: 0>
2023-10-04 05:38:50,487 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32907
2023-10-04 05:38:50,487 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40982
2023-10-04 05:38:50,488 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33337', status: init, memory: 0, processing: 0>
2023-10-04 05:38:50,488 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:50,488 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33337
2023-10-04 05:38:50,488 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41004
2023-10-04 05:38:50,489 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,489 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,489 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36159', status: init, memory: 0, processing: 0>
2023-10-04 05:38:50,489 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:50,489 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36159
2023-10-04 05:38:50,489 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41012
2023-10-04 05:38:50,490 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,490 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,490 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42461', status: init, memory: 0, processing: 0>
2023-10-04 05:38:50,490 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:50,490 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:50,491 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42461
2023-10-04 05:38:50,491 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40996
2023-10-04 05:38:50,491 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,491 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,492 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:50,492 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:50,493 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:50,493 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,493 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,495 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:50,497 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36559', status: init, memory: 0, processing: 0>
2023-10-04 05:38:50,498 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36559
2023-10-04 05:38:50,498 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41014
2023-10-04 05:38:50,499 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:38:50,500 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:38:50,500 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:38:50,502 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:38:50,579 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:38:50,579 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:38:50,579 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:38:50,580 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:38:50,580 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:38:50,580 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:38:50,580 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:38:50,580 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:38:50,584 - distributed.scheduler - INFO - Remove client Client-46eab9be-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:38:50,584 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34886; closing.
2023-10-04 05:38:50,585 - distributed.scheduler - INFO - Remove client Client-46eab9be-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:38:50,585 - distributed.scheduler - INFO - Close client connection: Client-46eab9be-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:38:50,586 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41137'. Reason: nanny-close
2023-10-04 05:38:50,587 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:50,588 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38279'. Reason: nanny-close
2023-10-04 05:38:50,588 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:50,588 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42461. Reason: nanny-close
2023-10-04 05:38:50,589 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39443'. Reason: nanny-close
2023-10-04 05:38:50,589 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:50,589 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39101. Reason: nanny-close
2023-10-04 05:38:50,589 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38007'. Reason: nanny-close
2023-10-04 05:38:50,590 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:50,590 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33337. Reason: nanny-close
2023-10-04 05:38:50,590 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42241'. Reason: nanny-close
2023-10-04 05:38:50,590 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:50,590 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36159. Reason: nanny-close
2023-10-04 05:38:50,591 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40996; closing.
2023-10-04 05:38:50,591 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:50,591 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42755'. Reason: nanny-close
2023-10-04 05:38:50,591 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:50,591 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42461', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397930.5913699')
2023-10-04 05:38:50,591 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38147. Reason: nanny-close
2023-10-04 05:38:50,591 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39965'. Reason: nanny-close
2023-10-04 05:38:50,591 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:50,591 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:50,592 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:50,592 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36559. Reason: nanny-close
2023-10-04 05:38:50,592 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33871'. Reason: nanny-close
2023-10-04 05:38:50,592 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:38:50,592 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41004; closing.
2023-10-04 05:38:50,592 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32907. Reason: nanny-close
2023-10-04 05:38:50,592 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:50,593 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:50,593 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38045. Reason: nanny-close
2023-10-04 05:38:50,593 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:50,593 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33337', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397930.5935512')
2023-10-04 05:38:50,593 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:50,594 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40974; closing.
2023-10-04 05:38:50,594 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:50,594 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:50,595 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:50,595 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:50,595 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:38:50,594 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:41004>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:41004>: Stream is closed
2023-10-04 05:38:50,596 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41012; closing.
2023-10-04 05:38:50,596 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:50,596 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39101', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397930.59667')
2023-10-04 05:38:50,596 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:50,597 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:50,597 - distributed.nanny - INFO - Worker closed
2023-10-04 05:38:50,597 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36159', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397930.597537')
2023-10-04 05:38:50,598 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40962; closing.
2023-10-04 05:38:50,598 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38147', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397930.5987408')
2023-10-04 05:38:50,599 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41014; closing.
2023-10-04 05:38:50,599 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40982; closing.
2023-10-04 05:38:50,599 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40956; closing.
2023-10-04 05:38:50,600 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36559', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397930.6001062')
2023-10-04 05:38:50,600 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32907', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397930.600541')
2023-10-04 05:38:50,600 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38045', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696397930.6009095')
2023-10-04 05:38:50,601 - distributed.scheduler - INFO - Lost all workers
2023-10-04 05:38:50,601 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:40982>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-04 05:38:50,601 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:41014>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-04 05:38:50,601 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:40956>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-04 05:38:52,030 - distributed.scheduler - INFO - Receive client connection: Client-4cdd38eb-6278-11ee-b643-d8c49764f6bb
2023-10-04 05:38:52,030 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41026
2023-10-04 05:38:52,154 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-04 05:38:52,154 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-04 05:38:52,154 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:38:52,156 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-04 05:38:52,156 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-10-04 05:38:54,449 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:38:54,453 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40941 instead
  warnings.warn(
2023-10-04 05:38:54,457 - distributed.scheduler - INFO - State start
2023-10-04 05:38:54,478 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:38:54,479 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-10-04 05:38:54,480 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:38:54,481 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-10-04 05:38:54,720 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37777'
2023-10-04 05:38:54,744 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45755'
2023-10-04 05:38:54,746 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36953'
2023-10-04 05:38:54,754 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36243'
2023-10-04 05:38:54,762 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40433'
2023-10-04 05:38:54,771 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46233'
2023-10-04 05:38:54,780 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34927'
2023-10-04 05:38:54,792 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33131'
2023-10-04 05:38:56,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:56,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:56,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:56,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:56,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:56,687 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:56,687 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:56,688 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:56,691 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:56,691 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:56,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:56,697 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:56,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:56,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:56,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:56,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:56,878 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:56,880 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:57,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:57,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:57,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:38:57,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:38:57,091 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:38:57,092 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:03,520 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40433'. Reason: nanny-close
2023-10-04 05:39:03,520 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46233'. Reason: nanny-close
2023-10-04 05:39:03,521 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34927'. Reason: nanny-close
2023-10-04 05:39:03,521 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33131'. Reason: nanny-close
2023-10-04 05:39:03,521 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37777'. Reason: nanny-close
2023-10-04 05:39:03,521 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45755'. Reason: nanny-close
2023-10-04 05:39:03,521 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36953'. Reason: nanny-close
2023-10-04 05:39:03,522 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36243'. Reason: nanny-close
2023-10-04 05:39:04,618 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38943
2023-10-04 05:39:04,620 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38943
2023-10-04 05:39:04,620 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38149
2023-10-04 05:39:04,620 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:04,620 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:04,620 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:04,620 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:04,620 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n1leffp9
2023-10-04 05:39:04,621 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1bfa4bb3-3f14-4d01-9e70-1b262ad1d976
2023-10-04 05:39:04,626 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41299
2023-10-04 05:39:04,627 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41299
2023-10-04 05:39:04,627 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38379
2023-10-04 05:39:04,627 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:04,627 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:04,627 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:04,628 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:04,628 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rbwwuzcr
2023-10-04 05:39:04,628 - distributed.worker - INFO - Starting Worker plugin PreImport-8f5771fe-3b3e-4281-9b17-36495179cf52
2023-10-04 05:39:04,628 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-706d2547-1f91-479e-a6f7-c1834b53626e
2023-10-04 05:39:04,629 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3429428e-2aab-4f48-bbb1-619aedff8e9a
2023-10-04 05:39:04,646 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32807
2023-10-04 05:39:04,647 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32807
2023-10-04 05:39:04,647 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37549
2023-10-04 05:39:04,647 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:04,647 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:04,647 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:04,647 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:04,647 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zqnt_hqp
2023-10-04 05:39:04,648 - distributed.worker - INFO - Starting Worker plugin RMMSetup-51c89541-4457-489f-955c-a1ef7adfdaf5
2023-10-04 05:39:04,653 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42077
2023-10-04 05:39:04,654 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42077
2023-10-04 05:39:04,654 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44537
2023-10-04 05:39:04,654 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:04,654 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:04,654 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:04,655 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:04,655 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mx63hkna
2023-10-04 05:39:04,655 - distributed.worker - INFO - Starting Worker plugin RMMSetup-625e8c83-5467-4c34-8276-378afd0ef213
2023-10-04 05:39:04,671 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45099
2023-10-04 05:39:04,671 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45099
2023-10-04 05:39:04,671 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44721
2023-10-04 05:39:04,671 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:04,672 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:04,672 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:04,672 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:04,672 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qng1unky
2023-10-04 05:39:04,672 - distributed.worker - INFO - Starting Worker plugin RMMSetup-67c33ee5-dc1b-4ced-82d9-1aa4ffd74aef
2023-10-04 05:39:04,671 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35801
2023-10-04 05:39:04,673 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35801
2023-10-04 05:39:04,673 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45953
2023-10-04 05:39:04,673 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:04,673 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:04,673 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:04,674 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:04,674 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n8shzl1b
2023-10-04 05:39:04,675 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d1a43bab-7a8c-4767-92ca-05ebfd3cbc7f
2023-10-04 05:39:04,675 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d3cbd7c8-acf6-4bc0-a3f0-b4f3fc2222a4
2023-10-04 05:39:04,699 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34561
2023-10-04 05:39:04,700 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34561
2023-10-04 05:39:04,700 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46091
2023-10-04 05:39:04,700 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:04,700 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:04,700 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:04,700 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:04,700 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5oo1o3xs
2023-10-04 05:39:04,701 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8a585ed8-1964-462b-974e-db7d6e43238e
2023-10-04 05:39:04,705 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35573
2023-10-04 05:39:04,706 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35573
2023-10-04 05:39:04,706 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43251
2023-10-04 05:39:04,706 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:04,706 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:04,706 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:04,706 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:04,706 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-iwgpev0i
2023-10-04 05:39:04,707 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7c573ce4-5c2a-4caa-a718-0c2004e85a98
2023-10-04 05:39:05,320 - distributed.worker - INFO - Starting Worker plugin PreImport-645b7c26-30d4-4226-affe-fd4d71dd78e6
2023-10-04 05:39:05,321 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,327 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ffc07fe1-9fca-4cb1-abef-14eff9d029c4
2023-10-04 05:39:05,327 - distributed.worker - INFO - Starting Worker plugin PreImport-23bb2973-9bca-4d8f-95c4-4ed4183c5828
2023-10-04 05:39:05,328 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,329 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5f771550-6a55-4c00-a676-98eddb892672
2023-10-04 05:39:05,329 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-636dcbfe-456a-4919-93fc-8729bf6247eb
2023-10-04 05:39:05,329 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e76e018e-4364-47a1-a2e4-b88eb23026cb
2023-10-04 05:39:05,329 - distributed.worker - INFO - Starting Worker plugin PreImport-59ac8b4d-8d2e-44f3-9b70-5c9c858c08d3
2023-10-04 05:39:05,330 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,330 - distributed.worker - INFO - Starting Worker plugin PreImport-c7435b85-d495-445d-80b5-b848470efae9
2023-10-04 05:39:05,330 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9f75358f-93d8-4793-8e25-0dc82c8d09ba
2023-10-04 05:39:05,330 - distributed.worker - INFO - Starting Worker plugin PreImport-26fd6aa3-2cdd-49c1-8174-c4b08f6a142a
2023-10-04 05:39:05,330 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b83d1bae-57d6-437c-9ce8-c4bb81e6794c
2023-10-04 05:39:05,330 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,330 - distributed.worker - INFO - Starting Worker plugin PreImport-b91b7928-8e4e-4c36-bcb0-e03ee6c699da
2023-10-04 05:39:05,331 - distributed.worker - INFO - Starting Worker plugin PreImport-c4584f0d-0fd1-43cb-8115-685ff99d68bc
2023-10-04 05:39:05,331 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,331 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,331 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,332 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,356 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:05,357 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:05,358 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,358 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:05,359 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:05,359 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:05,359 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:05,359 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,360 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:05,360 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,360 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:05,361 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:05,361 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:05,361 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,361 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:05,361 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:39:05,362 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:05,363 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:05,363 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35801. Reason: nanny-close
2023-10-04 05:39:05,364 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:05,364 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,365 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:05,366 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:05,367 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:05,368 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:39:05,369 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32807. Reason: nanny-close
2023-10-04 05:39:05,369 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:05,371 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:05,371 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:05,371 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,372 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:05,373 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:05,375 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:05,377 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:05,377 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,377 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:05,379 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:05,379 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:05,379 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:05,381 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:05,414 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:39:05,414 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:39:05,415 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:39:05,415 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41299. Reason: nanny-close
2023-10-04 05:39:05,415 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:39:05,415 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35573. Reason: nanny-close
2023-10-04 05:39:05,415 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34561. Reason: nanny-close
2023-10-04 05:39:05,416 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:39:05,416 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42077. Reason: nanny-close
2023-10-04 05:39:05,416 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:39:05,416 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45099. Reason: nanny-close
2023-10-04 05:39:05,417 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38943. Reason: nanny-close
2023-10-04 05:39:05,417 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:05,417 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:05,418 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:05,418 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:05,419 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:05,419 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:05,419 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:05,419 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:05,419 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:05,421 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:05,421 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:05,421 - distributed.nanny - INFO - Worker closed
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-10-04 05:39:09,346 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:39:09,351 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32955 instead
  warnings.warn(
2023-10-04 05:39:09,355 - distributed.scheduler - INFO - State start
2023-10-04 05:39:09,558 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:39:09,559 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-10-04 05:39:09,560 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:39:09,561 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-10-04 05:39:09,851 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38407'
2023-10-04 05:39:09,866 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39831'
2023-10-04 05:39:09,873 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43313'
2023-10-04 05:39:09,888 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41333'
2023-10-04 05:39:09,890 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34281'
2023-10-04 05:39:09,898 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45473'
2023-10-04 05:39:09,906 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34087'
2023-10-04 05:39:09,914 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44795'
2023-10-04 05:39:11,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:11,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:11,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:11,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:11,758 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:11,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:11,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:11,761 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:11,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:11,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:11,763 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:11,766 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:11,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:11,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:11,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:11,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:11,783 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:11,787 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:11,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:11,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:11,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:11,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:11,798 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:11,801 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:15,084 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42155
2023-10-04 05:39:15,085 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42155
2023-10-04 05:39:15,085 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40145
2023-10-04 05:39:15,085 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:15,085 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,085 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:15,085 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:15,085 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gfgwwboz
2023-10-04 05:39:15,086 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0fb688b1-688d-4e8d-aee2-67b79b0736b7
2023-10-04 05:39:15,091 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43027
2023-10-04 05:39:15,092 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43027
2023-10-04 05:39:15,092 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43093
2023-10-04 05:39:15,092 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:15,092 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,092 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:15,093 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:15,093 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8xszkn3u
2023-10-04 05:39:15,093 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-14cf79ef-8b7b-4cb1-87b3-f747e25d9e37
2023-10-04 05:39:15,093 - distributed.worker - INFO - Starting Worker plugin RMMSetup-804dcc02-f681-4b7b-bf07-e59329476930
2023-10-04 05:39:15,100 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34243
2023-10-04 05:39:15,101 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34243
2023-10-04 05:39:15,101 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42039
2023-10-04 05:39:15,101 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:15,101 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,101 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:15,101 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:15,101 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6y7mfrg0
2023-10-04 05:39:15,102 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6a432c1d-6aed-4686-aa18-042f2b654e81
2023-10-04 05:39:15,150 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41759
2023-10-04 05:39:15,151 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41759
2023-10-04 05:39:15,151 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43171
2023-10-04 05:39:15,151 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:15,151 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,151 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:15,151 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:15,151 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tdvibk21
2023-10-04 05:39:15,152 - distributed.worker - INFO - Starting Worker plugin PreImport-2533d8d7-783f-4114-ba97-743154782e5a
2023-10-04 05:39:15,152 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2d5e8e2c-2257-4604-917d-96c9d056f51c
2023-10-04 05:39:15,152 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f43cb1d9-af53-4766-8090-af3c41b87734
2023-10-04 05:39:15,159 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39681
2023-10-04 05:39:15,159 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39681
2023-10-04 05:39:15,160 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35357
2023-10-04 05:39:15,160 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:15,160 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,160 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:15,160 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:15,160 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-re0jbrwa
2023-10-04 05:39:15,160 - distributed.worker - INFO - Starting Worker plugin RMMSetup-14253929-76ba-4518-a1e2-8c2d5a29b9fd
2023-10-04 05:39:15,162 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34601
2023-10-04 05:39:15,163 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34601
2023-10-04 05:39:15,163 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34941
2023-10-04 05:39:15,163 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:15,163 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,163 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:15,163 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:15,163 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l0g3yii5
2023-10-04 05:39:15,164 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d2b27e86-eee0-45a7-9fd2-84e7f40bf0d7
2023-10-04 05:39:15,165 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45477
2023-10-04 05:39:15,165 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45477
2023-10-04 05:39:15,165 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44931
2023-10-04 05:39:15,166 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37775
2023-10-04 05:39:15,166 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44931
2023-10-04 05:39:15,166 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:15,166 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,166 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39407
2023-10-04 05:39:15,166 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:39:15,166 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,166 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:15,166 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:15,166 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zrnso70i
2023-10-04 05:39:15,166 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:39:15,166 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:39:15,166 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lo2kdpfz
2023-10-04 05:39:15,166 - distributed.worker - INFO - Starting Worker plugin RMMSetup-721287fc-4563-4931-9fa5-67e11e5d94f7
2023-10-04 05:39:15,167 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1c5fc7d3-d90b-417f-acac-1cddf58c5c85
2023-10-04 05:39:15,293 - distributed.worker - INFO - Starting Worker plugin PreImport-2603ba77-40ef-4ef2-b077-8d4b7a78408e
2023-10-04 05:39:15,294 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,310 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6bdc9e6e-691b-4643-a2d7-24cb516683a7
2023-10-04 05:39:15,311 - distributed.worker - INFO - Starting Worker plugin PreImport-5310a2c1-c66c-422f-be56-965b648531a1
2023-10-04 05:39:15,311 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,314 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-66d10450-801d-48fe-83d4-e1e81414c4a1
2023-10-04 05:39:15,316 - distributed.worker - INFO - Starting Worker plugin PreImport-fa49155e-f78d-4e14-87ea-185565453743
2023-10-04 05:39:15,316 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,383 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2cef8641-66cf-4b16-a4a0-e18d70be5cbb
2023-10-04 05:39:15,384 - distributed.worker - INFO - Starting Worker plugin PreImport-c86548e5-3549-4955-afdb-1a14e2cbffec
2023-10-04 05:39:15,384 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,402 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6eca1cb9-dffa-46b0-ae81-437d495b265a
2023-10-04 05:39:15,402 - distributed.worker - INFO - Starting Worker plugin PreImport-fd2a94e4-cae5-47a8-ad89-f29e632e6bc5
2023-10-04 05:39:15,403 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,411 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1b4acf7d-58f9-4553-9b55-c911fede2287
2023-10-04 05:39:15,412 - distributed.worker - INFO - Starting Worker plugin PreImport-a1da3852-415b-4b91-b57f-f590a167cf1b
2023-10-04 05:39:15,412 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,413 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:15,414 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6e72360c-40ab-4fe6-a3c3-3951acc916e3
2023-10-04 05:39:15,415 - distributed.worker - INFO - Starting Worker plugin PreImport-4e109ee6-4681-48bb-afd1-0e6f7cfd2abc
2023-10-04 05:39:15,415 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:16,847 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:16,848 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:16,848 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:16,850 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:16,853 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:16,854 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:16,854 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:16,856 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:16,863 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38407'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:16,864 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:16,865 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45477. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:16,867 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:16,869 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:16,897 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34087'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:16,897 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:16,898 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44931. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:16,900 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:16,902 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:16,976 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:16,976 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:16,977 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:16,978 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:16,998 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41333'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:16,998 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:16,999 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42155. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,001 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:17,002 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:17,040 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:17,041 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:17,041 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:17,043 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:17,048 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39831'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,048 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,049 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34243. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,051 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:17,053 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:17,085 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:17,086 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:17,086 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:17,087 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:17,100 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43313'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,100 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,101 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43027. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,102 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:17,104 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:17,433 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:17,434 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:17,434 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:17,436 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:17,454 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34281'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,455 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,456 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41759. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,458 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:17,460 - distributed.nanny - INFO - Worker closed
2023-10-04 05:39:17,469 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:39:17,470 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:39:17,470 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:39:17,472 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:39:17,506 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45473'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,506 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,507 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34601. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-10-04 05:39:17,511 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:39:17,513 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 376, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:59722 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-10-04 05:39:17,632 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64381 parent=64192 started daemon>
2023-10-04 05:39:17,632 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64375 parent=64192 started daemon>
2023-10-04 05:39:17,632 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64372 parent=64192 started daemon>
2023-10-04 05:39:17,632 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64368 parent=64192 started daemon>
2023-10-04 05:39:17,632 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64364 parent=64192 started daemon>
2023-10-04 05:39:17,632 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64360 parent=64192 started daemon>
2023-10-04 05:39:17,633 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64357 parent=64192 started daemon>
2023-10-04 05:39:18,101 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64381 exit status was already read will report exitcode 255
2023-10-04 05:39:18,167 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64375 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-10-04 05:39:53,980 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:39:53,986 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37409 instead
  warnings.warn(
2023-10-04 05:39:53,992 - distributed.scheduler - INFO - State start
2023-10-04 05:39:53,994 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-re0jbrwa', purging
2023-10-04 05:39:54,016 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:39:54,018 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-04 05:39:54,018 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37409/status
2023-10-04 05:39:54,019 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-04 05:39:54,125 - distributed.scheduler - INFO - Receive client connection: Client-70af3944-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:39:54,140 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41196
2023-10-04 05:39:54,201 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38117'
2023-10-04 05:39:54,219 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34743'
2023-10-04 05:39:54,233 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36767'
2023-10-04 05:39:54,243 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36829'
2023-10-04 05:39:54,245 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38973'
2023-10-04 05:39:54,254 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40835'
2023-10-04 05:39:54,262 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39571'
2023-10-04 05:39:54,271 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40009'
2023-10-04 05:39:56,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:56,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:56,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:56,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:56,275 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:56,278 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:56,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:56,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:56,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:56,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:56,283 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:56,285 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:56,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:56,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:56,290 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:56,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:56,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:56,295 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:56,295 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:56,298 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:56,299 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:39:56,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:39:56,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:39:56,505 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:00,842 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33813
2023-10-04 05:40:00,842 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33813
2023-10-04 05:40:00,843 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40771
2023-10-04 05:40:00,843 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:00,843 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:00,843 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:00,843 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:00,843 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rv0jtqpn
2023-10-04 05:40:00,843 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1f846484-dd49-4842-ba48-580a30256d86
2023-10-04 05:40:00,844 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c13a1d45-04cb-415c-9a5e-1c3bd057526b
2023-10-04 05:40:00,852 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37013
2023-10-04 05:40:00,852 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37013
2023-10-04 05:40:00,853 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43473
2023-10-04 05:40:00,853 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:00,853 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:00,853 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:00,853 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:00,853 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ivs3tho5
2023-10-04 05:40:00,853 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b290d427-3e56-480c-b7a2-3d474ed204f7
2023-10-04 05:40:00,857 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36265
2023-10-04 05:40:00,858 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36265
2023-10-04 05:40:00,858 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40055
2023-10-04 05:40:00,858 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:00,858 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:00,858 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:00,858 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:00,858 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-m9n31beh
2023-10-04 05:40:00,859 - distributed.worker - INFO - Starting Worker plugin RMMSetup-beaf786f-9fcf-48de-a0b6-73ae4c11c41b
2023-10-04 05:40:00,889 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46839
2023-10-04 05:40:00,890 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46839
2023-10-04 05:40:00,890 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44637
2023-10-04 05:40:00,890 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:00,890 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:00,890 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:00,890 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:00,890 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7rcxwpd_
2023-10-04 05:40:00,891 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8bd31f62-702e-46fd-8a66-d53aa8746516
2023-10-04 05:40:00,899 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44833
2023-10-04 05:40:00,900 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44833
2023-10-04 05:40:00,900 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44283
2023-10-04 05:40:00,900 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:00,900 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:00,900 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:00,900 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:00,900 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-flh0oaru
2023-10-04 05:40:00,900 - distributed.worker - INFO - Starting Worker plugin PreImport-c7d81d2b-8e98-4866-84d3-d9fb36dfc4cf
2023-10-04 05:40:00,901 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-882d498d-e56c-4d93-bf8f-9d36e7e213dd
2023-10-04 05:40:00,901 - distributed.worker - INFO - Starting Worker plugin RMMSetup-96a5de61-cade-4bb4-b424-e3c396c77dbc
2023-10-04 05:40:00,904 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34919
2023-10-04 05:40:00,905 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34919
2023-10-04 05:40:00,905 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37207
2023-10-04 05:40:00,905 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:00,905 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:00,905 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:00,905 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:00,905 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8nv680pr
2023-10-04 05:40:00,906 - distributed.worker - INFO - Starting Worker plugin RMMSetup-239367bf-0efe-45ea-90ee-87dce1448b6a
2023-10-04 05:40:00,910 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44731
2023-10-04 05:40:00,911 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44731
2023-10-04 05:40:00,911 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45087
2023-10-04 05:40:00,911 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:00,911 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:00,911 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:00,911 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:00,911 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6bpv2ec3
2023-10-04 05:40:00,911 - distributed.worker - INFO - Starting Worker plugin RMMSetup-70aa92ed-6cce-471b-9106-0dcc2e4e339f
2023-10-04 05:40:00,915 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37301
2023-10-04 05:40:00,916 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37301
2023-10-04 05:40:00,916 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32887
2023-10-04 05:40:00,916 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:00,916 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:00,916 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:00,916 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:00,916 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qwk33s43
2023-10-04 05:40:00,917 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a60e6f6b-7d2b-497c-a00e-72342fe322f4
2023-10-04 05:40:01,042 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,047 - distributed.worker - INFO - Starting Worker plugin PreImport-5e28a8f6-52dd-4975-b5aa-071c030ca83f
2023-10-04 05:40:01,048 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,050 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0d94fbfa-bc96-4b18-af91-7de1e4365189
2023-10-04 05:40:01,050 - distributed.worker - INFO - Starting Worker plugin PreImport-3a1c0b97-23f2-44d4-b491-000eef04b780
2023-10-04 05:40:01,051 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,059 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0439b1fc-269f-4e06-bc1f-4fcd34aef8c3
2023-10-04 05:40:01,059 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-98a78aa2-10b8-4b88-81fa-8a25ee857093
2023-10-04 05:40:01,059 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b9364c93-e86f-4b18-abb6-10ee54e0756f
2023-10-04 05:40:01,059 - distributed.worker - INFO - Starting Worker plugin PreImport-898b7c5b-25e0-4313-b33b-2feb89ce54f7
2023-10-04 05:40:01,059 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3714e020-1c6e-4e46-9ec9-fd08f6e0cc3f
2023-10-04 05:40:01,059 - distributed.worker - INFO - Starting Worker plugin PreImport-ed775a33-cb1d-4868-81f6-8ad56bf719a6
2023-10-04 05:40:01,059 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fcddcf83-fc32-4e20-a0cb-c8149f7ca0e8
2023-10-04 05:40:01,059 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,059 - distributed.worker - INFO - Starting Worker plugin PreImport-3743f6c0-a916-4e36-abf2-0e9d034c8627
2023-10-04 05:40:01,059 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,059 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,059 - distributed.worker - INFO - Starting Worker plugin PreImport-8418c56b-7d55-444c-85f6-f12cc07503b6
2023-10-04 05:40:01,060 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,060 - distributed.worker - INFO - Starting Worker plugin PreImport-619085d9-b545-4201-bcf3-682e71b790b4
2023-10-04 05:40:01,060 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,074 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44833', status: init, memory: 0, processing: 0>
2023-10-04 05:40:01,076 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44833
2023-10-04 05:40:01,076 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39048
2023-10-04 05:40:01,077 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33813', status: init, memory: 0, processing: 0>
2023-10-04 05:40:01,078 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33813
2023-10-04 05:40:01,078 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39056
2023-10-04 05:40:01,078 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:01,079 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:01,079 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,079 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:01,080 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:01,080 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,081 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:01,082 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:01,084 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37013', status: init, memory: 0, processing: 0>
2023-10-04 05:40:01,085 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37013
2023-10-04 05:40:01,085 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39072
2023-10-04 05:40:01,086 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46839', status: init, memory: 0, processing: 0>
2023-10-04 05:40:01,086 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:01,087 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46839
2023-10-04 05:40:01,087 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39090
2023-10-04 05:40:01,087 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:01,088 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,088 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:01,088 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44731', status: init, memory: 0, processing: 0>
2023-10-04 05:40:01,089 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:01,089 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,089 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44731
2023-10-04 05:40:01,089 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39088
2023-10-04 05:40:01,090 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36265', status: init, memory: 0, processing: 0>
2023-10-04 05:40:01,090 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:01,090 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:01,091 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36265
2023-10-04 05:40:01,091 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39080
2023-10-04 05:40:01,091 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:01,091 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:01,091 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,092 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:01,092 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:01,092 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34919', status: init, memory: 0, processing: 0>
2023-10-04 05:40:01,093 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,093 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:01,093 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34919
2023-10-04 05:40:01,093 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39098
2023-10-04 05:40:01,094 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:01,094 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37301', status: init, memory: 0, processing: 0>
2023-10-04 05:40:01,094 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:01,095 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37301
2023-10-04 05:40:01,095 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39110
2023-10-04 05:40:01,095 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:01,095 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,096 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:01,097 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:01,097 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:01,097 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:01,099 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:01,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:01,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:01,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:01,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:01,147 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:01,147 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:01,147 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:01,147 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:01,151 - distributed.scheduler - INFO - Remove client Client-70af3944-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:01,151 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41196; closing.
2023-10-04 05:40:01,152 - distributed.scheduler - INFO - Remove client Client-70af3944-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:01,152 - distributed.scheduler - INFO - Close client connection: Client-70af3944-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:01,153 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38117'. Reason: nanny-close
2023-10-04 05:40:01,154 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:01,155 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34743'. Reason: nanny-close
2023-10-04 05:40:01,155 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:01,155 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37301. Reason: nanny-close
2023-10-04 05:40:01,155 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36767'. Reason: nanny-close
2023-10-04 05:40:01,155 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:01,156 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34919. Reason: nanny-close
2023-10-04 05:40:01,156 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36829'. Reason: nanny-close
2023-10-04 05:40:01,156 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:01,156 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33813. Reason: nanny-close
2023-10-04 05:40:01,157 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38973'. Reason: nanny-close
2023-10-04 05:40:01,157 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:01,157 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44731. Reason: nanny-close
2023-10-04 05:40:01,157 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40835'. Reason: nanny-close
2023-10-04 05:40:01,157 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39110; closing.
2023-10-04 05:40:01,158 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:01,158 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:01,158 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37301', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398001.158217')
2023-10-04 05:40:01,158 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44833. Reason: nanny-close
2023-10-04 05:40:01,158 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39571'. Reason: nanny-close
2023-10-04 05:40:01,158 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:01,158 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:01,158 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37013. Reason: nanny-close
2023-10-04 05:40:01,159 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:01,159 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40009'. Reason: nanny-close
2023-10-04 05:40:01,159 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:01,159 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39056; closing.
2023-10-04 05:40:01,159 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36265. Reason: nanny-close
2023-10-04 05:40:01,159 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:01,159 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:01,160 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46839. Reason: nanny-close
2023-10-04 05:40:01,160 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33813', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398001.160434')
2023-10-04 05:40:01,160 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:01,160 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39098; closing.
2023-10-04 05:40:01,160 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:01,161 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:01,161 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:01,161 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:01,161 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:01,162 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:01,161 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39056>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39056>: Stream is closed
2023-10-04 05:40:01,163 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:01,163 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:01,163 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39088; closing.
2023-10-04 05:40:01,164 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34919', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398001.1641097')
2023-10-04 05:40:01,164 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:01,164 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:01,165 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44731', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398001.1649964')
2023-10-04 05:40:01,165 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39048; closing.
2023-10-04 05:40:01,166 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44833', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398001.1662507')
2023-10-04 05:40:01,166 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39072; closing.
2023-10-04 05:40:01,166 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39080; closing.
2023-10-04 05:40:01,167 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39090; closing.
2023-10-04 05:40:01,167 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37013', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398001.1676433')
2023-10-04 05:40:01,168 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36265', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398001.168038')
2023-10-04 05:40:01,168 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46839', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398001.1684802')
2023-10-04 05:40:01,168 - distributed.scheduler - INFO - Lost all workers
2023-10-04 05:40:01,168 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39080>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-04 05:40:01,169 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39072>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-04 05:40:01,169 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39090>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-04 05:40:02,972 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-04 05:40:02,972 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-04 05:40:02,973 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:40:02,974 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-04 05:40:02,974 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-10-04 05:40:05,230 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:05,234 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36321 instead
  warnings.warn(
2023-10-04 05:40:05,237 - distributed.scheduler - INFO - State start
2023-10-04 05:40:05,816 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:05,817 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-04 05:40:05,818 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36321/status
2023-10-04 05:40:05,818 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-04 05:40:05,922 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37471'
2023-10-04 05:40:05,939 - distributed.scheduler - INFO - Receive client connection: Client-77797a96-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:05,949 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39188
2023-10-04 05:40:08,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:08,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:08,649 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:09,759 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46809
2023-10-04 05:40:09,760 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46809
2023-10-04 05:40:09,760 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-10-04 05:40:09,760 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:09,760 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:09,760 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:09,760 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-04 05:40:09,760 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ma7tnjo4
2023-10-04 05:40:09,761 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a435c064-bca8-453a-966a-a684ea022ea4
2023-10-04 05:40:09,762 - distributed.worker - INFO - Starting Worker plugin RMMSetup-347c417c-446c-404b-9682-97a95329b86f
2023-10-04 05:40:09,762 - distributed.worker - INFO - Starting Worker plugin PreImport-74fa7cdf-e1b9-49c1-a8de-a217e82d70cb
2023-10-04 05:40:09,763 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:09,803 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46809', status: init, memory: 0, processing: 0>
2023-10-04 05:40:09,804 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46809
2023-10-04 05:40:09,804 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39206
2023-10-04 05:40:09,806 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:09,807 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:09,807 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:09,809 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:09,867 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:09,870 - distributed.scheduler - INFO - Remove client Client-77797a96-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:09,870 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39188; closing.
2023-10-04 05:40:09,870 - distributed.scheduler - INFO - Remove client Client-77797a96-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:09,871 - distributed.scheduler - INFO - Close client connection: Client-77797a96-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:09,872 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37471'. Reason: nanny-close
2023-10-04 05:40:09,872 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:09,873 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46809. Reason: nanny-close
2023-10-04 05:40:09,876 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39206; closing.
2023-10-04 05:40:09,876 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:09,876 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46809', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398009.8764894')
2023-10-04 05:40:09,876 - distributed.scheduler - INFO - Lost all workers
2023-10-04 05:40:09,878 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:11,139 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-04 05:40:11,139 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-04 05:40:11,140 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:40:11,141 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-04 05:40:11,141 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-10-04 05:40:15,056 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:15,060 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46691 instead
  warnings.warn(
2023-10-04 05:40:15,063 - distributed.scheduler - INFO - State start
2023-10-04 05:40:15,460 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:15,460 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-04 05:40:15,461 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46691/status
2023-10-04 05:40:15,461 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-04 05:40:15,556 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42727'
2023-10-04 05:40:15,559 - distributed.scheduler - INFO - Receive client connection: Client-7d645c33-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:15,570 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52572
2023-10-04 05:40:17,205 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:17,205 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:17,777 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:18,926 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43461
2023-10-04 05:40:18,927 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43461
2023-10-04 05:40:18,927 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40655
2023-10-04 05:40:18,927 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:18,927 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:18,927 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:18,927 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-04 05:40:18,927 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-po_d4tp4
2023-10-04 05:40:18,927 - distributed.worker - INFO - Starting Worker plugin PreImport-6f40aaf0-54c3-46f5-9d16-bcbe45707fd2
2023-10-04 05:40:18,929 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-52ba8a00-5a4e-48a8-8e33-36e6efd0cfdd
2023-10-04 05:40:18,929 - distributed.worker - INFO - Starting Worker plugin RMMSetup-85d0ef96-72e0-48c3-8c23-6109310c7ffd
2023-10-04 05:40:18,930 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:18,965 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43461', status: init, memory: 0, processing: 0>
2023-10-04 05:40:18,967 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43461
2023-10-04 05:40:18,967 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52604
2023-10-04 05:40:18,969 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:18,970 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:18,971 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:18,973 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:19,001 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:19,004 - distributed.scheduler - INFO - Remove client Client-7d645c33-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:19,004 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52572; closing.
2023-10-04 05:40:19,004 - distributed.scheduler - INFO - Remove client Client-7d645c33-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:19,005 - distributed.scheduler - INFO - Close client connection: Client-7d645c33-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:19,006 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42727'. Reason: nanny-close
2023-10-04 05:40:19,006 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:19,007 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43461. Reason: nanny-close
2023-10-04 05:40:19,010 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:19,010 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52604; closing.
2023-10-04 05:40:19,010 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43461', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398019.0108702')
2023-10-04 05:40:19,011 - distributed.scheduler - INFO - Lost all workers
2023-10-04 05:40:19,012 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:21,225 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-04 05:40:21,225 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-04 05:40:21,226 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:40:21,227 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-04 05:40:21,227 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-10-04 05:40:23,403 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:23,408 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33235 instead
  warnings.warn(
2023-10-04 05:40:23,412 - distributed.scheduler - INFO - State start
2023-10-04 05:40:23,851 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:23,852 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-04 05:40:23,853 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33235/status
2023-10-04 05:40:23,854 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-04 05:40:28,070 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:47582'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:47582>: Stream is closed
2023-10-04 05:40:28,443 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-04 05:40:28,443 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-04 05:40:28,444 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:40:28,445 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-04 05:40:28,445 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-10-04 05:40:30,536 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:30,540 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40405 instead
  warnings.warn(
2023-10-04 05:40:30,544 - distributed.scheduler - INFO - State start
2023-10-04 05:40:30,564 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:30,564 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-04 05:40:30,565 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40405/status
2023-10-04 05:40:30,565 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-04 05:40:30,817 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45287'
2023-10-04 05:40:31,046 - distributed.scheduler - INFO - Receive client connection: Client-8695c8d0-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:31,059 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49476
2023-10-04 05:40:32,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:32,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:32,536 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:35,022 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40929
2023-10-04 05:40:35,023 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40929
2023-10-04 05:40:35,023 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36225
2023-10-04 05:40:35,023 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-04 05:40:35,023 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:35,023 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:35,024 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-04 05:40:35,024 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-_hpha9js
2023-10-04 05:40:35,024 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d20e5ea6-4f45-4346-a91d-d1887c42f27b
2023-10-04 05:40:35,025 - distributed.worker - INFO - Starting Worker plugin PreImport-51475935-4c30-444d-9dd1-87195abb9576
2023-10-04 05:40:35,025 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a07ffb4b-4531-4976-b33a-e380b20d71a3
2023-10-04 05:40:35,025 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:35,052 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40929', status: init, memory: 0, processing: 0>
2023-10-04 05:40:35,054 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40929
2023-10-04 05:40:35,054 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49490
2023-10-04 05:40:35,056 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:35,057 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-04 05:40:35,057 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:35,059 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-04 05:40:35,140 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:35,143 - distributed.scheduler - INFO - Remove client Client-8695c8d0-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:35,144 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49476; closing.
2023-10-04 05:40:35,144 - distributed.scheduler - INFO - Remove client Client-8695c8d0-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:35,144 - distributed.scheduler - INFO - Close client connection: Client-8695c8d0-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:35,145 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45287'. Reason: nanny-close
2023-10-04 05:40:35,146 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:35,147 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40929. Reason: nanny-close
2023-10-04 05:40:35,149 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49490; closing.
2023-10-04 05:40:35,149 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-04 05:40:35,149 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40929', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398035.14974')
2023-10-04 05:40:35,150 - distributed.scheduler - INFO - Lost all workers
2023-10-04 05:40:35,151 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:36,161 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-04 05:40:36,162 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-04 05:40:36,162 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:40:36,163 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-04 05:40:36,164 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-10-04 05:40:38,438 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:38,443 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46819 instead
  warnings.warn(
2023-10-04 05:40:38,446 - distributed.scheduler - INFO - State start
2023-10-04 05:40:38,467 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:38,468 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-04 05:40:38,468 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46819/status
2023-10-04 05:40:38,469 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-04 05:40:38,636 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45301'
2023-10-04 05:40:38,660 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40317'
2023-10-04 05:40:38,673 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35405'
2023-10-04 05:40:38,676 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37843'
2023-10-04 05:40:38,687 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35783'
2023-10-04 05:40:38,697 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40949'
2023-10-04 05:40:38,706 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44657'
2023-10-04 05:40:38,715 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34145'
2023-10-04 05:40:38,796 - distributed.scheduler - INFO - Receive client connection: Client-8b433a50-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:38,811 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47336
2023-10-04 05:40:40,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:40,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:40,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:40,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:40,480 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:40,481 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:40,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:40,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:40,498 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:40,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:40,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:40,506 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:40,506 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:40,506 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:40,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:40,507 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:40,509 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:40,511 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:40,512 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:40,512 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:40,516 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:40,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:40,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:40,527 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:43,409 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43123
2023-10-04 05:40:43,410 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43123
2023-10-04 05:40:43,410 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43573
2023-10-04 05:40:43,410 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,410 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,410 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:43,410 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:43,410 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q3_2spg2
2023-10-04 05:40:43,411 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bba5caf1-ddd3-4721-bdd0-8ba6f0bb1446
2023-10-04 05:40:43,426 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39239
2023-10-04 05:40:43,427 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39239
2023-10-04 05:40:43,427 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35113
2023-10-04 05:40:43,427 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,427 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,427 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:43,428 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:43,428 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a5ryisdk
2023-10-04 05:40:43,428 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6bf3eee0-80f5-41bb-adf1-86d66139671f
2023-10-04 05:40:43,428 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ee38ad4c-4063-4e7b-8960-4e274d75ff74
2023-10-04 05:40:43,434 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42943
2023-10-04 05:40:43,435 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42943
2023-10-04 05:40:43,435 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33721
2023-10-04 05:40:43,435 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,435 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,436 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:43,436 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:43,436 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_op14a0e
2023-10-04 05:40:43,436 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b89e43fd-0572-4aef-93b0-29c25952abdf
2023-10-04 05:40:43,452 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39047
2023-10-04 05:40:43,453 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39047
2023-10-04 05:40:43,453 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33611
2023-10-04 05:40:43,453 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,453 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,453 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:43,453 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:43,453 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ngf9mmf7
2023-10-04 05:40:43,454 - distributed.worker - INFO - Starting Worker plugin PreImport-843da9f5-55a7-43a6-b56e-a0c44a555269
2023-10-04 05:40:43,454 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9015eba1-22d8-4510-a8da-9c5a34550e58
2023-10-04 05:40:43,454 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dd383c98-b6b1-4ddf-8460-4b8196802108
2023-10-04 05:40:43,454 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37649
2023-10-04 05:40:43,456 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37649
2023-10-04 05:40:43,456 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41105
2023-10-04 05:40:43,456 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,457 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,457 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:43,457 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:43,457 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j17ay5zx
2023-10-04 05:40:43,458 - distributed.worker - INFO - Starting Worker plugin RMMSetup-26f2422d-8a15-4f2e-9d41-b05f63558f1e
2023-10-04 05:40:43,461 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40027
2023-10-04 05:40:43,462 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40027
2023-10-04 05:40:43,462 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42717
2023-10-04 05:40:43,462 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,462 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,462 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:43,462 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:43,462 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ynq39t7y
2023-10-04 05:40:43,463 - distributed.worker - INFO - Starting Worker plugin RMMSetup-07623f6e-0c7d-4ce1-9246-b6a9c373c7e0
2023-10-04 05:40:43,466 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41695
2023-10-04 05:40:43,467 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41695
2023-10-04 05:40:43,467 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43981
2023-10-04 05:40:43,467 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,467 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,467 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:43,468 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:43,468 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7y61zwch
2023-10-04 05:40:43,468 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bc81d985-2410-441c-ba61-267a1dc4d8b9
2023-10-04 05:40:43,471 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45183
2023-10-04 05:40:43,472 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45183
2023-10-04 05:40:43,472 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46337
2023-10-04 05:40:43,472 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,472 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,472 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:43,472 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-04 05:40:43,472 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zzpaquq1
2023-10-04 05:40:43,473 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0da9cf84-a7ce-4639-9173-9fcc9fcae67f
2023-10-04 05:40:43,588 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-72a7b32e-59de-45f1-9481-31173281de37
2023-10-04 05:40:43,588 - distributed.worker - INFO - Starting Worker plugin PreImport-f42129eb-461e-427c-a605-da7865a667ce
2023-10-04 05:40:43,588 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,596 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fd54e270-9626-4589-8a4c-d4d7384b16e1
2023-10-04 05:40:43,596 - distributed.worker - INFO - Starting Worker plugin PreImport-3e9aef18-dbb9-47b0-a6d5-c865327d2478
2023-10-04 05:40:43,596 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,596 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,608 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c3f765dc-dc50-47c3-be92-f71c4b2bbbde
2023-10-04 05:40:43,608 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-55660c8d-1bac-4e11-9911-df10041960c3
2023-10-04 05:40:43,608 - distributed.worker - INFO - Starting Worker plugin PreImport-90ecc0b6-d264-45f9-987c-0621967b2a27
2023-10-04 05:40:43,608 - distributed.worker - INFO - Starting Worker plugin PreImport-8d6f6e90-cd19-4e0e-95ee-bb17e8518dd5
2023-10-04 05:40:43,608 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7bb7551b-e0f8-4f3d-b900-23225c142e2a
2023-10-04 05:40:43,608 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,608 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7d528f2d-756e-4b6f-9544-150453ced995
2023-10-04 05:40:43,609 - distributed.worker - INFO - Starting Worker plugin PreImport-1ff7f1d9-7c9c-4854-af4f-56eeea222bb2
2023-10-04 05:40:43,609 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,609 - distributed.worker - INFO - Starting Worker plugin PreImport-969364d9-311e-4367-8f9c-d8255b7f5249
2023-10-04 05:40:43,609 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,609 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,611 - distributed.worker - INFO - Starting Worker plugin PreImport-55acc365-4f9f-4b18-bfac-86d4d949ad08
2023-10-04 05:40:43,612 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,618 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43123', status: init, memory: 0, processing: 0>
2023-10-04 05:40:43,619 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43123
2023-10-04 05:40:43,619 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55166
2023-10-04 05:40:43,620 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:43,621 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,621 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,622 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:43,629 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39047', status: init, memory: 0, processing: 0>
2023-10-04 05:40:43,629 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39047
2023-10-04 05:40:43,629 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55172
2023-10-04 05:40:43,630 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42943', status: init, memory: 0, processing: 0>
2023-10-04 05:40:43,631 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42943
2023-10-04 05:40:43,631 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55168
2023-10-04 05:40:43,631 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:43,632 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:43,632 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,632 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,633 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,633 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,634 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:43,634 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:43,634 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41695', status: init, memory: 0, processing: 0>
2023-10-04 05:40:43,635 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41695
2023-10-04 05:40:43,635 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55174
2023-10-04 05:40:43,636 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:43,637 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45183', status: init, memory: 0, processing: 0>
2023-10-04 05:40:43,637 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,637 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,637 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45183
2023-10-04 05:40:43,637 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55190
2023-10-04 05:40:43,638 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:43,638 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:43,638 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37649', status: init, memory: 0, processing: 0>
2023-10-04 05:40:43,639 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37649
2023-10-04 05:40:43,639 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55198
2023-10-04 05:40:43,639 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,639 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,640 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:43,641 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:43,641 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,641 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,642 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:43,643 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40027', status: init, memory: 0, processing: 0>
2023-10-04 05:40:43,644 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40027
2023-10-04 05:40:43,644 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55214
2023-10-04 05:40:43,645 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:43,646 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39239', status: init, memory: 0, processing: 0>
2023-10-04 05:40:43,646 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39239
2023-10-04 05:40:43,647 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,647 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55204
2023-10-04 05:40:43,647 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,648 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:43,648 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:43,649 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:43,649 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:43,651 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:43,680 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:43,680 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:43,681 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:43,681 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:43,681 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:43,681 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:43,681 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:43,681 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-04 05:40:43,697 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:43,698 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:43,698 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:43,698 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:43,698 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:43,698 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:43,698 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:43,698 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:43,704 - distributed.scheduler - INFO - Remove client Client-8b433a50-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:43,705 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47336; closing.
2023-10-04 05:40:43,705 - distributed.scheduler - INFO - Remove client Client-8b433a50-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:43,705 - distributed.scheduler - INFO - Close client connection: Client-8b433a50-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:43,707 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45301'. Reason: nanny-close
2023-10-04 05:40:43,707 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:43,708 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40317'. Reason: nanny-close
2023-10-04 05:40:43,708 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:43,709 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45183. Reason: nanny-close
2023-10-04 05:40:43,709 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35405'. Reason: nanny-close
2023-10-04 05:40:43,709 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:43,709 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41695. Reason: nanny-close
2023-10-04 05:40:43,709 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37843'. Reason: nanny-close
2023-10-04 05:40:43,709 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:43,710 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35783'. Reason: nanny-close
2023-10-04 05:40:43,710 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39239. Reason: nanny-close
2023-10-04 05:40:43,710 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:43,710 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:43,710 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42943. Reason: nanny-close
2023-10-04 05:40:43,710 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55190; closing.
2023-10-04 05:40:43,710 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40949'. Reason: nanny-close
2023-10-04 05:40:43,711 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:43,711 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45183', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398043.7110484')
2023-10-04 05:40:43,711 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39047. Reason: nanny-close
2023-10-04 05:40:43,711 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:43,711 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44657'. Reason: nanny-close
2023-10-04 05:40:43,711 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:43,711 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40027. Reason: nanny-close
2023-10-04 05:40:43,711 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34145'. Reason: nanny-close
2023-10-04 05:40:43,712 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:43,712 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:43,712 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37649. Reason: nanny-close
2023-10-04 05:40:43,712 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:43,712 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:43,712 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55174; closing.
2023-10-04 05:40:43,712 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43123. Reason: nanny-close
2023-10-04 05:40:43,713 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:43,713 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41695', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398043.7137597')
2023-10-04 05:40:43,713 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:43,714 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:43,714 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55168; closing.
2023-10-04 05:40:43,714 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:43,714 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55204; closing.
2023-10-04 05:40:43,714 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42943', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398043.7147205')
2023-10-04 05:40:43,714 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:43,715 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39239', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398043.71502')
2023-10-04 05:40:43,715 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:43,715 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:43,715 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:43,715 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55172; closing.
2023-10-04 05:40:43,716 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:43,716 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55214; closing.
2023-10-04 05:40:43,716 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:43,716 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39047', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398043.716637')
2023-10-04 05:40:43,716 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:43,717 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40027', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398043.7170198')
2023-10-04 05:40:43,717 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55198; closing.
2023-10-04 05:40:43,717 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55166; closing.
2023-10-04 05:40:43,717 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37649', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398043.7179043')
2023-10-04 05:40:43,718 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43123', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398043.718294')
2023-10-04 05:40:43,718 - distributed.scheduler - INFO - Lost all workers
2023-10-04 05:40:45,624 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-04 05:40:45,625 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-04 05:40:45,625 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:40:45,626 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-04 05:40:45,627 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-10-04 05:40:47,984 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:47,989 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45919 instead
  warnings.warn(
2023-10-04 05:40:47,993 - distributed.scheduler - INFO - State start
2023-10-04 05:40:48,309 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:48,310 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-04 05:40:48,311 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45919/status
2023-10-04 05:40:48,311 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-04 05:40:48,413 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33479'
2023-10-04 05:40:49,684 - distributed.scheduler - INFO - Receive client connection: Client-90e84982-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:49,698 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55296
2023-10-04 05:40:50,261 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:50,261 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:50,267 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:51,512 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45565
2023-10-04 05:40:51,513 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45565
2023-10-04 05:40:51,513 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42219
2023-10-04 05:40:51,513 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:51,513 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:51,513 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:51,513 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-04 05:40:51,513 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8gjmdagr
2023-10-04 05:40:51,514 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ad1f11bd-2c9b-4860-b1fa-b23999abffd8
2023-10-04 05:40:51,514 - distributed.worker - INFO - Starting Worker plugin PreImport-adaf4eab-0770-4a53-a725-9c625c063fa5
2023-10-04 05:40:51,514 - distributed.worker - INFO - Starting Worker plugin RMMSetup-33249f9a-230c-4ba7-a8a7-74a5025137e1
2023-10-04 05:40:51,647 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:51,695 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45565', status: init, memory: 0, processing: 0>
2023-10-04 05:40:51,696 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45565
2023-10-04 05:40:51,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44032
2023-10-04 05:40:51,697 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:51,698 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:51,698 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:51,700 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:51,741 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-04 05:40:51,745 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:51,747 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:51,749 - distributed.scheduler - INFO - Remove client Client-90e84982-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:51,749 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55296; closing.
2023-10-04 05:40:51,750 - distributed.scheduler - INFO - Remove client Client-90e84982-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:51,750 - distributed.scheduler - INFO - Close client connection: Client-90e84982-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:51,751 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33479'. Reason: nanny-close
2023-10-04 05:40:51,751 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:51,752 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45565. Reason: nanny-close
2023-10-04 05:40:51,754 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:51,754 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44032; closing.
2023-10-04 05:40:51,754 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45565', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398051.7548356')
2023-10-04 05:40:51,755 - distributed.scheduler - INFO - Lost all workers
2023-10-04 05:40:51,756 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:52,717 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-04 05:40:52,717 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-04 05:40:52,717 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:40:52,718 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-04 05:40:52,719 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-10-04 05:40:54,751 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:54,755 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39259 instead
  warnings.warn(
2023-10-04 05:40:54,759 - distributed.scheduler - INFO - State start
2023-10-04 05:40:54,853 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-04 05:40:54,854 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-04 05:40:54,855 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39259/status
2023-10-04 05:40:54,855 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-04 05:40:54,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35611'
2023-10-04 05:40:56,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-04 05:40:56,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-04 05:40:56,525 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-04 05:40:56,600 - distributed.scheduler - INFO - Receive client connection: Client-9515dece-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:56,615 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44118
2023-10-04 05:40:57,588 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41867
2023-10-04 05:40:57,588 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41867
2023-10-04 05:40:57,588 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40979
2023-10-04 05:40:57,589 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-04 05:40:57,589 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:57,589 - distributed.worker - INFO -               Threads:                          1
2023-10-04 05:40:57,589 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-04 05:40:57,589 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q3eej1kd
2023-10-04 05:40:57,589 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b71ea52d-bbbb-4876-9602-40b8a7e8b1fc
2023-10-04 05:40:57,720 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e14c9772-c1eb-4788-a66c-29eec62aabee
2023-10-04 05:40:57,721 - distributed.worker - INFO - Starting Worker plugin PreImport-851a66b9-7a83-470a-980e-e03f0f0977d2
2023-10-04 05:40:57,721 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:57,749 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41867', status: init, memory: 0, processing: 0>
2023-10-04 05:40:57,750 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41867
2023-10-04 05:40:57,750 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44130
2023-10-04 05:40:57,751 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-04 05:40:57,752 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-04 05:40:57,752 - distributed.worker - INFO - -------------------------------------------------
2023-10-04 05:40:57,754 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-04 05:40:57,847 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-10-04 05:40:57,853 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-04 05:40:57,857 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:57,862 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-04 05:40:57,864 - distributed.scheduler - INFO - Remove client Client-9515dece-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:57,865 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44118; closing.
2023-10-04 05:40:57,865 - distributed.scheduler - INFO - Remove client Client-9515dece-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:57,866 - distributed.scheduler - INFO - Close client connection: Client-9515dece-6278-11ee-b5b3-d8c49764f6bb
2023-10-04 05:40:57,866 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35611'. Reason: nanny-close
2023-10-04 05:40:57,867 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-04 05:40:57,868 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41867. Reason: nanny-close
2023-10-04 05:40:57,869 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-04 05:40:57,869 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44130; closing.
2023-10-04 05:40:57,870 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41867', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696398057.8701797')
2023-10-04 05:40:57,870 - distributed.scheduler - INFO - Lost all workers
2023-10-04 05:40:57,871 - distributed.nanny - INFO - Worker closed
2023-10-04 05:40:59,233 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-04 05:40:59,233 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-04 05:40:59,234 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-04 05:40:59,235 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-04 05:40:59,235 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40455 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39987 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46603 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39689 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41405 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42273 instead
  warnings.warn(
2023-10-04 05:42:04,490 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CancelledError()
2023-10-04 05:42:04,496 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40917 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39703 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39529 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44285 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36903 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45671 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43345 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36693 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45577 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42115 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38953 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33917 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42301 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44601 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44369 instead
  warnings.warn(
2023-10-04 05:45:41,041 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 447, in ep
    raise CommClosedError("UCX Endpoint is closed")
distributed.comm.core.CommClosedError: UCX Endpoint is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('UCX Endpoint is closed')
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42137 instead
  warnings.warn(
2023-10-04 05:46:00,596 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-f5e880cd-1b57-4b39-8de1-7e892269202a
Function:  _run_coroutine_on_worker
args:      (326975189753558885712309126460538549276, <function shuffle_task at 0x7f9946742040>, ('explicit-comms-shuffle-d47332d23390482d1988a53121f8cd87', {0: {('explicit-comms-shuffle-958d4c306596076fb29ab08d1fbd55c1', 0)}, 1: set()}, {0: {0}, 1: set()}, ['_partitions'], 1, False, 1, 2))
kwargs:    {}
Exception: "CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 12 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
