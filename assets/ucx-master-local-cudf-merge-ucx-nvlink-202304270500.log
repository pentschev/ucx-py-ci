2023-04-27 05:50:19,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:19,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:19,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:19,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:19,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:19,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:19,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:19,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:19,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:19,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:19,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:19,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:19,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:19,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:20,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:20,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:79814:0:79814] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79814) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f3294054dec]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31fcf) [0x7f3294054fcf]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x32304) [0x7f3294055304]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f33332e8420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7f3291eb97b8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f3291eee058]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23457) [0x7f3291e43457]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a38) [0x7f3291e43a38]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x260fc) [0x7f3291e460fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f32940604d9]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f3291e461ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f3291eb5c2a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f3291f786e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55f34d1abb08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55f34d19c112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f34d19527a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f34d1a6c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f34d19681b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f34d1a6ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55f34d1b4a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55f34d2c49b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55f34d152817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55f34d19df83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55f34d19bd36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f34d1a6ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f34d19681b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f34d1a6ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f34d19681b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f34d1a6ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f34d19681b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f34d1a6ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f34d19681b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f34d19527a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f34d1a6c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55f34d19afa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f34d19527a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55f34d1b4935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55f34d1b5104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55f34d27bfc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55f34d19f2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f34d19a1bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f34d1a6ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55f34d1b4c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f34d19a1bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f34d1a6ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f34d19681b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f34d19527a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f34d1a6c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f34d19681b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f34d1a6ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55f34d196568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f34d19527a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f34d1a6c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55f34d1973cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f34d19527a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55f34d194f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55f34d194eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55f34d2458bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55f34d273adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55f34d26fc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55f34d2677ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55f34d2676bd]
=================================
[dgx13:79823:0:79823] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79823) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fc2f7746dec]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31fcf) [0x7fc2f7746fcf]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x32304) [0x7fc2f7747304]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fc3aea31420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7fc2f77d67b8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fc2f780b058]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23457) [0x7fc2f76f6457]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a38) [0x7fc2f76f6a38]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x260fc) [0x7fc2f76f90fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fc2f77524d9]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fc2f76f91ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fc2f77d2c2a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fc2f78956e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x559938533b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x559938524112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55993851d27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55993852ec05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55993851e81b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55993854370e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fc32e2fc2fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5599385272bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5599384da817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x559938525f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x559938523d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55993852eef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55993851e81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55993852eef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55993851e81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55993852eef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55993851e81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55993852eef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55993851e81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55993851d27a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55993852ec05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x559938522fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55993851d27a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55993853c935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55993853d104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x559938603fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5599385272bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5599385221bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55993852eef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55993853cc72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5599385221bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55993852eef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55993851e81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55993851d27a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55993852ec05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55993851e81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55993852eef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55993851e568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55993851d27a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55993852ec05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55993851f3cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55993851d27a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55993851cf07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55993851ceb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5599385cd8bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5599385fbadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5599385f7c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5599385ef7ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5599385ef6bd]
=================================
[dgx13:79820:0:79820] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79820) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f06f3487dec]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31fcf) [0x7f06f3487fcf]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x32304) [0x7f06f3488304]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f0796746420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7f06f35177b8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f06f354c058]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23457) [0x7f06f3437457]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a38) [0x7f06f3437a38]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x260fc) [0x7f06f343a0fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f06f34934d9]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f06f343a1ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f06f3513c2a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f06f35d66e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5606b0967b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5606b0958112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5606b095127a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5606b0962c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5606b095281b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x5606b097770e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f07160122fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5606b095b2bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5606b090e817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5606b0959f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5606b0957d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5606b0962ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5606b095281b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5606b0962ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5606b095281b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5606b0962ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5606b095281b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5606b0962ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5606b095281b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5606b095127a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5606b0962c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5606b0956fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5606b095127a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5606b0970935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5606b0971104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5606b0a37fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5606b095b2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5606b09561bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5606b0962ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5606b0970c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5606b09561bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5606b0962ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5606b095281b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5606b095127a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5606b0962c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5606b095281b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5606b0962ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5606b0952568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5606b095127a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5606b0962c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5606b09533cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5606b095127a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5606b0950f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5606b0950eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5606b0a018bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5606b0a2fadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5606b0a2bc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5606b0a237ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5606b0a236bd]
=================================
2023-04-27 05:50:27,956 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39475 -> ucx://127.0.0.1:39897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6b5399b380, tag: 0x1b3a9307e04fa83d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:27,956 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f4cfdcf3100, tag: 0x339a5871ea5ad514, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f4cfdcf3100, tag: 0x339a5871ea5ad514, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-04-27 05:50:27,956 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53479
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fa9c9bf3180, tag: 0x57f7876d473c120e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fa9c9bf3180, tag: 0x57f7876d473c120e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-27 05:50:27,959 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39475 -> ucx://127.0.0.1:53479
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6b5399b2c0, tag: 0xe27c78fa66a3ce98, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:27,959 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35675 -> ucx://127.0.0.1:39897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f4cfdcf32c0, tag: 0xa55c1f3fe3ed3f0a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:27,959 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f6b5399b1c0, tag: 0x70b8470ac2796409, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f6b5399b1c0, tag: 0x70b8470ac2796409, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-27 05:50:27,959 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fa9c9bf3200, tag: 0x41c4b3cfa67b76dd, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fa9c9bf3200, tag: 0x41c4b3cfa67b76dd, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-27 05:50:27,959 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53479
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f4cfdcf3140, tag: 0xb14ff5d398284b6b, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f4cfdcf3140, tag: 0xb14ff5d398284b6b, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-27 05:50:27,960 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53479
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f6b5399b280, tag: 0xade5aac8c3cc48f1, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f6b5399b280, tag: 0xade5aac8c3cc48f1, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-27 05:50:27,956 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53479
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8380183140, tag: 0xd4cdb6146a0c39f1, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8380183140, tag: 0xd4cdb6146a0c39f1, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-27 05:50:27,962 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f83801831c0, tag: 0xd219a69e18c810a1, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f83801831c0, tag: 0xd219a69e18c810a1, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:39897 after 30 s
2023-04-27 05:50:27,975 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41717
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f6b5399b240, tag: 0x95761f716589f6e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f6b5399b240, tag: 0x95761f716589f6e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-27 05:50:27,975 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41717
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8380183240, tag: 0x4c9e8b5248a26f4b, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8380183240, tag: 0x4c9e8b5248a26f4b, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-27 05:50:27,991 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41717
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f4cfdcf3280, tag: 0x806053ba92a07f15, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f4cfdcf3280, tag: 0x806053ba92a07f15, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-04-27 05:50:28,041 - distributed.nanny - WARNING - Restarting worker
2023-04-27 05:50:28,065 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49531 -> ucx://127.0.0.1:39897
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7f99e7545340 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:28,090 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44897 -> ucx://127.0.0.1:41717
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fa9c9bf3340, tag: 0xf27150a47d3da9e5, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:28,091 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41717
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fa9c9bf3100, tag: 0x378949c4847462c7, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fa9c9bf3100, tag: 0x378949c4847462c7, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-27 05:50:28,095 - distributed.nanny - WARNING - Restarting worker
2023-04-27 05:50:28,163 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49531 -> ucx://127.0.0.1:41717
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7f99e75452c0 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:28,164 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41717
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 708, in recv
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7f99e7545180 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXConnectionReset('Endpoint 0x7f99e7545180 error: Connection reset by remote peer')
2023-04-27 05:50:28,168 - distributed.nanny - WARNING - Restarting worker
[dgx13:79817:0:79817] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  79817) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f99e781bdec]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31fcf) [0x7f99e781bfcf]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x32304) [0x7f99e781c304]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f9a8ac6a420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7f99e78ab7b8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f99e78e0058]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23457) [0x7f99e77cb457]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a38) [0x7f99e77cba38]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x260fc) [0x7f99e77ce0fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f99e78274d9]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f99e77ce1ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f99e78a7c2a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f99e796a6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x555c37331b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x555c37322112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555c3731b27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555c3732cc05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555c3731c81b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x555c3734170e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f9a0a5362fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x555c373252bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x555c372d8817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x555c37323f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x555c37321d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555c3732cef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555c3731c81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555c3732cef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555c3731c81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555c3732cef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555c3731c81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555c3732cef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555c3731c81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555c3731b27a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555c3732cc05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x555c37320fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555c3731b27a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x555c3733a935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x555c3733b104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x555c37401fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x555c373252bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x555c373201bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555c3732cef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x555c3733ac72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x555c373201bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555c3732cef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555c3731c81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555c3731b27a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555c3732cc05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555c3731c81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555c3732cef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x555c3731c568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555c3731b27a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555c3732cc05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x555c3731d3cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555c3731b27a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x555c3731af07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x555c3731aeb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x555c373cb8bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x555c373f9adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x555c373f5c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x555c373ed7ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x555c373ed6bd]
=================================
2023-04-27 05:50:28,710 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fa9c9bf31c0, tag: 0xc03b272085e24684, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fa9c9bf31c0, tag: 0xc03b272085e24684, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-04-27 05:50:28,710 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f8380183200, tag: 0xa07121a45926759f, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f8380183200, tag: 0xa07121a45926759f, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-04-27 05:50:28,711 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39475 -> ucx://127.0.0.1:49531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6b5399b3c0, tag: 0x9e0ca306055e0617, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:28,711 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7f4cfdcf3180, tag: 0xdc660ab386397db1, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7f4cfdcf3180, tag: 0xdc660ab386397db1, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-04-27 05:50:28,711 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f6b5399b100, tag: 0x932fcb10ebd8b226, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f6b5399b100, tag: 0x932fcb10ebd8b226, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-04-27 05:50:28,712 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44897 -> ucx://127.0.0.1:49531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fa9c9bf32c0, tag: 0x37847f04f8db168d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:28,767 - distributed.nanny - WARNING - Restarting worker
2023-04-27 05:50:29,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:29,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:29,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:29,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:29,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:29,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:30,218 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:30,218 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:31,988 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 0)
Function:  <dask.layers.CallableLazyImport object at 0x7f47a9
args:      ([                key   payload
35018     707308032  71601652
35021     105999738  52493941
35029     853601498  72898471
101025    856973359  37325951
35036     863750007  41680451
...             ...       ...
99995928  507029619  74287078
99996034  850763632  20012039
99996037  707744776  13983258
99996051  819570808   9287500
99996057  207366517  53409755

[12497168 rows x 2 columns],                 key   payload
61485     523044641   6254272
61495     931824486  25501346
1735      912659460  85039130
1736      942039374  72472863
22047     123235268  29376274
...             ...       ...
99992540  517046774  77086531
99979179  413409367  71640894
99979182  916932646  50574273
99979185  624319978  48430943
99979197  952670516  92321795

[12502889 rows x 2 columns],                  key   payload
11374     1064964009  40511370
11382     1000842710  84478955
63717     1043182596  43533730
63718     1054220604  86440514
63735      333931485  51629093
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-04-27 05:50:32,047 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-04-27 05:50:32,047 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-04-27 05:50:32,051 - distributed.worker - ERROR - ('Unexpected response', {'op': 'get_data', 'keys': {"('split-simple-shuffle-bed529b319ff74526ad7bedb31ecf815', 2, 0)"}, 'who': 'ucx://127.0.0.1:59847', 'max_connections': None, 'reply': True})
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    status = response["status"]
KeyError: 'status'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2904, in get_data_from_worker
    raise ValueError("Unexpected response", response)
ValueError: ('Unexpected response', {'op': 'get_data', 'keys': {"('split-simple-shuffle-bed529b319ff74526ad7bedb31ecf815', 2, 0)"}, 'who': 'ucx://127.0.0.1:59847', 'max_connections': None, 'reply': True})
2023-04-27 05:50:32,077 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-04-27 05:50:32,077 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-04-27 05:50:32,099 - distributed.worker - ERROR - ('Unexpected response', {'op': 'get_data', 'keys': {"('split-simple-shuffle-bed529b319ff74526ad7bedb31ecf815', 4, 0)"}, 'who': 'ucx://127.0.0.1:44897', 'max_connections': None, 'reply': True})
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    status = response["status"]
KeyError: 'status'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2904, in get_data_from_worker
    raise ValueError("Unexpected response", response)
ValueError: ('Unexpected response', {'op': 'get_data', 'keys': {"('split-simple-shuffle-bed529b319ff74526ad7bedb31ecf815', 4, 0)"}, 'who': 'ucx://127.0.0.1:44897', 'max_connections': None, 'reply': True})
[dgx13:80333:0:80333] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  80333) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f13a9ed9dec]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31fcf) [0x7f13a9ed9fcf]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x32304) [0x7f13a9eda304]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f144d1c3420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7f13a9f697b8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f13a9f9e058]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23457) [0x7f13a9e89457]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a38) [0x7f13a9e89a38]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x260fc) [0x7f13a9e8c0fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f13a9ee54d9]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f13a9e8c1ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f13a9f65c2a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f13bc05f6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x564cf69ecb08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x564cf69dd112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564cf69d627a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564cf69e7c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564cf69d781b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x564cf69fc70e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f14405082fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x564cf69e02bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x564cf6993817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x564cf69def83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x564cf69dcd36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564cf69e7ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564cf69d781b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564cf69e7ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564cf69d781b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564cf69e7ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564cf69d781b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564cf69e7ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564cf69d781b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564cf69d627a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564cf69e7c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x564cf69dbfa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564cf69d627a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x564cf69f5935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x564cf69f6104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x564cf6abcfc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x564cf69e02bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x564cf69db1bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564cf69e7ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x564cf69f5c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x564cf69db1bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564cf69e7ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564cf69d781b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564cf69d627a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564cf69e7c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564cf69d781b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564cf69e7ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x564cf69d7568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564cf69d627a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564cf69e7c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x564cf69d83cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564cf69d627a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x564cf69d5f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x564cf69d5eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x564cf6a868bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x564cf6ab4adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x564cf6ab0c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x564cf6aa87ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x564cf6aa86bd]
=================================
2023-04-27 05:50:32,208 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 4)
Function:  <dask.layers.CallableLazyImport object at 0x7f47a9
args:      ([                key   payload
35013     200880699  35718986
35019     409285411  57880205
101028    802378848   6027821
101031    806191300  87035298
43185     843901536  95965316
...             ...       ...
99995933  710470577  68388319
99996035  814753106  41391958
99996036  305884513  84188363
99996050  839465128  76801943
99996059  862182770  10097482

[12500589 rows x 2 columns],                 key   payload
61472     316195104  47000490
61486     943843484   8673278
61487     915015508  75763817
1737      519031981  17025333
61488     946052780  64124748
...             ...       ...
99979169  116047374  90550061
99979174  620105086  91019390
99979178  959387749  84660229
99979187   21754664  84828594
99979190  943000209  70751221

[12501715 rows x 2 columns],                  key   payload
11360      432678083  26424789
11361      631092337   8659668
11363      227069130   1684915
11364     1048733317  46815590
63722      635130007   4188299
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-04-27 05:50:32,269 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-04-27 05:50:32,269 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-04-27 05:50:32,286 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39475 -> ucx://127.0.0.1:48415
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6b5399b3c0, tag: 0xd99805970c16d69e, nbytes: 99987912, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:32,330 - distributed.nanny - WARNING - Restarting worker
2023-04-27 05:50:32,376 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6)
Function:  <dask.layers.CallableLazyImport object at 0x7f47a9
args:      ([                key   payload
35009     869828358  88031466
35030     824940575  98713536
101029    802797257  92078771
101041      1694072  74154054
43173     818951771  70039920
...             ...       ...
99996039  826398119  77705873
99996041  111544690  73268275
99996043  817369490  42879274
99996047  600358164  30442758
99996054  863373933  53456446

[12497796 rows x 2 columns],                 key   payload
61473     925641900  67723361
61484     961840802  20993126
1732      928986780   3925902
1740      414527589  38341886
22027     719312113  75951478
...             ...       ...
99979176  115579188  58117229
99979177  117507946  22717788
99979189   17314286  35217168
99979193  418717434  64342254
99979196  966645526  40415969

[12497151 rows x 2 columns],                  key   payload
11375      233859481  89454859
11385     1035957983  21651213
11386     1009432709  21649426
63712     1035001305  81276161
63730      532571755  31350993
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-04-27 05:50:32,384 - distributed.core - ERROR - not enough values to unpack (expected 2, got 0)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 376, in read
    cuda_recv_frames, recv_frames = zip(
ValueError: not enough values to unpack (expected 2, got 0)
2023-04-27 05:50:32,385 - distributed.worker - ERROR - not enough values to unpack (expected 2, got 0)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 376, in read
    cuda_recv_frames, recv_frames = zip(
ValueError: not enough values to unpack (expected 2, got 0)
Task exception was never retrieved
future: <Task finished name='Task-1995' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
[dgx13:80336:0:80336] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  80336) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f2bbd934dec]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31fcf) [0x7f2bbd934fcf]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x32304) [0x7f2bbd935304]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f2c60bf4420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7f2bbd9c47b8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f2bbd9f9058]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23457) [0x7f2bbd8e4457]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a38) [0x7f2bbd8e4a38]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x260fc) [0x7f2bbd8e70fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f2bbd9404d9]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f2bbd8e71ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f2bbd9c0c2a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f2bbda836e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x557768c53b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x557768c44112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557768c3d27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x557768c4ec05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557768c3e81b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557768c4eef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x557768c5ca16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x557768d6c9b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x557768bfa817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x557768c45f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x557768c43d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557768c4eef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557768c3e81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557768c4eef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557768c3e81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557768c4eef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557768c3e81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557768c4eef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557768c3e81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557768c3d27a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x557768c4ec05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x557768c42fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557768c3d27a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x557768c5c935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x557768c5d104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x557768d23fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x557768c472bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x557768c421bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557768c4eef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x557768c5cc72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x557768c421bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557768c4eef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557768c3e81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557768c3d27a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x557768c4ec05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557768c3e81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557768c4eef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x557768c3e568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557768c3d27a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x557768c4ec05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x557768c3f3cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557768c3d27a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x557768c3cf07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x557768c3ceb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x557768ced8bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x557768d1badc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x557768d17c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x557768d0f7ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x557768d0f6bd]
=================================
[dgx13:80330:0:80330] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  80330) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fbac38a2dec]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31fcf) [0x7fbac38a2fcf]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x32304) [0x7fbac38a3304]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fbb62b78420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7fbac39327b8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fbac3967058]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23457) [0x7fbac3852457]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a38) [0x7fbac3852a38]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x260fc) [0x7fbac38550fc]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fbac38ae4d9]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fbac38551ab]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fbac392ec2a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fbac39f16e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55f4f6867b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55f4f6858112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f4f685127a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f4f6862c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f4f685281b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55f4f687770e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fbae24422fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55f4f685b2bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55f4f680e817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55f4f6859f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55f4f6857d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f4f6862ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f4f685281b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f4f6862ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f4f685281b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f4f6862ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f4f685281b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f4f6862ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f4f685281b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f4f685127a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f4f6862c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55f4f6856fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f4f685127a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55f4f6870935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55f4f6871104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55f4f6937fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55f4f685b2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f4f68561bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f4f6862ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55f4f6870c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f4f68561bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f4f6862ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f4f685281b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f4f685127a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f4f6862c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f4f685281b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f4f6862ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55f4f6852568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f4f685127a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f4f6862c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55f4f68533cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f4f685127a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55f4f6850f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55f4f6850eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55f4f69018bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55f4f692fadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55f4f692bc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55f4f69237ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55f4f69236bd]
=================================
2023-04-27 05:50:32,498 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-3979aa34570024387a9136e240255e28', 1)
Function:  subgraph_callable-4b94214e-e0f5-43be-b1ff-ef8642c1
args:      (               key   payload
shuffle                     
0            30531  77022531
0           392269  41577962
0           308707   4234972
0           205080  20419511
0           479570  49852460
...            ...       ...
7        799870719  10252578
7        799879843  62300745
7        799999815   7386920
7        799841472   6549337
7        799919703  21464081

[100005187 rows x 2 columns],                  key   payload
35011      105179594  70380153
35012      208426110  93948762
35027      855374672  55563289
101032     504548417  16691728
35033      866825809  30279200
...              ...       ...
99998676   495912995  62183304
99998682  1535596834  78772914
99998686  1552030777  28435331
99998507   589813681  26531655
99998509  1519330202  48611655

[99996328 rows x 2 columns])
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-04-27 05:50:32,532 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44897 -> ucx://127.0.0.1:58001
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fa9c9bf3100, tag: 0x1bce0898fd2202e6, nbytes: 99971368, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-2027' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-04-27 05:50:32,559 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44897 -> ucx://127.0.0.1:39699
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #006] ep: 0x7fa9c9bf31c0, tag: 0xd75c703029ca6b73, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1793, in get_data
    response = await comm.read(deserializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #006] ep: 0x7fa9c9bf31c0, tag: 0xd75c703029ca6b73, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-27 05:50:32,559 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39475 -> ucx://127.0.0.1:39699
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6b5399b240, tag: 0x6269c6c7db77e402, nbytes: 100000720, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:32,559 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35675 -> ucx://127.0.0.1:39699
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f4cfdcf3140, tag: 0x5a44dc74ebb2c09c, nbytes: 100018368, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:32,560 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59847 -> ucx://127.0.0.1:39699
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8380183200, tag: 0x9c3fe397a11c9290, nbytes: 99960248, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-27 05:50:32,570 - distributed.nanny - WARNING - Restarting worker
2023-04-27 05:50:32,616 - distributed.nanny - WARNING - Restarting worker
2023-04-27 05:50:33,052 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-bed529b319ff74526ad7bedb31ecf815', 5)
Function:  <dask.layers.CallableLazyImport object at 0x7f6604
args:      ([               key   payload
shuffle                     
0           409127  51014925
0           423666  81598354
0           300854  65762226
0            31601  32003843
0           559493  26965285
...            ...       ...
0        799812122  83170462
0        799910278  51428266
0        799813122  77250331
0        799892358  43110621
0        799863309  39911996

[12502296 rows x 2 columns],                key   payload
shuffle                     
1           375074  68874071
1            90651  40008229
1           416149  92025804
1            22602  60190282
1           580187  86144946
...            ...       ...
1        799979981   9838007
1        799789665  98701158
1        799856772  57078426
1        799956251   4184816
1        799799024  50452721

[12499115 rows x 2 columns],                key   payload
shuffle                     
2          1201854  42656680
2          1209436  28734434
2          1011088  25596088
2           663621  40870515
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-04-27 05:50:33,721 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:33,721 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:34,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:34,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-27 05:50:34,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-27 05:50:34,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
