============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.4.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.4
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-02-07 06:46:29,694 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:46:29,699 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-02-07 06:46:29,702 - distributed.scheduler - INFO - State start
2024-02-07 06:46:29,725 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:46:29,726 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-02-07 06:46:29,727 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-02-07 06:46:29,727 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:46:30,057 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43577'
2024-02-07 06:46:30,075 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39709'
2024-02-07 06:46:30,077 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44421'
2024-02-07 06:46:30,085 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37795'
2024-02-07 06:46:31,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:31,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:31,899 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:31,900 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45249
2024-02-07 06:46:31,900 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45249
2024-02-07 06:46:31,900 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42433
2024-02-07 06:46:31,900 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-02-07 06:46:31,900 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:31,900 - distributed.worker - INFO -               Threads:                          4
2024-02-07 06:46:31,900 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-02-07 06:46:31,900 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-hbnh_i5a
2024-02-07 06:46:31,901 - distributed.worker - INFO - Starting Worker plugin PreImport-1719b83b-feb7-4d09-84a7-9309106eb683
2024-02-07 06:46:31,901 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8bf1779a-1ed9-4a22-adbd-540c7ff61897
2024-02-07 06:46:31,901 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8cc91335-5014-40ad-9f9a-26066d920e59
2024-02-07 06:46:31,901 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:31,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:31,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:31,939 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:31,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:31,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:31,940 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34881
2024-02-07 06:46:31,940 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34881
2024-02-07 06:46:31,940 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36541
2024-02-07 06:46:31,940 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-02-07 06:46:31,940 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:31,940 - distributed.worker - INFO -               Threads:                          4
2024-02-07 06:46:31,940 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-02-07 06:46:31,940 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-wby3a5e4
2024-02-07 06:46:31,941 - distributed.worker - INFO - Starting Worker plugin RMMSetup-269189d4-946b-4c78-abeb-a1425aafb410
2024-02-07 06:46:31,941 - distributed.worker - INFO - Starting Worker plugin PreImport-444821ae-ba2e-4d10-bd9c-266e7632301f
2024-02-07 06:46:31,941 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1027fdcc-9154-47a5-9da3-0d236b5c3a79
2024-02-07 06:46:31,941 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:31,943 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:31,944 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39085
2024-02-07 06:46:31,944 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39085
2024-02-07 06:46:31,944 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34787
2024-02-07 06:46:31,944 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-02-07 06:46:31,944 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:31,944 - distributed.worker - INFO -               Threads:                          4
2024-02-07 06:46:31,944 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-02-07 06:46:31,944 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-9g8nkvg4
2024-02-07 06:46:31,945 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bf52eab9-3b0b-47a7-9f4c-ab01e03699ee
2024-02-07 06:46:31,945 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6e0b46ef-0238-417a-8d7d-6ce583b5838a
2024-02-07 06:46:31,945 - distributed.worker - INFO - Starting Worker plugin PreImport-d36c8afa-322b-49f4-a098-0d1a8317601e
2024-02-07 06:46:31,945 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:31,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:31,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:31,961 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:31,961 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46829
2024-02-07 06:46:31,961 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46829
2024-02-07 06:46:31,962 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41665
2024-02-07 06:46:31,962 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-02-07 06:46:31,962 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:31,962 - distributed.worker - INFO -               Threads:                          4
2024-02-07 06:46:31,962 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-02-07 06:46:31,962 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-y0ouxt_a
2024-02-07 06:46:31,962 - distributed.worker - INFO - Starting Worker plugin RMMSetup-062758cb-3280-45d3-b291-1c7205e35fa9
2024-02-07 06:46:31,962 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-21d715e7-dcf9-4b48-a778-4107d8673fb6
2024-02-07 06:46:31,962 - distributed.worker - INFO - Starting Worker plugin PreImport-1ced0da0-5981-4355-a3d0-c9078fc0e329
2024-02-07 06:46:31,963 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:31,988 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45249', status: init, memory: 0, processing: 0>
2024-02-07 06:46:31,999 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45249
2024-02-07 06:46:31,999 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55836
2024-02-07 06:46:32,000 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:32,001 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-02-07 06:46:32,001 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:32,002 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-02-07 06:46:32,049 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39085', status: init, memory: 0, processing: 0>
2024-02-07 06:46:32,050 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39085
2024-02-07 06:46:32,050 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55856
2024-02-07 06:46:32,050 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:32,051 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-02-07 06:46:32,051 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:32,052 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34881', status: init, memory: 0, processing: 0>
2024-02-07 06:46:32,052 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-02-07 06:46:32,053 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34881
2024-02-07 06:46:32,053 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55844
2024-02-07 06:46:32,053 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:32,054 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-02-07 06:46:32,054 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:32,055 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-02-07 06:46:32,062 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46829', status: init, memory: 0, processing: 0>
2024-02-07 06:46:32,063 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46829
2024-02-07 06:46:32,063 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55866
2024-02-07 06:46:32,064 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:32,064 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-02-07 06:46:32,064 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:32,066 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-02-07 06:46:35,853 - distributed.scheduler - INFO - Receive client connection: Client-9e7533a6-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:35,853 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55912
2024-02-07 06:46:35,862 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-02-07 06:46:35,862 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-02-07 06:46:35,862 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-02-07 06:46:35,862 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-02-07 06:46:35,867 - distributed.scheduler - INFO - Remove client Client-9e7533a6-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:35,867 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55912; closing.
2024-02-07 06:46:35,867 - distributed.scheduler - INFO - Remove client Client-9e7533a6-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:35,867 - distributed.scheduler - INFO - Close client connection: Client-9e7533a6-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:35,868 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43577'. Reason: nanny-close
2024-02-07 06:46:35,869 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:35,869 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39709'. Reason: nanny-close
2024-02-07 06:46:35,870 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:35,870 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45249. Reason: nanny-close
2024-02-07 06:46:35,870 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44421'. Reason: nanny-close
2024-02-07 06:46:35,870 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:35,871 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37795'. Reason: nanny-close
2024-02-07 06:46:35,871 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34881. Reason: nanny-close
2024-02-07 06:46:35,871 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:35,871 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46829. Reason: nanny-close
2024-02-07 06:46:35,872 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39085. Reason: nanny-close
2024-02-07 06:46:35,872 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55836; closing.
2024-02-07 06:46:35,872 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-02-07 06:46:35,872 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45249', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288395.872821')
2024-02-07 06:46:35,873 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-02-07 06:46:35,873 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-02-07 06:46:35,873 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55866; closing.
2024-02-07 06:46:35,873 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:35,874 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-02-07 06:46:35,874 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:35,874 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46829', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288395.8745723')
2024-02-07 06:46:35,874 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:35,875 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55844; closing.
2024-02-07 06:46:35,875 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:35,875 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:55866>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:55866>: Stream is closed
2024-02-07 06:46:35,877 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55856; closing.
2024-02-07 06:46:35,877 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34881', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288395.877367')
2024-02-07 06:46:35,877 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39085', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288395.877789')
2024-02-07 06:46:35,878 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:46:36,484 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:46:36,484 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:46:36,484 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:46:36,486 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-02-07 06:46:36,486 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-02-07 06:46:38,681 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:46:38,686 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42001 instead
  warnings.warn(
2024-02-07 06:46:38,690 - distributed.scheduler - INFO - State start
2024-02-07 06:46:38,714 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:46:38,715 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:46:38,716 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42001/status
2024-02-07 06:46:38,716 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:46:38,808 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34933'
2024-02-07 06:46:38,819 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35109'
2024-02-07 06:46:38,828 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37419'
2024-02-07 06:46:38,842 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46707'
2024-02-07 06:46:38,846 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38709'
2024-02-07 06:46:38,855 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33189'
2024-02-07 06:46:38,864 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41113'
2024-02-07 06:46:38,873 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35243'
2024-02-07 06:46:39,287 - distributed.scheduler - INFO - Receive client connection: Client-a3bd0fc1-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:39,300 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53950
2024-02-07 06:46:40,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:40,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:40,760 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:40,761 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39153
2024-02-07 06:46:40,761 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39153
2024-02-07 06:46:40,761 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44429
2024-02-07 06:46:40,761 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:40,761 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:40,761 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:40,761 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:40,761 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mqhmc7fr
2024-02-07 06:46:40,761 - distributed.worker - INFO - Starting Worker plugin PreImport-7691b70e-ae96-464c-ac94-5a4c4eca12eb
2024-02-07 06:46:40,762 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-78fbfef9-a6a5-4c44-8bc1-eda0a36405bb
2024-02-07 06:46:40,762 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dffe331a-70f7-4bbc-a97d-151ed928e8ff
2024-02-07 06:46:40,791 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:40,791 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:40,791 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:40,791 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:40,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:40,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:40,795 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:40,795 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:40,796 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40875
2024-02-07 06:46:40,796 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40875
2024-02-07 06:46:40,796 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33899
2024-02-07 06:46:40,796 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43365
2024-02-07 06:46:40,796 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:40,796 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43365
2024-02-07 06:46:40,796 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:40,796 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:40,796 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:40,796 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46787
2024-02-07 06:46:40,797 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:40,797 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:40,797 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:40,797 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vcc_gwqv
2024-02-07 06:46:40,797 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:40,797 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:40,797 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-efe5vh_e
2024-02-07 06:46:40,797 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-21b8c802-6a23-4882-a693-8d582a423ba2
2024-02-07 06:46:40,797 - distributed.worker - INFO - Starting Worker plugin RMMSetup-40eb8b6f-e4f7-4f7f-aab2-fcbe8c7c285e
2024-02-07 06:46:40,797 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34301
2024-02-07 06:46:40,797 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34301
2024-02-07 06:46:40,797 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34117
2024-02-07 06:46:40,797 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:40,798 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:40,798 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:40,798 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:40,798 - distributed.worker - INFO - Starting Worker plugin PreImport-f049e0eb-6b0b-4ab5-9735-08e77314f289
2024-02-07 06:46:40,798 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lav_ukim
2024-02-07 06:46:40,798 - distributed.worker - INFO - Starting Worker plugin RMMSetup-63b26e16-a762-4890-8c6a-a9718aa33a0f
2024-02-07 06:46:40,798 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6ddac836-0166-47a7-baf0-53e9b1685b30
2024-02-07 06:46:40,798 - distributed.worker - INFO - Starting Worker plugin PreImport-ef4bcf6e-2e56-433e-9ebe-77ac04ac82e4
2024-02-07 06:46:40,798 - distributed.worker - INFO - Starting Worker plugin RMMSetup-82f37395-cce4-43aa-a850-f91161ee4057
2024-02-07 06:46:40,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:40,810 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:40,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:40,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:40,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:40,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:40,814 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:40,815 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46345
2024-02-07 06:46:40,815 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46345
2024-02-07 06:46:40,815 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44293
2024-02-07 06:46:40,815 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:40,815 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:40,815 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:40,815 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:40,815 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:40,815 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v7rueilc
2024-02-07 06:46:40,815 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:40,815 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:40,815 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-763ace0c-8ace-430b-a775-16d1ca33e57c
2024-02-07 06:46:40,815 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:40,815 - distributed.worker - INFO - Starting Worker plugin PreImport-5316b09b-71b0-4a40-952f-070194bd26a1
2024-02-07 06:46:40,816 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7d6bddb9-a2fa-4366-abf6-41909972443e
2024-02-07 06:46:40,816 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37565
2024-02-07 06:46:40,816 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37565
2024-02-07 06:46:40,816 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42127
2024-02-07 06:46:40,816 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39497
2024-02-07 06:46:40,816 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42127
2024-02-07 06:46:40,816 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:40,816 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45795
2024-02-07 06:46:40,816 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:40,816 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:40,816 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:40,816 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:40,816 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:40,816 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:40,816 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:40,816 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k2rwwgug
2024-02-07 06:46:40,816 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-eqjwtd9o
2024-02-07 06:46:40,817 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bf5a4965-1d4e-4ff5-99a9-b318431edf64
2024-02-07 06:46:40,817 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cdfbb06a-558d-4db9-9192-736c65241da2
2024-02-07 06:46:40,817 - distributed.worker - INFO - Starting Worker plugin PreImport-be9dd199-d3a6-42e5-bd60-e78b4177a396
2024-02-07 06:46:40,817 - distributed.worker - INFO - Starting Worker plugin RMMSetup-23934917-91b2-48a7-aaaa-d0a16e9da62b
2024-02-07 06:46:40,819 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:40,820 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32843
2024-02-07 06:46:40,820 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32843
2024-02-07 06:46:40,821 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45949
2024-02-07 06:46:40,821 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:40,821 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:40,821 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:40,821 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:40,821 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1ttzpqdw
2024-02-07 06:46:40,821 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1979bab0-425d-4af9-95f0-da9ecc2e068f
2024-02-07 06:46:40,823 - distributed.worker - INFO - Starting Worker plugin PreImport-0133e0df-772e-465b-a9e2-6ac99f470d9f
2024-02-07 06:46:40,824 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c71fb424-12cc-428e-af63-7243e0e4dc3d
2024-02-07 06:46:43,165 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,187 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39153', status: init, memory: 0, processing: 0>
2024-02-07 06:46:43,190 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39153
2024-02-07 06:46:43,190 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48486
2024-02-07 06:46:43,190 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:43,191 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:43,191 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,192 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:43,214 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,237 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34301', status: init, memory: 0, processing: 0>
2024-02-07 06:46:43,238 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34301
2024-02-07 06:46:43,237 - distributed.worker - INFO - Starting Worker plugin PreImport-7385893f-425a-4e22-b0ae-a645b7e4c95b
2024-02-07 06:46:43,238 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48498
2024-02-07 06:46:43,238 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bdc81cb1-b15a-475d-83c3-689406dc7fb1
2024-02-07 06:46:43,239 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,239 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:43,240 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:43,240 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,241 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:43,256 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,260 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42127', status: init, memory: 0, processing: 0>
2024-02-07 06:46:43,261 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42127
2024-02-07 06:46:43,261 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48512
2024-02-07 06:46:43,262 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:43,263 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:43,263 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,263 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,264 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:43,272 - distributed.worker - INFO - Starting Worker plugin PreImport-8c5040cf-86ab-499d-aafb-88f1633a51a7
2024-02-07 06:46:43,272 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ff051bf2-0c98-4e49-b2b3-a26ed5ec3b6c
2024-02-07 06:46:43,274 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,276 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,286 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,287 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40875', status: init, memory: 0, processing: 0>
2024-02-07 06:46:43,288 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40875
2024-02-07 06:46:43,288 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48514
2024-02-07 06:46:43,289 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:43,290 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:43,291 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,293 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:43,294 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32843', status: init, memory: 0, processing: 0>
2024-02-07 06:46:43,294 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32843
2024-02-07 06:46:43,294 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48528
2024-02-07 06:46:43,296 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:43,297 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:43,297 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,299 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:43,309 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37565', status: init, memory: 0, processing: 0>
2024-02-07 06:46:43,310 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37565
2024-02-07 06:46:43,310 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48552
2024-02-07 06:46:43,311 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46345', status: init, memory: 0, processing: 0>
2024-02-07 06:46:43,311 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:43,311 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46345
2024-02-07 06:46:43,311 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48542
2024-02-07 06:46:43,312 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:43,312 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,312 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43365', status: init, memory: 0, processing: 0>
2024-02-07 06:46:43,313 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43365
2024-02-07 06:46:43,313 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48544
2024-02-07 06:46:43,313 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:43,313 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:43,314 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:43,314 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,315 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:43,316 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:43,316 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:43,316 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:43,318 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:43,383 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:43,383 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:43,383 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:43,383 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:43,383 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:43,384 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:43,384 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:43,384 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:43,388 - distributed.scheduler - INFO - Remove client Client-a3bd0fc1-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:43,388 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53950; closing.
2024-02-07 06:46:43,389 - distributed.scheduler - INFO - Remove client Client-a3bd0fc1-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:43,389 - distributed.scheduler - INFO - Close client connection: Client-a3bd0fc1-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:43,390 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34933'. Reason: nanny-close
2024-02-07 06:46:43,390 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:43,391 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35109'. Reason: nanny-close
2024-02-07 06:46:43,391 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39153. Reason: nanny-close
2024-02-07 06:46:43,394 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48486; closing.
2024-02-07 06:46:43,394 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:43,394 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39153', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288403.3943107')
2024-02-07 06:46:43,394 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:43,394 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37419'. Reason: nanny-close
2024-02-07 06:46:43,395 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:43,395 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46707'. Reason: nanny-close
2024-02-07 06:46:43,395 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:43,395 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34301. Reason: nanny-close
2024-02-07 06:46:43,395 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:43,395 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38709'. Reason: nanny-close
2024-02-07 06:46:43,396 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43365. Reason: nanny-close
2024-02-07 06:46:43,396 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:43,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33189'. Reason: nanny-close
2024-02-07 06:46:43,396 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:43,396 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40875. Reason: nanny-close
2024-02-07 06:46:43,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41113'. Reason: nanny-close
2024-02-07 06:46:43,396 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42127. Reason: nanny-close
2024-02-07 06:46:43,397 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:43,397 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35243'. Reason: nanny-close
2024-02-07 06:46:43,397 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37565. Reason: nanny-close
2024-02-07 06:46:43,397 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:43,397 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46345. Reason: nanny-close
2024-02-07 06:46:43,398 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:43,398 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:43,398 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:43,399 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48544; closing.
2024-02-07 06:46:43,399 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:43,399 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:43,399 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32843. Reason: nanny-close
2024-02-07 06:46:43,399 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48498; closing.
2024-02-07 06:46:43,399 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48512; closing.
2024-02-07 06:46:43,399 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:43,399 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:43,400 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43365', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288403.4002388')
2024-02-07 06:46:43,400 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:43,400 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:43,400 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:43,400 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:43,400 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48552; closing.
2024-02-07 06:46:43,401 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34301', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288403.4010732')
2024-02-07 06:46:43,401 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:43,401 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:43,401 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42127', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288403.4015808')
2024-02-07 06:46:43,402 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48514; closing.
2024-02-07 06:46:43,402 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:43,403 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37565', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288403.4030566')
2024-02-07 06:46:43,403 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40875', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288403.403855')
2024-02-07 06:46:43,404 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48542; closing.
2024-02-07 06:46:43,405 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46345', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288403.4055212')
2024-02-07 06:46:43,406 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48528; closing.
2024-02-07 06:46:43,406 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32843', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288403.4067338')
2024-02-07 06:46:43,407 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:46:43,407 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:48542>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 262, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-02-07 06:46:44,306 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:46:44,306 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:46:44,307 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:46:44,308 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:46:44,308 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-02-07 06:46:46,522 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:46:46,527 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46591 instead
  warnings.warn(
2024-02-07 06:46:46,531 - distributed.scheduler - INFO - State start
2024-02-07 06:46:46,607 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:46:46,608 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:46:46,609 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46591/status
2024-02-07 06:46:46,609 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:46:46,651 - distributed.scheduler - INFO - Receive client connection: Client-a868f17b-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:46,664 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48650
2024-02-07 06:46:46,731 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45137'
2024-02-07 06:46:46,749 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38549'
2024-02-07 06:46:46,751 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43255'
2024-02-07 06:46:46,759 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46643'
2024-02-07 06:46:46,779 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36629'
2024-02-07 06:46:46,788 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36741'
2024-02-07 06:46:46,796 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39619'
2024-02-07 06:46:46,805 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38311'
2024-02-07 06:46:48,670 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:48,670 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:48,674 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:48,675 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45833
2024-02-07 06:46:48,675 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45833
2024-02-07 06:46:48,675 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42233
2024-02-07 06:46:48,675 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:48,675 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:48,675 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:48,675 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:48,675 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7o79o8q9
2024-02-07 06:46:48,676 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-248baf8b-ea38-4745-a6e0-7c3886257c7b
2024-02-07 06:46:48,676 - distributed.worker - INFO - Starting Worker plugin PreImport-e328fe4c-41d2-4efd-8095-e181a86d56e9
2024-02-07 06:46:48,676 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cb678167-7556-491f-a342-f2014f022e24
2024-02-07 06:46:48,690 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:48,690 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:48,691 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:48,691 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:48,695 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:48,695 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:48,696 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36355
2024-02-07 06:46:48,696 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40309
2024-02-07 06:46:48,696 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40309
2024-02-07 06:46:48,696 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36355
2024-02-07 06:46:48,696 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43367
2024-02-07 06:46:48,696 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39473
2024-02-07 06:46:48,696 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:48,696 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:48,696 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:48,696 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:48,696 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:48,696 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:48,696 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:48,696 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:48,696 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wtia_owv
2024-02-07 06:46:48,696 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ypg6fcs6
2024-02-07 06:46:48,696 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2b5762c7-a9ae-4197-b9a8-57a035f0456b
2024-02-07 06:46:48,696 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-724a30a0-88d2-4ccc-98bf-560e273f2d15
2024-02-07 06:46:48,697 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c3fbceb9-17e1-4127-b366-8271151d0777
2024-02-07 06:46:48,697 - distributed.worker - INFO - Starting Worker plugin PreImport-bd0cf071-ac54-407d-aefe-4ef024bfe1f7
2024-02-07 06:46:48,697 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3060ea48-5d78-44f3-855b-2925bed0fdb1
2024-02-07 06:46:48,701 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:48,701 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:48,705 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:48,706 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40367
2024-02-07 06:46:48,706 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40367
2024-02-07 06:46:48,706 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34009
2024-02-07 06:46:48,706 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:48,707 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:48,707 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:48,707 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:48,707 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qjkyu6cf
2024-02-07 06:46:48,707 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4fac4702-30ae-4523-be63-f4bde1d8e010
2024-02-07 06:46:48,710 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2ad0f007-27f4-4384-9ef6-fab8c65b6e67
2024-02-07 06:46:48,737 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:48,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:48,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:48,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:48,742 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:48,743 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34549
2024-02-07 06:46:48,743 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34549
2024-02-07 06:46:48,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:48,743 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:48,743 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35869
2024-02-07 06:46:48,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:48,743 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:48,743 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:48,743 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:48,743 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:48,743 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bs9m4b00
2024-02-07 06:46:48,743 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8cc64401-789b-455e-b3dc-11ca1bce708d
2024-02-07 06:46:48,743 - distributed.worker - INFO - Starting Worker plugin PreImport-6abde501-0acd-4e23-a037-92201c794806
2024-02-07 06:46:48,744 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7c2dd27d-0302-4a95-8195-2939a4a2d7d4
2024-02-07 06:46:48,744 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41775
2024-02-07 06:46:48,744 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41775
2024-02-07 06:46:48,744 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34973
2024-02-07 06:46:48,744 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:48,744 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:48,744 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:48,744 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:48,744 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6i4n9dd4
2024-02-07 06:46:48,744 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f555e723-1a63-4458-9647-ae17fa95d12c
2024-02-07 06:46:48,744 - distributed.worker - INFO - Starting Worker plugin PreImport-defc3a92-6b00-4a74-aa8f-2af4a8dd3b8f
2024-02-07 06:46:48,744 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f6ede74b-3de6-4eac-8dee-ca9d2ffec1f2
2024-02-07 06:46:48,747 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:48,748 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40565
2024-02-07 06:46:48,748 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40565
2024-02-07 06:46:48,748 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38651
2024-02-07 06:46:48,748 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:48,749 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:48,749 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:48,749 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:48,749 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aorlxkvt
2024-02-07 06:46:48,749 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ae7356c1-a5d4-4f78-864c-7849cc2df09e
2024-02-07 06:46:48,751 - distributed.worker - INFO - Starting Worker plugin PreImport-4c5196fe-8aff-4653-ac0f-e0ca25e6b247
2024-02-07 06:46:48,752 - distributed.worker - INFO - Starting Worker plugin RMMSetup-63b28628-a28b-48b0-9026-2f164ea8c1b7
2024-02-07 06:46:48,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:48,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:48,818 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:48,819 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43471
2024-02-07 06:46:48,819 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43471
2024-02-07 06:46:48,819 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38533
2024-02-07 06:46:48,819 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:48,819 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:48,819 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:48,819 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:48,819 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cx0e9uov
2024-02-07 06:46:48,820 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-24922056-368d-4e2c-993a-bd3d86bf488c
2024-02-07 06:46:48,820 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e0e0bbbc-92b4-41b5-8aea-0593298324e8
2024-02-07 06:46:50,718 - distributed.worker - INFO - Starting Worker plugin PreImport-06a6afe0-8d69-4e53-a319-ac0622dcf375
2024-02-07 06:46:50,718 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:50,722 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:50,726 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:50,744 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40309', status: init, memory: 0, processing: 0>
2024-02-07 06:46:50,746 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40309
2024-02-07 06:46:50,747 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38962
2024-02-07 06:46:50,747 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:50,748 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:50,748 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:50,750 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:50,756 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36355', status: init, memory: 0, processing: 0>
2024-02-07 06:46:50,756 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36355
2024-02-07 06:46:50,756 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38968
2024-02-07 06:46:50,758 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:50,759 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45833', status: init, memory: 0, processing: 0>
2024-02-07 06:46:50,759 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:50,759 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:50,759 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45833
2024-02-07 06:46:50,759 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38980
2024-02-07 06:46:50,761 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:50,761 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:50,762 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:50,762 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:50,764 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:50,892 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:50,916 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41775', status: init, memory: 0, processing: 0>
2024-02-07 06:46:50,917 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41775
2024-02-07 06:46:50,917 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38990
2024-02-07 06:46:50,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:50,918 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:50,918 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:50,920 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:51,041 - distributed.worker - INFO - Starting Worker plugin PreImport-cf9a5f3f-f8f1-477e-943f-70503e24897a
2024-02-07 06:46:51,043 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:51,047 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:51,053 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:51,069 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34549', status: init, memory: 0, processing: 0>
2024-02-07 06:46:51,070 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34549
2024-02-07 06:46:51,070 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39016
2024-02-07 06:46:51,071 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:51,072 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:51,072 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:51,074 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:51,074 - distributed.worker - INFO - Starting Worker plugin PreImport-8518251e-dbe6-48d3-a5f7-ae12da31ea9f
2024-02-07 06:46:51,075 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:51,078 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40367', status: init, memory: 0, processing: 0>
2024-02-07 06:46:51,079 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40367
2024-02-07 06:46:51,079 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39004
2024-02-07 06:46:51,080 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:51,081 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:51,081 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:51,083 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:51,087 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40565', status: init, memory: 0, processing: 0>
2024-02-07 06:46:51,088 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40565
2024-02-07 06:46:51,088 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39022
2024-02-07 06:46:51,089 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:51,090 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:51,090 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:51,092 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:51,097 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43471', status: init, memory: 0, processing: 0>
2024-02-07 06:46:51,098 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43471
2024-02-07 06:46:51,098 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39030
2024-02-07 06:46:51,099 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:51,100 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:51,100 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:51,101 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:51,204 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:51,204 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:51,205 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:51,205 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:51,205 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:51,205 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:51,205 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:51,206 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:51,211 - distributed.scheduler - INFO - Remove client Client-a868f17b-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:51,211 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48650; closing.
2024-02-07 06:46:51,211 - distributed.scheduler - INFO - Remove client Client-a868f17b-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:51,212 - distributed.scheduler - INFO - Close client connection: Client-a868f17b-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:51,213 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45137'. Reason: nanny-close
2024-02-07 06:46:51,213 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:51,213 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38549'. Reason: nanny-close
2024-02-07 06:46:51,214 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:51,214 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43255'. Reason: nanny-close
2024-02-07 06:46:51,214 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:51,214 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40367. Reason: nanny-close
2024-02-07 06:46:51,214 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46643'. Reason: nanny-close
2024-02-07 06:46:51,215 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45833. Reason: nanny-close
2024-02-07 06:46:51,215 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:51,215 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36629'. Reason: nanny-close
2024-02-07 06:46:51,215 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34549. Reason: nanny-close
2024-02-07 06:46:51,215 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:51,215 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36741'. Reason: nanny-close
2024-02-07 06:46:51,216 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40309. Reason: nanny-close
2024-02-07 06:46:51,216 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:51,216 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39619'. Reason: nanny-close
2024-02-07 06:46:51,216 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36355. Reason: nanny-close
2024-02-07 06:46:51,216 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:51,216 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38311'. Reason: nanny-close
2024-02-07 06:46:51,217 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40565. Reason: nanny-close
2024-02-07 06:46:51,217 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:51,217 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:51,217 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39016; closing.
2024-02-07 06:46:51,217 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41775. Reason: nanny-close
2024-02-07 06:46:51,217 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:51,217 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:51,217 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38980; closing.
2024-02-07 06:46:51,217 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:51,218 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43471. Reason: nanny-close
2024-02-07 06:46:51,218 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34549', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288411.218091')
2024-02-07 06:46:51,218 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:51,218 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:51,218 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45833', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288411.218813')
2024-02-07 06:46:51,219 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:51,219 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:51,219 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:51,219 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:51,219 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:51,219 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39004; closing.
2024-02-07 06:46:51,219 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:51,220 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38962; closing.
2024-02-07 06:46:51,220 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:51,221 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:51,220 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40367', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288411.2209065')
2024-02-07 06:46:51,221 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:51,221 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:51,222 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40309', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288411.2227879')
2024-02-07 06:46:51,223 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38968; closing.
2024-02-07 06:46:51,224 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39004>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 262, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-02-07 06:46:51,226 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36355', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288411.226669')
2024-02-07 06:46:51,227 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39022; closing.
2024-02-07 06:46:51,227 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38990; closing.
2024-02-07 06:46:51,227 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39030; closing.
2024-02-07 06:46:51,228 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40565', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288411.2282598')
2024-02-07 06:46:51,228 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41775', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288411.2287948')
2024-02-07 06:46:51,229 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43471', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288411.229342')
2024-02-07 06:46:51,229 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:46:52,129 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:46:52,129 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:46:52,130 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:46:52,131 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:46:52,131 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-02-07 06:46:54,114 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:46:54,118 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33791 instead
  warnings.warn(
2024-02-07 06:46:54,122 - distributed.scheduler - INFO - State start
2024-02-07 06:46:54,220 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:46:54,221 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:46:54,221 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33791/status
2024-02-07 06:46:54,222 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:46:54,373 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43569'
2024-02-07 06:46:54,384 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38623'
2024-02-07 06:46:54,393 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43757'
2024-02-07 06:46:54,406 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46325'
2024-02-07 06:46:54,410 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45949'
2024-02-07 06:46:54,419 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44923'
2024-02-07 06:46:54,429 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42729'
2024-02-07 06:46:54,438 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37877'
2024-02-07 06:46:54,460 - distributed.scheduler - INFO - Receive client connection: Client-ad0fe6b5-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:54,472 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39164
2024-02-07 06:46:56,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:56,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:56,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:56,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:56,243 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:56,243 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:56,244 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46095
2024-02-07 06:46:56,244 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35555
2024-02-07 06:46:56,244 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46095
2024-02-07 06:46:56,244 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35555
2024-02-07 06:46:56,244 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39169
2024-02-07 06:46:56,244 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:56,244 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33881
2024-02-07 06:46:56,244 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:56,244 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:56,244 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:56,244 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:56,244 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:56,244 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lbrv1i80
2024-02-07 06:46:56,244 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:56,244 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:56,245 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v1j3pvb9
2024-02-07 06:46:56,245 - distributed.worker - INFO - Starting Worker plugin RMMSetup-acef1e09-9503-4756-8d49-7d3cd92f0eb9
2024-02-07 06:46:56,245 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e4a03aae-3d1d-49cb-8e00-cf35baa6f76d
2024-02-07 06:46:56,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:56,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:56,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:56,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:56,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:56,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:56,322 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:56,322 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:56,322 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:56,323 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:56,323 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39319
2024-02-07 06:46:56,323 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39319
2024-02-07 06:46:56,323 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39555
2024-02-07 06:46:56,323 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:56,324 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:56,324 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:56,324 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:56,324 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:56,324 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0plw4a9b
2024-02-07 06:46:56,324 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-83810894-c716-4a06-b921-264b226d464f
2024-02-07 06:46:56,324 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42387
2024-02-07 06:46:56,324 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42387
2024-02-07 06:46:56,324 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33959
2024-02-07 06:46:56,324 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:56,324 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:56,324 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:56,324 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:56,324 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fcfh93he
2024-02-07 06:46:56,324 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38659
2024-02-07 06:46:56,325 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38659
2024-02-07 06:46:56,325 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c2597daa-967b-4f9b-8ae2-62218502f54e
2024-02-07 06:46:56,325 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43977
2024-02-07 06:46:56,325 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:56,325 - distributed.worker - INFO - Starting Worker plugin RMMSetup-30c8eabd-2121-4f8a-ab97-78af1c79f73e
2024-02-07 06:46:56,325 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:56,325 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:56,325 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:56,325 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rf3ev28a
2024-02-07 06:46:56,325 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a9144ba9-4e15-4d90-aa50-bbc21f131f01
2024-02-07 06:46:56,325 - distributed.worker - INFO - Starting Worker plugin PreImport-bfaa65bc-5d93-4d7d-8bc3-c34de2e10b0e
2024-02-07 06:46:56,325 - distributed.worker - INFO - Starting Worker plugin RMMSetup-653ccfcf-afc7-407b-9c9f-ecfd75ad4fd3
2024-02-07 06:46:56,326 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:56,327 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34019
2024-02-07 06:46:56,327 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34019
2024-02-07 06:46:56,327 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38401
2024-02-07 06:46:56,327 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:56,327 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:56,327 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:56,327 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:56,328 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nx1l9ix4
2024-02-07 06:46:56,328 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f6621819-41c3-4c22-aefb-24420b19726d
2024-02-07 06:46:56,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:56,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:56,343 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:56,344 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45469
2024-02-07 06:46:56,344 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45469
2024-02-07 06:46:56,344 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43465
2024-02-07 06:46:56,344 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:56,344 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:56,344 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:56,345 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:56,345 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l87rho9c
2024-02-07 06:46:56,345 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2a93ad48-93be-4e6c-8c1f-ed4794703a84
2024-02-07 06:46:56,345 - distributed.worker - INFO - Starting Worker plugin RMMSetup-71342352-5f2d-40ec-879a-34c3b5687907
2024-02-07 06:46:56,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:46:56,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:46:56,724 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:46:56,726 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44833
2024-02-07 06:46:56,726 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44833
2024-02-07 06:46:56,726 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36873
2024-02-07 06:46:56,726 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:46:56,726 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:56,726 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:46:56,726 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:46:56,726 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2mozdzwj
2024-02-07 06:46:56,727 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fa905670-032c-4b81-a2fc-21ee776e3e58
2024-02-07 06:46:56,727 - distributed.worker - INFO - Starting Worker plugin PreImport-60ecfe05-b665-4f9d-8cd2-18b2b34b6d30
2024-02-07 06:46:56,727 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c63c3be0-59f8-4e95-9f95-817ca2dcbab2
2024-02-07 06:46:58,563 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c8032407-7507-4f6b-bf1b-4df57f9d4134
2024-02-07 06:46:58,564 - distributed.worker - INFO - Starting Worker plugin PreImport-12f85338-6c13-4c8d-b41d-770bfe556197
2024-02-07 06:46:58,565 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,569 - distributed.worker - INFO - Starting Worker plugin PreImport-4f271426-06c1-4e19-8e81-c2e6be300097
2024-02-07 06:46:58,570 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d61dfcd4-8c7e-4d5f-b882-012efca3a24b
2024-02-07 06:46:58,572 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,606 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46095', status: init, memory: 0, processing: 0>
2024-02-07 06:46:58,607 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46095
2024-02-07 06:46:58,608 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39190
2024-02-07 06:46:58,608 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35555', status: init, memory: 0, processing: 0>
2024-02-07 06:46:58,609 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35555
2024-02-07 06:46:58,609 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39194
2024-02-07 06:46:58,609 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:58,610 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:58,611 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:58,611 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,611 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:58,611 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,613 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:58,614 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:58,636 - distributed.worker - INFO - Starting Worker plugin PreImport-b0bf5f97-2b20-415d-a877-905e1246a667
2024-02-07 06:46:58,636 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,651 - distributed.worker - INFO - Starting Worker plugin PreImport-1813558f-8e8e-4eb9-b44e-4416de681231
2024-02-07 06:46:58,652 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7e5daa0d-3579-4c1c-8de5-4c99677b5b19
2024-02-07 06:46:58,652 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,660 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42387', status: init, memory: 0, processing: 0>
2024-02-07 06:46:58,661 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42387
2024-02-07 06:46:58,661 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39210
2024-02-07 06:46:58,662 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:58,662 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:58,662 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,663 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,664 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:58,665 - distributed.worker - INFO - Starting Worker plugin PreImport-20b1b54c-0fda-45bf-9652-3f8578efc28e
2024-02-07 06:46:58,666 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,666 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b0030ef0-7fad-4423-a272-ccfffb60f47d
2024-02-07 06:46:58,667 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,675 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34019', status: init, memory: 0, processing: 0>
2024-02-07 06:46:58,676 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34019
2024-02-07 06:46:58,676 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39226
2024-02-07 06:46:58,677 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:58,677 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:58,678 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,678 - distributed.worker - INFO - Starting Worker plugin PreImport-55119810-2447-4bdd-a68e-d93944e5fab1
2024-02-07 06:46:58,679 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:58,679 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,685 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44833', status: init, memory: 0, processing: 0>
2024-02-07 06:46:58,685 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44833
2024-02-07 06:46:58,686 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39252
2024-02-07 06:46:58,686 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38659', status: init, memory: 0, processing: 0>
2024-02-07 06:46:58,686 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:58,687 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38659
2024-02-07 06:46:58,687 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39258
2024-02-07 06:46:58,687 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:58,687 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,688 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:58,688 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:58,689 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:58,689 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,690 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:58,695 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39319', status: init, memory: 0, processing: 0>
2024-02-07 06:46:58,695 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39319
2024-02-07 06:46:58,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39238
2024-02-07 06:46:58,697 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:58,698 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:58,698 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,700 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:58,707 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45469', status: init, memory: 0, processing: 0>
2024-02-07 06:46:58,707 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45469
2024-02-07 06:46:58,707 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39262
2024-02-07 06:46:58,709 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:46:58,710 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:46:58,710 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:46:58,712 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:46:58,758 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:58,758 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:58,758 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:58,758 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:58,759 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:58,759 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:58,760 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:58,760 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:46:58,769 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:46:58,770 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:46:58,770 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:46:58,770 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:46:58,770 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:46:58,770 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:46:58,770 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:46:58,770 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:46:58,778 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:46:58,779 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:46:58,782 - distributed.scheduler - INFO - Remove client Client-ad0fe6b5-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:58,782 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39164; closing.
2024-02-07 06:46:58,782 - distributed.scheduler - INFO - Remove client Client-ad0fe6b5-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:58,782 - distributed.scheduler - INFO - Close client connection: Client-ad0fe6b5-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:46:58,783 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43569'. Reason: nanny-close
2024-02-07 06:46:58,783 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:58,784 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38623'. Reason: nanny-close
2024-02-07 06:46:58,784 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:58,784 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43757'. Reason: nanny-close
2024-02-07 06:46:58,785 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46095. Reason: nanny-close
2024-02-07 06:46:58,785 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:58,785 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46325'. Reason: nanny-close
2024-02-07 06:46:58,785 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35555. Reason: nanny-close
2024-02-07 06:46:58,785 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:58,785 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45949'. Reason: nanny-close
2024-02-07 06:46:58,785 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44833. Reason: nanny-close
2024-02-07 06:46:58,785 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:58,786 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44923'. Reason: nanny-close
2024-02-07 06:46:58,786 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34019. Reason: nanny-close
2024-02-07 06:46:58,786 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:58,786 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42729'. Reason: nanny-close
2024-02-07 06:46:58,786 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:58,786 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39319. Reason: nanny-close
2024-02-07 06:46:58,787 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37877'. Reason: nanny-close
2024-02-07 06:46:58,787 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:46:58,787 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45469. Reason: nanny-close
2024-02-07 06:46:58,787 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:58,787 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:58,787 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42387. Reason: nanny-close
2024-02-07 06:46:58,788 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:58,788 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38659. Reason: nanny-close
2024-02-07 06:46:58,788 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:58,788 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:58,789 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:58,789 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:58,789 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:58,789 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:58,790 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:58,790 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39190; closing.
2024-02-07 06:46:58,790 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:46:58,790 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39252; closing.
2024-02-07 06:46:58,790 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:58,790 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:58,791 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46095', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288418.7910788')
2024-02-07 06:46:58,791 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:58,791 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:58,792 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44833', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288418.792008')
2024-02-07 06:46:58,792 - distributed.nanny - INFO - Worker closed
2024-02-07 06:46:58,793 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39226; closing.
2024-02-07 06:46:58,793 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39194; closing.
2024-02-07 06:46:58,794 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34019', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288418.7945857')
2024-02-07 06:46:58,794 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35555', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288418.7949154')
2024-02-07 06:46:58,795 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39238; closing.
2024-02-07 06:46:58,795 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39210; closing.
2024-02-07 06:46:58,795 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39262; closing.
2024-02-07 06:46:58,795 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39258; closing.
2024-02-07 06:46:58,796 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39319', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288418.7963626')
2024-02-07 06:46:58,796 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42387', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288418.7968967')
2024-02-07 06:46:58,797 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45469', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288418.797251')
2024-02-07 06:46:58,797 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38659', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288418.7975867')
2024-02-07 06:46:58,797 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:46:59,699 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:46:59,700 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:46:59,700 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:46:59,701 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:46:59,702 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-02-07 06:47:01,768 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:01,771 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-02-07 06:47:01,774 - distributed.scheduler - INFO - State start
2024-02-07 06:47:01,794 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:01,794 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:47:01,795 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-02-07 06:47:01,795 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:47:01,963 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46143'
2024-02-07 06:47:01,973 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44367'
2024-02-07 06:47:01,985 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39497'
2024-02-07 06:47:01,995 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46101'
2024-02-07 06:47:01,999 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44955'
2024-02-07 06:47:02,007 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38767'
2024-02-07 06:47:02,015 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44207'
2024-02-07 06:47:02,023 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36613'
2024-02-07 06:47:02,528 - distributed.scheduler - INFO - Receive client connection: Client-b1998f56-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:02,541 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40508
2024-02-07 06:47:03,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:03,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:03,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:03,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:03,785 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:03,786 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44881
2024-02-07 06:47:03,786 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44881
2024-02-07 06:47:03,786 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36961
2024-02-07 06:47:03,786 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:03,786 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:03,786 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:03,786 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:03,786 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vmn05jjl
2024-02-07 06:47:03,787 - distributed.worker - INFO - Starting Worker plugin RMMSetup-67bc46a5-7ade-4f41-99cf-e5873bb4f4e8
2024-02-07 06:47:03,787 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:03,788 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37913
2024-02-07 06:47:03,788 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37913
2024-02-07 06:47:03,788 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46417
2024-02-07 06:47:03,788 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:03,788 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:03,788 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:03,788 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:03,788 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3ed7_5ik
2024-02-07 06:47:03,789 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b1758c1-ddb7-4896-87bd-79ec869d68a1
2024-02-07 06:47:03,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:03,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:03,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:03,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:03,848 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:03,848 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:03,849 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40677
2024-02-07 06:47:03,849 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46009
2024-02-07 06:47:03,849 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40677
2024-02-07 06:47:03,849 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46009
2024-02-07 06:47:03,849 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37995
2024-02-07 06:47:03,849 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46159
2024-02-07 06:47:03,849 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:03,849 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:03,849 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:03,849 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:03,850 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:03,850 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:03,850 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:03,850 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:03,850 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pes6qb3b
2024-02-07 06:47:03,850 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pvia49y7
2024-02-07 06:47:03,850 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1de04d2e-bece-478a-bea2-1e155b33e913
2024-02-07 06:47:03,850 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-57344b1f-ba67-4422-83d3-fc2ad38162ed
2024-02-07 06:47:03,850 - distributed.worker - INFO - Starting Worker plugin PreImport-25f86da1-6c56-4d01-b89e-c769cfacb567
2024-02-07 06:47:03,851 - distributed.worker - INFO - Starting Worker plugin RMMSetup-412c7505-bd6f-41d3-bd9d-79c2bd4ae176
2024-02-07 06:47:03,855 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c04a07eb-e319-44eb-bf90-0707594474e6
2024-02-07 06:47:03,871 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:03,871 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:03,875 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:03,876 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43027
2024-02-07 06:47:03,876 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43027
2024-02-07 06:47:03,876 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41295
2024-02-07 06:47:03,877 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:03,877 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:03,877 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:03,877 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:03,877 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1j65fxnu
2024-02-07 06:47:03,877 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bf71ec89-8cf5-4f00-83e8-1d1291dfc99f
2024-02-07 06:47:04,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:04,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:04,175 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:04,176 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38019
2024-02-07 06:47:04,176 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38019
2024-02-07 06:47:04,176 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33463
2024-02-07 06:47:04,176 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:04,176 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:04,176 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:04,177 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:04,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:04,177 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4nsqlsra
2024-02-07 06:47:04,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:04,177 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-af527c9b-9a77-4d46-b5eb-7cd7c8fa08ce
2024-02-07 06:47:04,177 - distributed.worker - INFO - Starting Worker plugin PreImport-8220758e-0a2b-4c5e-a5f0-bc14e1dccd8b
2024-02-07 06:47:04,177 - distributed.worker - INFO - Starting Worker plugin RMMSetup-169b3fe7-2998-425b-af06-59bc164b74fe
2024-02-07 06:47:04,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:04,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:04,181 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:04,182 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37707
2024-02-07 06:47:04,182 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37707
2024-02-07 06:47:04,182 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40297
2024-02-07 06:47:04,182 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:04,182 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:04,182 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:04,182 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:04,182 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qle_961m
2024-02-07 06:47:04,182 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3a42a96f-8d70-45dd-a183-7e2dfa8d836c
2024-02-07 06:47:04,185 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:04,186 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45477
2024-02-07 06:47:04,187 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45477
2024-02-07 06:47:04,187 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38791
2024-02-07 06:47:04,187 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:04,187 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:04,187 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:04,187 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:04,187 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-iqwpzovx
2024-02-07 06:47:04,187 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1a27b08a-c1f9-4237-b1e1-8e90bd175b23
2024-02-07 06:47:04,187 - distributed.worker - INFO - Starting Worker plugin RMMSetup-310c11c1-ea7c-4d16-b9c0-2074de4dfa86
2024-02-07 06:47:05,819 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ad514e6e-9439-4d0a-9b07-ae3c16590bc5
2024-02-07 06:47:05,821 - distributed.worker - INFO - Starting Worker plugin PreImport-3d93ea95-01d0-48c5-a708-a88735971e99
2024-02-07 06:47:05,822 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:05,852 - distributed.worker - INFO - Starting Worker plugin PreImport-389ce94f-068b-4934-a9ce-52bd76d8c046
2024-02-07 06:47:05,852 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1633c65a-46bd-4305-8374-c8123925496e
2024-02-07 06:47:05,854 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:05,856 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44881', status: init, memory: 0, processing: 0>
2024-02-07 06:47:05,858 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44881
2024-02-07 06:47:05,858 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40524
2024-02-07 06:47:05,860 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:05,861 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:05,861 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:05,863 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:05,887 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37913', status: init, memory: 0, processing: 0>
2024-02-07 06:47:05,887 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37913
2024-02-07 06:47:05,887 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40540
2024-02-07 06:47:05,889 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:05,890 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:05,890 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:05,892 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:06,011 - distributed.worker - INFO - Starting Worker plugin PreImport-9a11fb34-5ffb-4dfc-86c1-09b6a11c7a0a
2024-02-07 06:47:06,011 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b10bca61-2ce4-4537-b291-2d4c8a57368f
2024-02-07 06:47:06,012 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,013 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,020 - distributed.worker - INFO - Starting Worker plugin PreImport-8d4b12e5-3dd7-481f-a776-d7efde4a428d
2024-02-07 06:47:06,022 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,037 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43027', status: init, memory: 0, processing: 0>
2024-02-07 06:47:06,038 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43027
2024-02-07 06:47:06,038 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40552
2024-02-07 06:47:06,038 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:06,039 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:06,039 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,041 - distributed.worker - INFO - Starting Worker plugin PreImport-20c4ce11-ec6f-4019-b476-dbb2b575f182
2024-02-07 06:47:06,041 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:06,041 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,048 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40677', status: init, memory: 0, processing: 0>
2024-02-07 06:47:06,049 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40677
2024-02-07 06:47:06,049 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40558
2024-02-07 06:47:06,051 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:06,052 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:06,052 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,054 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:06,056 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46009', status: init, memory: 0, processing: 0>
2024-02-07 06:47:06,057 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,057 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46009
2024-02-07 06:47:06,057 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40560
2024-02-07 06:47:06,059 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:06,059 - distributed.worker - INFO - Starting Worker plugin PreImport-f53892c0-0bc0-46d7-8657-b4a5f166992f
2024-02-07 06:47:06,060 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dfd3fc41-4e9c-4863-9056-38ae6dcc5b28
2024-02-07 06:47:06,060 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:06,060 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,061 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,062 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45477', status: init, memory: 0, processing: 0>
2024-02-07 06:47:06,062 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:06,062 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45477
2024-02-07 06:47:06,063 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40570
2024-02-07 06:47:06,063 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:06,064 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:06,064 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,065 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:06,079 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38019', status: init, memory: 0, processing: 0>
2024-02-07 06:47:06,080 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38019
2024-02-07 06:47:06,080 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40576
2024-02-07 06:47:06,081 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:06,081 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:06,081 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,082 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37707', status: init, memory: 0, processing: 0>
2024-02-07 06:47:06,083 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37707
2024-02-07 06:47:06,083 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40582
2024-02-07 06:47:06,083 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:06,084 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:06,084 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:06,084 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:06,086 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:06,117 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:06,118 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:06,118 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:06,118 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:06,118 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:06,119 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:06,119 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:06,119 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:06,129 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:47:06,129 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:47:06,129 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:47:06,129 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:47:06,129 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:47:06,129 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:47:06,129 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:47:06,130 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:47:06,137 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:06,138 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:06,140 - distributed.scheduler - INFO - Remove client Client-b1998f56-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:06,140 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40508; closing.
2024-02-07 06:47:06,141 - distributed.scheduler - INFO - Remove client Client-b1998f56-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:06,141 - distributed.scheduler - INFO - Close client connection: Client-b1998f56-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:06,142 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46143'. Reason: nanny-close
2024-02-07 06:47:06,142 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:06,143 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44367'. Reason: nanny-close
2024-02-07 06:47:06,143 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:06,143 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39497'. Reason: nanny-close
2024-02-07 06:47:06,144 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:06,144 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44881. Reason: nanny-close
2024-02-07 06:47:06,144 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46101'. Reason: nanny-close
2024-02-07 06:47:06,144 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:06,144 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37913. Reason: nanny-close
2024-02-07 06:47:06,144 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44955'. Reason: nanny-close
2024-02-07 06:47:06,145 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38019. Reason: nanny-close
2024-02-07 06:47:06,145 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:06,145 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38767'. Reason: nanny-close
2024-02-07 06:47:06,145 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43027. Reason: nanny-close
2024-02-07 06:47:06,145 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:06,145 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44207'. Reason: nanny-close
2024-02-07 06:47:06,146 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:06,146 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40677. Reason: nanny-close
2024-02-07 06:47:06,146 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36613'. Reason: nanny-close
2024-02-07 06:47:06,146 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:06,146 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:06,146 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46009. Reason: nanny-close
2024-02-07 06:47:06,146 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:06,146 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40524; closing.
2024-02-07 06:47:06,146 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45477. Reason: nanny-close
2024-02-07 06:47:06,146 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44881', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288426.1469138')
2024-02-07 06:47:06,146 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:06,147 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:06,147 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37707. Reason: nanny-close
2024-02-07 06:47:06,147 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40576; closing.
2024-02-07 06:47:06,147 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:06,148 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38019', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288426.1479423')
2024-02-07 06:47:06,148 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:06,148 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40540; closing.
2024-02-07 06:47:06,148 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:06,148 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:06,148 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:06,148 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:06,149 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:06,149 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:06,149 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37913', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288426.1494844')
2024-02-07 06:47:06,149 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:06,149 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40552; closing.
2024-02-07 06:47:06,150 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:06,150 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:06,150 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:06,150 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:40576>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 262, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-02-07 06:47:06,152 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43027', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288426.1525154')
2024-02-07 06:47:06,152 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40558; closing.
2024-02-07 06:47:06,153 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40570; closing.
2024-02-07 06:47:06,153 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40560; closing.
2024-02-07 06:47:06,154 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40677', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288426.1539826')
2024-02-07 06:47:06,154 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45477', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288426.1543913')
2024-02-07 06:47:06,154 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46009', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288426.1548193')
2024-02-07 06:47:06,155 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40582; closing.
2024-02-07 06:47:06,155 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37707', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288426.1557336')
2024-02-07 06:47:06,155 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:47:07,008 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:47:07,008 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:47:07,009 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:47:07,010 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:47:07,010 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-02-07 06:47:09,119 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:09,124 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-02-07 06:47:09,127 - distributed.scheduler - INFO - State start
2024-02-07 06:47:09,149 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:09,150 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:47:09,150 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-02-07 06:47:09,150 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:47:09,153 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35229'
2024-02-07 06:47:09,174 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45171'
2024-02-07 06:47:09,176 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35985'
2024-02-07 06:47:09,184 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44557'
2024-02-07 06:47:09,201 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43933'
2024-02-07 06:47:09,204 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40811'
2024-02-07 06:47:09,279 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43019'
2024-02-07 06:47:09,303 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37675'
2024-02-07 06:47:09,437 - distributed.scheduler - INFO - Receive client connection: Client-b5ed1c18-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:09,450 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41024
2024-02-07 06:47:11,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:11,039 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:11,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:11,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:11,043 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:11,044 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41085
2024-02-07 06:47:11,044 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41085
2024-02-07 06:47:11,044 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35807
2024-02-07 06:47:11,044 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:11,044 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:11,044 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:11,044 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:11,044 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_rmtb4fy
2024-02-07 06:47:11,044 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8493dc72-85a4-403f-bae2-e56306924fb3
2024-02-07 06:47:11,045 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9443ce75-7b76-4f6f-adfd-21b2cfcc2d3f
2024-02-07 06:47:11,045 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:11,046 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36081
2024-02-07 06:47:11,046 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36081
2024-02-07 06:47:11,046 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38723
2024-02-07 06:47:11,046 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:11,046 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:11,046 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:11,046 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:11,046 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bmw_n9lj
2024-02-07 06:47:11,047 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-683373f3-c5bc-4f21-8943-964cfcda7363
2024-02-07 06:47:11,047 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a1224aca-945a-4535-8aea-862e10b8db55
2024-02-07 06:47:11,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:11,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:11,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:11,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:11,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:11,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:11,092 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:11,093 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:11,093 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:11,093 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32857
2024-02-07 06:47:11,093 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32857
2024-02-07 06:47:11,093 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37847
2024-02-07 06:47:11,093 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:11,093 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:11,093 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:11,093 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:11,093 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mhk076kg
2024-02-07 06:47:11,093 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44179
2024-02-07 06:47:11,094 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d788486d-44e0-479e-8b09-a54aad38e75a
2024-02-07 06:47:11,094 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44179
2024-02-07 06:47:11,094 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43451
2024-02-07 06:47:11,094 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:11,094 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39057
2024-02-07 06:47:11,094 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:11,094 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39057
2024-02-07 06:47:11,094 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:11,094 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46553
2024-02-07 06:47:11,094 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:11,094 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:11,094 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:11,094 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jhi977dr
2024-02-07 06:47:11,094 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:11,094 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:11,094 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u7geg_k1
2024-02-07 06:47:11,094 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5e5b82bf-c1f3-4c6c-820e-a439b9f5d06b
2024-02-07 06:47:11,094 - distributed.worker - INFO - Starting Worker plugin PreImport-1c01f1fc-405f-47f0-8d37-cccf57a1e258
2024-02-07 06:47:11,094 - distributed.worker - INFO - Starting Worker plugin RMMSetup-75c78604-eae9-4b0a-8d24-0521489cb100
2024-02-07 06:47:11,094 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9d0a040d-80e4-4b37-a212-e49bff575e90
2024-02-07 06:47:11,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:11,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:11,360 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:11,361 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36277
2024-02-07 06:47:11,361 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36277
2024-02-07 06:47:11,361 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36711
2024-02-07 06:47:11,361 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:11,361 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:11,361 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:11,361 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:11,361 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-izpwjfgq
2024-02-07 06:47:11,362 - distributed.worker - INFO - Starting Worker plugin RMMSetup-718244de-d4be-4316-8c95-62a20287af56
2024-02-07 06:47:11,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:11,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:11,512 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:11,512 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46527
2024-02-07 06:47:11,512 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46527
2024-02-07 06:47:11,513 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39575
2024-02-07 06:47:11,513 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:11,513 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:11,513 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:11,513 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:11,513 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lvc_ay_4
2024-02-07 06:47:11,513 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bc1a1bcc-e54a-4a3f-8c18-89f3351a6749
2024-02-07 06:47:11,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:11,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:11,537 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:11,538 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35261
2024-02-07 06:47:11,538 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35261
2024-02-07 06:47:11,539 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46841
2024-02-07 06:47:11,539 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:11,539 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:11,539 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:11,539 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:11,539 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lt9hcdlf
2024-02-07 06:47:11,539 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2764f5bb-06d8-4702-846f-46e44719c0d0
2024-02-07 06:47:11,540 - distributed.worker - INFO - Starting Worker plugin PreImport-66ae08a6-a852-4e5c-ab00-9d2f410f1c81
2024-02-07 06:47:11,540 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f24b1e01-a421-4e23-84be-532154eff447
2024-02-07 06:47:13,042 - distributed.worker - INFO - Starting Worker plugin PreImport-3e7ce60d-97d4-422b-8291-03207eac92c5
2024-02-07 06:47:13,044 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,075 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41085', status: init, memory: 0, processing: 0>
2024-02-07 06:47:13,076 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41085
2024-02-07 06:47:13,076 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36646
2024-02-07 06:47:13,078 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:13,079 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:13,079 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,081 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:13,089 - distributed.worker - INFO - Starting Worker plugin PreImport-a3daab2e-a3fc-4fa3-a8da-349a302d6bd2
2024-02-07 06:47:13,090 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,112 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36081', status: init, memory: 0, processing: 0>
2024-02-07 06:47:13,113 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36081
2024-02-07 06:47:13,113 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36650
2024-02-07 06:47:13,114 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:13,115 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:13,115 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,116 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:13,138 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5e143812-47e5-4f1b-a55c-a054cdb70553
2024-02-07 06:47:13,139 - distributed.worker - INFO - Starting Worker plugin PreImport-f9ee1de9-cf75-4960-9851-78977d38388e
2024-02-07 06:47:13,140 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,173 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32857', status: init, memory: 0, processing: 0>
2024-02-07 06:47:13,174 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32857
2024-02-07 06:47:13,174 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36654
2024-02-07 06:47:13,175 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:13,176 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:13,176 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,178 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:13,190 - distributed.worker - INFO - Starting Worker plugin PreImport-b672eb0d-3397-4e7d-bb5f-07bfc9e9518b
2024-02-07 06:47:13,191 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8ffdbcf4-00c3-4db4-9349-3ee70ec1d83f
2024-02-07 06:47:13,192 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,194 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,215 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39057', status: init, memory: 0, processing: 0>
2024-02-07 06:47:13,215 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39057
2024-02-07 06:47:13,215 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36658
2024-02-07 06:47:13,216 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44179', status: init, memory: 0, processing: 0>
2024-02-07 06:47:13,216 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:13,216 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44179
2024-02-07 06:47:13,216 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36664
2024-02-07 06:47:13,217 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:13,217 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,217 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:13,218 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:13,218 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,218 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:13,219 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:13,251 - distributed.worker - INFO - Starting Worker plugin PreImport-817bce8b-29a1-4954-854f-8396c4aefc7d
2024-02-07 06:47:13,251 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5ea9d18f-7b1b-4fc4-8bcf-684ff5832e79
2024-02-07 06:47:13,251 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,270 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36277', status: init, memory: 0, processing: 0>
2024-02-07 06:47:13,271 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36277
2024-02-07 06:47:13,271 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36672
2024-02-07 06:47:13,272 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:13,273 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:13,273 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,274 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:13,290 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,313 - distributed.worker - INFO - Starting Worker plugin PreImport-2091a168-9d00-4dcc-996a-0092eccf0ac0
2024-02-07 06:47:13,313 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ce1cc429-9fc3-46a3-aee8-d0cf2cf9af55
2024-02-07 06:47:13,314 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,315 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35261', status: init, memory: 0, processing: 0>
2024-02-07 06:47:13,316 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35261
2024-02-07 06:47:13,316 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36688
2024-02-07 06:47:13,317 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:13,318 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:13,318 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,320 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:13,347 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46527', status: init, memory: 0, processing: 0>
2024-02-07 06:47:13,348 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46527
2024-02-07 06:47:13,348 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36696
2024-02-07 06:47:13,349 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:13,350 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:13,350 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:13,353 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:13,394 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:13,394 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:13,394 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:13,395 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:13,395 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:13,395 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:13,396 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:13,396 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:13,401 - distributed.scheduler - INFO - Remove client Client-b5ed1c18-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:13,401 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41024; closing.
2024-02-07 06:47:13,402 - distributed.scheduler - INFO - Remove client Client-b5ed1c18-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:13,403 - distributed.scheduler - INFO - Close client connection: Client-b5ed1c18-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:13,403 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44557'. Reason: nanny-close
2024-02-07 06:47:13,404 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:13,404 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37675'. Reason: nanny-close
2024-02-07 06:47:13,404 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:13,405 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35985'. Reason: nanny-close
2024-02-07 06:47:13,405 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32857. Reason: nanny-close
2024-02-07 06:47:13,405 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:13,405 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43933'. Reason: nanny-close
2024-02-07 06:47:13,405 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46527. Reason: nanny-close
2024-02-07 06:47:13,405 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:13,405 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43019'. Reason: nanny-close
2024-02-07 06:47:13,405 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44179. Reason: nanny-close
2024-02-07 06:47:13,406 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:13,406 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45171'. Reason: nanny-close
2024-02-07 06:47:13,406 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39057. Reason: nanny-close
2024-02-07 06:47:13,406 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:13,406 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35229'. Reason: nanny-close
2024-02-07 06:47:13,406 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35261. Reason: nanny-close
2024-02-07 06:47:13,406 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:13,407 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40811'. Reason: nanny-close
2024-02-07 06:47:13,407 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:13,407 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41085. Reason: nanny-close
2024-02-07 06:47:13,407 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:13,407 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36664; closing.
2024-02-07 06:47:13,407 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:13,407 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36081. Reason: nanny-close
2024-02-07 06:47:13,408 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:13,408 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36277. Reason: nanny-close
2024-02-07 06:47:13,408 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44179', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288433.4082685')
2024-02-07 06:47:13,409 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:13,409 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:13,409 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:13,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36654; closing.
2024-02-07 06:47:13,409 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:13,410 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:13,410 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:13,410 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:13,410 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:13,410 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32857', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288433.4108717')
2024-02-07 06:47:13,411 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36658; closing.
2024-02-07 06:47:13,411 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:13,411 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:13,411 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36696; closing.
2024-02-07 06:47:13,412 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:13,412 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:13,412 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:13,413 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39057', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288433.4136796')
2024-02-07 06:47:13,414 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46527', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288433.4142358')
2024-02-07 06:47:13,414 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36688; closing.
2024-02-07 06:47:13,415 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36654>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 262, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-02-07 06:47:13,418 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36658>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36658>: Stream is closed
2024-02-07 06:47:13,419 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35261', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288433.4198444')
2024-02-07 06:47:13,420 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36646; closing.
2024-02-07 06:47:13,420 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36650; closing.
2024-02-07 06:47:13,421 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36672; closing.
2024-02-07 06:47:13,421 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41085', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288433.4216335')
2024-02-07 06:47:13,422 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36081', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288433.4222093')
2024-02-07 06:47:13,422 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36277', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288433.4227617')
2024-02-07 06:47:13,423 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:47:14,319 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:47:14,320 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:47:14,320 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:47:14,322 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:47:14,322 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-02-07 06:47:16,448 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:16,453 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41979 instead
  warnings.warn(
2024-02-07 06:47:16,457 - distributed.scheduler - INFO - State start
2024-02-07 06:47:16,478 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:16,479 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:47:16,480 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41979/status
2024-02-07 06:47:16,480 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:47:16,506 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45639'
2024-02-07 06:47:16,717 - distributed.scheduler - INFO - Receive client connection: Client-ba5903c9-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:16,737 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36772
2024-02-07 06:47:18,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:18,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:18,646 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:18,648 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46039
2024-02-07 06:47:18,648 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46039
2024-02-07 06:47:18,648 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-02-07 06:47:18,648 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:18,648 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:18,648 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:18,648 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-02-07 06:47:18,648 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1fj69eh1
2024-02-07 06:47:18,649 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-292facee-3d3a-494f-b7cf-4d7a1f240be3
2024-02-07 06:47:18,649 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cab37872-a339-464e-9ca2-b5a9a61f24fe
2024-02-07 06:47:18,650 - distributed.worker - INFO - Starting Worker plugin PreImport-0e0e98ad-e3ee-4c4d-97d5-8a5675b60308
2024-02-07 06:47:18,650 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:18,707 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46039', status: init, memory: 0, processing: 0>
2024-02-07 06:47:18,708 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46039
2024-02-07 06:47:18,708 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36800
2024-02-07 06:47:18,709 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:18,710 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:18,710 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:18,712 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:18,780 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:18,782 - distributed.scheduler - INFO - Remove client Client-ba5903c9-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:18,783 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36772; closing.
2024-02-07 06:47:18,783 - distributed.scheduler - INFO - Remove client Client-ba5903c9-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:18,784 - distributed.scheduler - INFO - Close client connection: Client-ba5903c9-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:18,784 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45639'. Reason: nanny-close
2024-02-07 06:47:18,785 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:18,786 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46039. Reason: nanny-close
2024-02-07 06:47:18,788 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36800; closing.
2024-02-07 06:47:18,788 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:18,789 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46039', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288438.7890632')
2024-02-07 06:47:18,789 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:47:18,790 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:19,450 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:47:19,450 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:47:19,451 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:47:19,452 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:47:19,452 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-02-07 06:47:23,512 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:23,516 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32885 instead
  warnings.warn(
2024-02-07 06:47:23,520 - distributed.scheduler - INFO - State start
2024-02-07 06:47:23,540 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:23,541 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:47:23,542 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:32885/status
2024-02-07 06:47:23,542 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:47:23,724 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35107'
2024-02-07 06:47:25,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:25,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:25,543 - distributed.scheduler - INFO - Receive client connection: Client-be8c779d-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:25,554 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38468
2024-02-07 06:47:26,153 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:26,154 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33017
2024-02-07 06:47:26,154 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33017
2024-02-07 06:47:26,154 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39733
2024-02-07 06:47:26,154 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:26,155 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:26,155 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:26,155 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-02-07 06:47:26,155 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0qsqxuu5
2024-02-07 06:47:26,155 - distributed.worker - INFO - Starting Worker plugin PreImport-abde627c-f89f-4b3c-aab4-d7ed3bb4eae8
2024-02-07 06:47:26,156 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f068db72-257e-409a-b6d2-fb7abd32deb7
2024-02-07 06:47:26,156 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f1da85f8-6d54-4dff-a91d-c9ae6517e0ad
2024-02-07 06:47:26,156 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:26,207 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33017', status: init, memory: 0, processing: 0>
2024-02-07 06:47:26,208 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33017
2024-02-07 06:47:26,208 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38488
2024-02-07 06:47:26,209 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:26,209 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:26,209 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:26,211 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:26,273 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:26,276 - distributed.scheduler - INFO - Remove client Client-be8c779d-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:26,276 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38468; closing.
2024-02-07 06:47:26,276 - distributed.scheduler - INFO - Remove client Client-be8c779d-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:26,277 - distributed.scheduler - INFO - Close client connection: Client-be8c779d-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:26,277 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35107'. Reason: nanny-close
2024-02-07 06:47:26,278 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:26,279 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33017. Reason: nanny-close
2024-02-07 06:47:26,281 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38488; closing.
2024-02-07 06:47:26,281 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:26,282 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33017', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288446.2820435')
2024-02-07 06:47:26,282 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:47:26,283 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:27,045 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:47:27,045 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:47:27,046 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:47:27,047 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:47:27,047 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-02-07 06:47:29,170 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:29,174 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-02-07 06:47:29,178 - distributed.scheduler - INFO - State start
2024-02-07 06:47:29,199 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:29,200 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:47:29,200 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-02-07 06:47:29,201 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:47:31,429 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:38498'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 970, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4440, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:38498>: Stream is closed
2024-02-07 06:47:31,639 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:47:31,639 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:47:31,640 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:47:31,641 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:47:31,642 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-02-07 06:47:33,767 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:33,772 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-02-07 06:47:33,775 - distributed.scheduler - INFO - State start
2024-02-07 06:47:33,795 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:33,796 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-02-07 06:47:33,796 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-02-07 06:47:33,796 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:47:33,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43967'
2024-02-07 06:47:34,080 - distributed.scheduler - INFO - Receive client connection: Client-c4b0dfcc-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:34,092 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48904
2024-02-07 06:47:35,443 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:35,443 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:35,447 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:35,447 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33521
2024-02-07 06:47:35,448 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33521
2024-02-07 06:47:35,448 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33437
2024-02-07 06:47:35,448 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-02-07 06:47:35,448 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:35,448 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:35,448 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-02-07 06:47:35,448 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-13ree72_
2024-02-07 06:47:35,448 - distributed.worker - INFO - Starting Worker plugin RMMSetup-25cad901-e968-4f74-ab9d-1bc27946d65c
2024-02-07 06:47:35,448 - distributed.worker - INFO - Starting Worker plugin PreImport-8b8dc18f-7a51-44a9-be49-2db2851150a4
2024-02-07 06:47:35,448 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-548e82bb-05cd-40ef-a7f6-b78e2ce39795
2024-02-07 06:47:35,448 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:35,500 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33521', status: init, memory: 0, processing: 0>
2024-02-07 06:47:35,501 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33521
2024-02-07 06:47:35,502 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48916
2024-02-07 06:47:35,502 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:35,503 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-02-07 06:47:35,503 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:35,504 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-02-07 06:47:35,550 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:35,553 - distributed.scheduler - INFO - Remove client Client-c4b0dfcc-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:35,553 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48904; closing.
2024-02-07 06:47:35,553 - distributed.scheduler - INFO - Remove client Client-c4b0dfcc-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:35,554 - distributed.scheduler - INFO - Close client connection: Client-c4b0dfcc-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:35,554 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43967'. Reason: nanny-close
2024-02-07 06:47:35,555 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:35,556 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33521. Reason: nanny-close
2024-02-07 06:47:35,557 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-02-07 06:47:35,557 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48916; closing.
2024-02-07 06:47:35,558 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33521', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288455.5580728')
2024-02-07 06:47:35,558 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:47:35,559 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:36,019 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:47:36,020 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:47:36,020 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:47:36,021 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-02-07 06:47:36,021 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-02-07 06:47:38,166 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:38,171 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-02-07 06:47:38,174 - distributed.scheduler - INFO - State start
2024-02-07 06:47:38,196 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:38,197 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:47:38,197 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-02-07 06:47:38,198 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:47:38,337 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44055'
2024-02-07 06:47:38,354 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35353'
2024-02-07 06:47:38,356 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41473'
2024-02-07 06:47:38,364 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41221'
2024-02-07 06:47:38,374 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43911'
2024-02-07 06:47:38,382 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35387'
2024-02-07 06:47:38,390 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43689'
2024-02-07 06:47:38,400 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37793'
2024-02-07 06:47:38,634 - distributed.scheduler - INFO - Receive client connection: Client-c7385b92-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:38,648 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49752
2024-02-07 06:47:40,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:40,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:40,199 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:40,200 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44617
2024-02-07 06:47:40,200 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44617
2024-02-07 06:47:40,200 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38273
2024-02-07 06:47:40,200 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:40,200 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:40,200 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:40,200 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:40,200 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ea0s8b_c
2024-02-07 06:47:40,200 - distributed.worker - INFO - Starting Worker plugin RMMSetup-af66519f-661a-42c8-9291-a7fe44e67502
2024-02-07 06:47:40,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:40,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:40,209 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:40,210 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33249
2024-02-07 06:47:40,210 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33249
2024-02-07 06:47:40,210 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43563
2024-02-07 06:47:40,210 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:40,210 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:40,210 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:40,210 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:40,210 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vj_e27j8
2024-02-07 06:47:40,211 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-394f15ff-75b4-4b96-8488-1f835b932054
2024-02-07 06:47:40,211 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a15f5664-42ba-40df-aeda-840eebdc07b9
2024-02-07 06:47:40,226 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:40,226 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:40,226 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:40,226 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:40,230 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:40,230 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:40,231 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33959
2024-02-07 06:47:40,231 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33959
2024-02-07 06:47:40,231 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33645
2024-02-07 06:47:40,231 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:40,231 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36663
2024-02-07 06:47:40,231 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:40,231 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36663
2024-02-07 06:47:40,231 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:40,231 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36449
2024-02-07 06:47:40,232 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:40,232 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:40,232 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:40,232 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-iefauodw
2024-02-07 06:47:40,232 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:40,232 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:40,232 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0czz3qvh
2024-02-07 06:47:40,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-036d8673-b045-491e-82c5-aa98973eb6f5
2024-02-07 06:47:40,232 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4972440f-78e9-45c3-97c4-23d05c7b0c39
2024-02-07 06:47:40,232 - distributed.worker - INFO - Starting Worker plugin PreImport-e12a08b3-d8cf-48e2-825f-14d1703e8a41
2024-02-07 06:47:40,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cb98e772-a85a-4132-a013-8484505d07c9
2024-02-07 06:47:40,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:40,250 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:40,254 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:40,255 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38537
2024-02-07 06:47:40,255 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38537
2024-02-07 06:47:40,255 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44835
2024-02-07 06:47:40,255 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:40,255 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:40,255 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:40,255 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:40,255 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pptzyplk
2024-02-07 06:47:40,255 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dc74c6e2-5749-467c-9fe9-c4fd99c69e3f
2024-02-07 06:47:40,256 - distributed.worker - INFO - Starting Worker plugin RMMSetup-426efb80-ac52-420c-9ae2-4aab581ac5cf
2024-02-07 06:47:40,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:40,261 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:40,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:40,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:40,265 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:40,266 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44517
2024-02-07 06:47:40,266 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44517
2024-02-07 06:47:40,266 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36647
2024-02-07 06:47:40,266 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:40,266 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:40,266 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:40,266 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:40,266 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zm0fmegf
2024-02-07 06:47:40,266 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a77696e4-9126-4cec-82db-1389212f1a59
2024-02-07 06:47:40,267 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:40,268 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35571
2024-02-07 06:47:40,268 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35571
2024-02-07 06:47:40,268 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42325
2024-02-07 06:47:40,268 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:40,268 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:40,268 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:40,268 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:40,268 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3k6yordx
2024-02-07 06:47:40,269 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f965aedb-54f5-489a-97e1-f73b0a5bed53
2024-02-07 06:47:40,270 - distributed.worker - INFO - Starting Worker plugin PreImport-595445eb-5841-41e4-8137-cc284fec683f
2024-02-07 06:47:40,270 - distributed.worker - INFO - Starting Worker plugin RMMSetup-85aea11f-61c9-4bfd-b8fd-2445379edd4c
2024-02-07 06:47:40,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:40,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:40,323 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:40,324 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35975
2024-02-07 06:47:40,324 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35975
2024-02-07 06:47:40,324 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37205
2024-02-07 06:47:40,324 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:40,324 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:40,324 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:40,324 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-02-07 06:47:40,324 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tapt2fq9
2024-02-07 06:47:40,325 - distributed.worker - INFO - Starting Worker plugin RMMSetup-732a0a1e-e1b4-489a-8ab2-b358c67c2615
2024-02-07 06:47:42,246 - distributed.worker - INFO - Starting Worker plugin PreImport-d59d959e-c6a6-4215-9fa0-cd66b1deb7b6
2024-02-07 06:47:42,247 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3984c4dc-2531-483e-b651-421622f05ec8
2024-02-07 06:47:42,248 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,279 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44617', status: init, memory: 0, processing: 0>
2024-02-07 06:47:42,283 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44617
2024-02-07 06:47:42,283 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35248
2024-02-07 06:47:42,284 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:42,285 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:42,286 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,287 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:42,310 - distributed.worker - INFO - Starting Worker plugin PreImport-c9fee7be-b8c5-4a19-80ca-7cd614682cdb
2024-02-07 06:47:42,311 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,336 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33249', status: init, memory: 0, processing: 0>
2024-02-07 06:47:42,336 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33249
2024-02-07 06:47:42,337 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35256
2024-02-07 06:47:42,338 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:42,338 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:42,339 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,340 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:42,363 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,378 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-686e62f7-d8ae-4fba-85aa-f76eb8d633c7
2024-02-07 06:47:42,379 - distributed.worker - INFO - Starting Worker plugin PreImport-e00949f6-a281-428b-892b-483d82264b20
2024-02-07 06:47:42,380 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,384 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36663', status: init, memory: 0, processing: 0>
2024-02-07 06:47:42,385 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36663
2024-02-07 06:47:42,385 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35258
2024-02-07 06:47:42,386 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:42,386 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:42,387 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,388 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:42,399 - distributed.worker - INFO - Starting Worker plugin PreImport-e18af10f-0b1b-4014-8e44-a29ac3f036af
2024-02-07 06:47:42,401 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,413 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33959', status: init, memory: 0, processing: 0>
2024-02-07 06:47:42,413 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33959
2024-02-07 06:47:42,413 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35266
2024-02-07 06:47:42,415 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:42,416 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:42,416 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,418 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:42,431 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38537', status: init, memory: 0, processing: 0>
2024-02-07 06:47:42,431 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,432 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38537
2024-02-07 06:47:42,432 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35278
2024-02-07 06:47:42,433 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:42,434 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:42,435 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,437 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:42,443 - distributed.worker - INFO - Starting Worker plugin PreImport-98f9f7bf-f4db-4b65-b6bf-10ce508037f5
2024-02-07 06:47:42,444 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9766ce0a-6932-4ca4-9a04-4e56fa1d5c5e
2024-02-07 06:47:42,444 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,450 - distributed.worker - INFO - Starting Worker plugin PreImport-76b91ec9-8120-45a7-90b0-747804104904
2024-02-07 06:47:42,450 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fb15879d-7eaf-47bb-b2fa-cff0a8876fa4
2024-02-07 06:47:42,452 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,462 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35571', status: init, memory: 0, processing: 0>
2024-02-07 06:47:42,462 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35571
2024-02-07 06:47:42,462 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35294
2024-02-07 06:47:42,464 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:42,465 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35975', status: init, memory: 0, processing: 0>
2024-02-07 06:47:42,465 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35975
2024-02-07 06:47:42,465 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35306
2024-02-07 06:47:42,465 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:42,465 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,466 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:42,467 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:42,467 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,468 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:42,468 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:42,485 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44517', status: init, memory: 0, processing: 0>
2024-02-07 06:47:42,485 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44517
2024-02-07 06:47:42,485 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35318
2024-02-07 06:47:42,487 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:42,488 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:42,488 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:42,490 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:42,528 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:42,528 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:42,529 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:42,529 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:42,529 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:42,529 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:42,529 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:42,530 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-02-07 06:47:42,543 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:42,544 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:42,544 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:42,544 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:42,544 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:42,544 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:42,544 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:42,544 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:42,548 - distributed.scheduler - INFO - Remove client Client-c7385b92-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:42,549 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49752; closing.
2024-02-07 06:47:42,549 - distributed.scheduler - INFO - Remove client Client-c7385b92-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:42,549 - distributed.scheduler - INFO - Close client connection: Client-c7385b92-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:42,550 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44055'. Reason: nanny-close
2024-02-07 06:47:42,551 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:42,551 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35353'. Reason: nanny-close
2024-02-07 06:47:42,551 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:42,552 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41473'. Reason: nanny-close
2024-02-07 06:47:42,552 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:42,552 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33959. Reason: nanny-close
2024-02-07 06:47:42,552 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41221'. Reason: nanny-close
2024-02-07 06:47:42,552 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44517. Reason: nanny-close
2024-02-07 06:47:42,552 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:42,553 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43911'. Reason: nanny-close
2024-02-07 06:47:42,553 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36663. Reason: nanny-close
2024-02-07 06:47:42,553 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:42,553 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35387'. Reason: nanny-close
2024-02-07 06:47:42,554 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44617. Reason: nanny-close
2024-02-07 06:47:42,554 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:42,554 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43689'. Reason: nanny-close
2024-02-07 06:47:42,554 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35571. Reason: nanny-close
2024-02-07 06:47:42,554 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:42,554 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37793'. Reason: nanny-close
2024-02-07 06:47:42,555 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38537. Reason: nanny-close
2024-02-07 06:47:42,555 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:42,555 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35258; closing.
2024-02-07 06:47:42,555 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:42,555 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33249. Reason: nanny-close
2024-02-07 06:47:42,555 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36663', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288462.5556283')
2024-02-07 06:47:42,555 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:42,555 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:42,555 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35975. Reason: nanny-close
2024-02-07 06:47:42,556 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:42,556 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:42,556 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:42,557 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35248; closing.
2024-02-07 06:47:42,557 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35318; closing.
2024-02-07 06:47:42,557 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35266; closing.
2024-02-07 06:47:42,557 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:42,557 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:42,557 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:42,558 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:42,558 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44617', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288462.558434')
2024-02-07 06:47:42,558 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:42,558 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:42,558 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:42,558 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44517', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288462.558851')
2024-02-07 06:47:42,559 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33959', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288462.559297')
2024-02-07 06:47:42,559 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:42,559 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:42,561 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:42,560 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:35248>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:35248>: Stream is closed
2024-02-07 06:47:42,562 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35294; closing.
2024-02-07 06:47:42,563 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35256; closing.
2024-02-07 06:47:42,563 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35571', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288462.5636652')
2024-02-07 06:47:42,564 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33249', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288462.564019')
2024-02-07 06:47:42,564 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35278; closing.
2024-02-07 06:47:42,564 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35306; closing.
2024-02-07 06:47:42,565 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38537', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288462.564989')
2024-02-07 06:47:42,565 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35975', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288462.5653143')
2024-02-07 06:47:42,565 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:47:43,467 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:47:43,467 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:47:43,468 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:47:43,469 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:47:43,469 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-02-07 06:47:45,571 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:45,575 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37199 instead
  warnings.warn(
2024-02-07 06:47:45,579 - distributed.scheduler - INFO - State start
2024-02-07 06:47:45,602 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:45,603 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:47:45,604 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37199/status
2024-02-07 06:47:45,604 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:47:45,642 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45933'
2024-02-07 06:47:45,815 - distributed.scheduler - INFO - Receive client connection: Client-cbb73c79-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:45,829 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35462
2024-02-07 06:47:47,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:47,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:47,213 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:47,214 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41717
2024-02-07 06:47:47,214 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41717
2024-02-07 06:47:47,214 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44333
2024-02-07 06:47:47,215 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:47,215 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:47,215 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:47,215 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-02-07 06:47:47,215 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6eihf991
2024-02-07 06:47:47,215 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bc6eb9ae-b891-4176-b9f4-1d0367785579
2024-02-07 06:47:47,705 - distributed.worker - INFO - Starting Worker plugin PreImport-45ece4c5-a5bd-4e01-97b5-bf22f6048895
2024-02-07 06:47:47,705 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1df24b58-cc65-49a4-a936-c502d87bcb01
2024-02-07 06:47:47,706 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:47,765 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41717', status: init, memory: 0, processing: 0>
2024-02-07 06:47:47,766 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41717
2024-02-07 06:47:47,766 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35472
2024-02-07 06:47:47,767 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:47,768 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:47,768 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:47,769 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:47,771 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:47:47,775 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:47,776 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:47,779 - distributed.scheduler - INFO - Remove client Client-cbb73c79-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:47,779 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35462; closing.
2024-02-07 06:47:47,779 - distributed.scheduler - INFO - Remove client Client-cbb73c79-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:47,780 - distributed.scheduler - INFO - Close client connection: Client-cbb73c79-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:47,781 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45933'. Reason: nanny-close
2024-02-07 06:47:47,821 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:47,822 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41717. Reason: nanny-close
2024-02-07 06:47:47,824 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:47,824 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35472; closing.
2024-02-07 06:47:47,824 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41717', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288467.8247564')
2024-02-07 06:47:47,825 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:47:47,825 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:48,496 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:47:48,496 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:47:48,497 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:47:48,498 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:47:48,498 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-02-07 06:47:50,530 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:50,534 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34625 instead
  warnings.warn(
2024-02-07 06:47:50,538 - distributed.scheduler - INFO - State start
2024-02-07 06:47:50,559 - distributed.scheduler - INFO - -----------------------------------------------
2024-02-07 06:47:50,560 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-02-07 06:47:50,561 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34625/status
2024-02-07 06:47:50,561 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-02-07 06:47:50,783 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39289'
2024-02-07 06:47:52,017 - distributed.scheduler - INFO - Receive client connection: Client-cea81851-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:52,029 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37296
2024-02-07 06:47:52,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-02-07 06:47:52,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-02-07 06:47:52,480 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-02-07 06:47:52,480 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37645
2024-02-07 06:47:52,481 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37645
2024-02-07 06:47:52,481 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38415
2024-02-07 06:47:52,481 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-02-07 06:47:52,481 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:52,481 - distributed.worker - INFO -               Threads:                          1
2024-02-07 06:47:52,481 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-02-07 06:47:52,481 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yzmeebcd
2024-02-07 06:47:52,481 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f93d55d0-4c61-4a1d-8276-a4b5a60a4344
2024-02-07 06:47:52,947 - distributed.worker - INFO - Starting Worker plugin PreImport-3445edb4-23dc-4563-94da-86cb04718f9c
2024-02-07 06:47:52,948 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-78d01ed0-9f06-4d3d-9f6a-fef4989e0c1c
2024-02-07 06:47:52,949 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:53,011 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37645', status: init, memory: 0, processing: 0>
2024-02-07 06:47:53,012 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37645
2024-02-07 06:47:53,012 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37318
2024-02-07 06:47:53,013 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-02-07 06:47:53,015 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-02-07 06:47:53,015 - distributed.worker - INFO - -------------------------------------------------
2024-02-07 06:47:53,017 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-02-07 06:47:53,084 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-02-07 06:47:53,089 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-02-07 06:47:53,094 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:53,095 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-02-07 06:47:53,098 - distributed.scheduler - INFO - Remove client Client-cea81851-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:53,098 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37296; closing.
2024-02-07 06:47:53,098 - distributed.scheduler - INFO - Remove client Client-cea81851-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:53,098 - distributed.scheduler - INFO - Close client connection: Client-cea81851-c584-11ee-8cd5-d8c49764f6bb
2024-02-07 06:47:53,099 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39289'. Reason: nanny-close
2024-02-07 06:47:53,100 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-02-07 06:47:53,101 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37645. Reason: nanny-close
2024-02-07 06:47:53,104 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37318; closing.
2024-02-07 06:47:53,104 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-02-07 06:47:53,104 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37645', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1707288473.1045678')
2024-02-07 06:47:53,104 - distributed.scheduler - INFO - Lost all workers
2024-02-07 06:47:53,106 - distributed.nanny - INFO - Worker closed
2024-02-07 06:47:53,865 - distributed._signals - INFO - Received signal SIGINT (2)
2024-02-07 06:47:53,866 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-02-07 06:47:53,866 - distributed.scheduler - INFO - Scheduler closing all comms
2024-02-07 06:47:53,867 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-02-07 06:47:53,868 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45543 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37965 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35739 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38603 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39123 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] 2024-02-07 06:48:55,769 - distributed.scheduler - ERROR - broadcast to ucxx://10.33.225.163:46589 failed: CommClosedError: Connection closed by writer.
Inner exception: UCXXConnectionResetError('Endpoint 0x7f5ee0030380 error: Connection reset by remote peer')
Process SpawnProcess-6:
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_dgx.py", line 200, in _test_ucx_infiniband_nvlink
    assert all(client.run(check_ucx_options).values())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/client.py", line 2998, in run
    return self.sync(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 358, in sync
    return sync(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 434, in sync
    raise error
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 408, in f
    result = yield future
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/client.py", line 2903, in _run
    raise exc
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXConnectionResetError('Endpoint 0x7f5ee0030380 error: Connection reset by remote peer')
FAILED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] 2024-02-07 06:49:08,453 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #006] ep: 0x7f26fd0f8180, tag: 0xc193b608838b5868, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #006] ep: 0x7f26fd0f8180, tag: 0xc193b608838b5868, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43785 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42397 instead
  warnings.warn(
2024-02-07 06:50:13,050 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 413, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 841, in wait
  File "libucxx.pyx", line 825, in wait_yield
  File "libucxx.pyx", line 820, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45529 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43879 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43069 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34309 instead
  warnings.warn(
[1707288658.377883] [dgx13:59407:0]            sock.c:481  UCX  ERROR bind(fd=130 addr=0.0.0.0:44078) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39803 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36421 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33887 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40149 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43607 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46405 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36381 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45579 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46659 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33007 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40691 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40835 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35839 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38241 instead
  warnings.warn(
[1707289010.997760] [dgx13:63925:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:46904) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45705 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42231 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38343 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37593 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34265 instead
  warnings.warn(
2024-02-07 06:59:27,728 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 175, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 172, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 178, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 179, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 136, in as_buffer
    return buffer_class(owner=owner_class._from_host_memory(data))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 197, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory
std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 450, in read
    return await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 78, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 61, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 175, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 172, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 178, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 179, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 136, in as_buffer
    return buffer_class(owner=owner_class._from_host_memory(data))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 197, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory
2024-02-07 06:59:27,847 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f6a33f68730>>, <Task finished name='Task-7' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:203> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 206, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1299, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1025, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 450, in read
    return await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 78, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 61, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 175, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 172, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 178, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 179, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 136, in as_buffer
    return buffer_class(owner=owner_class._from_host_memory(data))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 197, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-7' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:203> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 206, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1299, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1025, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 450, in read
    return await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 78, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 61, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 175, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 172, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 178, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 179, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 136, in as_buffer
    return buffer_class(owner=owner_class._from_host_memory(data))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 197, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/conda-bld/work/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory
2024-02-07 06:59:29,850 - distributed.nanny - ERROR - Worker process died unexpectedly
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 9 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
