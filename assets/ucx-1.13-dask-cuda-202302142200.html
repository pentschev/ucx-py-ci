<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>junit-dask-cuda.xml</title>
    <style type="text/css">
        body {
    background-color: white;
    padding-bottom: 20em;
    margin: 0;
    min-height: 15cm;
}

h1, h2, h3, h4, h5, h6, h7 {
    font-family: sans-serif;
}

h1 {
    background-color: #007acc;
    color: white;
    padding: 3mm;
    margin-top: 0;
    margin-bottom: 1mm;
}

.footer {
    font-style: italic;
    font-size: small;
    text-align: right;
    padding: 1em;
}

.testsuite {
    padding-bottom: 2em;
    margin-left: 1em;
}

.proplist {
    width: 100%;
    margin-bottom: 2em;
    border-collapse: collapse;
    border: 1px solid grey;
}

.proplist th {
    background-color: silver;
    width: 5em;
    padding: 2px;
    padding-right: 1em;
    text-align: left;
}

.proplist td {
    padding: 2px;
}

.index-table {
    width: 90%;
    margin-left: 1em;
}

.index-table td {
    vertical-align: top;
    width: 50%;
}

.failure-index {

}

.toc {
    margin-bottom: 2em;
    font-family: monospace;
}

.stdio, pre {
    min-height: 1em;
    background-color: #1e1e1e;
    color: silver;
    padding: 0.5em;
}
.tdpre {
    background-color: #1e1e1e;
}

.test {
    margin-left: 0.5cm;
}

.outcome {
    border-left: 1em;
    padding: 2px;
}

.outcome-failed {
    border-left: 1em solid lightcoral;
}

.outcome-passed {
    border-left: 1em solid lightgreen;
}

.outcome-skipped {
    border-left: 1em solid lightyellow;
}

.stats-table {
}

.stats-table td {
    min-width: 4em;
    text-align: right;
}

.stats-table .failed {
    background-color: lightcoral;
}

.stats-table .passed {
    background-color: lightgreen;
}

.matrix-table {
    table-layout: fixed;
    border-spacing: 0;
    width: available;
    margin-left: 1em;
}

.matrix-table td {
    vertical-align: center;
}

.matrix-table td:last-child {
    width: 0;
}

.matrix-table tr:hover {
    background-color: yellow;
}

.matrix-axis-name {
    white-space: nowrap;
    padding-right: 0.5em;
    border-left: 1px solid black;
    border-top: 1px solid black;
    text-align: right;
}

.matrix-axis-line {
    border-left: 1px solid black;
    width: 0.5em;
}

.matrix-classname {
    text-align: left;
    width: 100%;
    border-top: 2px solid grey;
    border-bottom: 1px solid silver;
}

.matrix-casename {
    text-align: left;
    font-weight: normal;
    font-style: italic;
    padding-left: 1em;
    border-bottom: 1px solid silver;
}

.matrix-result {
    display: block;
    width: 1em;
    text-align: center;
    padding: 1mm;
    margin: 0;
}

.matrix-result-combined {
    white-space: nowrap;
    padding-right: 0.2em;
    text-align: right;
}

.matrix-result-failed {
    background-color: lightcoral;
}

.matrix-result-passed {
    background-color: lightgreen;
}

.matrix-result-skipped {
    background-color: lightyellow;
}

.matrix-even {
    background-color: lightgray;
}
    </style>
</head>
<body>
    
<h1>
    Test Report : junit-dask-cuda.xml
</h1>
<a id="toc"></a>
<table class="index-table">
    <tr>
        <td>
            <ul class="toc">
            
                
                <li>dask_cuda.tests.test_cudf_builtin_spilling
                <ul>
                    
                    <li><a href="#c96d06f2-b8c2-4e74-a3f2-e674e861b50d">test_is_spillable_object_when_cudf_spilling_disabled</a></li>
                    
                    <li><a href="#13df642a-9d27-46a7-947a-69f32f78ef99">test_is_spillable_object_when_cudf_spilling_enabled</a></li>
                    
                    <li><a href="#33656a36-2919-41a7-845f-d0d9be4927da">test_device_host_file_when_cudf_spilling_is_disabled</a></li>
                    
                    <li><a href="#cec32964-1b16-4123-920d-06b469fcdc8e">test_device_host_file_step_by_step</a></li>
                    
                    <li><a href="#aab878d3-51bd-4919-9c98-003eb9bacfb4">test_proxify_host_file</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_dask_cuda_worker
                <ul>
                    
                    <li><a href="#95aa0025-45ea-42d9-8936-c6ba7dae3ed2">test_cuda_visible_devices_and_memory_limit_and_nthreads</a></li>
                    
                    <li><a href="#f17308e2-a5f5-4bb9-97ce-8b269472d6fc">test_rmm_pool</a></li>
                    
                    <li><a href="#624b9020-f03e-433c-be88-e3489a7500f4">test_rmm_managed</a></li>
                    
                    <li><a href="#74d46fdf-6c2e-4d03-aa0e-fc62352ef0e0">test_rmm_async</a></li>
                    
                    <li><a href="#103347e4-e359-4597-87cd-193a0e47d35c">test_rmm_logging</a></li>
                    
                    <li><a href="#e60bd484-0d4c-4a3f-9581-65e08b875f05">test_dashboard_address</a></li>
                    
                    <li><a href="#a288caa2-0646-457e-8ee6-44f74c816429">test_unknown_argument</a></li>
                    
                    <li><a href="#631804d8-345b-4210-bd0e-32573f860dbd">test_pre_import</a></li>
                    
                    <li><a href="#7ab237dc-5121-4e68-8610-ab6a1f3961bf">test_pre_import_not_found</a></li>
                    
                    <li><a href="#38d08557-50b4-4142-ba6a-6651a5bc2cd7">test_cuda_mig_visible_devices_and_memory_limit_and_nthreads</a></li>
                    
                    <li><a href="#510bd527-d3b8-4ced-9cb4-9b5f6ea26a68">test_cuda_visible_devices_uuid</a></li>
                    
                    <li><a href="#a27b0dc8-b317-4171-9be3-f64c2cbb3b7a">test_rmm_track_allocations</a></li>
                    
                    <li><a href="#0e59f48f-e517-47bd-b88a-735d59ffb17b">test_get_cluster_configuration</a></li>
                    
                    <li><a href="#6cddfe4a-d88f-457c-ae70-4b2b003119f5">test_worker_fraction_limits</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_device_host_file
                <ul>
                    
                    <li><a href="#ba485758-a502-496a-b970-4068642105bc">test_device_host_file_short[array_size_range0-1-1]</a></li>
                    
                    <li><a href="#ca347c7e-92da-4c06-ba7b-0004b756de2d">test_device_host_file_short[array_size_range0-1-10]</a></li>
                    
                    <li><a href="#5ad9889d-fb88-4ade-b73d-5874d377fda6">test_device_host_file_short[array_size_range0-1-100]</a></li>
                    
                    <li><a href="#961f0cdc-bb5e-40df-9e44-95fc1e064cf3">test_device_host_file_short[array_size_range0-10-1]</a></li>
                    
                    <li><a href="#baf924a9-a779-405d-8ef4-e9bf81e42886">test_device_host_file_short[array_size_range0-10-10]</a></li>
                    
                    <li><a href="#2499c7cd-0316-45a3-9e49-0deca4393cda">test_device_host_file_short[array_size_range0-10-100]</a></li>
                    
                    <li><a href="#3ff519f1-2a81-49de-be8b-c407ce784c35">test_device_host_file_short[array_size_range0-100-1]</a></li>
                    
                    <li><a href="#bdbc75cd-2bf0-454e-985b-13eb791251a8">test_device_host_file_short[array_size_range0-100-10]</a></li>
                    
                    <li><a href="#c1468cc6-4fc6-4397-8412-2d92c8008de8">test_device_host_file_short[array_size_range0-100-100]</a></li>
                    
                    <li><a href="#3c288fd0-8a11-4142-beef-494a46441de4">test_device_host_file_short[array_size_range1-1-1]</a></li>
                    
                    <li><a href="#c1a38223-d34e-4139-bdf2-d47d8ce17ef0">test_device_host_file_short[array_size_range1-1-10]</a></li>
                    
                    <li><a href="#7099cfc5-c792-44c6-92aa-1ca16984c11c">test_device_host_file_short[array_size_range1-1-100]</a></li>
                    
                    <li><a href="#cd45493c-13e4-4ba6-958e-f8161bf7df28">test_device_host_file_short[array_size_range1-10-1]</a></li>
                    
                    <li><a href="#27f49480-1001-478f-a4ea-5ef0d31d1363">test_device_host_file_short[array_size_range1-10-10]</a></li>
                    
                    <li><a href="#dbce41c5-003c-40af-abf7-1d688cc55f26">test_device_host_file_short[array_size_range1-10-100]</a></li>
                    
                    <li><a href="#907eb8e9-adf1-4f1d-aa0c-6fc45939bc43">test_device_host_file_short[array_size_range1-100-1]</a></li>
                    
                    <li><a href="#e5fa2adc-bb68-4985-beee-efe266376d8e">test_device_host_file_short[array_size_range1-100-10]</a></li>
                    
                    <li><a href="#10e98c71-eacd-40f6-a40b-194b85e9c7af">test_device_host_file_short[array_size_range1-100-100]</a></li>
                    
                    <li><a href="#749c1127-26b3-4774-af25-e7e63dc7d4cc">test_device_host_file_short[array_size_range2-1-1]</a></li>
                    
                    <li><a href="#996d652a-37e4-43bb-9320-bea19fd30c68">test_device_host_file_short[array_size_range2-1-10]</a></li>
                    
                    <li><a href="#64ab4211-6d28-4972-b11f-b13860024310">test_device_host_file_short[array_size_range2-1-100]</a></li>
                    
                    <li><a href="#40da74cf-cf8b-4edd-88c5-fa099dc39f20">test_device_host_file_short[array_size_range2-10-1]</a></li>
                    
                    <li><a href="#16e00e71-6d86-43c3-a69b-62f607874655">test_device_host_file_short[array_size_range2-10-10]</a></li>
                    
                    <li><a href="#68ed17a2-12f9-4daf-8943-1e27c611d8c6">test_device_host_file_short[array_size_range2-10-100]</a></li>
                    
                    <li><a href="#93cb069e-166c-4c28-a81c-6b040173b7f4">test_device_host_file_short[array_size_range2-100-1]</a></li>
                    
                    <li><a href="#5b32a52a-47c0-4760-ab14-ae1c11dbd341">test_device_host_file_short[array_size_range2-100-10]</a></li>
                    
                    <li><a href="#360c8988-1569-41eb-a91c-6f5bafe12e32">test_device_host_file_short[array_size_range2-100-100]</a></li>
                    
                    <li><a href="#6a0262c5-b26f-43ab-b940-e53f907e1fb8">test_device_host_file_step_by_step</a></li>
                    
                    <li><a href="#12b3ac85-b48b-4a18-83f9-4c9b93c8caab">test_serialize_cupy_collection[10-0-dict]</a></li>
                    
                    <li><a href="#58ce77c4-4fd6-464b-8d7d-c74eedb76f99">test_serialize_cupy_collection[10-0-list]</a></li>
                    
                    <li><a href="#a0d78619-5d13-4662-b679-aae7f8414bd2">test_serialize_cupy_collection[10-0-tuple]</a></li>
                    
                    <li><a href="#8be58a04-0f7c-406b-b68b-8a690a941ea9">test_serialize_cupy_collection[10-1-dict]</a></li>
                    
                    <li><a href="#b9fcea76-58c3-45a9-9893-5640d2f94820">test_serialize_cupy_collection[10-1-list]</a></li>
                    
                    <li><a href="#eb9e5551-a399-4285-878d-4815aae38b8d">test_serialize_cupy_collection[10-1-tuple]</a></li>
                    
                    <li><a href="#90e57330-c709-4b50-9be8-095a4d998eef">test_serialize_cupy_collection[10-3-dict]</a></li>
                    
                    <li><a href="#52198e26-ffbf-4d0a-b6e2-9507262470c0">test_serialize_cupy_collection[10-3-list]</a></li>
                    
                    <li><a href="#90eaae6c-bb08-4e7f-a573-bcfb11d573d5">test_serialize_cupy_collection[10-3-tuple]</a></li>
                    
                    <li><a href="#43edcf78-8622-47ec-acb3-fab9f3f8be74">test_serialize_cupy_collection[10-6-dict]</a></li>
                    
                    <li><a href="#2d064fe5-3e9b-415d-8ce1-f6f8f9d30e39">test_serialize_cupy_collection[10-6-list]</a></li>
                    
                    <li><a href="#f5f4433a-44b0-4841-a970-72e9f88c5ddc">test_serialize_cupy_collection[10-6-tuple]</a></li>
                    
                    <li><a href="#e55af84a-c803-4e28-b77d-b6ab37038f26">test_serialize_cupy_collection[value1-0-dict]</a></li>
                    
                    <li><a href="#baa79026-acb2-47c8-8b5d-6be11df7f8a8">test_serialize_cupy_collection[value1-0-list]</a></li>
                    
                    <li><a href="#7ea27da6-551f-4198-b777-7d9429e148bf">test_serialize_cupy_collection[value1-0-tuple]</a></li>
                    
                    <li><a href="#13ba4de5-80c0-4112-a715-8ac95874b4a3">test_serialize_cupy_collection[value1-1-dict]</a></li>
                    
                    <li><a href="#39d819e1-3417-419c-abb0-187deeecb3d9">test_serialize_cupy_collection[value1-1-list]</a></li>
                    
                    <li><a href="#5d2d1a4d-1028-4419-a2d1-93e13a488f63">test_serialize_cupy_collection[value1-1-tuple]</a></li>
                    
                    <li><a href="#57320e97-3444-4a4b-857b-2269bb3cd73d">test_serialize_cupy_collection[value1-3-dict]</a></li>
                    
                    <li><a href="#eeee5b40-b105-403c-a927-1095c5458587">test_serialize_cupy_collection[value1-3-list]</a></li>
                    
                    <li><a href="#fb2c73e1-c8ce-4ce8-9527-c236be306d6e">test_serialize_cupy_collection[value1-3-tuple]</a></li>
                    
                    <li><a href="#1c609a0b-6ddf-43f4-a8a7-2663bd4185fd">test_serialize_cupy_collection[value1-6-dict]</a></li>
                    
                    <li><a href="#08c1dfa8-7eca-44c5-bec1-c2cae21b2b0c">test_serialize_cupy_collection[value1-6-list]</a></li>
                    
                    <li><a href="#dbca081b-8bd7-462a-9651-6d9f41c57475">test_serialize_cupy_collection[value1-6-tuple]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_dgx
                <ul>
                    
                    <li><a href="#d969f967-2241-4ff5-9486-b557cde803c3">test_default</a></li>
                    
                    <li><a href="#a0d38ce1-f92a-4af6-b182-88d3438f720b">test_tcp_over_ucx</a></li>
                    
                    <li><a href="#9adaf23d-baee-4ccb-acb5-1c0f12e19658">test_tcp_only</a></li>
                    
                    <li><a href="#03bbd18f-2b03-4c0e-9980-193f5b57489c">test_ucx_infiniband_nvlink[params0]</a></li>
                    
                    <li><a href="#7f2565e6-be87-4ec1-aaa2-67c2e5c639b3">test_ucx_infiniband_nvlink[params1]</a></li>
                    
                    <li><a href="#c90ab780-3124-497c-9d2e-aacfc74ec2c2">test_ucx_infiniband_nvlink[params2]</a></li>
                    
                    <li><a href="#542b794b-a686-4e11-afd2-ab6e7fd0e9d8">test_ucx_infiniband_nvlink[params3]</a></li>
                    
                    <li><a href="#7e9e5072-4021-4083-83c3-c9f022ab5539">test_ucx_infiniband_nvlink[params4]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_explicit_comms
                <ul>
                    
                    <li><a href="#2ae58089-fe75-4d5a-8756-1252526ad094">test_local_cluster[tcp]</a></li>
                    
                    <li><a href="#8e73a5ec-b24b-4852-90ca-90b7a1bddb8f">test_local_cluster[ucx]</a></li>
                    
                    <li><a href="#ddf610b8-b14e-4d5c-a407-51055639ec79">test_dataframe_merge_empty_partitions</a></li>
                    
                    <li><a href="#298ae8b6-fdda-4d82-a3d1-96bdefbc8a44">test_dataframe_shuffle[tcp-pandas-1]</a></li>
                    
                    <li><a href="#56801956-298d-43de-924c-925253a9f6fa">test_dataframe_shuffle[tcp-pandas-2]</a></li>
                    
                    <li><a href="#4ec069f5-e04d-43b8-be42-5e6a4b8e43e8">test_dataframe_shuffle[tcp-pandas-3]</a></li>
                    
                    <li><a href="#dce30a0b-bc38-45f1-aa2d-c164f03cd8d7">test_dataframe_shuffle[tcp-cudf-1]</a></li>
                    
                    <li><a href="#d0c9a0d3-6b88-4796-812a-78f371302e80">test_dataframe_shuffle[tcp-cudf-2]</a></li>
                    
                    <li><a href="#17c12904-2b36-4e86-ade7-87a8967bba6d">test_dataframe_shuffle[tcp-cudf-3]</a></li>
                    
                    <li><a href="#5b6c61ec-04a9-4a10-8f84-bb0b03822b89">test_dataframe_shuffle[ucx-pandas-1]</a></li>
                    
                    <li><a href="#69e3613e-2fc8-40b8-9b99-2cdb95cb6130">test_dataframe_shuffle[ucx-pandas-2]</a></li>
                    
                    <li><a href="#09a310d0-74dc-488a-8c53-c3f1cd918630">test_dataframe_shuffle[ucx-pandas-3]</a></li>
                    
                    <li><a href="#e5d3fa0f-b278-47b8-80b8-557eb7e42b75">test_dataframe_shuffle[ucx-cudf-1]</a></li>
                    
                    <li><a href="#211903e4-0a36-4fae-b873-cfef0c93064c">test_dataframe_shuffle[ucx-cudf-2]</a></li>
                    
                    <li><a href="#2abe22c0-bb50-4869-889f-4a00a2cd38a3">test_dataframe_shuffle[ucx-cudf-3]</a></li>
                    
                    <li><a href="#585d9888-9ebc-45e3-8daf-d5b812e4722e">test_dask_use_explicit_comms[True]</a></li>
                    
                    <li><a href="#433f23af-7013-42be-8566-1b7953898022">test_dask_use_explicit_comms[False]</a></li>
                    
                    <li><a href="#f0fa4835-2cfd-4cb2-b296-9c4be07b0346">test_dataframe_shuffle_merge[tcp-pandas-1]</a></li>
                    
                    <li><a href="#a12c2604-e713-4e56-968f-bdcba6dc3537">test_dataframe_shuffle_merge[tcp-pandas-2]</a></li>
                    
                    <li><a href="#45928a68-135d-4a3a-8b50-1a6a94afd08e">test_dataframe_shuffle_merge[tcp-pandas-4]</a></li>
                    
                    <li><a href="#a2ee2027-adf4-41fd-879d-f167bfc766ab">test_dataframe_shuffle_merge[tcp-cudf-1]</a></li>
                    
                    <li><a href="#204fd7c1-9c11-4b24-a011-177307d8f94a">test_dataframe_shuffle_merge[tcp-cudf-2]</a></li>
                    
                    <li><a href="#3810b7be-1a33-4526-9762-9ef44da1d730">test_dataframe_shuffle_merge[tcp-cudf-4]</a></li>
                    
                    <li><a href="#2180bfa5-7427-464a-b604-ea6bea24d8f9">test_dataframe_shuffle_merge[ucx-pandas-1]</a></li>
                    
                    <li><a href="#6dcf9613-fd78-472b-8ae4-bf8874caa6de">test_dataframe_shuffle_merge[ucx-pandas-2]</a></li>
                    
                    <li><a href="#84d98104-a6fc-40a9-afdc-f13105d1116a">test_dataframe_shuffle_merge[ucx-pandas-4]</a></li>
                    
                    <li><a href="#04440487-1041-4ce8-86e9-b66d92c41b92">test_dataframe_shuffle_merge[ucx-cudf-1]</a></li>
                    
                    <li><a href="#ac583553-ab40-41a9-803b-4c587e069296">test_dataframe_shuffle_merge[ucx-cudf-2]</a></li>
                    
                    <li><a href="#7e8d3c6e-68f2-4e1a-87df-f6cbedd7fd68">test_dataframe_shuffle_merge[ucx-cudf-4]</a></li>
                    
                    <li><a href="#69e72139-f5cc-427e-993c-3e6e6f7e0b22">test_jit_unspill[tcp]</a></li>
                    
                    <li><a href="#4490668f-d0c6-4e72-8e3b-0e39e53faa77">test_jit_unspill[ucx]</a></li>
                    
                    <li><a href="#85e8a158-f175-4d35-aa50-21a6e1562e7f">test_lock_workers</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_gds
                <ul>
                    
                    <li><a href="#1f1b23c6-5f76-4901-9cf3-dfacd50d6abc">test_gds[True-cupy]</a></li>
                    
                    <li><a href="#5a0af78e-a9bc-4966-ac0f-e1248e7591d4">test_gds[True-cudf]</a></li>
                    
                    <li><a href="#5e2f2e43-0b40-4990-b9e7-aec4a47e4334">test_gds[True-numba.cuda]</a></li>
                    
                    <li><a href="#3f48ea22-ef34-4340-929b-b80bfa2846f7">test_gds[False-cupy]</a></li>
                    
                    <li><a href="#d26a35d5-8881-427a-9ee8-d30be6271ecc">test_gds[False-cudf]</a></li>
                    
                    <li><a href="#8e450ef9-2cb9-430b-9586-a154c8c24e3e">test_gds[False-numba.cuda]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_initialize
                <ul>
                    
                    <li><a href="#7d89e938-418b-414a-8c1a-775c1cbe703b">test_initialize_ucx_tcp</a></li>
                    
                    <li><a href="#1ba1da5c-af37-4eef-90a0-56fb751a4ed1">test_initialize_ucx_nvlink</a></li>
                    
                    <li><a href="#e0542446-3313-43b4-affc-f940f141865f">test_initialize_ucx_infiniband</a></li>
                    
                    <li><a href="#c25ee8e2-964d-474b-9c14-c2e5cf786213">test_initialize_ucx_all</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_local_cuda_cluster
                <ul>
                    
                    <li><a href="#68bb9181-0f12-4930-af4f-479694fe7350">test_local_cuda_cluster</a></li>
                    
                    <li><a href="#0f8237a8-5784-4fba-a2bd-c62734f74246">test_with_subset_of_cuda_visible_devices</a></li>
                    
                    <li><a href="#91a720bd-357d-494d-b56a-739d9c12fd26">test_ucx_protocol[ucx]</a></li>
                    
                    <li><a href="#14966890-459d-44d7-9d55-64583994dc93">test_ucx_protocol[None]</a></li>
                    
                    <li><a href="#7c69ca88-a04f-4677-bb53-cb67e68d30be">test_ucx_protocol_type_error</a></li>
                    
                    <li><a href="#e18a1c04-9d36-446b-b9ed-b3e3bd438937">test_n_workers</a></li>
                    
                    <li><a href="#4feadfc3-d72b-4b5b-a830-54db0be594e6">test_threads_per_worker_and_memory_limit</a></li>
                    
                    <li><a href="#6e1d1f43-a21a-452b-a798-4e994263ca3c">test_no_memory_limits_cluster</a></li>
                    
                    <li><a href="#067e1085-3008-44f1-aa04-08b9c089aa92">test_no_memory_limits_cudaworker</a></li>
                    
                    <li><a href="#f212c16e-9a54-434d-906b-3f281c1e3b1b">test_all_to_all</a></li>
                    
                    <li><a href="#d52f7057-0fa8-49af-83d9-4dbaa81a9a34">test_rmm_pool</a></li>
                    
                    <li><a href="#7996d189-369f-47da-9582-d9500cc4513c">test_rmm_maximum_poolsize_without_poolsize_error</a></li>
                    
                    <li><a href="#0e79df96-06e5-45c7-b1bd-7a25c4bd34b2">test_rmm_managed</a></li>
                    
                    <li><a href="#55b88d51-b6d8-4af0-a851-f4d4ad8d971f">test_rmm_async</a></li>
                    
                    <li><a href="#4c0918fb-7d89-4c72-992b-5a03510279c6">test_rmm_logging</a></li>
                    
                    <li><a href="#e9cec81b-f347-4cd8-bdc8-5786c445f411">test_pre_import</a></li>
                    
                    <li><a href="#58a8d5b5-d336-4677-b648-61c461f00e2f">test_pre_import_not_found</a></li>
                    
                    <li><a href="#cbb10d98-4257-4ef0-8def-8bf0bd0a0d36">test_cluster_worker</a></li>
                    
                    <li><a href="#def4a33b-0e18-4789-8c38-1621a3801e8c">test_available_mig_workers</a></li>
                    
                    <li><a href="#914a9f32-0c07-41c1-b02a-d2a65ab3ced8">test_gpu_uuid</a></li>
                    
                    <li><a href="#c89d7bf8-c46b-474a-8192-0dec067e3b14">test_rmm_track_allocations</a></li>
                    
                    <li><a href="#6b05d599-e2c9-45e8-84ce-8057d2ebf8b4">test_get_cluster_configuration</a></li>
                    
                    <li><a href="#89955733-509e-4981-af62-1872d7518c84">test_worker_fraction_limits</a></li>
                    
                    <li><a href="#7464f9fd-9ee0-4383-bd8b-e9f7d554008f">test_print_cluster_config</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_proxify_host_file
                <ul>
                    
                    <li><a href="#c3bb0e1f-e758-47d2-b435-2ca231ff5188">test_one_dev_item_limit</a></li>
                    
                    <li><a href="#3737ffc9-8f0b-46fa-8ebc-915ab04f69bd">test_one_item_host_limit</a></li>
                    
                    <li><a href="#8330f910-e785-4fd9-84d9-f4845922c88d">test_spill_on_demand</a></li>
                    
                    <li><a href="#d7f3e563-533b-443f-85a4-d6c78a32bc38">test_local_cuda_cluster[True]</a></li>
                    
                    <li><a href="#09d0ce41-5905-46c4-8159-d4d59886f730">test_local_cuda_cluster[False]</a></li>
                    
                    <li><a href="#21e029d0-3d55-425f-9cd9-deeb91f97795">test_dataframes_share_dev_mem</a></li>
                    
                    <li><a href="#3a94041c-6e26-4530-934c-53e8378e56cf">test_cudf_get_device_memory_objects</a></li>
                    
                    <li><a href="#ee2a6f51-7e6c-4750-a8dc-6f313167f8a4">test_externals</a></li>
                    
                    <li><a href="#c7936495-b554-477d-9eb0-cd5cb533da88">test_incompatible_types</a></li>
                    
                    <li><a href="#b35a603f-59a6-4f61-ba97-e9466c4ac38b">test_compatibility_mode_dataframe_shuffle[True-1]</a></li>
                    
                    <li><a href="#8d881f03-dfd7-4045-82ba-68448c515f85">test_compatibility_mode_dataframe_shuffle[True-2]</a></li>
                    
                    <li><a href="#50879082-2448-4714-b441-959d3811efa0">test_compatibility_mode_dataframe_shuffle[True-3]</a></li>
                    
                    <li><a href="#f200b24d-e367-4ec9-ba74-cd44de69e4a7">test_compatibility_mode_dataframe_shuffle[False-1]</a></li>
                    
                    <li><a href="#8cc2f1b4-e3bd-48b3-abaf-50fe7c5d7e1a">test_compatibility_mode_dataframe_shuffle[False-2]</a></li>
                    
                    <li><a href="#ec89c339-8dfe-40b7-b46c-fd99664dcaa9">test_compatibility_mode_dataframe_shuffle[False-3]</a></li>
                    
                    <li><a href="#5511fa03-f33d-4835-a4ec-c0765cbc9a6a">test_worker_force_spill_to_disk</a></li>
                    
                    <li><a href="#fea18d55-9942-4b38-9040-f841b9d7821b">test_on_demand_debug_info</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_proxy
                <ul>
                    
                    <li><a href="#e9d13678-cd06-4b5f-a679-67c94287db15">test_proxy_object[None]</a></li>
                    
                    <li><a href="#637886e1-35a3-4855-8c6b-c945d5ded6b4">test_proxy_object[serializers1]</a></li>
                    
                    <li><a href="#0632a6d3-047b-4078-ac95-122eab598653">test_proxy_object[serializers2]</a></li>
                    
                    <li><a href="#5ebb6c90-ced8-4762-a1c2-75950922a1cb">test_proxy_object_serializer</a></li>
                    
                    <li><a href="#c16e1b2a-d497-4f2a-a840-70c62b99cf51">test_double_proxy_object[None-None]</a></li>
                    
                    <li><a href="#8f39f685-c0cc-4adb-8faf-b92ecd8e8cb8">test_double_proxy_object[None-serializers_first1]</a></li>
                    
                    <li><a href="#b951b4b3-64c3-4be4-ad9b-da1258de511e">test_double_proxy_object[None-serializers_first2]</a></li>
                    
                    <li><a href="#48379418-c5c3-4c26-a27c-b3fe2e248ea9">test_double_proxy_object[serializers_second1-None]</a></li>
                    
                    <li><a href="#1a828c08-50b0-45a9-810f-c7b0578daed9">test_double_proxy_object[serializers_second1-serializers_first1]</a></li>
                    
                    <li><a href="#d7090f72-dbe0-4c31-8ad2-5ba7e0551892">test_double_proxy_object[serializers_second1-serializers_first2]</a></li>
                    
                    <li><a href="#53c856dd-1387-4b8d-9ab3-bffb737df50e">test_double_proxy_object[serializers_second2-None]</a></li>
                    
                    <li><a href="#20250269-33b5-405c-b78a-0a32eb2b2538">test_double_proxy_object[serializers_second2-serializers_first1]</a></li>
                    
                    <li><a href="#d7e42f6e-5786-46fa-bb1c-13386540a9bd">test_double_proxy_object[serializers_second2-serializers_first2]</a></li>
                    
                    <li><a href="#7229b188-c6ec-4804-841e-45c22457658a">test_proxy_object_of_array[numpy-None]</a></li>
                    
                    <li><a href="#22cbe038-6f11-4c6e-9e66-a7037e066bc0">test_proxy_object_of_array[numpy-serializers1]</a></li>
                    
                    <li><a href="#ebb7de04-fef8-4e06-84cf-ee093e2ecf7d">test_proxy_object_of_array[numpy-serializers2]</a></li>
                    
                    <li><a href="#f42b55a5-b9c1-451e-9dde-2d952e6915c1">test_proxy_object_of_array[cupy-None]</a></li>
                    
                    <li><a href="#b0f7b3a2-9b75-4503-b605-b78c1c12f145">test_proxy_object_of_array[cupy-serializers1]</a></li>
                    
                    <li><a href="#b7b99056-7eff-49a0-9bfe-910acabbd2da">test_proxy_object_of_array[cupy-serializers2]</a></li>
                    
                    <li><a href="#b4ab2228-5b0b-46b4-84e8-2ecec8a0baaa">test_proxy_object_of_cudf[None]</a></li>
                    
                    <li><a href="#6dc5d2f0-5855-4cef-830b-537d71d41ae9">test_proxy_object_of_cudf[serializers1]</a></li>
                    
                    <li><a href="#8ccd58b0-f8c1-4b4f-9c59-e80551c2c522">test_proxy_object_of_cudf[serializers2]</a></li>
                    
                    <li><a href="#4df05b61-98f0-44fb-b33a-ef04e6f2722d">test_serialize_of_proxied_cudf[dask_serializers0-None]</a></li>
                    
                    <li><a href="#ea41bcd4-2312-4969-bbc5-99974fa8b8af">test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1]</a></li>
                    
                    <li><a href="#a68c98b1-153b-4a04-a40e-6bd32223b402">test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2]</a></li>
                    
                    <li><a href="#bf6a7060-4435-467b-b2ca-6b5718aa1447">test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3]</a></li>
                    
                    <li><a href="#f076199a-aa72-4f76-8fe7-761f94cbfe1f">test_serialize_of_proxied_cudf[dask_serializers1-None]</a></li>
                    
                    <li><a href="#a76f153a-51b8-4a10-b502-b5354048dc71">test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1]</a></li>
                    
                    <li><a href="#5a8a5dfe-f27b-4d45-aed1-42a49476929c">test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2]</a></li>
                    
                    <li><a href="#80928c5e-4354-4179-9c02-d30e8966a54a">test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3]</a></li>
                    
                    <li><a href="#aedb1978-ab49-44d4-9d28-eacc3d6b38b2">test_fixed_attribute_length[numpy]</a></li>
                    
                    <li><a href="#3151c09f-f81c-403a-9f73-4070670f4c16">test_fixed_attribute_length[cupy]</a></li>
                    
                    <li><a href="#5f4abeb6-3f32-4210-a570-0fce941a7338">test_fixed_attribute_name</a></li>
                    
                    <li><a href="#b0da7fc0-1c60-46c4-92fd-d83fc9956384">test_spilling_local_cuda_cluster[True]</a></li>
                    
                    <li><a href="#03daa5f0-6a80-4df5-9a42-3f8d2ab2c3fa">test_spilling_local_cuda_cluster[False]</a></li>
                    
                    <li><a href="#b83cac12-daf0-4543-9268-934ecf04368c">test_serializing_to_disk[obj0]</a></li>
                    
                    <li><a href="#205193f0-bd81-4e27-8f8d-4a9e67693310">test_serializing_to_disk[obj1]</a></li>
                    
                    <li><a href="#2348b1bb-b403-4401-8837-adbc3d748d65">test_multiple_deserializations[dask]</a></li>
                    
                    <li><a href="#d6ab30ab-953b-4985-9389-df1eabd12f6b">test_multiple_deserializations[pickle]</a></li>
                    
                    <li><a href="#a0ece6e7-2805-477b-a7e6-be927390e37b">test_multiple_deserializations[disk]</a></li>
                    
                    <li><a href="#86f3bcae-2cf0-4344-be96-3f604bb9005a">test_serializing_array_to_disk[numpy-None-10]</a></li>
                    
                    <li><a href="#a1b151f7-dacb-4d66-99f0-eeff0db4a931">test_serializing_array_to_disk[numpy-None-10000]</a></li>
                    
                    <li><a href="#573320f2-fbb0-4f5f-89a0-c6298b70c304">test_serializing_array_to_disk[numpy-serializers1-10]</a></li>
                    
                    <li><a href="#a879f665-a1a6-472c-b22a-7e40c56664cd">test_serializing_array_to_disk[numpy-serializers1-10000]</a></li>
                    
                    <li><a href="#d89ac390-3609-417e-a110-e38f1c501a7b">test_serializing_array_to_disk[numpy-serializers2-10]</a></li>
                    
                    <li><a href="#2e756745-9627-48be-8cac-d54bf8d0aeb7">test_serializing_array_to_disk[numpy-serializers2-10000]</a></li>
                    
                    <li><a href="#9d5a9f3e-8e45-4ae1-a0fc-daf1271d16d8">test_serializing_array_to_disk[numpy-serializers3-10]</a></li>
                    
                    <li><a href="#35eb8b91-94e3-41cd-9893-1d629966ab42">test_serializing_array_to_disk[numpy-serializers3-10000]</a></li>
                    
                    <li><a href="#ab615236-239e-419b-b0d7-0949cdb6304c">test_serializing_array_to_disk[numpy-serializers4-10]</a></li>
                    
                    <li><a href="#5f39f489-589b-4e49-8676-76e7a1ef09e3">test_serializing_array_to_disk[numpy-serializers4-10000]</a></li>
                    
                    <li><a href="#298f25c6-14dd-40cb-80c6-2c0dbb4ed521">test_serializing_array_to_disk[cupy-None-10]</a></li>
                    
                    <li><a href="#c9167187-d719-4c9d-b17c-96d7e348dadb">test_serializing_array_to_disk[cupy-None-10000]</a></li>
                    
                    <li><a href="#486c30b5-c266-48f9-804d-a59d192f0445">test_serializing_array_to_disk[cupy-serializers1-10]</a></li>
                    
                    <li><a href="#160df083-5b48-483f-b985-4cd309546b69">test_serializing_array_to_disk[cupy-serializers1-10000]</a></li>
                    
                    <li><a href="#8329e504-a8b2-4770-885c-f4cef1c65735">test_serializing_array_to_disk[cupy-serializers2-10]</a></li>
                    
                    <li><a href="#fac57e0c-a883-4515-8dee-874e47343c2f">test_serializing_array_to_disk[cupy-serializers2-10000]</a></li>
                    
                    <li><a href="#a4194fc4-7920-43a9-8553-df70c2d7154d">test_serializing_array_to_disk[cupy-serializers3-10]</a></li>
                    
                    <li><a href="#0b2f5357-c8dd-4145-af44-55f680af0b0d">test_serializing_array_to_disk[cupy-serializers3-10000]</a></li>
                    
                    <li><a href="#cb414683-7c05-4390-9766-e05dbffdd15a">test_serializing_array_to_disk[cupy-serializers4-10]</a></li>
                    
                    <li><a href="#64e8995f-e5ca-415d-8486-902c4485b1ee">test_serializing_array_to_disk[cupy-serializers4-10000]</a></li>
                    
                    <li><a href="#2b3eab66-c49c-454d-935a-6973c95a6689">test_communicating_proxy_objects[tcp-None]</a></li>
                    
                    <li><a href="#3ff5ba6e-4f87-40d0-95ec-e03bc6919cdc">test_communicating_proxy_objects[tcp-send_serializers1]</a></li>
                    
                    <li><a href="#a8393f6f-99af-41a3-be77-15bb2f911245">test_communicating_proxy_objects[tcp-send_serializers2]</a></li>
                    
                    <li><a href="#6a0ba091-5793-42ac-ab37-981b8f1b073c">test_communicating_proxy_objects[ucx-None]</a></li>
                    
                    <li><a href="#c6cda4c1-c86d-4bd6-920b-7d4aaf588cbb">test_communicating_proxy_objects[ucx-send_serializers1]</a></li>
                    
                    <li><a href="#87e4cd75-eebe-42dc-af4f-2caee6160391">test_communicating_proxy_objects[ucx-send_serializers2]</a></li>
                    
                    <li><a href="#809c9334-f25d-444f-8fc8-b66937e98e21">test_communicating_disk_objects[True-tcp]</a></li>
                    
                    <li><a href="#d8d19095-98e9-4aa9-89fa-63e739182143">test_communicating_disk_objects[True-ucx]</a></li>
                    
                    <li><a href="#f130ceac-2a51-4dc3-ad77-1e960006ed9f">test_communicating_disk_objects[False-tcp]</a></li>
                    
                    <li><a href="#51cdcb09-9262-4a5d-9d71-4d7f8d9bc9b2">test_communicating_disk_objects[False-ucx]</a></li>
                    
                    <li><a href="#d021aca7-d14b-4d51-bdf9-f36d765861d0">test_pickle_proxy_object[None-numpy]</a></li>
                    
                    <li><a href="#269467e1-8fe5-422d-977f-de5327addfd1">test_pickle_proxy_object[None-cupy]</a></li>
                    
                    <li><a href="#05abd97f-002f-4f23-809d-742b7d9d6413">test_pickle_proxy_object[serializers1-numpy]</a></li>
                    
                    <li><a href="#6b237690-c049-4e24-9a60-6d6e24d9049c">test_pickle_proxy_object[serializers1-cupy]</a></li>
                    
                    <li><a href="#7809fdba-daea-43e5-bca3-06a3f510782b">test_pickle_proxy_object[serializers2-numpy]</a></li>
                    
                    <li><a href="#15af12a3-b850-4168-9ddc-fe2cee7f9bf4">test_pickle_proxy_object[serializers2-cupy]</a></li>
                    
                    <li><a href="#0facacd3-f8d2-4eaa-833d-1b43c3eb875b">test_pickle_proxy_object[serializers3-numpy]</a></li>
                    
                    <li><a href="#bf8ce12f-0480-4d77-b9dd-5cd1fb60e5a4">test_pickle_proxy_object[serializers3-cupy]</a></li>
                    
                    <li><a href="#c94c7925-9ab3-492f-a88d-c35dd808d317">test_pandas</a></li>
                    
                    <li><a href="#50f43ed5-256b-4a01-b6d5-f0388691c7ae">test_from_cudf_of_proxy_object</a></li>
                    
                    <li><a href="#24463b20-1493-46c2-b7c3-88fd5b7fa312">test_proxy_object_parquet</a></li>
                    
                    <li><a href="#2d5379a5-2a39-4579-9fc0-ac4ef02632d3">test_assignments</a></li>
                    
                    <li><a href="#a1d2ebc9-a608-4989-a632-0da6100c13bc">test_concatenate3_of_proxied_cupy_arrays</a></li>
                    
                    <li><a href="#b6280dd5-c8ca-4585-a089-b35b6df2bb8a">test_tensordot_of_proxied_cupy_arrays</a></li>
                    
                    <li><a href="#6fe7905f-4397-4411-9d67-dbfb5aa375c3">test_einsum_of_proxied_cupy_arrays</a></li>
                    
                    <li><a href="#92957340-99b4-44d6-ac38-fde71daad120">test_array_ufucn_proxified_object[less]</a></li>
                    
                    <li><a href="#2d4d5b39-df8f-4caf-8fac-83afbaf36a6d">test_array_ufucn_proxified_object[less_equal]</a></li>
                    
                    <li><a href="#65ac1e62-de6c-4a4f-8316-624ee5ca3f43">test_array_ufucn_proxified_object[greater]</a></li>
                    
                    <li><a href="#c39699cc-5c7b-4ac1-817c-0210a019efd3">test_array_ufucn_proxified_object[greater_equal]</a></li>
                    
                    <li><a href="#690f81b0-93e6-4d28-975e-1cb8f12533d4">test_array_ufucn_proxified_object[equal]</a></li>
                    
                    <li><a href="#367c0feb-df2f-4424-8da5-0b46d88ffc4f">test_cudf_copy</a></li>
                    
                    <li><a href="#8c70d944-0311-460a-bfe5-b231ce69130b">test_cudf_fillna</a></li>
                    
                    <li><a href="#896450d1-e40e-45cc-925e-f1fe3d9ea44b">test_sizeof_cupy</a></li>
                    
                    <li><a href="#246f1397-d913-4820-86cf-3db5f5b1e936">test_sizeof_cudf</a></li>
                    
                    <li><a href="#603422df-f793-4c52-8fe9-5d74277c896b">test_cupy_broadcast_to</a></li>
                    
                    <li><a href="#9329858c-1122-4f05-b99c-b7ff87219c22">test_cupy_matmul</a></li>
                    
                    <li><a href="#69d8f69c-6b5c-4a6e-8a4d-603e0afe39d4">test_cupy_imatmul</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_spill
                <ul>
                    
                    <li><a href="#4b964de8-2396-4884-a37c-8307f1161e07">test_cupy_cluster_device_spill[params0]</a></li>
                    
                    <li><a href="#d749bce1-51d0-4f9c-b58d-6217982523a2">test_cupy_cluster_device_spill[params1]</a></li>
                    
                    <li><a href="#359ea255-f0f3-4826-901f-fd8fa26cc87a">test_cupy_cluster_device_spill[params2]</a></li>
                    
                    <li><a href="#7cff40ab-7032-4ec8-b975-4e1e49f06d3d">test_cupy_cluster_device_spill[params3]</a></li>
                    
                    <li><a href="#c05b3d29-dc9a-4765-90c8-452197f299fd">test_cudf_cluster_device_spill[params0]</a></li>
                    
                    <li><a href="#d966de8a-13cf-4fd5-b410-ade057e279c5">test_cudf_cluster_device_spill[params1]</a></li>
                    
                    <li><a href="#0f6d4434-17d3-4a80-b833-23ac6ad799cb">test_cudf_cluster_device_spill[params2]</a></li>
                    
                    <li><a href="#5a21fb8c-2609-46a0-830c-8c79e0a70143">test_cudf_cluster_device_spill[params3]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_utils
                <ul>
                    
                    <li><a href="#5242adf9-cc8a-4ff8-afa5-506ceed7318c">test_get_n_gpus</a></li>
                    
                    <li><a href="#cc9e0568-85b6-41b4-b649-de89d38370eb">test_unpack_bitmask[params0]</a></li>
                    
                    <li><a href="#47e542b1-e1cb-4962-b4b4-5168ddbc7b8e">test_unpack_bitmask[params1]</a></li>
                    
                    <li><a href="#33b4fe7f-b068-4691-b9f9-dd3b3cc491fa">test_unpack_bitmask[params2]</a></li>
                    
                    <li><a href="#0d3a9ed6-73f5-44ff-a33d-60d71abcc065">test_unpack_bitmask[params3]</a></li>
                    
                    <li><a href="#fb4e7882-bc6c-4fd6-b663-ae25e71377dd">test_unpack_bitmask_single_value</a></li>
                    
                    <li><a href="#0c5b5573-87cf-4a7d-a916-d178f27b5465">test_cpu_affinity</a></li>
                    
                    <li><a href="#2132e93a-1d42-469d-adb4-00df2d01a4c2">test_cpu_affinity_and_cuda_visible_devices</a></li>
                    
                    <li><a href="#de800a32-e3b5-40e2-a908-1108cd1c3d83">test_get_device_total_memory</a></li>
                    
                    <li><a href="#eaf9714a-66a8-4775-8e58-d59980bd7eca">test_get_preload_options_default</a></li>
                    
                    <li><a href="#24e9065f-f05d-4227-911b-d67330912f50">test_get_preload_options[True-True-True]</a></li>
                    
                    <li><a href="#237107a9-8fc5-4e66-a5a4-05c25781ef2f">test_get_preload_options[True-True-False]</a></li>
                    
                    <li><a href="#d16f206d-3d8b-4e41-8bcc-e630bb5aff3f">test_get_preload_options[True-False-True]</a></li>
                    
                    <li><a href="#302f7770-7f27-43b6-8192-d4d86384e33d">test_get_preload_options[True-False-False]</a></li>
                    
                    <li><a href="#86047bfc-b30b-4e82-9a82-07868d22c8ad">test_get_preload_options[False-True-True]</a></li>
                    
                    <li><a href="#19f24db6-ad1e-40ec-b20c-b6579af139a2">test_get_preload_options[False-True-False]</a></li>
                    
                    <li><a href="#9cae3453-5350-4f23-af5c-06ec2daccab5">test_get_preload_options[False-False-True]</a></li>
                    
                    <li><a href="#c7a41614-52fa-4929-bc3c-8afcc6e950d3">test_get_preload_options[False-False-False]</a></li>
                    
                    <li><a href="#e5b44a3f-3f06-4ba8-8fdf-2e00b16979dd">test_get_ucx_config[True-True-True]</a></li>
                    
                    <li><a href="#8f3f2050-9f51-411f-8ff4-6630921b6c8f">test_get_ucx_config[True-True-False]</a></li>
                    
                    <li><a href="#1f660117-e893-415f-acec-03931d374c16">test_get_ucx_config[True-True-None]</a></li>
                    
                    <li><a href="#c911f71f-4331-4e63-ab5a-6bccb7906790">test_get_ucx_config[True-False-True]</a></li>
                    
                    <li><a href="#a88a4872-3244-4e07-8bdb-0e7a387bbd10">test_get_ucx_config[True-False-False]</a></li>
                    
                    <li><a href="#d5c0350c-be3e-44cd-9125-075b8a8de93d">test_get_ucx_config[True-False-None]</a></li>
                    
                    <li><a href="#99233ad8-a904-479f-836c-40d25d617c13">test_get_ucx_config[True-None-True]</a></li>
                    
                    <li><a href="#e1a3ac1a-fffa-4e2b-817c-c9f51f9a1153">test_get_ucx_config[True-None-False]</a></li>
                    
                    <li><a href="#8550113c-6971-4bbe-b800-401e77aa88a2">test_get_ucx_config[True-None-None]</a></li>
                    
                    <li><a href="#9ddf5564-a64f-4d59-afb2-3dc211e260a1">test_get_ucx_config[False-True-True]</a></li>
                    
                    <li><a href="#1b9fc1c1-5c9f-438b-b519-c093c7f443ac">test_get_ucx_config[False-True-False]</a></li>
                    
                    <li><a href="#a43c7bf4-c165-401b-82d1-a81aa942e1aa">test_get_ucx_config[False-True-None]</a></li>
                    
                    <li><a href="#c76da453-7dd1-4030-a975-62f11c87277e">test_get_ucx_config[False-False-True]</a></li>
                    
                    <li><a href="#b0fd900e-91f3-45f8-8e07-bb2df5124a4f">test_get_ucx_config[False-False-False]</a></li>
                    
                    <li><a href="#e59b2eff-6088-4082-b4e5-331eba8b85cf">test_get_ucx_config[False-False-None]</a></li>
                    
                    <li><a href="#b7829bfc-b0c7-4b6b-859e-62b5e76ce764">test_get_ucx_config[False-None-True]</a></li>
                    
                    <li><a href="#114fa166-f28b-4e56-8cc6-d5905afe5247">test_get_ucx_config[False-None-False]</a></li>
                    
                    <li><a href="#0dba3f8e-1abb-4a73-8bfa-75a59bf70e55">test_get_ucx_config[False-None-None]</a></li>
                    
                    <li><a href="#3a4b90d4-1f44-4d49-939b-4958868eb515">test_get_ucx_config[None-True-True]</a></li>
                    
                    <li><a href="#c047ceeb-4c89-4246-ba84-0a5bb12014d1">test_get_ucx_config[None-True-False]</a></li>
                    
                    <li><a href="#40439f74-92d6-40ad-a73f-b3ba41e4ed16">test_get_ucx_config[None-True-None]</a></li>
                    
                    <li><a href="#809e5b95-c8e0-4b3e-a503-13eb414ed763">test_get_ucx_config[None-False-True]</a></li>
                    
                    <li><a href="#ad6c5ac4-f1d2-47b1-9eb0-51c02b0aa0d3">test_get_ucx_config[None-False-False]</a></li>
                    
                    <li><a href="#ca4b2262-74b3-4091-b9d7-1e8691566edc">test_get_ucx_config[None-False-None]</a></li>
                    
                    <li><a href="#d7a10660-310c-4553-825a-51a4fa5b82ee">test_get_ucx_config[None-None-True]</a></li>
                    
                    <li><a href="#0101e03b-3718-43ff-a1c9-adc89653045e">test_get_ucx_config[None-None-False]</a></li>
                    
                    <li><a href="#357ce841-5ba8-4536-a152-bbca1e21f08d">test_get_ucx_config[None-None-None]</a></li>
                    
                    <li><a href="#08074114-f2d1-4127-acd5-337e2e401557">test_parse_visible_devices</a></li>
                    
                    <li><a href="#95229859-a9a9-469d-9ab0-921e824c64b9">test_parse_device_memory_limit</a></li>
                    
                    <li><a href="#484e32b6-3263-4707-9523-a7d6712e2734">test_parse_visible_mig_devices</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_worker_spec
                <ul>
                    
                    <li><a href="#9c43999f-2d8b-43bb-b4b1-a4285aae0ef1">test_worker_spec[False-False-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#ba4ad79a-c86a-4db0-952c-f003b687e4bd">test_worker_spec[False-False-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#58152f8e-0b8a-42b0-91b4-4e1e933d69a4">test_worker_spec[False-False-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#dd3825a4-98b0-4e7e-aa44-0575dc9efb12">test_worker_spec[False-False-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#fb5a2913-3191-4661-8d2d-53c287d55b2e">test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#de9dd33f-e76f-424b-a14f-9d11577a3c9d">test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2107164a-daba-40a0-829f-5b7e2ed9fd05">test_worker_spec[False-False-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#54695683-08cc-4cf8-bee7-85801f58107b">test_worker_spec[False-False-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#902581f1-c235-409a-903c-59543a9abdfb">test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4915dd20-1a17-4990-81a7-633d2e8834ee">test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1b2f52e2-213d-4001-805a-d4f88aff994d">test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#40e526d1-52bb-4901-a8c1-26f59656c7b2">test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7ab2e5df-daf7-4473-ad13-c5f34f30b45c">test_worker_spec[False-False-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#bbc30dc4-0448-4068-a992-7de2e23dcbb3">test_worker_spec[False-False-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ed8b35a1-16e1-41cf-a06b-1b3c8b6cb9f6">test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5a7fd4aa-fc86-488e-af6d-b084a6b947b7">test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1f7223d0-51cb-42d4-bc64-68377ff19505">test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#20f0e6a2-6f95-4a15-9e56-8a0aad569d06">test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#50165942-cf1b-4fd5-90c1-fd1cbc104526">test_worker_spec[False-False-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#82ccba00-c7a1-41fd-8057-c31f5c40b791">test_worker_spec[False-False-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#4d57af2a-a2c7-4715-8d16-cf1014f8c729">test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8a99915e-49a4-47fd-ba3d-e6716a870f6f">test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ea7e1b2e-b82a-4ad8-874e-4dd6c7454986">test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f9b59f02-b396-4d9e-89d0-034f042520af">test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#6c162d6b-7b1f-4a4c-85d7-e48e3cc52804">test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#7362295d-e250-4322-b0bc-c1f054775611">test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#6ca07dd5-d9a9-4071-82c1-52d3737ba6bd">test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#79b89565-674c-479c-b7ff-a35b790c7c74">test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1b0eec2b-567e-4da5-9046-39f61ff59a12">test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#1fd33ed7-81b4-4690-8162-d60050cbc3c5">test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#31e5a505-a7b6-4785-8909-a10694cfb431">test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#94837fe4-61b2-4b6f-a846-e7cb4c35da69">test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#cf300312-a20a-46d5-b398-e0cef926f39b">test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#95baaa0e-8158-4ada-b239-e22d30d37907">test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f8192851-cad2-4a44-b44b-8e3a79c64798">test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c485e22f-fb06-4076-b327-a60adff08d9c">test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#337b4b41-b4ef-41a3-b0ab-e33b447e3bbb">test_worker_spec[False-False-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#20932221-154f-4474-b81c-4b4b653796ac">test_worker_spec[False-False-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#406046ec-e048-4b31-8a18-963d11c83fa9">test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3e737882-0677-4488-8f34-135f1f039b7b">test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#51e9f1b0-39ea-4c8a-a94c-be3eba7e83bb">test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#87f8e7e8-9bb4-4ef0-9225-d2382b8bc40d">test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#6ed2ee29-7045-4cc2-adc5-522d9099295c">test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#ac1ef9c3-dd11-41f7-bf11-b0fdb662b341">test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#071d6590-dd25-4d0b-aaf9-de70bced6ddb">test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#143f2bea-2ec9-446c-9daa-f33eb3f0b2b8">test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a53c8d0e-a1de-4749-9b4c-a5324de2faa3">test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ce99f9e2-94c4-4591-a68c-98283deada47">test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2b47b3f3-57f4-4597-9af9-c2a74565c73b">test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#d1ea56ac-ac1d-4db2-9df2-f8248bac49a5">test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#a02a09f5-e124-4158-a983-903c6104eee0">test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3d4138c5-7681-48eb-83fe-ddb9de80a38e">test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8e5c59d6-fd2d-44d0-8228-07db219eab37">test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#056abe2b-c71a-446c-8014-3ca1a959fe1e">test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a6fef87b-b924-4d72-956b-e20badf72554">test_worker_spec[False-False-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#3c921b78-acf1-4c6f-917e-e341f1346be9">test_worker_spec[False-False-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#54bd0b33-8b6a-46aa-8d31-b9487580c53f">test_worker_spec[False-False-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b23f59ba-a2ff-4faf-aa97-f614926f48ce">test_worker_spec[False-False-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b8fda8b7-565a-41c8-8dd1-14c9218fe925">test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c47a4874-6c05-49e3-9deb-ea217bcd5805">test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9a9d21bb-0ffd-464d-9b15-6e86a5c3812c">test_worker_spec[False-False-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#be9fc914-935c-4c19-9378-ca9582e52f71">test_worker_spec[False-False-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#9754f91c-a9a5-40ff-b527-e90433485f61">test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#97230cc5-b6e6-40cf-801e-8136258a2106">test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0a1bfd5e-9976-4736-8aa7-d34f04e24374">test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#76712c43-d660-4716-8c40-df5af1a619b4">test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#295f4d71-9865-4ef5-a345-5197ed59ef2c">test_worker_spec[False-False-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#6c517338-4daf-4502-9cbb-1def4bbd610f">test_worker_spec[False-False-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#4df03fee-48cd-4c71-8638-ba67d93a2a1c">test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#f4510f24-b272-44f6-9c6e-8f12aee8fa6c">test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5a96736b-dfb8-4ba7-967f-8c69e89dc2bd">test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a9adbd13-8eab-4975-b4ff-23575603ff59">test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#52189974-ab16-4e70-9e2f-dcdbb5e2f105">test_worker_spec[False-False-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#7bd5637d-68e3-4872-8ba4-fe7ced844498">test_worker_spec[False-False-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#de079742-5ee3-4040-87f4-c1b49ce07a81">test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#961a040d-0ed6-47ef-a288-3a72d12f21a9">test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6847694e-a1a9-4e32-af7c-1c0e65969252">test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d8be78a9-ec68-40cc-b672-78681e11a582">test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#66bbe307-0e98-45bb-b7b8-0a9020fde270">test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#aa682f21-fad3-4d61-b4f8-2c4ecf439b60">test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#71aa69cb-7dea-4e14-a6f3-277f542c230d">test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ef3bccfe-e22d-4a0f-97ba-87dadbff411e">test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#95b1abd6-5799-413a-ba0f-08f02880a80f">test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ad01e59f-b08c-4d2d-867d-89e59338ae96">test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d8670786-8913-44f4-90f9-cc4c1d1783eb">test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#6eb5130f-1995-4f9e-ade7-cd4844c33555">test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#834098fd-44d7-418b-a5d0-46bab9d1d20c">test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ad0fb306-3dac-47ca-bee2-09647baf1bcf">test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8c75cc99-50bc-41f8-9386-7854153be390">test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#cea1dab4-06bd-48b7-8d46-570dd29c1a31">test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#fbc8b524-56f9-4bed-b12b-9cef73c75e1c">test_worker_spec[False-False-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f1c2aea9-7709-4c06-acd4-fc0ba01fcd1c">test_worker_spec[False-False-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#e84f79bf-14b6-425c-a1ef-da59be00ed89">test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0b5ff549-603a-4898-873d-73e4b7c3fff4">test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#39036788-cf4d-441d-b271-10580f4b7733">test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#77ffadd9-f355-4edc-af00-617fdd3f0687">test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d5149e35-37a3-44f6-88af-67ced528ad7d">test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#0ec8fc7e-d436-47b9-af3d-ef23c6911b0c">test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#29306c28-6edd-4534-bcd1-0665c862f2b4">test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5922ba30-1107-431f-be6d-c5d8b0b1b55c">test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#013d19df-6d91-4f20-ac8c-4a82990f17f5">test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#07709a3a-765f-4abe-889c-3d981ce8c013">test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0c1ae51e-4fbd-4c57-b58c-e5f93eeaba35">test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#f4d58e8e-75ba-49f7-947b-f3f4f24ffa3d">test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#d370cbcf-eeb0-4561-ae6c-f0191ae58bdf">test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e1442a85-8916-4a25-993e-6434bb22f9c3">test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#77f5508b-a40b-41e0-8e87-fc0e92fe64aa">test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#67b42199-23dc-4564-a813-ad0b5e77bd6a">test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7e2be392-74fc-4d8a-8cb6-9b3a9551dced">test_worker_spec[False-False-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#bbb570a6-baa3-40a3-8ebd-b002c20db553">test_worker_spec[False-False-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#840bc654-e9d7-402a-be85-1f58fa56890d">test_worker_spec[False-False-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3e2eb5e6-d5e6-4eca-8dd2-60735abafb21">test_worker_spec[False-False-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#526652e2-ab0c-4b86-9c0f-44d88c15c806">test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#00707c6c-62f4-4f02-b6eb-b221ffda023a">test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ee5dffc6-08c8-4703-86b5-fe8e2deef55d">test_worker_spec[False-False-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#41b25a42-1035-454e-bff1-0a77e65cbc17">test_worker_spec[False-False-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#0ab1f812-2ed7-488b-bfc5-d39e73f89945">test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d72163a6-043a-4b2a-b9dc-ffe5b5feed81">test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3a7de397-d713-44bc-8440-1c5950e7c361">test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ed1861cf-73df-49ca-a0c9-539353490ce2">test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c4a4b86a-2cb7-4e86-a1e6-0c6eaf13d768">test_worker_spec[False-False-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#c6e8ac50-04ff-4503-9b80-0e7a7313d415">test_worker_spec[False-False-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#673c5f2e-4877-4ceb-bd13-65ed4706e8cb">test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ccefe2b3-b86d-4a35-8a14-f8a56328b7cd">test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0056fbee-cde2-4f47-83f1-f4cb496eefcc">test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f99006f0-0f8d-49ea-b5b3-83dfe8a75b73">test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9b6821c2-3b47-46e5-9683-4adde9c69537">test_worker_spec[False-False-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#6c1fc6bd-0a00-4676-a60d-1e599ac6a70d">test_worker_spec[False-False-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#76acefe4-71c2-42c0-abc4-3ca50f1eb825">test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0d24135b-f242-41f3-9b8f-93983732c77b">test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f41ad6ad-c2b6-421b-926c-0fedfbe02639">test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#05f15895-ec98-4d30-8d2d-d3bbf0bb705f">test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#20758b8d-8069-4fcd-97ee-907682426c3f">test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#4e75ba91-1a5e-492e-880a-16c1b9763782">test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#81b178b4-010a-44a3-8b79-eab112d1c4a3">test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#434d8896-65f0-4277-8c2c-a8e73912934e">test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8ad0413c-d5a3-4056-a92e-cf8e883b3769">test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e6f7d552-1e5a-437e-9f8b-909b1d8dfff4">test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#52fb6763-bf42-4cc7-b33c-8958ec729875">test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#b1c81800-076b-4e0f-be79-6ef8e918f014">test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#f0400303-a0e0-4441-861c-d2d084ba1c84">test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a17744de-9839-4703-8d99-42023bc0199e">test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9dead193-ad65-4489-9365-ee92b1bb3935">test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#34f7dbbd-d3e3-49ef-816f-9ba2c109e2eb">test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ac87bc4a-0bb7-41e6-9363-6526b5884aaa">test_worker_spec[False-False-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#30dd2389-1d17-40d1-a390-ebdc2772303f">test_worker_spec[False-False-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#fe7f46f4-bf70-4a79-840e-4dce174d27a8">test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#234de536-7697-4b23-be96-ba7bb4ef7544">test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a2c8870f-1004-4ea2-b271-5edb215496bb">test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e487da54-ab07-43fc-b510-ca487149a2f0">test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ba18c621-f935-4d7a-b385-fc5001f0c14d">test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#4107dd1c-8a7f-463b-90ce-47ddc18358c1">test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#9f351761-f9b5-40ff-8224-b5ace1d7640e">test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#bc507951-c1ec-46f3-8599-a5587b342eff">test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#154ac99b-e38a-4d20-8a8b-8d788fbb20f2">test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7824368d-4aaf-4b47-8959-e96180578f1d">test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c89a2b06-547b-442f-9074-bfd6a0df1b3c">test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#1e62d8f4-b054-4203-bfd6-10bbbaed6091">test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#d27676f6-d620-4d8b-833e-398bc9b49668">test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0c03a548-d179-43ed-816b-1a16dea3675e">test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#cfda2333-54ee-47e7-88bc-c8433b109576">test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7eca3aae-c511-437b-b453-bd92cc31c9ca">test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ef9c258e-feec-4c93-93b1-8be3b5ca2b19">test_worker_spec[False-False-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#7755ae37-1ad0-46b0-93b5-af99888b011f">test_worker_spec[False-False-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#c922fe03-508c-4669-8558-f36918e5efb3">test_worker_spec[False-False-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9575cf77-65b9-4138-be19-f902f1865f31">test_worker_spec[False-False-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#cc864159-be42-4fb3-bae8-922484320de7">test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ab778eea-c293-4384-86e1-50744da2300a">test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d2dc5e1e-2c15-4223-949b-d8992a9f804b">test_worker_spec[False-False-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#8ea85e24-1a87-49aa-8d86-3a48cb529b75">test_worker_spec[False-False-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#27ec8560-7839-4016-8ba5-39ea1ab62f44">test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3422ffbd-3297-4cbb-95e9-ed95626a5ff7">test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#fb937830-ca82-4974-ab4d-c81db8ec7592">test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0c3f283e-15f4-4876-9f90-74c8a6e42aad">test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ea0e82e9-c2b1-4124-966e-25bda9535149">test_worker_spec[False-False-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#11cf61fa-32be-44fa-a38d-0bb89598d693">test_worker_spec[False-False-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#6ae5f814-68d8-4633-b267-15d056f4d185">test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#81f3ded3-03b5-41f9-bc98-3af52bf7a91d">test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1748b50a-2c2a-4c5e-ae3d-b90285a8d6eb">test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c749a8a7-aee9-440f-bf7e-7d750792b3fb">test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c6930e06-d149-42f0-a21b-2142d41d7434">test_worker_spec[False-False-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f7445714-8b4b-4e38-a557-923bfa9a5644">test_worker_spec[False-False-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#d9b446be-b6bf-43d8-ab12-9dd41eefad95">test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#01f19888-7481-452f-a7a3-21f683bffac8">test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#06d3bd10-c33e-4bb9-8de5-c71d0bf5b8cc">test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#deaa6117-beb0-4e6b-af4b-552967b5311e">test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ffb7a9a1-da3d-4c40-96fe-5428cc840db1">test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#aa4c5f68-dda3-4358-8284-7cd9e78be241">test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#79502ee4-e251-4701-9c2e-c407ba0537bf">test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7ff9ea99-6010-441a-b3a9-2dcbcd3e55f0">test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5ee21150-445b-4de1-8907-a23eee74d415">test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#54987cc7-901c-49ff-bbea-25372dbf5a91">test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c139bdb0-0344-4154-979c-7db58cd253a6">test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#d7c26915-7482-4878-adb1-4f6712885847">test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#8470d6a3-d0a7-439c-9d42-02944d7b0fa1">test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ae30ffc5-a7af-48b4-90b0-87c621daf8ff">test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f41fe7dc-53e3-4139-bd04-4a3518656d99">test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b91238c1-6f5d-4b7a-b32c-3653210a9cea">test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4d1f41a2-9175-4502-8e40-35a1645c70de">test_worker_spec[False-False-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#b5220f33-0c27-4167-804c-24095043a6d4">test_worker_spec[False-False-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#aaeed648-5b2b-466d-a0fd-8168a0912c81">test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e486ca9f-bf3b-4cb6-8f58-02af92b81a5a">test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#49e992a9-29be-4fe6-966e-6b2060ffe816">test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#79e1f8a0-aebe-4d62-803c-a747417d868e">test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#fd7b3eed-dee1-4a18-86a8-05e4ba3b2a6f">test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#6b50fbdb-a5f5-4533-8438-68429ad05781">test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#6aa727a1-8562-4490-a440-16742aa57221">test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#17088b94-58c3-40bf-82b1-cec5745bc2e1">test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2b52a8b7-3db2-4a9b-8fa3-913c5fd89efa">test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#47394a7a-6682-4295-aca3-c9fdff4bdb40">test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5bcdab6a-5ee1-4da3-a16d-2676c8afb7cb">test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#5ed56ee1-9842-451f-b0d3-3fd0568be2b8">test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#6df23cfc-2501-4236-8e14-2cf569a590aa">test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#bf61fb2f-6fd7-4e85-8fee-ce31a1fbe7a0">test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5e945e6b-c507-4d1e-8c78-29ccb1760bbc">test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8539fba7-d75f-4919-97cc-c3245b90040c">test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ec81875d-30b0-4635-b8d8-7317ffce55b0">test_worker_spec[False-True-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#31ffd4c4-609e-44f2-9a9d-2e76c8cae6b9">test_worker_spec[False-True-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#b3b878a4-8f21-48bb-a250-216f0eb4b64f">test_worker_spec[False-True-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b84a7ae1-7910-40bf-9808-316bad818f36">test_worker_spec[False-True-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4fbead5e-235d-46a2-bd2b-176e2d1ce547">test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f0067dee-caa6-4686-8ad1-9e40ae339fdd">test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#106fbb81-803e-44a6-b0d0-d784cc197394">test_worker_spec[False-True-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#3326eedc-4786-4d2b-87f9-21c1d1925fa2">test_worker_spec[False-True-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#edd3fa9a-8cd5-4936-9204-807dfce3b652">test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d8a8255c-e38b-41cc-940a-c264f51ba4ce">test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d9a8b3ba-6b0b-4731-a84a-570fb8f9f971">test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9fbcd011-d2dd-43e9-9657-bd08c34d1f35">test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d48d0b47-ccc7-45e4-bf27-f93201c56e0f">test_worker_spec[False-True-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#2a424516-2b62-4e1d-a456-ad68e38f107d">test_worker_spec[False-True-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#31783b0a-63bb-4eac-9ec2-a737a4cffc6d">test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0eb1c134-13b7-4004-8015-b59141741d59">test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#12a03583-e594-476e-b2ae-017e954aec12">test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f4a835cb-a4e4-48b9-a174-c06ebb62623c">test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b070cae2-f6d6-4654-af1d-b79c28c4afdf">test_worker_spec[False-True-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#9bb6e956-cdaf-4d6f-b884-3d1c6f3bc14d">test_worker_spec[False-True-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#c86d9e65-b9c5-4470-aee4-7030c6875ea7">test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b37cbac0-7a49-455c-98ee-f4bceb622c81">test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d83adc9e-5929-47e5-9075-f432aadf327b">test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#fa267222-7b60-4832-82de-86042b5161c7">test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4d762f26-1224-4f7d-a82b-c28c5d89322a">test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#9fe58185-1ad6-46ac-a26f-38caa8cb1cf9">test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#0f8a920f-4df5-4572-b965-2ce890a3aa4d">test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ab81c00d-188d-45a0-8621-4dd3c9dacfc2">test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ee9f034b-96dc-4d47-bd8e-b0ebab5a6c4b">test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2cf0ee20-d344-4a9f-b2f7-011781a9c8e0">test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#095c3c5a-8804-4235-ae78-8b84e92a7f3b">test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#00a4e961-9f7b-47ec-9cb2-32faf376ebe5">test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#5d1184f1-efa9-4298-bd0a-745291aea79e">test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c9b57b1d-cd44-4252-ada7-e838ad59de98">test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#562c9f11-ad65-4853-a6ad-f05b7b0d5b56">test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a80a63c1-3fa4-4d3b-872d-d54c560206a7">test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#22249865-68b9-4be8-ae49-06a869debd56">test_worker_spec[False-True-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#abe679bc-879c-44b3-a287-f658bfeac520">test_worker_spec[False-True-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#dcd2211a-5580-4bee-8ca3-53d1ee652d66">test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#602de55c-78cf-454f-aaac-3c46b6b04bb3">test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1fc047a4-32e9-49ab-a9f4-865e3fd3e97c">test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#1c4345bf-830c-4bce-bc74-be64e84b51e5">test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3b24af4a-88c7-435f-aa32-c75723262865">test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#78a8447b-bd1a-49e6-984d-362dba4d2a62">test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#d23196f4-fdaf-43b2-8c16-0087e548c6fa">test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#02a732df-e44e-4d17-a6ba-7b22b053421d">test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a5e3425a-defa-4fa2-ac6b-e0c419324b43">test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d0433236-62da-48d9-906d-14d3f78ae718">test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#732124c3-5c53-4323-8af1-ee27e326c889">test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#7eb75873-bb50-470b-b503-3be7649ae92a">test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#1327f2ae-9c23-42e8-bb69-1edbf1e98119">test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#27c39e17-cd2f-4efc-a535-b69c17b95eda">test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#61eaac99-c9a1-495f-9d65-e092546e9f33">test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#58f503e2-c304-4842-b8c4-ed974c9e46c5">test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b3b0509b-47e8-4e06-a8d2-33952ddd060b">test_worker_spec[False-True-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#6b929c1f-007c-432f-94b9-41a6bd19bd1c">test_worker_spec[False-True-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#9b7574f0-b1b2-4d3b-ae5d-5fdf04f10730">test_worker_spec[False-True-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8bbc97cb-5893-4e83-b2cb-33b97f1dbd97">test_worker_spec[False-True-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#c59a6501-870a-47e9-ac68-e916fc892c7a">test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#fea45ce4-e9ba-4617-aaa0-bc08d0cc14fc">test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#47569a73-280c-4e6d-983d-8db888660ccd">test_worker_spec[False-True-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#f9d4fa5f-fc02-4559-8963-7fc8adf767cd">test_worker_spec[False-True-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#c423bb17-d622-43bc-a365-360a868d600e">test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3d1f8359-db27-4a6a-ac2f-7719227992ed">test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6f66b5b2-857a-430a-8655-a5e617f96ff4">test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b664f5c9-baaf-4615-ac28-1d63c9da0014">test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#09211f0d-d406-4ff5-9265-95ee4fedcd76">test_worker_spec[False-True-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#1671cd85-12f4-41d3-a181-587e3f752ab4">test_worker_spec[False-True-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ec10c9dc-fb5e-4356-aecf-a14b971288f3">test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#84499ae9-52a1-4500-9b8b-542e528e0548">test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6a1f129e-e5e0-4f40-893a-0f1579d581cf">test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e046702c-1dbc-4803-abda-fcf9f1822bca">test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#31dfc9d6-2d22-40e9-82a6-7ca474686456">test_worker_spec[False-True-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#5fb24b9d-29bc-4657-80d9-bbaa9fb6b692">test_worker_spec[False-True-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#f2472bf9-0306-4bed-9b90-f43493441c79">test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#192af269-d3ad-4330-8644-67d4a34d54b4">test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f568fd95-fcc6-4567-b9d5-0209d10b05bb">test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d0147abd-81ab-450f-b7ac-4cd55fefd988">test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f7345faa-0303-4863-b8ca-4aeca358d6aa">test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#e806cd5c-025e-466d-89e1-a04e8baeee49">test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#fd84ced7-8141-49d6-a01d-0dbc39df8cb1">test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#108416d3-7dae-4e25-90bd-c767280f2372">test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#293dda82-ccf8-4d7d-ab18-ed54247e837f">test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d14b4ef1-878a-4f04-a9d2-ba3285cad803">test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a5449770-64e5-4fce-be8f-01c6d3766591">test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#2726064f-a332-48af-a249-76c3cedbd88d">test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ca714d7b-bbf5-4831-b113-1454338cff55">test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7e8046b9-6367-45a1-991f-e6d533439fda">test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#997bcf53-cf59-4693-8875-6afc52f9463e">test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ea1f9a81-c0c7-4533-8678-55c2dc3a4667">test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7b2c24cd-e2a9-4b75-aad2-8e68ee7fd53f">test_worker_spec[False-True-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#9d9011f1-ff79-4e2e-a021-03c43ad2abb4">test_worker_spec[False-True-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#caae1475-87c6-4b95-81e7-a76b20246801">test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d57c30a1-bf8f-42bc-8ccc-b227c491da7b">test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#385d6cac-85bb-4723-a73f-6d7f82af68a6">test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#695cea7c-be2c-49cd-b05a-d189569d8059">test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f0646967-a692-4e7a-b667-f60c306eef8e">test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#26f97ba3-3881-413e-8be3-3427c3ee66ee">test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#97d4810f-7a9f-4758-8751-f9d1cd190971">test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b6b8503c-ba41-45de-af1b-fcaa1fbb2a78">test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#558d9559-cd6b-4749-84ca-e08a190d6705">test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#313f5694-2def-4255-9624-499e6b5f2a10">test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0f4e0e19-c50d-4cc8-b34f-0367366a6195">test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#e1266a4a-07ef-4c03-81ef-544959d48673">test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#c1317cb2-1401-4149-b211-6fed0689327b">test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#974f4e9d-a0f7-4a95-93a9-fbbc84e50198">test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#72272578-8cee-49ae-8119-d2c7624b846b">test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a9cc4af6-2593-4c00-af46-018ee8d7efab">test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f958f9a7-2f2b-4c6a-a435-4d6de422e080">test_worker_spec[False-True-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#198c451b-b568-41f9-ae97-9f1e86d090d3">test_worker_spec[False-True-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#cae85b95-3965-4c02-ac84-961b0d63ae79">test_worker_spec[False-True-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7db7f387-cebc-4823-af0d-3cbd8e8977b9">test_worker_spec[False-True-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f81c2d7c-077e-485b-9df4-dd974476d5dd">test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a4bf01cb-0239-4f69-9ba3-4db95b0094b5">test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a30e43ea-7bd1-4852-b46a-bed22aa120f2">test_worker_spec[False-True-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#d57465ec-64e4-4b65-99ba-f9c7e0f80e00">test_worker_spec[False-True-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#2e356028-c6cd-42cf-8c31-feaabccdb81c">test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e0e82d7e-8a5a-44af-9721-e4c856505856">test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#afc76bee-df65-4ff2-86e7-7344162df74a">test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f34e8038-c8dc-4390-a900-024c85eb852d">test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#600c04b7-1a40-43f4-85d1-9a1068ad5e0a">test_worker_spec[False-True-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#30ebed0a-edd0-46c8-9b9a-96e239fc640b">test_worker_spec[False-True-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#f94956aa-5cd9-4497-8e5d-585e9dbf81f4">test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4e71bc7e-8892-4464-af16-17a59fc6eab5">test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#48a6b956-b356-47f6-8215-b2f53d5f0cbb">test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3e5d8aff-ef81-4246-ad21-fb12978814ce">test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#86ab5dd8-f6c8-4ed2-bef4-586a9b55dce9">test_worker_spec[False-True-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#948e17a5-34d6-418c-b9cc-2c41a1367db5">test_worker_spec[False-True-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#a14c1012-11ca-409f-8db3-ba7e1b47e628">test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#f5478b46-db00-49da-81b8-dfd3951c0061">test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#aea50475-07fe-4ce8-ac6b-d44a15fb7ca3">test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#53b9d990-e8c2-4ec8-87b1-784d7bd3e162">test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#61fe4faa-b7a4-4936-b0e5-43b1f9296502">test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#b470aaef-7763-4e31-9ab8-037de414ae1e">test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#4865e041-980c-4076-a1ac-098d48ad9a9a">test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#22743135-4673-4ce8-8551-b95ba636ff55">test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1040d77e-a2b0-4a1e-bb14-2f4b5fb4ca64">test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b1e0d492-be49-40f9-9161-aea65596815d">test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#455970dc-ad36-4404-b207-ce9857321549">test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#0fa6f149-fa93-495e-a9c2-ebb32629c13a">test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#83227005-e934-41fe-a5fa-026ade2fb196">test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b6fc63a7-d3c8-4271-9cf6-412f3cd0c1d7">test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#67e07d08-e414-46b0-86d7-e91ee8d0c394">test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9f5f04a7-81d6-420b-b4e2-d390b3852300">test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d33c6152-5713-4aab-b322-4ffb31c4f069">test_worker_spec[False-True-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#7fadf6ae-6d28-40ce-afe5-176d9de16a69">test_worker_spec[False-True-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#14ef4866-163c-40e3-865f-e3d6ed47c70c">test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4a7fcb6a-d31b-4681-bd70-73963d501e1a">test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8aec75c7-ad94-4a0d-9ca7-5fe0bdddb275">test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#26f037e7-f1c7-4ad0-9c78-b6c9a03a332f">test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#34a2c64b-8e3e-43c2-90b5-d1cd9127392e">test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#2fffc0ff-22c4-4c00-9a3c-03ab8e472265">test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#0000e1e1-ff04-40ea-9c00-9b9b694ac0cc">test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#714a1888-ff32-400e-a14b-6da444997e67">test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ed805713-7649-4cb1-a490-5237db22e36c">test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f148aa33-bcd8-4673-8c97-538ec0454d7c">test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#cc0cb409-1fdc-438d-9082-b4948547bd9b">test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#5490ad22-33f5-4091-bb41-a513bb96841a">test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#711ea36a-ccad-4cbd-bded-821d785bc43f">test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#95c4820c-8518-48e7-818a-1febedbec0f0">test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#04c07cf2-defb-4689-8e3f-d5d556f939d2">test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a9d151bf-631e-4bb5-98ea-823f9901c377">test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5a0f9894-a54d-44f1-af38-4fa5a0705b2b">test_worker_spec[False-True-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#cd1ccb52-517b-4c1b-8cd2-8b3c7526886b">test_worker_spec[False-True-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#5bbcc54b-5946-4032-bfd6-064c4b0421a0">test_worker_spec[False-True-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3405854c-8dec-4a59-a153-6e610b53fd48">test_worker_spec[False-True-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b1cb3384-066f-4d20-8931-bd9e6accdd8c">test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7e2dba5c-d176-4321-9cc5-3258849af45a">test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#899ef7cf-33ec-407d-ae28-a94b14a90e08">test_worker_spec[False-True-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#10cecc8c-7b79-4ec2-853e-32d020bd4fd5">test_worker_spec[False-True-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#4579dc86-5af8-443a-918c-6f3824b2f49e">test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5fad3111-e095-4b86-be83-fc7aea9c00d3">test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d6a84e4d-ac2c-4f4a-8e5a-16037f3cad93">test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f468778f-23c8-4623-9e4a-7a87779ca220">test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#014042a8-2b98-419d-a961-b4c35f24ff36">test_worker_spec[False-True-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#1a13bcf2-f905-467c-bac6-48d2fbb42332">test_worker_spec[False-True-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#0f2e280c-b7c9-4a14-8956-09b7b39d93d0">test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#703a2a65-ebac-48ca-8279-ffe96c9a9e44">test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a28e508d-adbd-455d-b57d-9ae303294758">test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a89c68ab-4fd5-4c57-b32e-e019dd4a5647">test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8e46d5b5-06e5-495d-bf08-181528a2127c">test_worker_spec[False-True-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#62b1fa8f-3e26-4024-a009-6dc777cd2be6">test_worker_spec[False-True-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#3c35844b-59c8-40ed-9ca5-d7d14a499f68">test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#966cdd96-471c-48e9-b4bd-33b50884b544">test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2e92dd92-d9c4-44ea-adcd-8f4a7ddf97e3">test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8930384d-f751-447a-8ca0-c9ece88e6192">test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#31b9011c-2c86-456a-8fce-70712fe8ffb8">test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#f25aaf4b-7105-4a17-a222-0b681fa30280">test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#0afdad54-6809-4db4-9690-862b1fcb6264">test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#256d2506-542c-44b2-a603-f5d0aa719da2">test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#107be56c-a500-4fbc-97cf-061ba94bcae0">test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#995737d3-cce9-4a9d-9b4b-ebad8635a5d1">test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b393291c-2097-4f89-bdad-b2d22ee42ac9">test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#a37f36eb-11a1-416d-9d48-7218be35f45e">test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#419e8145-8e79-4ca1-897a-d7b2b05b7e12">test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a80ed033-1b40-4159-b8e8-f4da110311d8">test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#493cf1ba-21de-4b46-8909-5eefe41b8e9e">test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6e565d38-a6d0-444b-be4e-3ed8d47bff7e">test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3f5808c2-c420-4f44-8cbd-7b498d6c8344">test_worker_spec[False-True-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#e5bfccea-366e-49e3-bdf6-cad145992a99">test_worker_spec[False-True-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#17d9d272-b015-4b47-8924-7dcabed1b5f3">test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a8d21c9a-ee06-4563-9426-1fe9c13c89a2">test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#719051b5-84c1-4ef9-afd7-b5df38b66a4f">test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d2b52bc4-9d8c-4e73-b09c-efc94b21ccd7">test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e81a1adc-65f1-4165-a2bf-7835c8e9c697">test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#7bca7fbe-b7bf-4c17-abd0-1cb0576317ca">test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#d72c864c-f6a7-483b-aedb-9a9316c39e1d">test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#622e3e5f-3fcb-4b8b-9191-f584216f4707">test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#cc8c4379-a3ca-4996-82c7-fb346317c893">test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#74727b7d-0b9d-42d1-8a3a-a79d8b23c45c">test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#00bd9dea-0dbb-4e61-92ea-058703770926">test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#96a25239-26a3-4c43-9f08-0ef4f15a05f3">test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#879d5369-55f7-44d1-b9fa-693fded8ac34">test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d05d96f6-fc5f-4ddc-9f4e-c69e84e5ea6a">test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5abd63cc-a884-45bc-a2dd-9b12fdcbb625">test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#63e49261-49ea-4c60-9107-c4a0856089e9">test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9412cac5-7860-4b98-aef7-d846012a8384">test_worker_spec[True-False-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#36456dc4-27b0-4273-a4d9-069a3d9953dd">test_worker_spec[True-False-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#a98f423e-bd81-483a-9141-cd4cd2681cd8">test_worker_spec[True-False-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6192cf31-793e-4634-81b8-66cf4fd28951">test_worker_spec[True-False-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e163feb9-a673-44bc-8c70-26c542127a50">test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ae6f23d4-0a15-40d5-ba27-dda8ec7dec0f">test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#484b0074-f7e4-4742-a8c2-a19d2b54dc86">test_worker_spec[True-False-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#743463dd-4c89-43dc-a680-f415107eaee7">test_worker_spec[True-False-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#62a066a4-2421-412f-abe4-f7e72192a818">test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0a7f57f3-893c-444a-8395-2fcbcacb680f">test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#c639cb1d-68ad-43ed-b286-db958fa22081">test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0dcaedfb-ee7c-4992-ab7d-68a2054bc63c">test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#6d609969-d457-4f8b-a345-a7cbcc4759a3">test_worker_spec[True-False-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#593020e1-ac22-4322-9591-ffb8f3b7a8c8">test_worker_spec[True-False-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#95dd3a52-2209-47b2-b762-a2514837d6fb">test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#49b16e14-d7e7-456c-ac81-faf853875e0f">test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#bfb626de-7105-4133-b270-6939e6ca6b01">test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#fb5b49dc-fb7f-4728-bf3d-101ca1802888">test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#95d655c5-a379-4031-a335-2ca0a018672a">test_worker_spec[True-False-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#e9e58ba3-6156-41d3-ad83-5ed11357b7d5">test_worker_spec[True-False-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#6dc527a7-4f4c-410b-a5d5-2e5bccc4e1bd">test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#32ffd03d-5dab-4a87-8a50-9efa69ffb76a">test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#17e4f398-9055-4c3f-a661-48c799568e7a">test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6fd928fe-97ba-4fff-8d41-257a91e25275">test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e8bac45e-cb52-41fa-ba1a-319ac43d62ae">test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#fe2b9ee1-a96f-437a-b2d2-8925109e3277">test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#492bc30e-101a-4f41-b479-88c4d8f07070">test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0f9b5432-2598-4b54-af74-f2c662fa08ad">test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#be155e7d-20c6-47ae-a9cb-5753e9807854">test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#49895b9f-6d8f-4632-aa89-143defb8d518">test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2ffa0c0c-c836-4fa5-9b79-7f474dca2a54">test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#300d41c8-8b1e-4fb9-9157-b9baf8d0129e">test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#90f2bb50-94c3-4a92-b91f-ec2c448fbee3">test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#73207c6c-a057-4784-aed4-fcc5544b7056">test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b50d290a-bab8-4893-ba66-67ea0f12247e">test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7eb0f877-c8be-4a09-af38-7b6164babae8">test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d6909b6a-8628-44b3-a599-ae7c9a81e65c">test_worker_spec[True-False-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#cb752d91-3fa2-4e90-a62f-d380aad47fa0">test_worker_spec[True-False-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#b1cf4651-f9b1-4a42-8c2d-c6746a798750">test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#255369c4-a54f-4e06-b5c4-aceaf23d93a2">test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8d638c99-e04b-4754-ba57-8912bf00621a">test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7b881cd6-096d-4934-b866-d3d10bca4167">test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#da9b1d2b-58af-4c44-b4a8-33328feda19e">test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#b6149183-8a24-484a-8796-b7c12b0feec3">test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#de2d6705-e638-4e04-b75e-b501381eab9b">test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#59091a1c-ff0a-4e08-acd0-a36fb9d5dd1f">test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7ad81eba-1930-43de-b0bb-fb5ed82cc5a5">test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#bf200452-26af-4eff-b1f9-edc0dc705902">test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#74fa2e8e-b08f-45ff-bbbf-970a12b7449f">test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#614618f8-5fa7-42ca-9a28-09d40cdf374c">test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#0c32f6b9-b535-4f4f-bb4b-4cc9c3c1da6f">test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a6b87ff0-d932-4da1-91e6-8c1f08d4cbf0">test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#028c31cd-f5bf-46ef-9fcd-d0dbd58ea494">test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#40f9e1fb-e1f9-45b6-ba42-383854cac87f">test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#eb9fa167-9333-4445-8ea2-e22a9d907301">test_worker_spec[True-False-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#5d73a6fa-f501-4802-ae33-e06ced17a3bc">test_worker_spec[True-False-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#10c40412-5158-4a8c-a6b3-d95f6fb13631">test_worker_spec[True-False-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a9656f5a-c8d5-4fd0-9b6a-809f6ba476e3">test_worker_spec[True-False-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b532d7af-b86d-4571-b2df-fe7ff2192fdb">test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#df4996c1-63cd-4319-a017-02a9162c132c">test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b8f80223-69d2-40dd-bcbc-90a8f239912a">test_worker_spec[True-False-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#999e1cda-66b9-4cc9-a8cd-30f5b0fd5dc0">test_worker_spec[True-False-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#14ad909f-00ae-4c38-a602-7369a1bcde5c">test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3b4ae9b0-dcf3-4728-a8e0-642516a1506c">test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#64ae0c91-2979-4fde-a10e-9e24e7bb9bf7">test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e03082c3-9731-478c-b49d-f50b4954fe15">test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#748a9697-c941-4c38-b91f-8a2ad20eb9c4">test_worker_spec[True-False-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#772c62bc-b38b-49ff-9922-ec76eb02526c">test_worker_spec[True-False-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#691e198c-f23e-4dc0-80dc-b057c414122a">test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0101b1f3-9aac-45fa-87ac-1a4bb2ea935e">test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b5285c6f-0737-460b-acb9-879048bbeff4">test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#925ce7f7-079d-4cd5-94cc-64c1cd66f656">test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8426454e-e3d2-4fc6-b0f2-6c36d4e37d7a">test_worker_spec[True-False-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#b2e178e6-e83a-4d69-a39a-ba11d35a3751">test_worker_spec[True-False-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#d36a2ecc-8465-49db-85f2-50e00d15a2b8">test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#981d0ee3-7900-46b5-bf05-01b4e8567eba">test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#abc74d45-23b9-4dba-bf06-f7564f62c79a">test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#5a83d3e0-07ec-436f-ac0f-32e08cba4ddf">test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a7f033df-306e-445a-bffc-0c7f80ed05b2">test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#ac2fa8ca-429a-4e1f-974a-8096627e8ad9">test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#9b057121-525e-4fde-8ad1-9678531dbdf4">test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6811596e-1bcd-4876-87b7-ac83aca6b2d1">test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#c45a0f0e-f53f-4483-be93-1485cac30f29">test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#86048db9-3410-4210-ab5c-b7b29379ec7f">test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7fabe3b0-c19e-4be0-9c1d-92eee8d9b11f">test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#ca5c6a92-d83b-41ec-9eff-0b29ac8b9ff4">test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#abca45ac-4d4f-441b-b2df-a79af366e10e">test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#fad0eba6-da02-4b82-997f-fda64f691ec6">test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a2849f7c-dc1f-4229-a01c-09183befc259">test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a24bc547-213b-4e6a-a9de-13228cef1bf8">test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#1470c325-c399-472a-953e-93b52eb0d1ea">test_worker_spec[True-False-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#83bc0656-968d-4507-8b84-0ce5b86b271a">test_worker_spec[True-False-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#d024e860-5c37-421e-9f33-e1fc3033597b">test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#424986fa-f123-4309-86f7-e9af3e706eb3">test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#44020981-c966-4d2b-a2d0-c1e7eba34806">test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#be9dfae4-5b3f-4823-bce3-0c34e395cfd7">test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#6a53b13e-4760-4c93-85dc-cbb4cd9a0e7e">test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#f2d10876-75ed-4a28-8043-d4a5f6287015">test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#4045a53d-1d16-4e10-90ef-e1be876855e1">test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#68b37172-5cb4-422d-a85d-d39fd857899b">test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e19a2dd0-4d62-4367-a34f-0753d74784c2">test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8f5f437b-ea29-4013-bc64-3ed201950cd0">test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#76a2a09b-24ac-497d-8cd1-1ff7344c380b">test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#527f1985-df95-4464-b157-69d8bb69a307">test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#80f7c8e2-ca32-4858-bed6-3768609d31e8">test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b9e717c7-9a62-4887-9fbb-68e5ee26d9a4">test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8bea1d82-6f1c-42fc-82f7-0be7e62123fc">test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#cabf6dc1-3351-44ef-9754-1f2caa677a9e">test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0ad09271-3d32-4867-8c3a-24cee35fba7d">test_worker_spec[True-False-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#fbbe4048-af4f-4336-b81f-a1f86803f2b1">test_worker_spec[True-False-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#195bd390-389d-4e04-bbdd-e7a4282affc3">test_worker_spec[True-False-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#664feae5-c2a2-4c0e-aa2a-c26f50bdc29f">test_worker_spec[True-False-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#36e7344e-99d7-431f-915b-0d2f95a1672a">test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#dee6aea2-a009-42ff-97e7-5c91464339bb">test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#15005e2e-89dd-4fe0-948a-f62b0ba5c583">test_worker_spec[True-False-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#86a71c46-2e79-47b7-a55d-9eb8e44ae0aa">test_worker_spec[True-False-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#10fbbf7e-6278-4674-ab02-744694bdfd00">test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#f73a810c-79fc-41ff-b85a-d7949a50c391">test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f59612e9-f46b-47df-ad38-8d500488bb41">test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9453f3fa-1c77-4a33-80d0-77f7f70b3c1c">test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#70d6ee09-939b-40ec-95ac-e7967bbbc656">test_worker_spec[True-False-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#0f365286-afa8-4691-b644-39d007a61824">test_worker_spec[True-False-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#72732d0e-d064-4530-b8ff-6c15727d3e5b">test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a00829b6-6363-4487-baf7-35dca36b3e16">test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8d9e1ed8-b97b-4447-b4c4-6ddf857e26ba">test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#81a7cda0-78a0-4f0d-ac2a-b6d83bf89bf8">test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#caf416f9-a28e-4583-9899-bbe6ef833eef">test_worker_spec[True-False-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#39d4a9b7-a004-40d7-88e4-b2f0c5a3ec31">test_worker_spec[True-False-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#209e5d4e-9322-48c7-9577-e50fe36c11ec">test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#19f198b1-ba84-4dbd-8138-0b1eaf4feba8">test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3015204f-27b0-4d70-8a42-0a47ef0273a6">test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#43771d1a-a3b1-47ed-a411-16e71671d64b">test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a712bec1-62fc-4ac4-b7cb-8241af0a71cd">test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#1276d579-666e-4595-b250-533b87c6fe4e">test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#1a20ce16-fabf-41dc-8562-b977b94c4053">test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#cf8e4391-b700-409c-9da0-9feaf6783c4e">test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#dda7e221-e7a2-4bd9-b190-a872a055f83a">test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7cc112d3-c567-405e-b296-4da177dad45b">test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2f11596e-ecc8-4647-ab47-292b636ee443">test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#3e19fb40-0e31-4828-90c4-d5c13d9fa2b2">test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#cb1536cf-25fa-4c84-a32d-940955bd1a24">test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3b51bb46-8b15-4126-969f-9908b4d68b15">test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2d673bf7-5ffc-4c2a-92a5-45a463fbbf9b">test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c5d106c1-e062-425d-8e9e-668b511e8b5c">test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b7ba8d60-3be8-471f-92b2-7e28b8fd10ca">test_worker_spec[True-False-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#2585012a-7cf7-43ab-b496-d63080a535b1">test_worker_spec[True-False-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#d452220d-53d1-41b5-bd35-ec09c26bd109">test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#648c07e2-f131-4127-be8f-fb83d7c5e40d">test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#92bcef7c-82e6-4e7f-8c10-c95e98804d6d">test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3e22295c-ba1e-47d3-afe5-bca9feb27257">test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e797ab83-27e8-43c7-9f71-568c16668162">test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#56d83107-39ff-4c5f-81f2-9d9cfb292e52">test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#d1f9cff1-b9e7-4690-bc00-b5379f96ec73">test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#19f02a10-6bbf-4356-8f90-5ae979b469f3">test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#97f24e77-4c7d-4fef-ae62-421a5be78c70">test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#05355e9f-4c5d-4a4b-b941-c78d9a8a332d">test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#41250d65-f4bc-4492-8397-68b3fe304922">test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#e90a8586-320f-4b39-9b0a-ea4f36e2e9bc">test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#f990650d-20de-493e-a19a-309a7ceb6010">test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#bd4e557e-0fb3-4462-b58b-ef6f82d88d41">test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8afe6715-62f7-4745-aa16-3f28356b409b">test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#55ba0094-b8ec-44ce-b02c-44884b1bbbc1">test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b13659b5-8283-4372-8a53-9590fa6c8ecf">test_worker_spec[True-False-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#2e2c5716-370c-473b-9389-8eefce0b822e">test_worker_spec[True-False-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#d6d11dd7-b024-415d-8b22-a32a3500b5b8">test_worker_spec[True-False-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#71305b0b-7fa0-4119-9384-1a701a5309df">test_worker_spec[True-False-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2649889c-aed2-430a-a665-6651c1ed060a">test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f4b396ec-acc8-42fe-a20c-1c799d3617ea">test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2ca86e30-1e28-49fe-9e10-6859239273d6">test_worker_spec[True-False-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#63796644-1ee0-4e67-89c2-92c99dab66d0">test_worker_spec[True-False-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#b73c555a-29a7-492f-b15b-dddffc86ea0d">test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#be10e2a6-0534-440f-ab89-19192b108745">test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8795e0dc-894a-4b0a-9976-f6cd5245d85f">test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0d00ad3d-532e-496b-b09d-7f9cc1777a87">test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#bf50cf91-896c-4563-8872-0a42bcf12836">test_worker_spec[True-False-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#7d2553f9-91f6-420f-83ed-67989e59a736">test_worker_spec[True-False-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#47b43afc-3c3e-404f-ac9f-0872b79b48d8">test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#08e00c58-8b20-43b3-a206-ffce5696da08">test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e3b7c71d-c86d-40c7-a3fb-c1a6d5b5f6a4">test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#925f7f5f-12b7-43c4-8a42-794aebe19884">test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5855f573-b806-4f5e-8f75-ff31506b71a6">test_worker_spec[True-False-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#e52dbd37-b8cd-4969-9001-cbd982658b12">test_worker_spec[True-False-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#cc354af3-d7bc-4d13-a5a6-a0d42d9e4a28">test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c7c8eeb1-51b4-4ee4-ba3f-a1ed93d75a34">test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4a7d6eab-657d-4005-ada5-17f5ae8ce9d1">test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#99c52b88-382f-4e17-8df5-d4795249ecb5">test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a7b5d5fe-512c-481d-b1a6-5ba277dd879c">test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#7946ef42-198a-4a5f-8f7e-535f9a280ea4">test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#308fb256-80d9-4f7e-aed2-574d100e77db">test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c6ec9c53-817e-4e1a-a3d7-7a4ea94c3909">test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5e563d86-5563-4818-965f-6e3dac076731">test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#fd5d5e06-8116-47a8-a1b9-9e0f1a18dd59">test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f29b2361-7786-4d8e-9a39-bc9e6b3e8e5a">test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#a6a501fa-7eee-4708-aa63-bfe6f231dcf4">test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ef71b966-a838-4b42-bf70-2bbd9a9b6837">test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#344e14fb-c531-4ee5-bc87-2a67e0fa2994">test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1e9d25d4-4d57-42be-bb0d-66fed737e36c">test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#922e62e7-7718-49d6-be12-e2fda9ed2da3">test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c4bc04f7-002f-4c2a-b5e8-eb2ebfe398ba">test_worker_spec[True-False-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#07885341-dd78-468f-af50-c6dabe1988c8">test_worker_spec[True-False-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#1aba3c59-81b4-465e-bc3b-4f67825a50bf">test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7f9a2b5e-9583-41dc-92b9-a013493caf05">test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5d21e92e-9862-46aa-9022-51c8c51c7936">test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d5c69d0f-2116-4439-971a-4467c62ef1aa">test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f68f2322-ad4d-4cea-b871-bdf0ec37e9ca">test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#341ff271-3036-4083-b088-a6576d8fcbea">test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#2194bfd9-48bf-4b49-897d-6a4e3106dd9e">test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#221a38b7-8fa5-4480-888c-7bebd2bb3d7a">test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#193a6bef-d343-449a-894a-54fd6a08de6c">test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#30c99bb9-d31d-4560-bf26-b7dada3d94fe">test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8dae0702-fd9c-4f7f-8490-df1ec7dcb6fc">test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#5a7d0a7b-91bd-4db5-ba2c-43dde9d054c8">test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#1c4bb7e8-45dc-4bef-bd6d-2350cdc188d1">test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#63ce6a48-9a6b-4026-99bd-a47347b030e7">test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#76b2d6f3-b96d-4dae-a73c-c70bf928c56c">test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#aebbe1ef-1f9a-48a8-866a-d8fc59445496">test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#87018e8a-9d81-4ead-ad27-c5d8d973d05e">test_worker_spec[True-True-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#fc8379dc-97c4-4f4d-91db-47edbed3d000">test_worker_spec[True-True-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#8a740636-7bb8-4d3e-9394-06b9f8d4f1b9">test_worker_spec[True-True-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#41a9b70f-73e1-4bd9-9e25-a9479347baa3">test_worker_spec[True-True-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a198b0c5-d01c-4f42-9918-f3ae3ec57bab">test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#68d4aae9-627b-4dd8-940c-41a5a1f2578f">test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7f6a01de-aa3a-4a6b-8adc-91f5d6332771">test_worker_spec[True-True-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#45251088-8dd3-4a4f-bd64-70322d51f296">test_worker_spec[True-True-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#473a9e89-6473-46e4-9b30-4baec11c7a19">test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#69a3a9eb-5d12-41d6-9beb-dcc81680691c">test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0af6d1f9-9dc0-4747-8de9-4eb4d00555fd">test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0533489f-bb68-405b-9ce1-5c7f21204e46">test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#65d4bffe-f46f-4005-be27-611623a7ebfe">test_worker_spec[True-True-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#fff417ad-5b08-4d25-8332-fa6258326a2a">test_worker_spec[True-True-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#10d74e97-04c9-47ed-98f1-cd1822cfbfb5">test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#1aabcece-b527-4a2e-ad03-f5ea711a091b">test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#23441e17-2a11-4122-a951-70fecda88bf3">test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#1e3f1c92-727c-4e84-86e5-4258fbcc9674">test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b45e1a54-b7f5-4115-8347-db4efe14756f">test_worker_spec[True-True-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f0d91308-2b43-49bc-bc58-9c59bcf046e5">test_worker_spec[True-True-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#c40b1aaa-fa13-419f-a418-742de587a546">test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c6560f82-caba-4bb4-8439-c28d3e5a84a2">test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b501f412-9b60-4e4e-a25c-8c7591aababc">test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#16281d55-d128-4692-9d20-f789f5d90446">test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b576a3a2-df01-4fee-a710-a0a828dac167">test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#b0a175f9-1fef-4882-bb41-be0e9e015901">test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#a5002fb4-80ae-466c-920d-68660945d7dd">test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0e1118c6-1db8-454d-b918-d8ad8848e99b">test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3fa09105-5524-47d6-aaa7-6c91e18ec630">test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#77b9346d-742c-4297-a9c9-bcf38731d03e">test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b80b7aab-f770-4e05-a909-ed5dcc9ff639">test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#c47e42d6-9ea8-408e-9d0c-69df9f3ce785">test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#7e314f32-b890-47e4-804d-3990a78e9d33">test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ffa71d5e-601f-489b-9142-a2b32c31928e">test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4e16c115-ff4b-4d38-ab11-088700e055ff">test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#73a4b124-0bd4-4197-af64-4c814bc269af">test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4dc4ca8a-4e1f-4685-a124-cfc47b2cd39e">test_worker_spec[True-True-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#9a25add7-2a8c-4276-8cee-ac7473813191">test_worker_spec[True-True-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#4121f9e8-5ee2-4945-be40-493eeeff4b96">test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#053ab2af-55eb-472f-8d0f-44e5848abc79">test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#674be9c5-421b-49fb-a28e-c52f51571ed4">test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#45313471-0e25-4b6b-ada6-a2c37c2e43b2">test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#65840c1b-4503-4434-aeb5-6084029c402d">test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#d0962d23-c3f0-4f8b-8806-01f5fc629a62">test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#a1f14559-7280-4268-8eef-a3548126fbb4">test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#bf9ee42d-d715-4cb0-b882-3596c4e0af0b">test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f9df7383-8734-4d6e-bfe0-e0c21162d727">test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#05c025c3-188f-4c94-8f8a-1fb2dd4d391c">test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#affab3cc-27f6-40b6-8d1a-1a3cf2176de9">test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#ac0aebfc-201f-452c-a348-397410bec707">test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#6e5e35bc-75f6-47ec-aed0-76bdb3ef5137">test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5a98f890-42ed-498d-ab1f-d164cb1d7d83">test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#59be026d-05c8-4fa8-8a71-dd94cf059276">test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e7d4b20d-0599-4b12-ad1f-d0cb1f05c1c8">test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#615a9ce9-a938-41e0-92e4-38a5f61a6027">test_worker_spec[True-True-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#08b8f8c0-36cb-4f5c-a8b4-f12cd586e807">test_worker_spec[True-True-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#2e876664-8b11-461b-b0d6-7503da3ffaf2">test_worker_spec[True-True-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d9c3ee3d-8a94-470c-b15d-3b740a13005a">test_worker_spec[True-True-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1e6c5dcf-b392-42be-969a-1f01272f3fc9">test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4f207674-9572-4b9d-801f-0ac4d7f05f92">test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9e010017-3432-4e78-860a-e0952831de38">test_worker_spec[True-True-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#abbfc47f-d141-4698-8a93-3be9bef4dac5">test_worker_spec[True-True-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#27927991-ac14-4f14-a464-7a996134dc33">test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9ab08d55-358d-4e94-bbae-034fb7f99a88">test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7353b191-282f-4c2a-b6a1-ea67d3771caf">test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6348b7c7-832b-4a5c-bc7c-ad94b051961d">test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#dc129327-dc2e-4523-8848-b7235a1409b6">test_worker_spec[True-True-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#7ef1ecbf-77c9-47bc-89bd-500839fdd614">test_worker_spec[True-True-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#f5f28af3-5a04-4a0e-a604-acf61545d417">test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#34afee75-0ca9-44ad-ad9d-a005d173d334">test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b15f963a-9144-46ce-ab56-74f60736a514">test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9d4c5817-9b22-4597-a623-d0e2a510bbfd">test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5838947d-d9e1-4c6d-b4da-3737752a1bc6">test_worker_spec[True-True-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#8048a840-dfb9-41c2-9dcd-a5f8d12804ba">test_worker_spec[True-True-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#8737883d-fe43-42b3-b6b3-ce1234e30d26">test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7ef50b0d-5ccf-484d-a1c8-d9e2d04ac6b8">test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4a4510be-b00f-4727-b5b0-cee74d4d67b1">test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#41e68fbf-a1ea-4316-87fd-958931881fd3">test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0aaacd82-34bc-4d9e-8d99-8436039dd193">test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#3084c37d-52f2-4e63-ba59-2923d9f55da5">test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#31bfe205-31de-45b1-8f1e-9da3eb2e2abd">test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#584f88e2-320e-4216-8f9b-9716749f45ca">test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9fa0ecf0-77e5-4a6c-8ce5-a12bdc2f965c">test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#25aca0b5-ec0a-4bc2-898b-5b4b6eacd7a1">test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3599be16-5e53-459d-ac15-6280fd3a4f36">test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#49868b7d-853f-4924-8f6a-04e0a3254b4b">test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#112db3e9-bb01-4414-b31b-e39c59105c1b">test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4d1b652c-9d6d-4ad2-ade8-458a3023723a">test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e47c6970-0a49-4580-98fe-3122fe0914b8">test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9e033313-0d43-4569-8677-31c18cebe273">test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d373eba4-2ac0-46f3-83c1-893c7a46e8a0">test_worker_spec[True-True-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#e8bbe437-8e04-419e-8b2c-09e05d9ff241">test_worker_spec[True-True-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#bee92992-5028-41c3-9b98-213c3e1adc9a">test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8f8cfc87-2b69-4561-9566-e0f58e4da5df">test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#560ec7eb-9027-4ffd-a5d0-046949fc0872">test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#5914c2d2-f876-4cd6-a3ea-9919a6b86fe1">test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7dce86ce-d44e-488e-a447-46c419b9cee2">test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#1ce84400-8075-4c6b-b40b-725753eaebf2">test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#abda383c-5154-49c0-9b06-7866ed5cfd19">test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ec8b4681-071b-457b-a73f-1df291de41fc">test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#041ae562-109f-4cbd-8b91-33accb6caf82">test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3cba10c6-0ffc-4385-a305-45b57726b3f6">test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#72ad7638-8b8f-446c-898d-49e7c7d4ecfc">test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#b070a3db-ae9d-426e-807f-5abf63969ded">test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#5325cca2-2f8d-48b9-b93b-7153ae72403c">test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ed03fc1b-a039-421b-b5c1-3e3c142276af">test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ed359ac5-d8fc-498d-80f7-533266a515f2">test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#535e6edb-33eb-422d-8334-a8c18e6ba630">test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3f1ad4de-ed44-46d0-a1c9-1fcc677a821f">test_worker_spec[True-True-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#de6036a7-0c3f-4885-aa32-8206e7bc665f">test_worker_spec[True-True-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#2124685a-2bad-4fb2-bd01-81d46a73d32d">test_worker_spec[True-True-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#1d8706c4-9b9f-43da-a9b3-91c3aa9d8abc">test_worker_spec[True-True-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#12aed048-3e6d-4a6d-a5b5-10a75ba4af38">test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#bcde46d9-bc44-4039-ad75-496a2b190621">test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#51d9c66a-6f6f-4a54-ae76-e57268c10374">test_worker_spec[True-True-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#49c02351-a6cc-422e-a4d4-c66293899525">test_worker_spec[True-True-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#fb1abd08-e0a8-4765-ad78-c1f2e1a0dee4">test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#2a0d0ff1-0696-420c-97c8-956955e61e05">test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#55444e4c-524f-4f5b-b2f6-1658b8902d97">test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d7a9ed18-b332-4d56-a148-3c9d73669b5b">test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d888be4d-0e49-498c-843c-f6d702637563">test_worker_spec[True-True-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#0a8dfef0-048c-439d-b7d5-bff0b0f46202">test_worker_spec[True-True-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#79a31131-883c-4b18-b9ff-f054921fcf31">test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a02607cc-407c-4a9d-b53f-f017da06d543">test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#781aaa16-d419-4fb5-9358-9d5f78c9226d">test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#69c73724-ea9d-4468-a2bd-f7aed883da20">test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#263a41d6-ae99-473e-8fb2-d6b9f4fd83f0">test_worker_spec[True-True-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f147d779-00af-4c05-9a3d-1821694a3477">test_worker_spec[True-True-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#dc2570fb-cf19-4ea0-b087-da560b3452e3">test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#cc698d38-6b98-4947-8a46-92518c6e42f4">test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7182db7e-d3ba-47e7-98d9-599f036ef2cf">test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#aadc3e25-3ef1-4877-8803-30517942e814">test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#02c0ad51-6a93-4145-9fdc-979c893c7781">test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#fef4e14e-f673-410d-b90a-fecce33f4898">test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#54517405-1f56-4b4b-98f3-b3ae322b31d9">test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c9fab60c-2710-495e-abcb-71f8284e7ce7">test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f87b76af-94fc-4a1c-91f0-ccf1948d5258">test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#af55f285-7009-4bd9-8f69-ffb046d5959e">test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9bc766ff-b940-4c43-8c25-473e1ee99ec4">test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#1394fa81-f41d-44a2-8bbe-08900f7701b5">test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ef6caf93-69ca-4ce3-8e7d-f49cc11668da">test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6e13daa5-7207-43d2-9d71-4c38a751679d">test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#23ea7972-5651-4a2b-9514-86237388323e">test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#20b02914-8dfb-4275-a677-17e0267e2b9f">test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#6946c374-d281-438c-8c61-b549a1f56b76">test_worker_spec[True-True-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#a2046d52-c287-4902-9e29-97f235c84bed">test_worker_spec[True-True-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#90a83f55-1221-4b03-9b4c-89b26cd997e9">test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#68afae60-151c-48e2-a0af-bae0cc6d5e97">test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#c9d56be9-6c31-4bea-8fca-6f6e8d658699">test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#db0e0b70-2938-4105-9f90-9396c29d5fa0">test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0e7ca55c-b2dc-4615-9fc4-366509b6c4dc">test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#1907cf32-1f51-476e-a574-02027f46b04c">test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#e9be8912-6a8c-495f-9558-cf45e3c34ef2">test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0734472a-257b-43fe-ae09-eb853afd8c41">test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a3dbcaaf-836d-4f5a-8ca4-54ea9e52cbc0">test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9109a6a3-6b06-4f92-a8f3-578ec0cccb95">test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ac9549a3-89e5-4dc3-8d35-4554c51a7d6d">test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#b13b7b5b-63bb-4694-abb0-d9e4488fe65f">test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#8a611530-281b-4fbe-b035-8a9307b26ed4">test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4477ca28-1a78-4e8c-a024-ffbed0e19044">test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#36b6cac0-31b9-4133-a469-326eae4e349a">test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8a500def-1525-4eea-a379-449d1bc227bb">test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#fea76889-d84a-412f-a79f-7df9f89e8561">test_worker_spec[True-True-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#0d60120d-9bfd-4797-9619-a068f62198bd">test_worker_spec[True-True-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#56cf5907-56f8-48b3-a502-f6d5d03c4220">test_worker_spec[True-True-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#186a87ed-cdc9-4f48-857d-965e45516dae">test_worker_spec[True-True-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a413dbf9-0e19-40d1-af8c-12bb6d188a2d">test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4321781f-0a74-4d17-b3fc-4007b2031e47">test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#afff674f-f95e-431a-8927-fab53f321e17">test_worker_spec[True-True-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#6da4eec4-a71e-433b-9ff9-f683e169bb3a">test_worker_spec[True-True-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#3d14b5a7-e31f-47c2-86f4-00e149a4c9db">test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#70d3cf71-2c90-4a08-9538-44092e3b92a3">test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0a444807-7f62-4dc1-b609-84770efa7996">test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f96f2e3d-2843-46d1-8553-ac61dabb5d7c">test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#cfb3a529-ea47-4928-8785-604a46eacbb2">test_worker_spec[True-True-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#fd0815e1-d89d-401d-94d7-445a610d6412">test_worker_spec[True-True-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#4bf38ad3-5b00-4d2c-a478-8526a3045911">test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ca939494-c596-4e76-8cf3-e397d089de0e">test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ab1538b1-0d76-4fa2-bfc4-3dc6a4ef036d">test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a3703669-30ad-4fdc-b550-af8c09b10de1">test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9a7e3e67-4f62-4159-9c61-734b96d20324">test_worker_spec[True-True-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#94ae5198-a70c-4720-bf25-2442fc2b9ac2">test_worker_spec[True-True-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#b267bd4e-0100-4c2c-975b-eedd3d09c45e">test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#16527f44-5180-453b-980b-614d8c34963c">test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7cc7838e-259c-40cb-8e7d-66c49574aee3">test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a3fac793-f2dd-41c8-a143-5ce298bf3149">test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#68bb7a54-f595-4a96-a48d-d936559fa8e7">test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#5052c2df-8384-4a3c-a781-1a6f1960df73">test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#705e2849-0125-487e-8495-9066c0100161">test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a4984d90-7e0a-42d8-b467-fad8bd70e463">test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#85ebb12e-6f2b-45de-816a-841df9fa8856">test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7d362893-6f71-44a5-8f11-984cb6ab9cd9">test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#441ea52d-b00d-4c70-9413-d6b0ee1d5dce">test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#a9b755b2-e95b-4bd4-9c1f-e3603df243bc">test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#efc9f06a-d503-4b8c-acb8-c61f6fa85348">test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#eeadd273-6cf0-490f-a7d5-cd575922249c">test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0b0c8980-83d3-4f60-86a6-a0baa697938a">test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b721a8be-7961-4fb3-b45f-6023663138fb">test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7b591960-8cf8-4593-bc5e-38261ca3b664">test_worker_spec[True-True-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#c9ea2439-8309-46f0-87f5-efe2ac3aef22">test_worker_spec[True-True-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#bf4ab78f-d379-463d-987f-3478a46772ae">test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ab84fdfe-26a3-41a8-833e-426110ff07f5">test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d7582216-534b-46c2-aa33-f2072e29129e">test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0c014f19-db46-45d4-ae67-2a341a72b916">test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#436efd17-3251-4e4e-a740-f48359fa4a6d">test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#49f8937c-0ff6-4e80-a980-769c30b38cd2">test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#55a15023-651d-4f8b-9cd8-3e3340103318">test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0148a488-29b4-4d83-b21f-c8b90133473f">test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e6a343c7-ac82-4381-9a2b-9c24773fdfdb">test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a97886db-e403-4e43-881f-ceebb901db3f">test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#660d744a-f43c-409b-9558-82ce9a8a6909">test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#23792618-44b8-4567-96f0-280c9c5a3f48">test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#79ffee73-6a06-4b72-b194-f8fae10aced0">test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#21f66281-5e6a-417a-b64b-e1cac637af25">test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e4cb92cf-32c2-42e6-b91a-a40274b93ac2">test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3c20b5a5-eff5-4f3c-b578-63ef4211177b">test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                </ul>
                </li>
                
            
            </ul>
        </td>
        <td class="failure-index">
            <ul class="toc">
            
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#95aa0025-45ea-42d9-8936-c6ba7dae3ed2">[F] dask_cuda.tests.test_dask_cuda_worker : test_cuda_visible_devices_and_memory_limit_and_nthreads</a></li>
                    
                    
                    
                    <li><a href="#f17308e2-a5f5-4bb9-97ce-8b269472d6fc">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_pool</a></li>
                    
                    
                    
                    <li><a href="#624b9020-f03e-433c-be88-e3489a7500f4">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_managed</a></li>
                    
                    
                    
                    <li><a href="#74d46fdf-6c2e-4d03-aa0e-fc62352ef0e0">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_async</a></li>
                    
                    
                    
                    <li><a href="#103347e4-e359-4597-87cd-193a0e47d35c">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_logging</a></li>
                    
                    
                    
                    <li><a href="#e60bd484-0d4c-4a3f-9581-65e08b875f05">[F] dask_cuda.tests.test_dask_cuda_worker : test_dashboard_address</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#631804d8-345b-4210-bd0e-32573f860dbd">[F] dask_cuda.tests.test_dask_cuda_worker : test_pre_import</a></li>
                    
                    
                    
                    <li><a href="#7ab237dc-5121-4e68-8610-ab6a1f3961bf">[F] dask_cuda.tests.test_dask_cuda_worker : test_pre_import_not_found</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#510bd527-d3b8-4ced-9cb4-9b5f6ea26a68">[F] dask_cuda.tests.test_dask_cuda_worker : test_cuda_visible_devices_uuid</a></li>
                    
                    
                    
                    <li><a href="#a27b0dc8-b317-4171-9be3-f64c2cbb3b7a">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_track_allocations</a></li>
                    
                    
                    
                    <li><a href="#0e59f48f-e517-47bd-b88a-735d59ffb17b">[F] dask_cuda.tests.test_dask_cuda_worker : test_get_cluster_configuration</a></li>
                    
                    
                    
                    <li><a href="#6cddfe4a-d88f-457c-ae70-4b2b003119f5">[F] dask_cuda.tests.test_dask_cuda_worker : test_worker_fraction_limits</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#d969f967-2241-4ff5-9486-b557cde803c3">[F] dask_cuda.tests.test_dgx : test_default</a></li>
                    
                    
                    
                    <li><a href="#a0d38ce1-f92a-4af6-b182-88d3438f720b">[F] dask_cuda.tests.test_dgx : test_tcp_over_ucx</a></li>
                    
                    
                    
                    <li><a href="#9adaf23d-baee-4ccb-acb5-1c0f12e19658">[F] dask_cuda.tests.test_dgx : test_tcp_only</a></li>
                    
                    
                    
                    <li><a href="#03bbd18f-2b03-4c0e-9980-193f5b57489c">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params0]</a></li>
                    
                    
                    
                    <li><a href="#7f2565e6-be87-4ec1-aaa2-67c2e5c639b3">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params1]</a></li>
                    
                    
                    
                    <li><a href="#c90ab780-3124-497c-9d2e-aacfc74ec2c2">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params2]</a></li>
                    
                    
                    
                    <li><a href="#542b794b-a686-4e11-afd2-ab6e7fd0e9d8">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params3]</a></li>
                    
                    
                    
                    <li><a href="#7e9e5072-4021-4083-83c3-c9f022ab5539">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params4]</a></li>
                    
                    
                
                    
                    
                    <li><a href="#2ae58089-fe75-4d5a-8756-1252526ad094">[F] dask_cuda.tests.test_explicit_comms : test_local_cluster[tcp]</a></li>
                    
                    
                    
                    <li><a href="#8e73a5ec-b24b-4852-90ca-90b7a1bddb8f">[F] dask_cuda.tests.test_explicit_comms : test_local_cluster[ucx]</a></li>
                    
                    
                    
                    <li><a href="#ddf610b8-b14e-4d5c-a407-51055639ec79">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_merge_empty_partitions</a></li>
                    
                    
                    
                    <li><a href="#298ae8b6-fdda-4d82-a3d1-96bdefbc8a44">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#56801956-298d-43de-924c-925253a9f6fa">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#4ec069f5-e04d-43b8-be42-5e6a4b8e43e8">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-pandas-3]</a></li>
                    
                    
                    
                    <li><a href="#dce30a0b-bc38-45f1-aa2d-c164f03cd8d7">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#d0c9a0d3-6b88-4796-812a-78f371302e80">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#17c12904-2b36-4e86-ade7-87a8967bba6d">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-cudf-3]</a></li>
                    
                    
                    
                    <li><a href="#5b6c61ec-04a9-4a10-8f84-bb0b03822b89">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#69e3613e-2fc8-40b8-9b99-2cdb95cb6130">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#09a310d0-74dc-488a-8c53-c3f1cd918630">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-pandas-3]</a></li>
                    
                    
                    
                    <li><a href="#e5d3fa0f-b278-47b8-80b8-557eb7e42b75">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#211903e4-0a36-4fae-b873-cfef0c93064c">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#2abe22c0-bb50-4869-889f-4a00a2cd38a3">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-cudf-3]</a></li>
                    
                    
                    
                    <li><a href="#585d9888-9ebc-45e3-8daf-d5b812e4722e">[F] dask_cuda.tests.test_explicit_comms : test_dask_use_explicit_comms[True]</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#f0fa4835-2cfd-4cb2-b296-9c4be07b0346">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#a12c2604-e713-4e56-968f-bdcba6dc3537">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#45928a68-135d-4a3a-8b50-1a6a94afd08e">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-pandas-4]</a></li>
                    
                    
                    
                    <li><a href="#a2ee2027-adf4-41fd-879d-f167bfc766ab">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#204fd7c1-9c11-4b24-a011-177307d8f94a">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#3810b7be-1a33-4526-9762-9ef44da1d730">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-cudf-4]</a></li>
                    
                    
                    
                    <li><a href="#2180bfa5-7427-464a-b604-ea6bea24d8f9">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#6dcf9613-fd78-472b-8ae4-bf8874caa6de">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#84d98104-a6fc-40a9-afdc-f13105d1116a">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-pandas-4]</a></li>
                    
                    
                    
                    <li><a href="#04440487-1041-4ce8-86e9-b66d92c41b92">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#ac583553-ab40-41a9-803b-4c587e069296">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#7e8d3c6e-68f2-4e1a-87df-f6cbedd7fd68">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-cudf-4]</a></li>
                    
                    
                    
                    <li><a href="#69e72139-f5cc-427e-993c-3e6e6f7e0b22">[F] dask_cuda.tests.test_explicit_comms : test_jit_unspill[tcp]</a></li>
                    
                    
                    
                    <li><a href="#4490668f-d0c6-4e72-8e3b-0e39e53faa77">[F] dask_cuda.tests.test_explicit_comms : test_jit_unspill[ucx]</a></li>
                    
                    
                    
                    <li><a href="#85e8a158-f175-4d35-aa50-21a6e1562e7f">[F] dask_cuda.tests.test_explicit_comms : test_lock_workers</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#7d89e938-418b-414a-8c1a-775c1cbe703b">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_tcp</a></li>
                    
                    
                    
                    <li><a href="#1ba1da5c-af37-4eef-90a0-56fb751a4ed1">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_nvlink</a></li>
                    
                    
                    
                    <li><a href="#e0542446-3313-43b4-affc-f940f141865f">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_infiniband</a></li>
                    
                    
                    
                    <li><a href="#c25ee8e2-964d-474b-9c14-c2e5cf786213">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_all</a></li>
                    
                    
                
                    
                    
                    <li><a href="#68bb9181-0f12-4930-af4f-479694fe7350">[F] dask_cuda.tests.test_local_cuda_cluster : test_local_cuda_cluster</a></li>
                    
                    
                    
                    <li><a href="#0f8237a8-5784-4fba-a2bd-c62734f74246">[F] dask_cuda.tests.test_local_cuda_cluster : test_with_subset_of_cuda_visible_devices</a></li>
                    
                    
                    
                    <li><a href="#91a720bd-357d-494d-b56a-739d9c12fd26">[F] dask_cuda.tests.test_local_cuda_cluster : test_ucx_protocol[ucx]</a></li>
                    
                    
                    
                    <li><a href="#14966890-459d-44d7-9d55-64583994dc93">[F] dask_cuda.tests.test_local_cuda_cluster : test_ucx_protocol[None]</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#e18a1c04-9d36-446b-b9ed-b3e3bd438937">[F] dask_cuda.tests.test_local_cuda_cluster : test_n_workers</a></li>
                    
                    
                    
                    <li><a href="#4feadfc3-d72b-4b5b-a830-54db0be594e6">[F] dask_cuda.tests.test_local_cuda_cluster : test_threads_per_worker_and_memory_limit</a></li>
                    
                    
                    
                    <li><a href="#6e1d1f43-a21a-452b-a798-4e994263ca3c">[F] dask_cuda.tests.test_local_cuda_cluster : test_no_memory_limits_cluster</a></li>
                    
                    
                    
                    <li><a href="#067e1085-3008-44f1-aa04-08b9c089aa92">[F] dask_cuda.tests.test_local_cuda_cluster : test_no_memory_limits_cudaworker</a></li>
                    
                    
                    
                    <li><a href="#f212c16e-9a54-434d-906b-3f281c1e3b1b">[F] dask_cuda.tests.test_local_cuda_cluster : test_all_to_all</a></li>
                    
                    
                    
                    <li><a href="#d52f7057-0fa8-49af-83d9-4dbaa81a9a34">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_pool</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#0e79df96-06e5-45c7-b1bd-7a25c4bd34b2">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_managed</a></li>
                    
                    
                    
                    <li><a href="#55b88d51-b6d8-4af0-a851-f4d4ad8d971f">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_async</a></li>
                    
                    
                    
                    <li><a href="#4c0918fb-7d89-4c72-992b-5a03510279c6">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_logging</a></li>
                    
                    
                    
                    <li><a href="#e9cec81b-f347-4cd8-bdc8-5786c445f411">[F] dask_cuda.tests.test_local_cuda_cluster : test_pre_import</a></li>
                    
                    
                    
                    <li><a href="#58a8d5b5-d336-4677-b648-61c461f00e2f">[F] dask_cuda.tests.test_local_cuda_cluster : test_pre_import_not_found</a></li>
                    
                    
                    
                    <li><a href="#cbb10d98-4257-4ef0-8def-8bf0bd0a0d36">[F] dask_cuda.tests.test_local_cuda_cluster : test_cluster_worker</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#914a9f32-0c07-41c1-b02a-d2a65ab3ced8">[F] dask_cuda.tests.test_local_cuda_cluster : test_gpu_uuid</a></li>
                    
                    
                    
                    <li><a href="#c89d7bf8-c46b-474a-8192-0dec067e3b14">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_track_allocations</a></li>
                    
                    
                    
                    <li><a href="#6b05d599-e2c9-45e8-84ce-8057d2ebf8b4">[F] dask_cuda.tests.test_local_cuda_cluster : test_get_cluster_configuration</a></li>
                    
                    
                    
                    <li><a href="#89955733-509e-4981-af62-1872d7518c84">[F] dask_cuda.tests.test_local_cuda_cluster : test_worker_fraction_limits</a></li>
                    
                    
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#d7f3e563-533b-443f-85a4-d6c78a32bc38">[F] dask_cuda.tests.test_proxify_host_file : test_local_cuda_cluster[True]</a></li>
                    
                    
                    
                    <li><a href="#09d0ce41-5905-46c4-8159-d4d59886f730">[F] dask_cuda.tests.test_proxify_host_file : test_local_cuda_cluster[False]</a></li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#b35a603f-59a6-4f61-ba97-e9466c4ac38b">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[True-1]</a></li>
                    
                    
                    
                    <li><a href="#8d881f03-dfd7-4045-82ba-68448c515f85">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[True-2]</a></li>
                    
                    
                    
                    <li><a href="#50879082-2448-4714-b441-959d3811efa0">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[True-3]</a></li>
                    
                    
                    
                    <li><a href="#f200b24d-e367-4ec9-ba74-cd44de69e4a7">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[False-1]</a></li>
                    
                    
                    
                    <li><a href="#8cc2f1b4-e3bd-48b3-abaf-50fe7c5d7e1a">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[False-2]</a></li>
                    
                    
                    
                    <li><a href="#ec89c339-8dfe-40b7-b46c-fd99664dcaa9">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[False-3]</a></li>
                    
                    
                    
                    <li><a href="#5511fa03-f33d-4835-a4ec-c0765cbc9a6a">[F] dask_cuda.tests.test_proxify_host_file : test_worker_force_spill_to_disk</a></li>
                    
                    
                    
                    <li><a href="#fea18d55-9942-4b38-9040-f841b9d7821b">[F] dask_cuda.tests.test_proxify_host_file : test_on_demand_debug_info</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#b0da7fc0-1c60-46c4-92fd-d83fc9956384">[F] dask_cuda.tests.test_proxy : test_spilling_local_cuda_cluster[True]</a></li>
                    
                    
                    
                    <li><a href="#03daa5f0-6a80-4df5-9a42-3f8d2ab2c3fa">[F] dask_cuda.tests.test_proxy : test_spilling_local_cuda_cluster[False]</a></li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#2b3eab66-c49c-454d-935a-6973c95a6689">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[tcp-None]</a></li>
                    
                    
                    
                    <li><a href="#3ff5ba6e-4f87-40d0-95ec-e03bc6919cdc">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[tcp-send_serializers1]</a></li>
                    
                    
                    
                    <li><a href="#a8393f6f-99af-41a3-be77-15bb2f911245">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[tcp-send_serializers2]</a></li>
                    
                    
                    
                    <li><a href="#6a0ba091-5793-42ac-ab37-981b8f1b073c">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[ucx-None]</a></li>
                    
                    
                    
                    <li><a href="#c6cda4c1-c86d-4bd6-920b-7d4aaf588cbb">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[ucx-send_serializers1]</a></li>
                    
                    
                    
                    <li><a href="#87e4cd75-eebe-42dc-af4f-2caee6160391">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[ucx-send_serializers2]</a></li>
                    
                    
                    
                    <li><a href="#809c9334-f25d-444f-8fc8-b66937e98e21">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[True-tcp]</a></li>
                    
                    
                    
                    <li><a href="#d8d19095-98e9-4aa9-89fa-63e739182143">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[True-ucx]</a></li>
                    
                    
                    
                    <li><a href="#f130ceac-2a51-4dc3-ad77-1e960006ed9f">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[False-tcp]</a></li>
                    
                    
                    
                    <li><a href="#51cdcb09-9262-4a5d-9d71-4d7f8d9bc9b2">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[False-ucx]</a></li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#4b964de8-2396-4884-a37c-8307f1161e07">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params0]</a></li>
                    
                    
                    
                    <li><a href="#d749bce1-51d0-4f9c-b58d-6217982523a2">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params1]</a></li>
                    
                    
                    
                    <li><a href="#359ea255-f0f3-4826-901f-fd8fa26cc87a">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params2]</a></li>
                    
                    
                    
                    <li><a href="#7cff40ab-7032-4ec8-b975-4e1e49f06d3d">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params3]</a></li>
                    
                    
                    
                    <li><a href="#c05b3d29-dc9a-4765-90c8-452197f299fd">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params0]</a></li>
                    
                    
                    
                    <li><a href="#d966de8a-13cf-4fd5-b410-ade057e279c5">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params1]</a></li>
                    
                    
                    
                    <li><a href="#0f6d4434-17d3-4a80-b833-23ac6ad799cb">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params2]</a></li>
                    
                    
                    
                    <li><a href="#5a21fb8c-2609-46a0-830c-8c79e0a70143">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params3]</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#08074114-f2d1-4127-acd5-337e2e401557">[F] dask_cuda.tests.test_utils : test_parse_visible_devices</a></li>
                    
                    
                    
                    
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
            
            </ul>
        </td>
    </tr>
</table>


    <div class="testsuite">
        <h2>Test Suite: pytest</h2>
        <a id="97cbe2aa-9e0a-40b7-b4bc-28e41b3183f6"></a>
        
        
        <h3>Results</h3>
        <table class="proplist">
            <tr>
                <th>Duration</th><td>462.147 sec</td>
            </tr>
            <tr>
                <th>Tests</th><td>1179</td>
            </tr>
            <tr>
                <th>Failures</th><td>106</td>
            </tr>
        </table>

        <div class="testclasses">
            <h3>Tests</h3>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_cudf_builtin_spilling</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="c96d06f2-b8c2-4e74-a3f2-e674e861b50d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_is_spillable_object_when_cudf_spilling_disabled</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="13df642a-9d27-46a7-947a-69f32f78ef99"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_is_spillable_object_when_cudf_spilling_enabled</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.041 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="33656a36-2919-41a7-845f-d0d9be4927da"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_when_cudf_spilling_is_disabled</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.006 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cec32964-1b16-4123-920d-06b469fcdc8e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_step_by_step</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.043 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aab878d3-51bd-4919-9c98-003eb9bacfb4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxify_host_file</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.072 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_dask_cuda_worker</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="95aa0025-45ea-42d9-8936-c6ba7dae3ed2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cuda_visible_devices_and_memory_limit_and_nthreads</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.12 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9359 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9359&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9359&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb4102c82e0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb4102ca0d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-22&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gd...&lt;distributed.comm.tcp.TCPConnector object at 0x7fb4102c82e0&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.014397859573364258

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb4102c82e0&gt;
address = &#39;127.0.0.1:9359&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9359, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb4102c82e0&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7fb4102c82e0&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb41031f190&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0,3,7,8&#34;})
    def test_cuda_visible_devices_and_memory_limit_and_nthreads(loop):  # noqa: F811
        nthreads = 4
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9359&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9359&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--device-memory-limit&#34;,
                    &#34;1 MB&#34;,
                    &#34;--nthreads&#34;,
                    str(nthreads),
                    &#34;--no-dashboard&#34;,
                    &#34;--worker-class&#34;,
                    &#34;dask_cuda.utils.MockWorker&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9359&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9359&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9359&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb4102c82e0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb4102ca0d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9359 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f17308e2-a5f5-4bb9-97ce-8b269472d6fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_pool</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.092 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eecb6760&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3ef186a60&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-41&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.00048160552978515625

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb3eeb94ca0&gt;

    def test_rmm_pool(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eecb6760&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3ef186a60&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="624b9020-f03e-433c-be88-e3489a7500f4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_managed</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.086 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eef1a1f0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3e6a79e50&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-65&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gd...&lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eef1a1f0&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0010371208190917969

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eef1a1f0&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eef1a1f0&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eef1a1f0&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb3eef552e0&gt;

    def test_rmm_managed(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-managed-memory&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eef1a1f0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3e6a79e50&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="74d46fdf-6c2e-4d03-aa0e-fc62352ef0e0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_async</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.103 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3ef13cbe0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3eeebc3a0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-91&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gd...&lt;distributed.comm.tcp.TCPConnector object at 0x7fb3ef13cbe0&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.010707855224609375

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3ef13cbe0&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3ef13cbe0&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3ef13cbe0&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb3eedea070&gt;

    def test_rmm_async(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
        driver_version = rmm._cuda.gpu.driverGetVersion()
        runtime_version = rmm._cuda.gpu.runtimeGetVersion()
        if driver_version &lt; 11020 or runtime_version &lt; 11020:
            pytest.skip(&#34;cudaMallocAsync not supported&#34;)
    
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-async&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3ef13cbe0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3eeebc3a0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="103347e4-e359-4597-87cd-193a0e47d35c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_logging</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.11 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eeb11730&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3eecb3e50&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-114&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.0005140304565429688

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb3eeaeb0d0&gt;

    def test_rmm_logging(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--rmm-log-directory&#34;,
                    &#34;.&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eeb11730&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3eecb3e50&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="e60bd484-0d4c-4a3f-9581-65e08b875f05"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dashboard_address</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.11 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3ef213100&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3e6a79040&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-141&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.0004456043243408203

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb3e6a1e400&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_dashboard_address(loop):  # noqa: F811
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--dashboard-address&#34;,
                    &#34;127.0.0.1:9370&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3ef213100&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3e6a79040&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a288caa2-0646-457e-8ee6-44f74c816429"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unknown_argument</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>2.065 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="631804d8-345b-4210-bd0e-32573f860dbd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.188 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eec4f850&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3eeb4ab80&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-165&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/g...&lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eec4f850&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0005655288696289062

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eec4f850&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eec4f850&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eec4f850&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb3ef05bcd0&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_pre_import(loop):  # noqa: F811
        module = None
    
        # Pick a module that isn&#39;t currently loaded
        for m in pkgutil.iter_modules():
            if m.ispkg and m.name not in sys.modules.keys():
                module = m.name
                break
    
        if module is None:
            pytest.skip(&#34;No module found that isn&#39;t already loaded&#34;)
    
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--pre-import&#34;,
                    module,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eec4f850&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3eeb4ab80&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="7ab237dc-5121-4e68-8610-ab6a1f3961bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import_not_found</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.356 sec</td></tr>
                        
                            <tr><th>Failed</th><td>assert b&#34;ModuleNotFoundError: No module named &#39;my_module&#39;&#34; in b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;
 +  where b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39; = CompletedProcess(args=[&#39;dask&#39;, &#39;cuda&#39;, &#39;worker&#39;, &#39;127.0.0.1:9369&#39;, &#39;--pre-import&#39;, &#39;my_module&#39;], returncode=1, stdout=b&#39;&#39;, stderr=b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/minico...ts/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;).stderr</td></tr>
                        
                        
                        </table>

                        
                        <pre>@pytest.mark.timeout(20)
    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_pre_import_not_found():
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            ret = subprocess.run(
                [&#34;dask&#34;, &#34;cuda&#34;, &#34;worker&#34;, &#34;127.0.0.1:9369&#34;, &#34;--pre-import&#34;, &#34;my_module&#34;],
                capture_output=True,
            )
            assert ret.returncode != 0
&gt;           assert b&#34;ModuleNotFoundError: No module named &#39;my_module&#39;&#34; in ret.stderr
E           assert b&#34;ModuleNotFoundError: No module named &#39;my_module&#39;&#34; in b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;
E            +  where b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39; = CompletedProcess(args=[&#39;dask&#39;, &#39;cuda&#39;, &#39;worker&#39;, &#39;127.0.0.1:9369&#39;, &#39;--pre-import&#39;, &#39;my_module&#39;], returncode=1, stdout=b&#39;&#39;, stderr=b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/minico...ts/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;).stderr

dask_cuda/tests/test_dask_cuda_worker.py:246: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="38d08557-50b4-4142-ba6a-6651a5bc2cd7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cuda_mig_visible_devices_and_memory_limit_and_nthreads</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>No MIG devices found</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_dask_cuda_worker.py:256: No MIG devices found</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="510bd527-d3b8-4ced-9cb4-9b5f6ea26a68"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cuda_visible_devices_uuid</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb3eee0d730&gt;

    def test_cuda_visible_devices_uuid(loop):  # noqa: F811
&gt;       gpu_uuid = get_gpu_uuid_from_index(0)

dask_cuda/tests/test_dask_cuda_worker.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device_index = 0

    def get_gpu_uuid_from_index(device_index=0):
        &#34;&#34;&#34;Get GPU UUID from CUDA device index.
    
        Parameters
        ----------
        device_index: int or str
            The index of the device from which to obtain the UUID. Default: 0.
    
        Examples
        --------
        &gt;&gt;&gt; get_gpu_uuid_from_index()
        &#39;GPU-9baca7f5-0f2f-01ac-6b05-8da14d6e9005&#39;
    
        &gt;&gt;&gt; get_gpu_uuid_from_index(3)
        &#39;GPU-9fb42d6f-7d6b-368f-f79c-3c3e784c93f6&#39;
        &#34;&#34;&#34;
        import pynvml
    
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
&gt;       return pynvml.nvmlDeviceGetUUID(handle).decode(&#34;utf-8&#34;)
E       AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/utils.py:679: AttributeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a27b0dc8-b317-4171-9be3-f64c2cbb3b7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_track_allocations</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.099 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3ef057b50&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3ef271550&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-192&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.0001862049102783203

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb3eeabb1f0&gt;

    def test_rmm_track_allocations(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--no-dashboard&#34;,
                    &#34;--rmm-track-allocations&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3ef057b50&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3ef271550&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0e59f48f-e517-47bd-b88a-735d59ffb17b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_cluster_configuration</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.096 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eebfccd0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3eecee9d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-212&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/g...&lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eebfccd0&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.005900859832763672

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eebfccd0&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eebfccd0&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eebfccd0&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb3ef07cd00&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_get_cluster_configuration(loop):  # noqa: F811
        pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--device-memory-limit&#34;,
                    &#34;30 B&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--rmm-maximum-pool-size&#34;,
                    &#34;3 GB&#34;,
                    &#34;--no-dashboard&#34;,
                    &#34;--rmm-track-allocations&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:373: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3eebfccd0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3eecee9d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6cddfe4a-d88f-457c-ae70-4b2b003119f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_fraction_limits</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.103 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3e69f2e50&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3ef2714c0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-234&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.0004944801330566406

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb3ef0d9d60&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_worker_fraction_limits(loop):  # noqa: F811
        pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--device-memory-limit&#34;,
                    &#34;0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;0.2&#34;,
                    &#34;--rmm-maximum-pool-size&#34;,
                    &#34;0.3&#34;,
                    &#34;--no-dashboard&#34;,
                    &#34;--rmm-track-allocations&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7fb172185850&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7fb3e69f2e50&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7fb3ef2714c0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_device_host_file</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="ba485758-a502-496a-b970-4068642105bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-1-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.065 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ca347c7e-92da-4c06-ba7b-0004b756de2d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.006 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5ad9889d-fb88-4ade-b73d-5874d377fda6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-1-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.037 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="961f0cdc-bb5e-40df-9e44-95fc1e064cf3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-10-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.009 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="baf924a9-a779-405d-8ef4-e9bf81e42886"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-10-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.011 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2499c7cd-0316-45a3-9e49-0deca4393cda"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-10-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.04 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3ff519f1-2a81-49de-be8b-c407ce784c35"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-100-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.068 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bdbc75cd-2bf0-454e-985b-13eb791251a8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-100-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.073 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c1468cc6-4fc6-4397-8412-2d92c8008de8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-100-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.105 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c288fd0-8a11-4142-beef-494a46441de4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-1-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c1a38223-d34e-4139-bdf2-d47d8ce17ef0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7099cfc5-c792-44c6-92aa-1ca16984c11c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-1-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.033 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cd45493c-13e4-4ba6-958e-f8161bf7df28"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-10-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="27f49480-1001-478f-a4ea-5ef0d31d1363"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-10-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dbce41c5-003c-40af-abf7-1d688cc55f26"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-10-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.032 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="907eb8e9-adf1-4f1d-aa0c-6fc45939bc43"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-100-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.055 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e5fa2adc-bb68-4985-beee-efe266376d8e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-100-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.06 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="10e98c71-eacd-40f6-a40b-194b85e9c7af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-100-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.091 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="749c1127-26b3-4774-af25-e7e63dc7d4cc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-1-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="996d652a-37e4-43bb-9320-bea19fd30c68"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="64ab4211-6d28-4972-b11f-b13860024310"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-1-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.036 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="40da74cf-cf8b-4edd-88c5-fa099dc39f20"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-10-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.008 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="16e00e71-6d86-43c3-a69b-62f607874655"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-10-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.011 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="68ed17a2-12f9-4daf-8943-1e27c611d8c6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-10-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.043 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="93cb069e-166c-4c28-a81c-6b040173b7f4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-100-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.07 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5b32a52a-47c0-4760-ab14-ae1c11dbd341"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-100-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.076 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="360c8988-1569-41eb-a91c-6f5bafe12e32"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-100-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.107 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6a0262c5-b26f-43ab-b940-e53f907e1fb8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_step_by_step</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="12b3ac85-b48b-4a18-83f9-4c9b93c8caab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-0-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="58ce77c4-4fd6-464b-8d7d-c74eedb76f99"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-0-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a0d78619-5d13-4662-b679-aae7f8414bd2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-0-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8be58a04-0f7c-406b-b68b-8a690a941ea9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-1-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b9fcea76-58c3-45a9-9893-5640d2f94820"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-1-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eb9e5551-a399-4285-878d-4815aae38b8d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-1-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="90e57330-c709-4b50-9be8-095a4d998eef"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-3-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="52198e26-ffbf-4d0a-b6e2-9507262470c0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-3-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="90eaae6c-bb08-4e7f-a573-bcfb11d573d5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-3-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="43edcf78-8622-47ec-acb3-fab9f3f8be74"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-6-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d064fe5-3e9b-415d-8ce1-f6f8f9d30e39"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-6-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f5f4433a-44b0-4841-a970-72e9f88c5ddc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-6-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e55af84a-c803-4e28-b77d-b6ab37038f26"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-0-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="baa79026-acb2-47c8-8b5d-6be11df7f8a8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-0-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ea27da6-551f-4198-b777-7d9429e148bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-0-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="13ba4de5-80c0-4112-a715-8ac95874b4a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-1-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39d819e1-3417-419c-abb0-187deeecb3d9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-1-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5d2d1a4d-1028-4419-a2d1-93e13a488f63"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-1-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="57320e97-3444-4a4b-857b-2269bb3cd73d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-3-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.026 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eeee5b40-b105-403c-a927-1095c5458587"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-3-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.026 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb2c73e1-c8ce-4ce8-9527-c236be306d6e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-3-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.026 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1c609a0b-6ddf-43f4-a8a7-2663bd4185fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-6-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.051 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="08c1dfa8-7eca-44c5-bec1-c2cae21b2b0c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-6-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.052 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dbca081b-8bd7-462a-9651-6d9f41c57475"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-6-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.05 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_dgx</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="d969f967-2241-4ff5-9486-b557cde803c3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_default</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.97 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-1&#39; pid=38751 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_default():
        p = mp.Process(target=_test_default)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-1&#39; pid=38751 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:73: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a0d38ce1-f92a-4af6-b182-88d3438f720b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_tcp_over_ucx</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.591 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-2&#39; pid=38912 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_tcp_over_ucx():
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        p = mp.Process(target=_test_tcp_over_ucx)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-2&#39; pid=38912 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:102: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="9adaf23d-baee-4ccb-acb5-1c0f12e19658"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_tcp_only</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.468 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-3&#39; pid=39012 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_tcp_only():
        p = mp.Process(target=_test_tcp_only)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-3&#39; pid=39012 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:117: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="03bbd18f-2b03-4c0e-9980-193f5b57489c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.932 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-4&#39; pid=39100 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: False, &#39;enable_nvlink&#39;: False, &#39;enable_rdmacm&#39;: False}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-4&#39; pid=39100 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="7f2565e6-be87-4ec1-aaa2-67c2e5c639b3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.655 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-5&#39; pid=39238 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: True, &#39;enable_nvlink&#39;: True, &#39;enable_rdmacm&#39;: False}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-5&#39; pid=39238 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="c90ab780-3124-497c-9d2e-aacfc74ec2c2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.743 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-6&#39; pid=39335 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: True, &#39;enable_nvlink&#39;: False, &#39;enable_rdmacm&#39;: True}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-6&#39; pid=39335 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="542b794b-a686-4e11-afd2-ab6e7fd0e9d8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>4.261 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-7&#39; pid=39431 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: True, &#39;enable_nvlink&#39;: True, &#39;enable_rdmacm&#39;: True}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-7&#39; pid=39431 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="7e9e5072-4021-4083-83c3-c9f022ab5539"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.559 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-8&#39; pid=39568 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: None, &#39;enable_nvlink&#39;: None, &#39;enable_rdmacm&#39;: None}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-8&#39; pid=39568 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_explicit_comms</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="2ae58089-fe75-4d5a-8756-1252526ad094"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cluster[tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.255 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-9&#39; pid=39665 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;tcp&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_local_cluster(protocol):
        p = mp.Process(target=_test_local_cluster, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-9&#39; pid=39665 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:60: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8e73a5ec-b24b-4852-90ca-90b7a1bddb8f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cluster[ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.42 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-10&#39; pid=39752 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;ucx&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_local_cluster(protocol):
        p = mp.Process(target=_test_local_cluster, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-10&#39; pid=39752 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:60: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ddf610b8-b14e-4d5c-a407-51055639ec79"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_merge_empty_partitions</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.414 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-11&#39; pid=39839 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_dataframe_merge_empty_partitions():
        # Notice, we use more partitions than rows
        p = mp.Process(target=_test_dataframe_merge_empty_partitions, args=(2, 4))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-11&#39; pid=39839 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:94: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="298ae8b6-fdda-4d82-a3d1-96bdefbc8a44"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.252 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-12&#39; pid=39971 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-12&#39; pid=39971 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="56801956-298d-43de-924c-925253a9f6fa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>1.978 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-13&#39; pid=40058 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-13&#39; pid=40058 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4ec069f5-e04d-43b8-be42-5e6a4b8e43e8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-pandas-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.09 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-14&#39; pid=40144 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-14&#39; pid=40144 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="dce30a0b-bc38-45f1-aa2d-c164f03cd8d7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.684 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-15&#39; pid=40227 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-15&#39; pid=40227 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d0c9a0d3-6b88-4796-812a-78f371302e80"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.607 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-16&#39; pid=40490 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-16&#39; pid=40490 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="17c12904-2b36-4e86-ade7-87a8967bba6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-cudf-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.678 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-17&#39; pid=40712 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-17&#39; pid=40712 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="5b6c61ec-04a9-4a10-8f84-bb0b03822b89"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.071 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-18&#39; pid=40933 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-18&#39; pid=40933 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="69e3613e-2fc8-40b8-9b99-2cdb95cb6130"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.269 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-19&#39; pid=41066 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-19&#39; pid=41066 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="09a310d0-74dc-488a-8c53-c3f1cd918630"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-pandas-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.066 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-20&#39; pid=41152 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-20&#39; pid=41152 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="e5d3fa0f-b278-47b8-80b8-557eb7e42b75"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.579 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-21&#39; pid=41238 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-21&#39; pid=41238 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="211903e4-0a36-4fae-b873-cfef0c93064c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.652 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-22&#39; pid=41456 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-22&#39; pid=41456 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="2abe22c0-bb50-4869-889f-4a00a2cd38a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-cudf-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.537 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-23&#39; pid=41722 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-23&#39; pid=41722 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="585d9888-9ebc-45e3-8daf-d5b812e4722e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dask_use_explicit_comms[True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.018 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCluster(cdc71443, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb412288ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb412288ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb412288ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3eec17140&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3eee15700&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3eeb26af0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3eeef1140&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

in_cluster = True

    @pytest.mark.parametrize(&#34;in_cluster&#34;, [True, False])
    def test_dask_use_explicit_comms(in_cluster):
        def check_shuffle():
            &#34;&#34;&#34;Check if shuffle use explicit-comms by search for keys named
            &#39;explicit-comms-shuffle&#39;
            &#34;&#34;&#34;
            name = &#34;explicit-comms-shuffle&#34;
            ddf = dd.from_pandas(pd.DataFrame({&#34;key&#34;: np.arange(10)}), npartitions=2)
            with dask.config.set(explicit_comms=False):
                res = ddf.shuffle(on=&#34;key&#34;, npartitions=4, shuffle=&#34;tasks&#34;)
                assert all(name not in str(key) for key in res.dask)
            with dask.config.set(explicit_comms=True):
                res = ddf.shuffle(on=&#34;key&#34;, npartitions=4, shuffle=&#34;tasks&#34;)
                if in_cluster:
                    assert any(name in str(key) for key in res.dask)
                else:  # If not in cluster, we cannot use explicit comms
                    assert all(name not in str(key) for key in res.dask)
    
            if in_cluster:
                # We check environment variables by setting an illegal batchsize
                with patch.dict(
                    os.environ,
                    {&#34;DASK_EXPLICIT_COMMS&#34;: &#34;1&#34;, &#34;DASK_EXPLICIT_COMMS_BATCHSIZE&#34;: &#34;-2&#34;},
                ):
                    dask.config.refresh()  # Trigger re-read of the environment variables
                    with pytest.raises(ValueError, match=&#34;explicit-comms-batchsize&#34;):
                        ddf.shuffle(on=&#34;key&#34;, npartitions=4, shuffle=&#34;tasks&#34;)
    
        if in_cluster:
&gt;           with LocalCluster(
                protocol=&#34;tcp&#34;,
                dashboard_address=None,
                n_workers=2,
                threads_per_worker=1,
                processes=True,
            ) as cluster:

dask_cuda/tests/test_explicit_comms.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/local.py:253: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:286: in __init__
    self.sync(self._start)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:338: in sync
    return sync(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCluster(cdc71443, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="433f23af-7013-42be-8566-1b7953898022"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dask_use_explicit_comms[False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f0fa4835-2cfd-4cb2-b296-9c4be07b0346"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.11 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-24&#39; pid=41944 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-24&#39; pid=41944 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a12c2604-e713-4e56-968f-bdcba6dc3537"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.059 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-25&#39; pid=42030 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-25&#39; pid=42030 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="45928a68-135d-4a3a-8b50-1a6a94afd08e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-pandas-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.193 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-26&#39; pid=42116 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-26&#39; pid=42116 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a2ee2027-adf4-41fd-879d-f167bfc766ab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.908 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-27&#39; pid=42251 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-27&#39; pid=42251 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="204fd7c1-9c11-4b24-a011-177307d8f94a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.687 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-28&#39; pid=42470 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-28&#39; pid=42470 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="3810b7be-1a33-4526-9762-9ef44da1d730"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-cudf-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.581 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-29&#39; pid=42696 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-29&#39; pid=42696 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="2180bfa5-7427-464a-b604-ea6bea24d8f9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.047 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-30&#39; pid=42961 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-30&#39; pid=42961 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6dcf9613-fd78-472b-8ae4-bf8874caa6de"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.023 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-31&#39; pid=43047 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-31&#39; pid=43047 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="84d98104-a6fc-40a9-afdc-f13105d1116a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-pandas-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.161 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-32&#39; pid=43133 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-32&#39; pid=43133 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="04440487-1041-4ce8-86e9-b66d92c41b92"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.643 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-33&#39; pid=43219 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-33&#39; pid=43219 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ac583553-ab40-41a9-803b-4c587e069296"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.622 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-34&#39; pid=43478 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-34&#39; pid=43478 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="7e8d3c6e-68f2-4e1a-87df-f6cbedd7fd68"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-cudf-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.578 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-35&#39; pid=43698 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-35&#39; pid=43698 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="69e72139-f5cc-427e-993c-3e6e6f7e0b22"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_jit_unspill[tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.599 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-36&#39; pid=43917 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;tcp&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_jit_unspill(protocol):
        pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_jit_unspill, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-36&#39; pid=43917 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:313: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4490668f-d0c6-4e72-8e3b-0e39e53faa77"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_jit_unspill[ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.596 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-37&#39; pid=44174 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;ucx&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_jit_unspill(protocol):
        pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_jit_unspill, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-37&#39; pid=44174 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:313: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="85e8a158-f175-4d35-aa50-21a6e1562e7f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_lock_workers</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.008 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCluster(60696364, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3ef17f040&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3ef17f040&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3ef17f040&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3eeae3e00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3eeae3800&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3eeb11550&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3eef9dd40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    def test_lock_workers():
        &#34;&#34;&#34;
        Testing `run(...,lock_workers=True)` by spawning 30 runs with overlapping
        and non-overlapping worker sets.
        &#34;&#34;&#34;
        try:
            from distributed import MultiLock  # noqa F401
        except ImportError as e:
            pytest.skip(str(e))
    
&gt;       with LocalCluster(
            protocol=&#34;tcp&#34;,
            dashboard_address=None,
            n_workers=4,
            threads_per_worker=5,
            processes=True,
        ) as cluster:

dask_cuda/tests/test_explicit_comms.py:341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/local.py:253: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:286: in __init__
    self.sync(self._start)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:338: in sync
    return sync(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCluster(60696364, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_gds</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-skipped">
                        <a id="1f1b23c6-5f76-4901-9cf3-dfacd50d6abc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[True-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>GDS not available</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_gds.py:36: GDS not available</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="5a0af78e-a9bc-4966-ac0f-e1248e7591d4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[True-cudf]</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>GDS not available</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_gds.py:36: GDS not available</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="5e2f2e43-0b40-4990-b9e7-aec4a47e4334"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[True-numba.cuda]</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>GDS not available</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_gds.py:36: GDS not available</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3f48ea22-ef34-4340-929b-b80bfa2846f7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[False-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d26a35d5-8881-427a-9ee8-d30be6271ecc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[False-cudf]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8e450ef9-2cb9-430b-9586-a154c8c24e3e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[False-numba.cuda]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_initialize</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="7d89e938-418b-414a-8c1a-775c1cbe703b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_tcp</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.672 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-38&#39; pid=44392 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_initialize_ucx_tcp():
        p = mp.Process(target=_test_initialize_ucx_tcp)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-38&#39; pid=44392 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:55: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="1ba1da5c-af37-4eef-90a0-56fb751a4ed1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_nvlink</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.798 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-39&#39; pid=44488 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_initialize_ucx_nvlink():
        p = mp.Process(target=_test_initialize_ucx_nvlink)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-39&#39; pid=44488 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:91: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="e0542446-3313-43b4-affc-f940f141865f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_infiniband</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.985 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-40&#39; pid=44626 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>@pytest.mark.skipif(
        &#34;ib0&#34; not in psutil.net_if_addrs(), reason=&#34;Infiniband interface ib0 not found&#34;
    )
    def test_initialize_ucx_infiniband():
        p = mp.Process(target=_test_initialize_ucx_infiniband)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-40&#39; pid=44626 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:130: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="c25ee8e2-964d-474b-9c14-c2e5cf786213"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_all</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.193 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-41&#39; pid=44718 parent=33831 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_initialize_ucx_all():
        p = mp.Process(target=_test_initialize_ucx_all)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-41&#39; pid=44718 parent=33831 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:168: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_local_cuda_cluster</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="68bb9181-0f12-4930-af4f-479694fe7350"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cuda_cluster</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.547 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(ee0c52c3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3ef17f9e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3ef17f9e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3ef17f9e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4e632c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4e62f00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4e5ef40&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c5081dc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_local_cuda_cluster():
&gt;       async with LocalCUDACluster(
            scheduler_port=0, asynchronous=True, device_memory_limit=1
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(ee0c52c3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0f8237a8-5784-4fba-a2bd-c62734f74246"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_with_subset_of_cuda_visible_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.048 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(b1c62323, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cf3180&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cf1d80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4cf54c0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4e73cc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @pytest.mark.filterwarnings(&#34;ignore:Cannot get CPU affinity&#34;)
    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0,3,6,8&#34;})
    @gen_test(timeout=20)
    async def test_with_subset_of_cuda_visible_devices():
&gt;       async with LocalCUDACluster(
            scheduler_port=0,
            asynchronous=True,
            device_memory_limit=1,
            worker_class=MockWorker,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(b1c62323, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="91a720bd-357d-494d-b56a-739d9c12fd26"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_protocol[ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.163 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(f4a1a250, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3ef17f9e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3ef17f9e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3ef17f9e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cf4040&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3eef5d480&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4cd29a0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4cb86c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;ucx&#34;, None])
    @gen_test(timeout=20)
    async def test_ucx_protocol(protocol):
        pytest.importorskip(&#34;ucp&#34;)
    
        initialize(enable_tcp_over_ucx=True)
&gt;       async with LocalCUDACluster(
            protocol=protocol, enable_tcp_over_ucx=True, asynchronous=True, data=dict
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(f4a1a250, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="14966890-459d-44d7-9d55-64583994dc93"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_protocol[None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.023 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(bcbd4a8b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc498680&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c23580&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4eec7c0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4cfe6c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = None

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;ucx&#34;, None])
    @gen_test(timeout=20)
    async def test_ucx_protocol(protocol):
        pytest.importorskip(&#34;ucp&#34;)
    
        initialize(enable_tcp_over_ucx=True)
&gt;       async with LocalCUDACluster(
            protocol=protocol, enable_tcp_over_ucx=True, asynchronous=True, data=dict
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(bcbd4a8b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7c69ca88-a04f-4677-bb53-cb67e68d30be"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_protocol_type_error</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="e18a1c04-9d36-446b-b9ed-b3e3bd438937"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_n_workers</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(c39a9817, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4eded80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc64b340&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4eecbe0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4c81e40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_n_workers():
&gt;       async with LocalCUDACluster(
            CUDA_VISIBLE_DEVICES=&#34;0,1&#34;, worker_class=MockWorker, asynchronous=True
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(c39a9817, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4feadfc3-d72b-4b5b-a830-54db0be594e6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_threads_per_worker_and_memory_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(a4223b43, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4ef1d40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4ef14c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc7d1a90&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4ee0140&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_threads_per_worker_and_memory_limit():
&gt;       async with LocalCUDACluster(threads_per_worker=4, asynchronous=True) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(a4223b43, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6e1d1f43-a21a-452b-a798-4e994263ca3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_no_memory_limits_cluster</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.023 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(dc1abe24, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cf3100&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cf3d00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc8c7fd0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4e7b040&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_no_memory_limits_cluster():
    
&gt;       async with LocalCUDACluster(
            asynchronous=True, memory_limit=None, device_memory_limit=None
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(dc1abe24, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="067e1085-3008-44f1-aa04-08b9c089aa92"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_no_memory_limits_cudaworker</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.023 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(5259257e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4ee70c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4ee74c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bca37f40&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4eeeec0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_no_memory_limits_cudaworker():
    
&gt;       async with LocalCUDACluster(
            asynchronous=True,
            memory_limit=None,
            device_memory_limit=None,
            n_workers=1,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:150: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(5259257e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f212c16e-9a54-434d-906b-3f281c1e3b1b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_all_to_all</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.019 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(963a9335, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c02cc0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c3b040&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4ce81c0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4e5aa40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_all_to_all():
&gt;       async with LocalCUDACluster(
            CUDA_VISIBLE_DEVICES=&#34;0,1&#34;, worker_class=MockWorker, asynchronous=True
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(963a9335, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d52f7057-0fa8-49af-83d9-4dbaa81a9a34"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_pool</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(5cdb05f7, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4e833c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4e83a00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4e4b2e0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4cdca40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_pool():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(5cdb05f7, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7996d189-369f-47da-9582-d9500cc4513c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_maximum_poolsize_without_poolsize_error</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0e79df96-06e5-45c7-b1bd-7a25c4bd34b2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_managed</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(224dcc8b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc926900&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc926b00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc3fad60&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4ed0ac0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_managed():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_managed_memory=True,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(224dcc8b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="55b88d51-b6d8-4af0-a851-f4d4ad8d971f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_async</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.025 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(9118f822, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc4cea40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc4ced00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3b40ad610&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4cc78c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_async():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
        driver_version = rmm._cuda.gpu.driverGetVersion()
        runtime_version = rmm._cuda.gpu.runtimeGetVersion()
        if driver_version &lt; 11020 or runtime_version &lt; 11020:
            pytest.skip(&#34;cudaMallocAsync not supported&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_async=True,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(9118f822, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4c0918fb-7d89-4c72-992b-5a03510279c6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_logging</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.164 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(68b3982f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc7d20c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc7d2f00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bca69c10&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4cc5840&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_logging():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            rmm_log_directory=&#34;.&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(68b3982f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="e9cec81b-f347-4cd8-bdc8-5786c445f411"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.098 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(3a0f1584, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c40640&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c40600&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc495340&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4cc7840&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_pre_import():
        module = None
    
        # Pick a module that isn&#39;t currently loaded
        for m in pkgutil.iter_modules():
            if m.ispkg and m.name not in sys.modules.keys():
                module = m.name
                break
    
        if module is None:
            pytest.skip(&#34;No module found that isn&#39;t already loaded&#34;)
    
&gt;       async with LocalCUDACluster(
            n_workers=1,
            pre_import=module,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:274: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(3a0f1584, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="58a8d5b5-d336-4677-b648-61c461f00e2f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import_not_found</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(b28e1050, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc4fca80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc4fc880&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc62d2b0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4c9f540&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    def test_pre_import_not_found():
        async def _test_pre_import_not_found():
            with raises_with_cause(RuntimeError, None, ImportError, None):
                await LocalCUDACluster(
                    n_workers=1,
                    pre_import=&#34;my_module&#34;,
                    asynchronous=True,
                    silence_logs=True,
                )
    
&gt;       asyncio.run(_test_pre_import_not_found())

dask_cuda/tests/test_local_cuda_cluster.py:296: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/asyncio/runners.py:44: in run
    return loop.run_until_complete(main)
../../../miniconda3/envs/gdf/lib/python3.8/asyncio/base_events.py:616: in run_until_complete
    return future.result()
dask_cuda/tests/test_local_cuda_cluster.py:289: in _test_pre_import_not_found
    await LocalCUDACluster(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(b28e1050, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="cbb10d98-4257-4ef0-8def-8bf0bd0a0d36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cluster_worker</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(a7704d88, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc498b00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc498880&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc562fd0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4c4de40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_cluster_worker():
&gt;       async with LocalCUDACluster(
            scheduler_port=0,
            asynchronous=True,
            device_memory_limit=1,
            n_workers=1,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(a7704d88, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="def4a33b-0e18-4789-8c38-1621a3801e8c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_available_mig_workers</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>No MIG devices found</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_local_cuda_cluster.py:321: No MIG devices found</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="914a9f32-0c07-41c1-b02a-d2a65ab3ced8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gpu_uuid</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>@gen_test(timeout=20)
    async def test_gpu_uuid():
&gt;       gpu_uuid = get_gpu_uuid_from_index(0)

dask_cuda/tests/test_local_cuda_cluster.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device_index = 0

    def get_gpu_uuid_from_index(device_index=0):
        &#34;&#34;&#34;Get GPU UUID from CUDA device index.
    
        Parameters
        ----------
        device_index: int or str
            The index of the device from which to obtain the UUID. Default: 0.
    
        Examples
        --------
        &gt;&gt;&gt; get_gpu_uuid_from_index()
        &#39;GPU-9baca7f5-0f2f-01ac-6b05-8da14d6e9005&#39;
    
        &gt;&gt;&gt; get_gpu_uuid_from_index(3)
        &#39;GPU-9fb42d6f-7d6b-368f-f79c-3c3e784c93f6&#39;
        &#34;&#34;&#34;
        import pynvml
    
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
&gt;       return pynvml.nvmlDeviceGetUUID(handle).decode(&#34;utf-8&#34;)
E       AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/utils.py:679: AttributeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="c89d7bf8-c46b-474a-8192-0dec067e3b14"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_track_allocations</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(fbdf4794, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c1f680&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c9ae00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3b425a6a0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc4d9a40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_track_allocations():
        rmm = pytest.importorskip(&#34;rmm&#34;)
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            asynchronous=True,
            rmm_track_allocations=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(fbdf4794, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6b05d599-e2c9-45e8-84ce-8057d2ebf8b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_cluster_configuration</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(5f02e880, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4caca40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cac880&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc532130&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc4d56c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_get_cluster_configuration():
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            rmm_maximum_pool_size=&#34;3GB&#34;,
            device_memory_limit=&#34;30B&#34;,
            CUDA_VISIBLE_DEVICES=&#34;0&#34;,
            scheduler_port=0,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:384: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(5f02e880, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="89955733-509e-4981-af62-1872d7518c84"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_fraction_limits</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(3239a5d4, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb41206c100&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3eeac8200&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4ae04c0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3c4c49d40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_worker_fraction_limits():
&gt;       async with LocalCUDACluster(
            device_memory_limit=0.1,
            rmm_pool_size=0.2,
            rmm_maximum_pool_size=0.3,
            CUDA_VISIBLE_DEVICES=&#34;0&#34;,
            scheduler_port=0,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:402: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(3239a5d4, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="7464f9fd-9ee0-4383-bd8b-e9f7d554008f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_print_cluster_config</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>could not import &#39;rich&#39;: No module named &#39;rich&#39;</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_local_cuda_cluster.py:426: could not import &#39;rich&#39;: No module named &#39;rich&#39;</pre>
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_proxify_host_file</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="c3bb0e1f-e758-47d2-b435-2ca231ff5188"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_one_dev_item_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.006 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3737ffc9-8f0b-46fa-8ebc-915ab04f69bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_one_item_host_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8330f910-e785-4fd9-84d9-f4845922c88d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_spill_on_demand</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>6.327 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d7f3e563-533b-443f-85a4-d6c78a32bc38"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cuda_cluster[True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.023 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(28e4b8d4, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cacc00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cd8a00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4b91280&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc752140&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = True

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(28e4b8d4, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="09d0ce41-5905-46c4-8159-d4d59886f730"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cuda_cluster[False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.019 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(63269c84, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90b40&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90b40&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90b40&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cd1a00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cd1d00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc495430&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc777e40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = False

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(63269c84, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="21e029d0-3d55-425f-9cd9-deeb91f97795"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframes_share_dev_mem</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a94041c-6e26-4530-934c-53e8378e56cf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_get_device_memory_objects</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ee2a6f51-7e6c-4750-a8dc-6f313167f8a4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_externals</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c7936495-b554-477d-9eb0-cd5cb533da88"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_incompatible_types</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b35a603f-59a6-4f61-ba97-e9466c4ac38b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[True-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d3abb1f3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3b41e2880&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3b41e2240&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc51f370&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc7649c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = True, npartitions = 1

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d3abb1f3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8d881f03-dfd7-4045-82ba-68448c515f85"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[True-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(c32360fe, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4ee3f80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4ee3cc0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc309c10&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3b409e9c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = True, npartitions = 2

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(c32360fe, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="50879082-2448-4714-b441-959d3811efa0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[True-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(95abcd25, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c66480&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c66f80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc6274c0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3b409e940&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = True, npartitions = 3

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(95abcd25, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f200b24d-e367-4ec9-ba74-cd44de69e4a7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[False-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(0605adc9, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90b40&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90b40&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90b40&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4ae4880&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4ae4540&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc572ee0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc7ba2c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = False, npartitions = 1

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(0605adc9, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8cc2f1b4-e3bd-48b3-abaf-50fe7c5d7e1a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[False-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(e7b110ef, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c18d80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c185c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4e4bc70&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3b40ac4c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = False, npartitions = 2

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(e7b110ef, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ec89c339-8dfe-40b7-b46c-fd99664dcaa9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[False-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(8250e2e6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc553440&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc553f80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3b3df3e80&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3b40b2e40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = False, npartitions = 3

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(8250e2e6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="5511fa03-f33d-4835-a4ec-c0765cbc9a6a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_force_spill_to_disk</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.044 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(b3fcd10b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc77dac0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc77d740&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc60bc10&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3b40c2340&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=60)
    async def test_worker_force_spill_to_disk():
        &#34;&#34;&#34;Test Dask triggering CPU-to-Disk spilling&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, device_memory_limit=&#34;1MB&#34;, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(b3fcd10b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="fea18d55-9942-4b38-9040-f841b9d7821b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_on_demand_debug_info</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.019 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(f835a7f0, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90b40&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90b40&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90b40&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc8af840&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc5e6fc0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc37f5e0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3b40b89c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    def test_on_demand_debug_info():
        &#34;&#34;&#34;Test worker logging when on-demand-spilling fails&#34;&#34;&#34;
        rmm = pytest.importorskip(&#34;rmm&#34;)
        if not hasattr(rmm.mr, &#34;FailureCallbackResourceAdaptor&#34;):
            pytest.skip(&#34;RMM doesn&#39;t implement FailureCallbackResourceAdaptor&#34;)
    
        rmm_pool_size = 2**20
    
        def task():
            (
                rmm.DeviceBuffer(size=rmm_pool_size // 2),
                rmm.DeviceBuffer(size=rmm_pool_size // 2),
                rmm.DeviceBuffer(size=rmm_pool_size),  # Trigger OOM
            )
    
&gt;       with dask_cuda.LocalCUDACluster(
            n_workers=1,
            jit_unspill=True,
            rmm_pool_size=rmm_pool_size,
            rmm_maximum_pool_size=rmm_pool_size,
            rmm_track_allocations=True,
        ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/local_cuda_cluster.py:336: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/local.py:253: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:286: in __init__
    self.sync(self._start)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:338: in sync
    return sync(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(f835a7f0, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_proxy</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="e9d13678-cd06-4b5f-a679-67c94287db15"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object[None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="637886e1-35a3-4855-8c6b-c945d5ded6b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object[serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0632a6d3-047b-4078-ac95-122eab598653"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object[serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5ebb6c90-ced8-4762-a1c2-75950922a1cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_serializer</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c16e1b2a-d497-4f2a-a840-70c62b99cf51"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8f39f685-c0cc-4adb-8faf-b92ecd8e8cb8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[None-serializers_first1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b951b4b3-64c3-4be4-ad9b-da1258de511e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[None-serializers_first2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="48379418-c5c3-4c26-a27c-b3fe2e248ea9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second1-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1a828c08-50b0-45a9-810f-c7b0578daed9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second1-serializers_first1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7090f72-dbe0-4c31-8ad2-5ba7e0551892"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second1-serializers_first2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="53c856dd-1387-4b8d-9ab3-bffb737df50e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second2-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20250269-33b5-405c-b78a-0a32eb2b2538"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second2-serializers_first1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7e42f6e-5786-46fa-bb1c-13386540a9bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second2-serializers_first2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7229b188-c6ec-4804-841e-45c22457658a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[numpy-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="22cbe038-6f11-4c6e-9e66-a7037e066bc0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[numpy-serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ebb7de04-fef8-4e06-84cf-ee093e2ecf7d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[numpy-serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f42b55a5-b9c1-451e-9dde-2d952e6915c1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[cupy-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.083 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b0f7b3a2-9b75-4503-b605-b78c1c12f145"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[cupy-serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.062 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b7b99056-7eff-49a0-9bfe-910acabbd2da"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[cupy-serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.072 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b4ab2228-5b0b-46b4-84e8-2ecec8a0baaa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_cudf[None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6dc5d2f0-5855-4cef-830b-537d71d41ae9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_cudf[serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8ccd58b0-f8c1-4b4f-9c59-e80551c2c522"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_cudf[serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4df05b61-98f0-44fb-b33a-ef04e6f2722d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea41bcd4-2312-4969-bbc5-99974fa8b8af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a68c98b1-153b-4a04-a40e-6bd32223b402"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf6a7060-4435-467b-b2ca-6b5718aa1447"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f076199a-aa72-4f76-8fe7-761f94cbfe1f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a76f153a-51b8-4a10-b502-b5354048dc71"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a8a5dfe-f27b-4d45-aed1-42a49476929c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="80928c5e-4354-4179-9c02-d30e8966a54a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aedb1978-ab49-44d4-9d28-eacc3d6b38b2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_fixed_attribute_length[numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3151c09f-f81c-403a-9f73-4070670f4c16"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_fixed_attribute_length[cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5f4abeb6-3f32-4210-a570-0fce941a7338"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_fixed_attribute_name</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b0da7fc0-1c60-46c4-92fd-d83fc9956384"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_spilling_local_cuda_cluster[True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(df4deaeb, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c6c9c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c60280&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc8574f0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc817b40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = True

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_spilling_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(df4deaeb, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="03daa5f0-6a80-4df5-9a42-3f8d2ab2c3fa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_spilling_local_cuda_cluster[False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(17973b06, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bca523c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc7f4300&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc603640&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc818340&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = False

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_spilling_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(17973b06, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b83cac12-daf0-4543-9268-934ecf04368c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_to_disk[obj0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="205193f0-bd81-4e27-8f8d-4a9e67693310"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_to_disk[obj1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.006 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2348b1bb-b403-4401-8837-adbc3d748d65"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_multiple_deserializations[dask]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d6ab30ab-953b-4985-9389-df1eabd12f6b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_multiple_deserializations[pickle]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a0ece6e7-2805-477b-a7e6-be927390e37b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_multiple_deserializations[disk]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="86f3bcae-2cf0-4344-be96-3f604bb9005a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-None-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a1b151f7-dacb-4d66-99f0-eeff0db4a931"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-None-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="573320f2-fbb0-4f5f-89a0-c6298b70c304"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a879f665-a1a6-472c-b22a-7e40c56664cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers1-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d89ac390-3609-417e-a110-e38f1c501a7b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers2-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e756745-9627-48be-8cac-d54bf8d0aeb7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers2-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9d5a9f3e-8e45-4ae1-a0fc-daf1271d16d8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers3-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="35eb8b91-94e3-41cd-9893-1d629966ab42"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers3-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ab615236-239e-419b-b0d7-0949cdb6304c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers4-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5f39f489-589b-4e49-8676-76e7a1ef09e3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers4-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="298f25c6-14dd-40cb-80c6-2c0dbb4ed521"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-None-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c9167187-d719-4c9d-b17c-96d7e348dadb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-None-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.588 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="486c30b5-c266-48f9-804d-a59d192f0445"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="160df083-5b48-483f-b985-4cd309546b69"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers1-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.645 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8329e504-a8b2-4770-885c-f4cef1c65735"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers2-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fac57e0c-a883-4515-8dee-874e47343c2f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers2-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.59 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a4194fc4-7920-43a9-8553-df70c2d7154d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers3-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0b2f5357-c8dd-4145-af44-55f680af0b0d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers3-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.644 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cb414683-7c05-4390-9766-e05dbffdd15a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers4-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="64e8995f-e5ca-415d-8486-902c4485b1ee"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers4-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.588 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="2b3eab66-c49c-454d-935a-6973c95a6689"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[tcp-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d35e188e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc83a200&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c1f440&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3b3c99490&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc828f40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, send_serializers = None

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d35e188e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="3ff5ba6e-4f87-40d0-95ec-e03bc6919cdc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[tcp-send_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(36153ebf, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4ec9500&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c2cb80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc9f0b80&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc811540&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, send_serializers = (&#39;dask&#39;, &#39;pickle&#39;)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(36153ebf, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a8393f6f-99af-41a3-be77-15bb2f911245"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[tcp-send_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.076 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(da176268, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cac440&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cacf80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3b416b100&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc6ccdc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, send_serializers = (&#39;cuda&#39;,)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(da176268, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6a0ba091-5793-42ac-ab37-981b8f1b073c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[ucx-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(68725d39, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c699c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c69580&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4e4bf40&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc9fd7c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, send_serializers = None

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(68725d39, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="c6cda4c1-c86d-4bd6-920b-7d4aaf588cbb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[ucx-send_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(dbd4fc5d, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3b3d9e840&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc6868c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc3fab50&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc6e1440&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, send_serializers = (&#39;dask&#39;, &#39;pickle&#39;)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(dbd4fc5d, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="87e4cd75-eebe-42dc-af4f-2caee6160391"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[ucx-send_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(ec511e39, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3b401b080&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3b401b280&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4ce86a0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc6f4c40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, send_serializers = (&#39;cuda&#39;,)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(ec511e39, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="809c9334-f25d-444f-8fc8-b66937e98e21"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[True-tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(b341f31f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cefa00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4cefa40&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc6279d0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc82ec40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, shared_fs = True

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(b341f31f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d8d19095-98e9-4aa9-89fa-63e739182143"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[True-ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(23f93abb, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc81a400&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc547d00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc9277c0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc814740&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, shared_fs = True

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(23f93abb, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f130ceac-2a51-4dc3-ad77-1e960006ed9f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[False-tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(e5a95ae7, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bca89880&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bca89e80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc6f8790&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc6d86c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, shared_fs = False

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(e5a95ae7, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="51cdcb09-9262-4a5d-9d71-4d7f8d9bc9b2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[False-ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(10c0f666, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4e64c00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3a3078280&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc33f640&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc3df8c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, shared_fs = False

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(10c0f666, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d021aca7-d14b-4d51-bdf9-f36d765861d0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[None-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="269467e1-8fe5-422d-977f-de5327addfd1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[None-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="05abd97f-002f-4f23-809d-742b7d9d6413"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers1-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6b237690-c049-4e24-9a60-6d6e24d9049c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers1-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7809fdba-daea-43e5-bca3-06a3f510782b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers2-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="15af12a3-b850-4168-9ddc-fe2cee7f9bf4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers2-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0facacd3-f8d2-4eaa-833d-1b43c3eb875b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers3-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf8ce12f-0480-4d77-b9dd-5cd1fb60e5a4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers3-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c94c7925-9ab3-492f-a88d-c35dd808d317"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pandas</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="50f43ed5-256b-4a01-b6d5-f0388691c7ae"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_from_cudf_of_proxy_object</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.016 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="24463b20-1493-46c2-b7c3-88fd5b7fa312"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_parquet</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.013 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d5379a5-2a39-4579-9fc0-ac4ef02632d3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_assignments</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a1d2ebc9-a608-4989-a632-0da6100c13bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_concatenate3_of_proxied_cupy_arrays</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b6280dd5-c8ca-4585-a089-b35b6df2bb8a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_tensordot_of_proxied_cupy_arrays</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6fe7905f-4397-4411-9d67-dbfb5aa375c3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_einsum_of_proxied_cupy_arrays</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.012 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="92957340-99b4-44d6-ac38-fde71daad120"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[less]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d4d5b39-df8f-4caf-8fac-83afbaf36a6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[less_equal]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="65ac1e62-de6c-4a4f-8316-624ee5ca3f43"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[greater]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c39699cc-5c7b-4ac1-817c-0210a019efd3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[greater_equal]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="690f81b0-93e6-4d28-975e-1cb8f12533d4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[equal]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="367c0feb-df2f-4424-8da5-0b46d88ffc4f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_copy</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8c70d944-0311-460a-bfe5-b231ce69130b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_fillna</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="896450d1-e40e-45cc-925e-f1fe3d9ea44b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_sizeof_cupy</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.031 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="246f1397-d913-4820-86cf-3db5f5b1e936"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_sizeof_cudf</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.748 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="603422df-f793-4c52-8fe9-5d74277c896b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_broadcast_to</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="9329858c-1122-4f05-b99c-b7ff87219c22"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_matmul</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>See: https://github.com/rapidsai/dask-cuda/issues/995</td></tr>
                        
                        </table>

                        
                        
                        <pre>skipped</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="69d8f69c-6b5c-4a6e-8a4d-603e0afe39d4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_imatmul</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>See: https://github.com/rapidsai/dask-cuda/issues/995</td></tr>
                        
                        </table>

                        
                        
                        <pre>skipped</pre>
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_spill</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="4b964de8-2396-4884-a37c-8307f1161e07"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(dcad0da2, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c2ed40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc557c00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc60b130&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc405cc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(dcad0da2, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d749bce1-51d0-4f9c-b58d-6217982523a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(7b4d709f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4b4fbc0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4b4f240&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc921550&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc744ac0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(7b4d709f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="359ea255-f0f3-4826-901f-fd8fa26cc87a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(4c5ca105, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c66b40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3b4229240&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc30dd90&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bca2d2c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: None, &#39;host_target&#39;: None, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(4c5ca105, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="7cff40ab-7032-4ec8-b975-4e1e49f06d3d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.006 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(3aa52fd3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc3910c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc391640&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3c4c32850&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bca298c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(3aa52fd3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="c05b3d29-dc9a-4765-90c8-452197f299fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(03777630, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc63cec0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc63c740&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc4be8b0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc713ec0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(03777630, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d966de8a-13cf-4fd5-b410-ade057e279c5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(560e6125, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f909e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3b41fa540&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3b41fa400&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc9f06d0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc713f40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(560e6125, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0f6d4434-17d3-4a80-b833-23ac6ad799cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(01f34030, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f90460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc2ddf40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3bc2dd740&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc585400&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc70c2c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: None, &#39;host_target&#39;: None, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(01f34030, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="5a21fb8c-2609-46a0-830c-8c79e0a70143"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(a277cb95, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7fb3c4f901a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb412131fc0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7fb3c4c9a740&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7fb3bc60b760&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fb3bc4bb4c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(a277cb95, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_utils</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="5242adf9-cc8a-4ff8-afa5-506ceed7318c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_n_gpus</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc9e0568-85b6-41b4-b649-de89d38370eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="47e542b1-e1cb-4962-b4b4-5168ddbc7b8e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="33b4fe7f-b068-4691-b9f9-dd3b3cc491fa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0d3a9ed6-73f5-44ff-a33d-60d71abcc065"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb4e7882-bc6c-4fd6-b663-ae25e71377dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask_single_value</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0c5b5573-87cf-4a7d-a916-d178f27b5465"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cpu_affinity</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2132e93a-1d42-469d-adb4-00df2d01a4c2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cpu_affinity_and_cuda_visible_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="de800a32-e3b5-40e2-a908-1108cd1c3d83"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_device_total_memory</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>1.219 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eaf9714a-66a8-4775-8e58-d59980bd7eca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options_default</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="24e9065f-f05d-4227-911b-d67330912f50"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="237107a9-8fc5-4e66-a5a4-05c25781ef2f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d16f206d-3d8b-4e41-8bcc-e630bb5aff3f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="302f7770-7f27-43b6-8192-d4d86384e33d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="86047bfc-b30b-4e82-9a82-07868d22c8ad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="19f24db6-ad1e-40ec-b20c-b6579af139a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9cae3453-5350-4f23-af5c-06ec2daccab5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c7a41614-52fa-4929-bc3c-8afcc6e950d3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e5b44a3f-3f06-4ba8-8fdf-2e00b16979dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8f3f2050-9f51-411f-8ff4-6630921b6c8f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1f660117-e893-415f-acec-03931d374c16"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-True-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c911f71f-4331-4e63-ab5a-6bccb7906790"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a88a4872-3244-4e07-8bdb-0e7a387bbd10"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d5c0350c-be3e-44cd-9125-075b8a8de93d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-False-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="99233ad8-a904-479f-836c-40d25d617c13"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-None-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1a3ac1a-fffa-4e2b-817c-c9f51f9a1153"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-None-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8550113c-6971-4bbe-b800-401e77aa88a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9ddf5564-a64f-4d59-afb2-3dc211e260a1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1b9fc1c1-5c9f-438b-b519-c093c7f443ac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a43c7bf4-c165-401b-82d1-a81aa942e1aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-True-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c76da453-7dd1-4030-a975-62f11c87277e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b0fd900e-91f3-45f8-8e07-bb2df5124a4f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e59b2eff-6088-4082-b4e5-331eba8b85cf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-False-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b7829bfc-b0c7-4b6b-859e-62b5e76ce764"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-None-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="114fa166-f28b-4e56-8cc6-d5905afe5247"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-None-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0dba3f8e-1abb-4a73-8bfa-75a59bf70e55"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a4b90d4-1f44-4d49-939b-4958868eb515"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c047ceeb-4c89-4246-ba84-0a5bb12014d1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="40439f74-92d6-40ad-a73f-b3ba41e4ed16"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-True-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="809e5b95-c8e0-4b3e-a503-13eb414ed763"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ad6c5ac4-f1d2-47b1-9eb0-51c02b0aa0d3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ca4b2262-74b3-4091-b9d7-1e8691566edc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-False-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7a10660-310c-4553-825a-51a4fa5b82ee"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-None-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0101e03b-3718-43ff-a1c9-adc89653045e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-None-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="357ce841-5ba8-4536-a152-bbca1e21f08d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="08074114-f2d1-4127-acd5-337e2e401557"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_parse_visible_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_parse_visible_devices():
        pynvml = pytest.importorskip(&#34;pynvml&#34;)
        pynvml.nvmlInit()
        indices = []
        uuids = []
        for index in range(get_gpu_count()):
            handle = pynvml.nvmlDeviceGetHandleByIndex(index)
&gt;           uuid = pynvml.nvmlDeviceGetUUID(handle).decode(&#34;utf-8&#34;)
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

dask_cuda/tests/test_utils.py:192: AttributeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95229859-a9a9-469d-9ab0-921e824c64b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_parse_device_memory_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="484e32b6-3263-4707-9523-a7d6712e2734"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_parse_visible_mig_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_worker_spec</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="9c43999f-2d8b-43bb-b4b1-a4285aae0ef1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ba4ad79a-c86a-4db0-952c-f003b687e4bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="58152f8e-0b8a-42b0-91b4-4e1e933d69a4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dd3825a4-98b0-4e7e-aa44-0575dc9efb12"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb5a2913-3191-4661-8d2d-53c287d55b2e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="de9dd33f-e76f-424b-a14f-9d11577a3c9d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2107164a-daba-40a0-829f-5b7e2ed9fd05"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="54695683-08cc-4cf8-bee7-85801f58107b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="902581f1-c235-409a-903c-59543a9abdfb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4915dd20-1a17-4990-81a7-633d2e8834ee"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1b2f52e2-213d-4001-805a-d4f88aff994d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="40e526d1-52bb-4901-a8c1-26f59656c7b2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ab2e5df-daf7-4473-ad13-c5f34f30b45c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bbc30dc4-0448-4068-a992-7de2e23dcbb3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed8b35a1-16e1-41cf-a06b-1b3c8b6cb9f6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a7fd4aa-fc86-488e-af6d-b084a6b947b7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1f7223d0-51cb-42d4-bc64-68377ff19505"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20f0e6a2-6f95-4a15-9e56-8a0aad569d06"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="50165942-cf1b-4fd5-90c1-fd1cbc104526"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="82ccba00-c7a1-41fd-8057-c31f5c40b791"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4d57af2a-a2c7-4715-8d16-cf1014f8c729"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8a99915e-49a4-47fd-ba3d-e6716a870f6f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea7e1b2e-b82a-4ad8-874e-4dd6c7454986"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f9b59f02-b396-4d9e-89d0-034f042520af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6c162d6b-7b1f-4a4c-85d7-e48e3cc52804"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7362295d-e250-4322-b0bc-c1f054775611"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6ca07dd5-d9a9-4071-82c1-52d3737ba6bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="79b89565-674c-479c-b7ff-a35b790c7c74"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1b0eec2b-567e-4da5-9046-39f61ff59a12"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1fd33ed7-81b4-4690-8162-d60050cbc3c5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31e5a505-a7b6-4785-8909-a10694cfb431"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="94837fe4-61b2-4b6f-a846-e7cb4c35da69"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cf300312-a20a-46d5-b398-e0cef926f39b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95baaa0e-8158-4ada-b239-e22d30d37907"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f8192851-cad2-4a44-b44b-8e3a79c64798"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c485e22f-fb06-4076-b327-a60adff08d9c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="337b4b41-b4ef-41a3-b0ab-e33b447e3bbb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20932221-154f-4474-b81c-4b4b653796ac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="406046ec-e048-4b31-8a18-963d11c83fa9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e737882-0677-4488-8f34-135f1f039b7b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="51e9f1b0-39ea-4c8a-a94c-be3eba7e83bb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="87f8e7e8-9bb4-4ef0-9225-d2382b8bc40d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6ed2ee29-7045-4cc2-adc5-522d9099295c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ac1ef9c3-dd11-41f7-bf11-b0fdb662b341"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="071d6590-dd25-4d0b-aaf9-de70bced6ddb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="143f2bea-2ec9-446c-9daa-f33eb3f0b2b8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a53c8d0e-a1de-4749-9b4c-a5324de2faa3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ce99f9e2-94c4-4591-a68c-98283deada47"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2b47b3f3-57f4-4597-9af9-c2a74565c73b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d1ea56ac-ac1d-4db2-9df2-f8248bac49a5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a02a09f5-e124-4158-a983-903c6104eee0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3d4138c5-7681-48eb-83fe-ddb9de80a38e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8e5c59d6-fd2d-44d0-8228-07db219eab37"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="056abe2b-c71a-446c-8014-3ca1a959fe1e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a6fef87b-b924-4d72-956b-e20badf72554"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c921b78-acf1-4c6f-917e-e341f1346be9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="54bd0b33-8b6a-46aa-8d31-b9487580c53f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b23f59ba-a2ff-4faf-aa97-f614926f48ce"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b8fda8b7-565a-41c8-8dd1-14c9218fe925"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c47a4874-6c05-49e3-9deb-ea217bcd5805"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9a9d21bb-0ffd-464d-9b15-6e86a5c3812c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="be9fc914-935c-4c19-9378-ca9582e52f71"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9754f91c-a9a5-40ff-b527-e90433485f61"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="97230cc5-b6e6-40cf-801e-8136258a2106"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0a1bfd5e-9976-4736-8aa7-d34f04e24374"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="76712c43-d660-4716-8c40-df5af1a619b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="295f4d71-9865-4ef5-a345-5197ed59ef2c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6c517338-4daf-4502-9cbb-1def4bbd610f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4df03fee-48cd-4c71-8638-ba67d93a2a1c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f4510f24-b272-44f6-9c6e-8f12aee8fa6c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a96736b-dfb8-4ba7-967f-8c69e89dc2bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a9adbd13-8eab-4975-b4ff-23575603ff59"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="52189974-ab16-4e70-9e2f-dcdbb5e2f105"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7bd5637d-68e3-4872-8ba4-fe7ced844498"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="de079742-5ee3-4040-87f4-c1b49ce07a81"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="961a040d-0ed6-47ef-a288-3a72d12f21a9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6847694e-a1a9-4e32-af7c-1c0e65969252"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d8be78a9-ec68-40cc-b672-78681e11a582"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="66bbe307-0e98-45bb-b7b8-0a9020fde270"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aa682f21-fad3-4d61-b4f8-2c4ecf439b60"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="71aa69cb-7dea-4e14-a6f3-277f542c230d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ef3bccfe-e22d-4a0f-97ba-87dadbff411e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95b1abd6-5799-413a-ba0f-08f02880a80f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ad01e59f-b08c-4d2d-867d-89e59338ae96"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d8670786-8913-44f4-90f9-cc4c1d1783eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6eb5130f-1995-4f9e-ade7-cd4844c33555"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="834098fd-44d7-418b-a5d0-46bab9d1d20c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ad0fb306-3dac-47ca-bee2-09647baf1bcf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8c75cc99-50bc-41f8-9386-7854153be390"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cea1dab4-06bd-48b7-8d46-570dd29c1a31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fbc8b524-56f9-4bed-b12b-9cef73c75e1c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f1c2aea9-7709-4c06-acd4-fc0ba01fcd1c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e84f79bf-14b6-425c-a1ef-da59be00ed89"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0b5ff549-603a-4898-873d-73e4b7c3fff4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39036788-cf4d-441d-b271-10580f4b7733"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="77ffadd9-f355-4edc-af00-617fdd3f0687"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d5149e35-37a3-44f6-88af-67ced528ad7d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0ec8fc7e-d436-47b9-af3d-ef23c6911b0c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="29306c28-6edd-4534-bcd1-0665c862f2b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5922ba30-1107-431f-be6d-c5d8b0b1b55c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="013d19df-6d91-4f20-ac8c-4a82990f17f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="07709a3a-765f-4abe-889c-3d981ce8c013"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0c1ae51e-4fbd-4c57-b58c-e5f93eeaba35"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f4d58e8e-75ba-49f7-947b-f3f4f24ffa3d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d370cbcf-eeb0-4561-ae6c-f0191ae58bdf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1442a85-8916-4a25-993e-6434bb22f9c3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="77f5508b-a40b-41e0-8e87-fc0e92fe64aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="67b42199-23dc-4564-a813-ad0b5e77bd6a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7e2be392-74fc-4d8a-8cb6-9b3a9551dced"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bbb570a6-baa3-40a3-8ebd-b002c20db553"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="840bc654-e9d7-402a-be85-1f58fa56890d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e2eb5e6-d5e6-4eca-8dd2-60735abafb21"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="526652e2-ab0c-4b86-9c0f-44d88c15c806"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="00707c6c-62f4-4f02-b6eb-b221ffda023a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ee5dffc6-08c8-4703-86b5-fe8e2deef55d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="41b25a42-1035-454e-bff1-0a77e65cbc17"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0ab1f812-2ed7-488b-bfc5-d39e73f89945"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d72163a6-043a-4b2a-b9dc-ffe5b5feed81"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a7de397-d713-44bc-8440-1c5950e7c361"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed1861cf-73df-49ca-a0c9-539353490ce2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c4a4b86a-2cb7-4e86-a1e6-0c6eaf13d768"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c6e8ac50-04ff-4503-9b80-0e7a7313d415"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="673c5f2e-4877-4ceb-bd13-65ed4706e8cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ccefe2b3-b86d-4a35-8a14-f8a56328b7cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0056fbee-cde2-4f47-83f1-f4cb496eefcc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f99006f0-0f8d-49ea-b5b3-83dfe8a75b73"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9b6821c2-3b47-46e5-9683-4adde9c69537"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6c1fc6bd-0a00-4676-a60d-1e599ac6a70d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="76acefe4-71c2-42c0-abc4-3ca50f1eb825"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0d24135b-f242-41f3-9b8f-93983732c77b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f41ad6ad-c2b6-421b-926c-0fedfbe02639"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="05f15895-ec98-4d30-8d2d-d3bbf0bb705f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20758b8d-8069-4fcd-97ee-907682426c3f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e75ba91-1a5e-492e-880a-16c1b9763782"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="81b178b4-010a-44a3-8b79-eab112d1c4a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="434d8896-65f0-4277-8c2c-a8e73912934e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8ad0413c-d5a3-4056-a92e-cf8e883b3769"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e6f7d552-1e5a-437e-9f8b-909b1d8dfff4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="52fb6763-bf42-4cc7-b33c-8958ec729875"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1c81800-076b-4e0f-be79-6ef8e918f014"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0400303-a0e0-4441-861c-d2d084ba1c84"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a17744de-9839-4703-8d99-42023bc0199e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9dead193-ad65-4489-9365-ee92b1bb3935"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="34f7dbbd-d3e3-49ef-816f-9ba2c109e2eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ac87bc4a-0bb7-41e6-9363-6526b5884aaa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="30dd2389-1d17-40d1-a390-ebdc2772303f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fe7f46f4-bf70-4a79-840e-4dce174d27a8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="234de536-7697-4b23-be96-ba7bb4ef7544"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a2c8870f-1004-4ea2-b271-5edb215496bb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e487da54-ab07-43fc-b510-ca487149a2f0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ba18c621-f935-4d7a-b385-fc5001f0c14d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4107dd1c-8a7f-463b-90ce-47ddc18358c1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9f351761-f9b5-40ff-8224-b5ace1d7640e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bc507951-c1ec-46f3-8599-a5587b342eff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="154ac99b-e38a-4d20-8a8b-8d788fbb20f2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7824368d-4aaf-4b47-8959-e96180578f1d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c89a2b06-547b-442f-9074-bfd6a0df1b3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1e62d8f4-b054-4203-bfd6-10bbbaed6091"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d27676f6-d620-4d8b-833e-398bc9b49668"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0c03a548-d179-43ed-816b-1a16dea3675e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cfda2333-54ee-47e7-88bc-c8433b109576"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7eca3aae-c511-437b-b453-bd92cc31c9ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ef9c258e-feec-4c93-93b1-8be3b5ca2b19"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7755ae37-1ad0-46b0-93b5-af99888b011f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c922fe03-508c-4669-8558-f36918e5efb3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9575cf77-65b9-4138-be19-f902f1865f31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc864159-be42-4fb3-bae8-922484320de7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ab778eea-c293-4384-86e1-50744da2300a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d2dc5e1e-2c15-4223-949b-d8992a9f804b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8ea85e24-1a87-49aa-8d86-3a48cb529b75"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="27ec8560-7839-4016-8ba5-39ea1ab62f44"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3422ffbd-3297-4cbb-95e9-ed95626a5ff7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb937830-ca82-4974-ab4d-c81db8ec7592"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0c3f283e-15f4-4876-9f90-74c8a6e42aad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea0e82e9-c2b1-4124-966e-25bda9535149"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="11cf61fa-32be-44fa-a38d-0bb89598d693"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6ae5f814-68d8-4633-b267-15d056f4d185"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="81f3ded3-03b5-41f9-bc98-3af52bf7a91d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1748b50a-2c2a-4c5e-ae3d-b90285a8d6eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c749a8a7-aee9-440f-bf7e-7d750792b3fb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c6930e06-d149-42f0-a21b-2142d41d7434"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f7445714-8b4b-4e38-a557-923bfa9a5644"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d9b446be-b6bf-43d8-ab12-9dd41eefad95"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="01f19888-7481-452f-a7a3-21f683bffac8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="06d3bd10-c33e-4bb9-8de5-c71d0bf5b8cc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="deaa6117-beb0-4e6b-af4b-552967b5311e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ffb7a9a1-da3d-4c40-96fe-5428cc840db1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aa4c5f68-dda3-4358-8284-7cd9e78be241"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="79502ee4-e251-4701-9c2e-c407ba0537bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ff9ea99-6010-441a-b3a9-2dcbcd3e55f0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5ee21150-445b-4de1-8907-a23eee74d415"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="54987cc7-901c-49ff-bbea-25372dbf5a91"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c139bdb0-0344-4154-979c-7db58cd253a6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7c26915-7482-4878-adb1-4f6712885847"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8470d6a3-d0a7-439c-9d42-02944d7b0fa1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ae30ffc5-a7af-48b4-90b0-87c621daf8ff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f41fe7dc-53e3-4139-bd04-4a3518656d99"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b91238c1-6f5d-4b7a-b32c-3653210a9cea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4d1f41a2-9175-4502-8e40-35a1645c70de"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b5220f33-0c27-4167-804c-24095043a6d4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aaeed648-5b2b-466d-a0fd-8168a0912c81"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e486ca9f-bf3b-4cb6-8f58-02af92b81a5a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49e992a9-29be-4fe6-966e-6b2060ffe816"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="79e1f8a0-aebe-4d62-803c-a747417d868e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fd7b3eed-dee1-4a18-86a8-05e4ba3b2a6f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6b50fbdb-a5f5-4533-8438-68429ad05781"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6aa727a1-8562-4490-a440-16742aa57221"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17088b94-58c3-40bf-82b1-cec5745bc2e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2b52a8b7-3db2-4a9b-8fa3-913c5fd89efa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="47394a7a-6682-4295-aca3-c9fdff4bdb40"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5bcdab6a-5ee1-4da3-a16d-2676c8afb7cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5ed56ee1-9842-451f-b0d3-3fd0568be2b8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6df23cfc-2501-4236-8e14-2cf569a590aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf61fb2f-6fd7-4e85-8fee-ce31a1fbe7a0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5e945e6b-c507-4d1e-8c78-29ccb1760bbc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8539fba7-d75f-4919-97cc-c3245b90040c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec81875d-30b0-4635-b8d8-7317ffce55b0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31ffd4c4-609e-44f2-9a9d-2e76c8cae6b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b3b878a4-8f21-48bb-a250-216f0eb4b64f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b84a7ae1-7910-40bf-9808-316bad818f36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4fbead5e-235d-46a2-bd2b-176e2d1ce547"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0067dee-caa6-4686-8ad1-9e40ae339fdd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="106fbb81-803e-44a6-b0d0-d784cc197394"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3326eedc-4786-4d2b-87f9-21c1d1925fa2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="edd3fa9a-8cd5-4936-9204-807dfce3b652"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d8a8255c-e38b-41cc-940a-c264f51ba4ce"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d9a8b3ba-6b0b-4731-a84a-570fb8f9f971"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9fbcd011-d2dd-43e9-9657-bd08c34d1f35"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d48d0b47-ccc7-45e4-bf27-f93201c56e0f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2a424516-2b62-4e1d-a456-ad68e38f107d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31783b0a-63bb-4eac-9ec2-a737a4cffc6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0eb1c134-13b7-4004-8015-b59141741d59"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="12a03583-e594-476e-b2ae-017e954aec12"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f4a835cb-a4e4-48b9-a174-c06ebb62623c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b070cae2-f6d6-4654-af1d-b79c28c4afdf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9bb6e956-cdaf-4d6f-b884-3d1c6f3bc14d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c86d9e65-b9c5-4470-aee4-7030c6875ea7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b37cbac0-7a49-455c-98ee-f4bceb622c81"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d83adc9e-5929-47e5-9075-f432aadf327b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fa267222-7b60-4832-82de-86042b5161c7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4d762f26-1224-4f7d-a82b-c28c5d89322a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9fe58185-1ad6-46ac-a26f-38caa8cb1cf9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0f8a920f-4df5-4572-b965-2ce890a3aa4d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ab81c00d-188d-45a0-8621-4dd3c9dacfc2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ee9f034b-96dc-4d47-bd8e-b0ebab5a6c4b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2cf0ee20-d344-4a9f-b2f7-011781a9c8e0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="095c3c5a-8804-4235-ae78-8b84e92a7f3b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="00a4e961-9f7b-47ec-9cb2-32faf376ebe5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5d1184f1-efa9-4298-bd0a-745291aea79e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c9b57b1d-cd44-4252-ada7-e838ad59de98"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="562c9f11-ad65-4853-a6ad-f05b7b0d5b56"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a80a63c1-3fa4-4d3b-872d-d54c560206a7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="22249865-68b9-4be8-ae49-06a869debd56"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="abe679bc-879c-44b3-a287-f658bfeac520"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dcd2211a-5580-4bee-8ca3-53d1ee652d66"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="602de55c-78cf-454f-aaac-3c46b6b04bb3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1fc047a4-32e9-49ab-a9f4-865e3fd3e97c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1c4345bf-830c-4bce-bc74-be64e84b51e5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3b24af4a-88c7-435f-aa32-c75723262865"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="78a8447b-bd1a-49e6-984d-362dba4d2a62"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d23196f4-fdaf-43b2-8c16-0087e548c6fa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="02a732df-e44e-4d17-a6ba-7b22b053421d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a5e3425a-defa-4fa2-ac6b-e0c419324b43"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d0433236-62da-48d9-906d-14d3f78ae718"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="732124c3-5c53-4323-8af1-ee27e326c889"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7eb75873-bb50-470b-b503-3be7649ae92a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1327f2ae-9c23-42e8-bb69-1edbf1e98119"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="27c39e17-cd2f-4efc-a535-b69c17b95eda"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="61eaac99-c9a1-495f-9d65-e092546e9f33"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="58f503e2-c304-4842-b8c4-ed974c9e46c5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b3b0509b-47e8-4e06-a8d2-33952ddd060b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6b929c1f-007c-432f-94b9-41a6bd19bd1c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9b7574f0-b1b2-4d3b-ae5d-5fdf04f10730"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8bbc97cb-5893-4e83-b2cb-33b97f1dbd97"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c59a6501-870a-47e9-ac68-e916fc892c7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fea45ce4-e9ba-4617-aaa0-bc08d0cc14fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="47569a73-280c-4e6d-983d-8db888660ccd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f9d4fa5f-fc02-4559-8963-7fc8adf767cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c423bb17-d622-43bc-a365-360a868d600e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3d1f8359-db27-4a6a-ac2f-7719227992ed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6f66b5b2-857a-430a-8655-a5e617f96ff4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b664f5c9-baaf-4615-ac28-1d63c9da0014"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="09211f0d-d406-4ff5-9265-95ee4fedcd76"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1671cd85-12f4-41d3-a181-587e3f752ab4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec10c9dc-fb5e-4356-aecf-a14b971288f3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="84499ae9-52a1-4500-9b8b-542e528e0548"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6a1f129e-e5e0-4f40-893a-0f1579d581cf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e046702c-1dbc-4803-abda-fcf9f1822bca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31dfc9d6-2d22-40e9-82a6-7ca474686456"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5fb24b9d-29bc-4657-80d9-bbaa9fb6b692"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f2472bf9-0306-4bed-9b90-f43493441c79"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="192af269-d3ad-4330-8644-67d4a34d54b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f568fd95-fcc6-4567-b9d5-0209d10b05bb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d0147abd-81ab-450f-b7ac-4cd55fefd988"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f7345faa-0303-4863-b8ca-4aeca358d6aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e806cd5c-025e-466d-89e1-a04e8baeee49"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fd84ced7-8141-49d6-a01d-0dbc39df8cb1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="108416d3-7dae-4e25-90bd-c767280f2372"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="293dda82-ccf8-4d7d-ab18-ed54247e837f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d14b4ef1-878a-4f04-a9d2-ba3285cad803"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a5449770-64e5-4fce-be8f-01c6d3766591"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2726064f-a332-48af-a249-76c3cedbd88d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ca714d7b-bbf5-4831-b113-1454338cff55"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7e8046b9-6367-45a1-991f-e6d533439fda"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="997bcf53-cf59-4693-8875-6afc52f9463e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea1f9a81-c0c7-4533-8678-55c2dc3a4667"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7b2c24cd-e2a9-4b75-aad2-8e68ee7fd53f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9d9011f1-ff79-4e2e-a021-03c43ad2abb4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="caae1475-87c6-4b95-81e7-a76b20246801"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d57c30a1-bf8f-42bc-8ccc-b227c491da7b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="385d6cac-85bb-4723-a73f-6d7f82af68a6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="695cea7c-be2c-49cd-b05a-d189569d8059"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0646967-a692-4e7a-b667-f60c306eef8e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="26f97ba3-3881-413e-8be3-3427c3ee66ee"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="97d4810f-7a9f-4758-8751-f9d1cd190971"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b6b8503c-ba41-45de-af1b-fcaa1fbb2a78"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="558d9559-cd6b-4749-84ca-e08a190d6705"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="313f5694-2def-4255-9624-499e6b5f2a10"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0f4e0e19-c50d-4cc8-b34f-0367366a6195"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1266a4a-07ef-4c03-81ef-544959d48673"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c1317cb2-1401-4149-b211-6fed0689327b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="974f4e9d-a0f7-4a95-93a9-fbbc84e50198"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="72272578-8cee-49ae-8119-d2c7624b846b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a9cc4af6-2593-4c00-af46-018ee8d7efab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f958f9a7-2f2b-4c6a-a435-4d6de422e080"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="198c451b-b568-41f9-ae97-9f1e86d090d3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cae85b95-3965-4c02-ac84-961b0d63ae79"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7db7f387-cebc-4823-af0d-3cbd8e8977b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f81c2d7c-077e-485b-9df4-dd974476d5dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a4bf01cb-0239-4f69-9ba3-4db95b0094b5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a30e43ea-7bd1-4852-b46a-bed22aa120f2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d57465ec-64e4-4b65-99ba-f9c7e0f80e00"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e356028-c6cd-42cf-8c31-feaabccdb81c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e0e82d7e-8a5a-44af-9721-e4c856505856"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="afc76bee-df65-4ff2-86e7-7344162df74a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f34e8038-c8dc-4390-a900-024c85eb852d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="600c04b7-1a40-43f4-85d1-9a1068ad5e0a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="30ebed0a-edd0-46c8-9b9a-96e239fc640b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f94956aa-5cd9-4497-8e5d-585e9dbf81f4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e71bc7e-8892-4464-af16-17a59fc6eab5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="48a6b956-b356-47f6-8215-b2f53d5f0cbb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e5d8aff-ef81-4246-ad21-fb12978814ce"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="86ab5dd8-f6c8-4ed2-bef4-586a9b55dce9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="948e17a5-34d6-418c-b9cc-2c41a1367db5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a14c1012-11ca-409f-8db3-ba7e1b47e628"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f5478b46-db00-49da-81b8-dfd3951c0061"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aea50475-07fe-4ce8-ac6b-d44a15fb7ca3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="53b9d990-e8c2-4ec8-87b1-784d7bd3e162"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="61fe4faa-b7a4-4936-b0e5-43b1f9296502"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b470aaef-7763-4e31-9ab8-037de414ae1e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4865e041-980c-4076-a1ac-098d48ad9a9a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="22743135-4673-4ce8-8551-b95ba636ff55"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1040d77e-a2b0-4a1e-bb14-2f4b5fb4ca64"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1e0d492-be49-40f9-9161-aea65596815d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="455970dc-ad36-4404-b207-ce9857321549"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0fa6f149-fa93-495e-a9c2-ebb32629c13a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="83227005-e934-41fe-a5fa-026ade2fb196"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b6fc63a7-d3c8-4271-9cf6-412f3cd0c1d7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="67e07d08-e414-46b0-86d7-e91ee8d0c394"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9f5f04a7-81d6-420b-b4e2-d390b3852300"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d33c6152-5713-4aab-b322-4ffb31c4f069"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7fadf6ae-6d28-40ce-afe5-176d9de16a69"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="14ef4866-163c-40e3-865f-e3d6ed47c70c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a7fcb6a-d31b-4681-bd70-73963d501e1a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8aec75c7-ad94-4a0d-9ca7-5fe0bdddb275"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="26f037e7-f1c7-4ad0-9c78-b6c9a03a332f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="34a2c64b-8e3e-43c2-90b5-d1cd9127392e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2fffc0ff-22c4-4c00-9a3c-03ab8e472265"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0000e1e1-ff04-40ea-9c00-9b9b694ac0cc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="714a1888-ff32-400e-a14b-6da444997e67"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed805713-7649-4cb1-a490-5237db22e36c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f148aa33-bcd8-4673-8c97-538ec0454d7c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc0cb409-1fdc-438d-9082-b4948547bd9b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5490ad22-33f5-4091-bb41-a513bb96841a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="711ea36a-ccad-4cbd-bded-821d785bc43f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95c4820c-8518-48e7-818a-1febedbec0f0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="04c07cf2-defb-4689-8e3f-d5d556f939d2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a9d151bf-631e-4bb5-98ea-823f9901c377"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a0f9894-a54d-44f1-af38-4fa5a0705b2b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cd1ccb52-517b-4c1b-8cd2-8b3c7526886b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5bbcc54b-5946-4032-bfd6-064c4b0421a0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3405854c-8dec-4a59-a153-6e610b53fd48"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1cb3384-066f-4d20-8931-bd9e6accdd8c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7e2dba5c-d176-4321-9cc5-3258849af45a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="899ef7cf-33ec-407d-ae28-a94b14a90e08"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="10cecc8c-7b79-4ec2-853e-32d020bd4fd5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4579dc86-5af8-443a-918c-6f3824b2f49e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5fad3111-e095-4b86-be83-fc7aea9c00d3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d6a84e4d-ac2c-4f4a-8e5a-16037f3cad93"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f468778f-23c8-4623-9e4a-7a87779ca220"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="014042a8-2b98-419d-a961-b4c35f24ff36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1a13bcf2-f905-467c-bac6-48d2fbb42332"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0f2e280c-b7c9-4a14-8956-09b7b39d93d0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="703a2a65-ebac-48ca-8279-ffe96c9a9e44"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a28e508d-adbd-455d-b57d-9ae303294758"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a89c68ab-4fd5-4c57-b32e-e019dd4a5647"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8e46d5b5-06e5-495d-bf08-181528a2127c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="62b1fa8f-3e26-4024-a009-6dc777cd2be6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c35844b-59c8-40ed-9ca5-d7d14a499f68"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="966cdd96-471c-48e9-b4bd-33b50884b544"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e92dd92-d9c4-44ea-adcd-8f4a7ddf97e3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8930384d-f751-447a-8ca0-c9ece88e6192"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31b9011c-2c86-456a-8fce-70712fe8ffb8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f25aaf4b-7105-4a17-a222-0b681fa30280"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0afdad54-6809-4db4-9690-862b1fcb6264"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="256d2506-542c-44b2-a603-f5d0aa719da2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="107be56c-a500-4fbc-97cf-061ba94bcae0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="995737d3-cce9-4a9d-9b4b-ebad8635a5d1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b393291c-2097-4f89-bdad-b2d22ee42ac9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a37f36eb-11a1-416d-9d48-7218be35f45e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="419e8145-8e79-4ca1-897a-d7b2b05b7e12"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a80ed033-1b40-4159-b8e8-f4da110311d8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="493cf1ba-21de-4b46-8909-5eefe41b8e9e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6e565d38-a6d0-444b-be4e-3ed8d47bff7e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3f5808c2-c420-4f44-8cbd-7b498d6c8344"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e5bfccea-366e-49e3-bdf6-cad145992a99"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17d9d272-b015-4b47-8924-7dcabed1b5f3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a8d21c9a-ee06-4563-9426-1fe9c13c89a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="719051b5-84c1-4ef9-afd7-b5df38b66a4f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d2b52bc4-9d8c-4e73-b09c-efc94b21ccd7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e81a1adc-65f1-4165-a2bf-7835c8e9c697"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7bca7fbe-b7bf-4c17-abd0-1cb0576317ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d72c864c-f6a7-483b-aedb-9a9316c39e1d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="622e3e5f-3fcb-4b8b-9191-f584216f4707"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc8c4379-a3ca-4996-82c7-fb346317c893"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="74727b7d-0b9d-42d1-8a3a-a79d8b23c45c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="00bd9dea-0dbb-4e61-92ea-058703770926"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="96a25239-26a3-4c43-9f08-0ef4f15a05f3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="879d5369-55f7-44d1-b9fa-693fded8ac34"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d05d96f6-fc5f-4ddc-9f4e-c69e84e5ea6a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5abd63cc-a884-45bc-a2dd-9b12fdcbb625"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="63e49261-49ea-4c60-9107-c4a0856089e9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9412cac5-7860-4b98-aef7-d846012a8384"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="36456dc4-27b0-4273-a4d9-069a3d9953dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a98f423e-bd81-483a-9141-cd4cd2681cd8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6192cf31-793e-4634-81b8-66cf4fd28951"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e163feb9-a673-44bc-8c70-26c542127a50"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ae6f23d4-0a15-40d5-ba27-dda8ec7dec0f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="484b0074-f7e4-4742-a8c2-a19d2b54dc86"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="743463dd-4c89-43dc-a680-f415107eaee7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="62a066a4-2421-412f-abe4-f7e72192a818"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0a7f57f3-893c-444a-8395-2fcbcacb680f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c639cb1d-68ad-43ed-b286-db958fa22081"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0dcaedfb-ee7c-4992-ab7d-68a2054bc63c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6d609969-d457-4f8b-a345-a7cbcc4759a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="593020e1-ac22-4322-9591-ffb8f3b7a8c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95dd3a52-2209-47b2-b762-a2514837d6fb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49b16e14-d7e7-456c-ac81-faf853875e0f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bfb626de-7105-4133-b270-6939e6ca6b01"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb5b49dc-fb7f-4728-bf3d-101ca1802888"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95d655c5-a379-4031-a335-2ca0a018672a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e9e58ba3-6156-41d3-ad83-5ed11357b7d5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6dc527a7-4f4c-410b-a5d5-2e5bccc4e1bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="32ffd03d-5dab-4a87-8a50-9efa69ffb76a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17e4f398-9055-4c3f-a661-48c799568e7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6fd928fe-97ba-4fff-8d41-257a91e25275"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e8bac45e-cb52-41fa-ba1a-319ac43d62ae"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fe2b9ee1-a96f-437a-b2d2-8925109e3277"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="492bc30e-101a-4f41-b479-88c4d8f07070"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0f9b5432-2598-4b54-af74-f2c662fa08ad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="be155e7d-20c6-47ae-a9cb-5753e9807854"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49895b9f-6d8f-4632-aa89-143defb8d518"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2ffa0c0c-c836-4fa5-9b79-7f474dca2a54"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="300d41c8-8b1e-4fb9-9157-b9baf8d0129e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="90f2bb50-94c3-4a92-b91f-ec2c448fbee3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="73207c6c-a057-4784-aed4-fcc5544b7056"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b50d290a-bab8-4893-ba66-67ea0f12247e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7eb0f877-c8be-4a09-af38-7b6164babae8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d6909b6a-8628-44b3-a599-ae7c9a81e65c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cb752d91-3fa2-4e90-a62f-d380aad47fa0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1cf4651-f9b1-4a42-8c2d-c6746a798750"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="255369c4-a54f-4e06-b5c4-aceaf23d93a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8d638c99-e04b-4754-ba57-8912bf00621a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7b881cd6-096d-4934-b866-d3d10bca4167"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="da9b1d2b-58af-4c44-b4a8-33328feda19e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b6149183-8a24-484a-8796-b7c12b0feec3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="de2d6705-e638-4e04-b75e-b501381eab9b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="59091a1c-ff0a-4e08-acd0-a36fb9d5dd1f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ad81eba-1930-43de-b0bb-fb5ed82cc5a5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf200452-26af-4eff-b1f9-edc0dc705902"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="74fa2e8e-b08f-45ff-bbbf-970a12b7449f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="614618f8-5fa7-42ca-9a28-09d40cdf374c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0c32f6b9-b535-4f4f-bb4b-4cc9c3c1da6f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a6b87ff0-d932-4da1-91e6-8c1f08d4cbf0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="028c31cd-f5bf-46ef-9fcd-d0dbd58ea494"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="40f9e1fb-e1f9-45b6-ba42-383854cac87f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eb9fa167-9333-4445-8ea2-e22a9d907301"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5d73a6fa-f501-4802-ae33-e06ced17a3bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="10c40412-5158-4a8c-a6b3-d95f6fb13631"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a9656f5a-c8d5-4fd0-9b6a-809f6ba476e3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b532d7af-b86d-4571-b2df-fe7ff2192fdb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="df4996c1-63cd-4319-a017-02a9162c132c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b8f80223-69d2-40dd-bcbc-90a8f239912a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="999e1cda-66b9-4cc9-a8cd-30f5b0fd5dc0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="14ad909f-00ae-4c38-a602-7369a1bcde5c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3b4ae9b0-dcf3-4728-a8e0-642516a1506c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="64ae0c91-2979-4fde-a10e-9e24e7bb9bf7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e03082c3-9731-478c-b49d-f50b4954fe15"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="748a9697-c941-4c38-b91f-8a2ad20eb9c4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="772c62bc-b38b-49ff-9922-ec76eb02526c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="691e198c-f23e-4dc0-80dc-b057c414122a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0101b1f3-9aac-45fa-87ac-1a4bb2ea935e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b5285c6f-0737-460b-acb9-879048bbeff4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="925ce7f7-079d-4cd5-94cc-64c1cd66f656"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8426454e-e3d2-4fc6-b0f2-6c36d4e37d7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b2e178e6-e83a-4d69-a39a-ba11d35a3751"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d36a2ecc-8465-49db-85f2-50e00d15a2b8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="981d0ee3-7900-46b5-bf05-01b4e8567eba"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="abc74d45-23b9-4dba-bf06-f7564f62c79a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a83d3e0-07ec-436f-ac0f-32e08cba4ddf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a7f033df-306e-445a-bffc-0c7f80ed05b2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ac2fa8ca-429a-4e1f-974a-8096627e8ad9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9b057121-525e-4fde-8ad1-9678531dbdf4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6811596e-1bcd-4876-87b7-ac83aca6b2d1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c45a0f0e-f53f-4483-be93-1485cac30f29"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="86048db9-3410-4210-ab5c-b7b29379ec7f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7fabe3b0-c19e-4be0-9c1d-92eee8d9b11f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ca5c6a92-d83b-41ec-9eff-0b29ac8b9ff4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="abca45ac-4d4f-441b-b2df-a79af366e10e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fad0eba6-da02-4b82-997f-fda64f691ec6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a2849f7c-dc1f-4229-a01c-09183befc259"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a24bc547-213b-4e6a-a9de-13228cef1bf8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1470c325-c399-472a-953e-93b52eb0d1ea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="83bc0656-968d-4507-8b84-0ce5b86b271a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d024e860-5c37-421e-9f33-e1fc3033597b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="424986fa-f123-4309-86f7-e9af3e706eb3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="44020981-c966-4d2b-a2d0-c1e7eba34806"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="be9dfae4-5b3f-4823-bce3-0c34e395cfd7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6a53b13e-4760-4c93-85dc-cbb4cd9a0e7e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f2d10876-75ed-4a28-8043-d4a5f6287015"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4045a53d-1d16-4e10-90ef-e1be876855e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="68b37172-5cb4-422d-a85d-d39fd857899b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e19a2dd0-4d62-4367-a34f-0753d74784c2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8f5f437b-ea29-4013-bc64-3ed201950cd0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="76a2a09b-24ac-497d-8cd1-1ff7344c380b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="527f1985-df95-4464-b157-69d8bb69a307"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="80f7c8e2-ca32-4858-bed6-3768609d31e8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b9e717c7-9a62-4887-9fbb-68e5ee26d9a4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8bea1d82-6f1c-42fc-82f7-0be7e62123fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cabf6dc1-3351-44ef-9754-1f2caa677a9e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0ad09271-3d32-4867-8c3a-24cee35fba7d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fbbe4048-af4f-4336-b81f-a1f86803f2b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="195bd390-389d-4e04-bbdd-e7a4282affc3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="664feae5-c2a2-4c0e-aa2a-c26f50bdc29f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="36e7344e-99d7-431f-915b-0d2f95a1672a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dee6aea2-a009-42ff-97e7-5c91464339bb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="15005e2e-89dd-4fe0-948a-f62b0ba5c583"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="86a71c46-2e79-47b7-a55d-9eb8e44ae0aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="10fbbf7e-6278-4674-ab02-744694bdfd00"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f73a810c-79fc-41ff-b85a-d7949a50c391"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f59612e9-f46b-47df-ad38-8d500488bb41"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9453f3fa-1c77-4a33-80d0-77f7f70b3c1c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="70d6ee09-939b-40ec-95ac-e7967bbbc656"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0f365286-afa8-4691-b644-39d007a61824"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="72732d0e-d064-4530-b8ff-6c15727d3e5b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a00829b6-6363-4487-baf7-35dca36b3e16"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8d9e1ed8-b97b-4447-b4c4-6ddf857e26ba"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="81a7cda0-78a0-4f0d-ac2a-b6d83bf89bf8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="caf416f9-a28e-4583-9899-bbe6ef833eef"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39d4a9b7-a004-40d7-88e4-b2f0c5a3ec31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="209e5d4e-9322-48c7-9577-e50fe36c11ec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="19f198b1-ba84-4dbd-8138-0b1eaf4feba8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3015204f-27b0-4d70-8a42-0a47ef0273a6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="43771d1a-a3b1-47ed-a411-16e71671d64b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a712bec1-62fc-4ac4-b7cb-8241af0a71cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1276d579-666e-4595-b250-533b87c6fe4e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1a20ce16-fabf-41dc-8562-b977b94c4053"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cf8e4391-b700-409c-9da0-9feaf6783c4e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dda7e221-e7a2-4bd9-b190-a872a055f83a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7cc112d3-c567-405e-b296-4da177dad45b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2f11596e-ecc8-4647-ab47-292b636ee443"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e19fb40-0e31-4828-90c4-d5c13d9fa2b2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cb1536cf-25fa-4c84-a32d-940955bd1a24"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3b51bb46-8b15-4126-969f-9908b4d68b15"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d673bf7-5ffc-4c2a-92a5-45a463fbbf9b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c5d106c1-e062-425d-8e9e-668b511e8b5c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b7ba8d60-3be8-471f-92b2-7e28b8fd10ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2585012a-7cf7-43ab-b496-d63080a535b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d452220d-53d1-41b5-bd35-ec09c26bd109"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="648c07e2-f131-4127-be8f-fb83d7c5e40d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="92bcef7c-82e6-4e7f-8c10-c95e98804d6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e22295c-ba1e-47d3-afe5-bca9feb27257"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e797ab83-27e8-43c7-9f71-568c16668162"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="56d83107-39ff-4c5f-81f2-9d9cfb292e52"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d1f9cff1-b9e7-4690-bc00-b5379f96ec73"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="19f02a10-6bbf-4356-8f90-5ae979b469f3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="97f24e77-4c7d-4fef-ae62-421a5be78c70"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="05355e9f-4c5d-4a4b-b941-c78d9a8a332d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="41250d65-f4bc-4492-8397-68b3fe304922"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e90a8586-320f-4b39-9b0a-ea4f36e2e9bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f990650d-20de-493e-a19a-309a7ceb6010"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bd4e557e-0fb3-4462-b58b-ef6f82d88d41"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8afe6715-62f7-4745-aa16-3f28356b409b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="55ba0094-b8ec-44ce-b02c-44884b1bbbc1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b13659b5-8283-4372-8a53-9590fa6c8ecf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e2c5716-370c-473b-9389-8eefce0b822e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d6d11dd7-b024-415d-8b22-a32a3500b5b8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="71305b0b-7fa0-4119-9384-1a701a5309df"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2649889c-aed2-430a-a665-6651c1ed060a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f4b396ec-acc8-42fe-a20c-1c799d3617ea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2ca86e30-1e28-49fe-9e10-6859239273d6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="63796644-1ee0-4e67-89c2-92c99dab66d0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b73c555a-29a7-492f-b15b-dddffc86ea0d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="be10e2a6-0534-440f-ab89-19192b108745"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8795e0dc-894a-4b0a-9976-f6cd5245d85f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0d00ad3d-532e-496b-b09d-7f9cc1777a87"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf50cf91-896c-4563-8872-0a42bcf12836"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7d2553f9-91f6-420f-83ed-67989e59a736"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="47b43afc-3c3e-404f-ac9f-0872b79b48d8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="08e00c58-8b20-43b3-a206-ffce5696da08"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e3b7c71d-c86d-40c7-a3fb-c1a6d5b5f6a4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="925f7f5f-12b7-43c4-8a42-794aebe19884"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5855f573-b806-4f5e-8f75-ff31506b71a6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e52dbd37-b8cd-4969-9001-cbd982658b12"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc354af3-d7bc-4d13-a5a6-a0d42d9e4a28"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c7c8eeb1-51b4-4ee4-ba3f-a1ed93d75a34"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a7d6eab-657d-4005-ada5-17f5ae8ce9d1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="99c52b88-382f-4e17-8df5-d4795249ecb5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a7b5d5fe-512c-481d-b1a6-5ba277dd879c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7946ef42-198a-4a5f-8f7e-535f9a280ea4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="308fb256-80d9-4f7e-aed2-574d100e77db"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c6ec9c53-817e-4e1a-a3d7-7a4ea94c3909"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5e563d86-5563-4818-965f-6e3dac076731"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fd5d5e06-8116-47a8-a1b9-9e0f1a18dd59"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f29b2361-7786-4d8e-9a39-bc9e6b3e8e5a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a6a501fa-7eee-4708-aa63-bfe6f231dcf4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ef71b966-a838-4b42-bf70-2bbd9a9b6837"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="344e14fb-c531-4ee5-bc87-2a67e0fa2994"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1e9d25d4-4d57-42be-bb0d-66fed737e36c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="922e62e7-7718-49d6-be12-e2fda9ed2da3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c4bc04f7-002f-4c2a-b5e8-eb2ebfe398ba"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="07885341-dd78-468f-af50-c6dabe1988c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1aba3c59-81b4-465e-bc3b-4f67825a50bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7f9a2b5e-9583-41dc-92b9-a013493caf05"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5d21e92e-9862-46aa-9022-51c8c51c7936"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d5c69d0f-2116-4439-971a-4467c62ef1aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f68f2322-ad4d-4cea-b871-bdf0ec37e9ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="341ff271-3036-4083-b088-a6576d8fcbea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2194bfd9-48bf-4b49-897d-6a4e3106dd9e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="221a38b7-8fa5-4480-888c-7bebd2bb3d7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="193a6bef-d343-449a-894a-54fd6a08de6c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="30c99bb9-d31d-4560-bf26-b7dada3d94fe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8dae0702-fd9c-4f7f-8490-df1ec7dcb6fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a7d0a7b-91bd-4db5-ba2c-43dde9d054c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1c4bb7e8-45dc-4bef-bd6d-2350cdc188d1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="63ce6a48-9a6b-4026-99bd-a47347b030e7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="76b2d6f3-b96d-4dae-a73c-c70bf928c56c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aebbe1ef-1f9a-48a8-866a-d8fc59445496"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="87018e8a-9d81-4ead-ad27-c5d8d973d05e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fc8379dc-97c4-4f4d-91db-47edbed3d000"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8a740636-7bb8-4d3e-9394-06b9f8d4f1b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="41a9b70f-73e1-4bd9-9e25-a9479347baa3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a198b0c5-d01c-4f42-9918-f3ae3ec57bab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="68d4aae9-627b-4dd8-940c-41a5a1f2578f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7f6a01de-aa3a-4a6b-8adc-91f5d6332771"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="45251088-8dd3-4a4f-bd64-70322d51f296"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="473a9e89-6473-46e4-9b30-4baec11c7a19"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="69a3a9eb-5d12-41d6-9beb-dcc81680691c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0af6d1f9-9dc0-4747-8de9-4eb4d00555fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0533489f-bb68-405b-9ce1-5c7f21204e46"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="65d4bffe-f46f-4005-be27-611623a7ebfe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fff417ad-5b08-4d25-8332-fa6258326a2a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="10d74e97-04c9-47ed-98f1-cd1822cfbfb5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1aabcece-b527-4a2e-ad03-f5ea711a091b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="23441e17-2a11-4122-a951-70fecda88bf3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1e3f1c92-727c-4e84-86e5-4258fbcc9674"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b45e1a54-b7f5-4115-8347-db4efe14756f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0d91308-2b43-49bc-bc58-9c59bcf046e5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c40b1aaa-fa13-419f-a418-742de587a546"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c6560f82-caba-4bb4-8439-c28d3e5a84a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b501f412-9b60-4e4e-a25c-8c7591aababc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="16281d55-d128-4692-9d20-f789f5d90446"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b576a3a2-df01-4fee-a710-a0a828dac167"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b0a175f9-1fef-4882-bb41-be0e9e015901"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a5002fb4-80ae-466c-920d-68660945d7dd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0e1118c6-1db8-454d-b918-d8ad8848e99b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3fa09105-5524-47d6-aaa7-6c91e18ec630"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="77b9346d-742c-4297-a9c9-bcf38731d03e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b80b7aab-f770-4e05-a909-ed5dcc9ff639"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c47e42d6-9ea8-408e-9d0c-69df9f3ce785"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7e314f32-b890-47e4-804d-3990a78e9d33"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ffa71d5e-601f-489b-9142-a2b32c31928e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e16c115-ff4b-4d38-ab11-088700e055ff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="73a4b124-0bd4-4197-af64-4c814bc269af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4dc4ca8a-4e1f-4685-a124-cfc47b2cd39e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9a25add7-2a8c-4276-8cee-ac7473813191"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4121f9e8-5ee2-4945-be40-493eeeff4b96"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="053ab2af-55eb-472f-8d0f-44e5848abc79"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="674be9c5-421b-49fb-a28e-c52f51571ed4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="45313471-0e25-4b6b-ada6-a2c37c2e43b2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="65840c1b-4503-4434-aeb5-6084029c402d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d0962d23-c3f0-4f8b-8806-01f5fc629a62"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a1f14559-7280-4268-8eef-a3548126fbb4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf9ee42d-d715-4cb0-b882-3596c4e0af0b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f9df7383-8734-4d6e-bfe0-e0c21162d727"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="05c025c3-188f-4c94-8f8a-1fb2dd4d391c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="affab3cc-27f6-40b6-8d1a-1a3cf2176de9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ac0aebfc-201f-452c-a348-397410bec707"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6e5e35bc-75f6-47ec-aed0-76bdb3ef5137"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a98f890-42ed-498d-ab1f-d164cb1d7d83"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="59be026d-05c8-4fa8-8a71-dd94cf059276"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e7d4b20d-0599-4b12-ad1f-d0cb1f05c1c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="615a9ce9-a938-41e0-92e4-38a5f61a6027"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="08b8f8c0-36cb-4f5c-a8b4-f12cd586e807"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e876664-8b11-461b-b0d6-7503da3ffaf2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d9c3ee3d-8a94-470c-b15d-3b740a13005a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1e6c5dcf-b392-42be-969a-1f01272f3fc9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4f207674-9572-4b9d-801f-0ac4d7f05f92"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9e010017-3432-4e78-860a-e0952831de38"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="abbfc47f-d141-4698-8a93-3be9bef4dac5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="27927991-ac14-4f14-a464-7a996134dc33"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9ab08d55-358d-4e94-bbae-034fb7f99a88"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7353b191-282f-4c2a-b6a1-ea67d3771caf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6348b7c7-832b-4a5c-bc7c-ad94b051961d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dc129327-dc2e-4523-8848-b7235a1409b6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ef1ecbf-77c9-47bc-89bd-500839fdd614"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f5f28af3-5a04-4a0e-a604-acf61545d417"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="34afee75-0ca9-44ad-ad9d-a005d173d334"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b15f963a-9144-46ce-ab56-74f60736a514"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9d4c5817-9b22-4597-a623-d0e2a510bbfd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5838947d-d9e1-4c6d-b4da-3737752a1bc6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8048a840-dfb9-41c2-9dcd-a5f8d12804ba"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8737883d-fe43-42b3-b6b3-ce1234e30d26"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ef50b0d-5ccf-484d-a1c8-d9e2d04ac6b8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a4510be-b00f-4727-b5b0-cee74d4d67b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="41e68fbf-a1ea-4316-87fd-958931881fd3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0aaacd82-34bc-4d9e-8d99-8436039dd193"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3084c37d-52f2-4e63-ba59-2923d9f55da5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31bfe205-31de-45b1-8f1e-9da3eb2e2abd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="584f88e2-320e-4216-8f9b-9716749f45ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9fa0ecf0-77e5-4a6c-8ce5-a12bdc2f965c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="25aca0b5-ec0a-4bc2-898b-5b4b6eacd7a1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3599be16-5e53-459d-ac15-6280fd3a4f36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49868b7d-853f-4924-8f6a-04e0a3254b4b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="112db3e9-bb01-4414-b31b-e39c59105c1b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4d1b652c-9d6d-4ad2-ade8-458a3023723a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e47c6970-0a49-4580-98fe-3122fe0914b8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9e033313-0d43-4569-8677-31c18cebe273"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d373eba4-2ac0-46f3-83c1-893c7a46e8a0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e8bbe437-8e04-419e-8b2c-09e05d9ff241"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bee92992-5028-41c3-9b98-213c3e1adc9a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8f8cfc87-2b69-4561-9566-e0f58e4da5df"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="560ec7eb-9027-4ffd-a5d0-046949fc0872"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5914c2d2-f876-4cd6-a3ea-9919a6b86fe1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7dce86ce-d44e-488e-a447-46c419b9cee2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1ce84400-8075-4c6b-b40b-725753eaebf2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="abda383c-5154-49c0-9b06-7866ed5cfd19"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec8b4681-071b-457b-a73f-1df291de41fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="041ae562-109f-4cbd-8b91-33accb6caf82"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3cba10c6-0ffc-4385-a305-45b57726b3f6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="72ad7638-8b8f-446c-898d-49e7c7d4ecfc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b070a3db-ae9d-426e-807f-5abf63969ded"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5325cca2-2f8d-48b9-b93b-7153ae72403c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed03fc1b-a039-421b-b5c1-3e3c142276af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed359ac5-d8fc-498d-80f7-533266a515f2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="535e6edb-33eb-422d-8334-a8c18e6ba630"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3f1ad4de-ed44-46d0-a1c9-1fcc677a821f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="de6036a7-0c3f-4885-aa32-8206e7bc665f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2124685a-2bad-4fb2-bd01-81d46a73d32d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1d8706c4-9b9f-43da-a9b3-91c3aa9d8abc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="12aed048-3e6d-4a6d-a5b5-10a75ba4af38"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bcde46d9-bc44-4039-ad75-496a2b190621"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="51d9c66a-6f6f-4a54-ae76-e57268c10374"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49c02351-a6cc-422e-a4d4-c66293899525"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb1abd08-e0a8-4765-ad78-c1f2e1a0dee4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2a0d0ff1-0696-420c-97c8-956955e61e05"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="55444e4c-524f-4f5b-b2f6-1658b8902d97"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7a9ed18-b332-4d56-a148-3c9d73669b5b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d888be4d-0e49-498c-843c-f6d702637563"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0a8dfef0-048c-439d-b7d5-bff0b0f46202"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="79a31131-883c-4b18-b9ff-f054921fcf31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a02607cc-407c-4a9d-b53f-f017da06d543"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="781aaa16-d419-4fb5-9358-9d5f78c9226d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="69c73724-ea9d-4468-a2bd-f7aed883da20"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="263a41d6-ae99-473e-8fb2-d6b9f4fd83f0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f147d779-00af-4c05-9a3d-1821694a3477"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dc2570fb-cf19-4ea0-b087-da560b3452e3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc698d38-6b98-4947-8a46-92518c6e42f4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7182db7e-d3ba-47e7-98d9-599f036ef2cf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aadc3e25-3ef1-4877-8803-30517942e814"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="02c0ad51-6a93-4145-9fdc-979c893c7781"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fef4e14e-f673-410d-b90a-fecce33f4898"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="54517405-1f56-4b4b-98f3-b3ae322b31d9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c9fab60c-2710-495e-abcb-71f8284e7ce7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f87b76af-94fc-4a1c-91f0-ccf1948d5258"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af55f285-7009-4bd9-8f69-ffb046d5959e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9bc766ff-b940-4c43-8c25-473e1ee99ec4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1394fa81-f41d-44a2-8bbe-08900f7701b5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ef6caf93-69ca-4ce3-8e7d-f49cc11668da"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6e13daa5-7207-43d2-9d71-4c38a751679d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="23ea7972-5651-4a2b-9514-86237388323e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20b02914-8dfb-4275-a677-17e0267e2b9f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6946c374-d281-438c-8c61-b549a1f56b76"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a2046d52-c287-4902-9e29-97f235c84bed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="90a83f55-1221-4b03-9b4c-89b26cd997e9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="68afae60-151c-48e2-a0af-bae0cc6d5e97"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c9d56be9-6c31-4bea-8fca-6f6e8d658699"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="db0e0b70-2938-4105-9f90-9396c29d5fa0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0e7ca55c-b2dc-4615-9fc4-366509b6c4dc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1907cf32-1f51-476e-a574-02027f46b04c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e9be8912-6a8c-495f-9558-cf45e3c34ef2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0734472a-257b-43fe-ae09-eb853afd8c41"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a3dbcaaf-836d-4f5a-8ca4-54ea9e52cbc0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9109a6a3-6b06-4f92-a8f3-578ec0cccb95"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ac9549a3-89e5-4dc3-8d35-4554c51a7d6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b13b7b5b-63bb-4694-abb0-d9e4488fe65f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8a611530-281b-4fbe-b035-8a9307b26ed4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4477ca28-1a78-4e8c-a024-ffbed0e19044"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="36b6cac0-31b9-4133-a469-326eae4e349a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8a500def-1525-4eea-a379-449d1bc227bb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fea76889-d84a-412f-a79f-7df9f89e8561"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0d60120d-9bfd-4797-9619-a068f62198bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="56cf5907-56f8-48b3-a502-f6d5d03c4220"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="186a87ed-cdc9-4f48-857d-965e45516dae"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a413dbf9-0e19-40d1-af8c-12bb6d188a2d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4321781f-0a74-4d17-b3fc-4007b2031e47"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="afff674f-f95e-431a-8927-fab53f321e17"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6da4eec4-a71e-433b-9ff9-f683e169bb3a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3d14b5a7-e31f-47c2-86f4-00e149a4c9db"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="70d3cf71-2c90-4a08-9538-44092e3b92a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0a444807-7f62-4dc1-b609-84770efa7996"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f96f2e3d-2843-46d1-8553-ac61dabb5d7c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cfb3a529-ea47-4928-8785-604a46eacbb2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fd0815e1-d89d-401d-94d7-445a610d6412"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4bf38ad3-5b00-4d2c-a478-8526a3045911"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ca939494-c596-4e76-8cf3-e397d089de0e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ab1538b1-0d76-4fa2-bfc4-3dc6a4ef036d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a3703669-30ad-4fdc-b550-af8c09b10de1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9a7e3e67-4f62-4159-9c61-734b96d20324"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="94ae5198-a70c-4720-bf25-2442fc2b9ac2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b267bd4e-0100-4c2c-975b-eedd3d09c45e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="16527f44-5180-453b-980b-614d8c34963c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7cc7838e-259c-40cb-8e7d-66c49574aee3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a3fac793-f2dd-41c8-a143-5ce298bf3149"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="68bb7a54-f595-4a96-a48d-d936559fa8e7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5052c2df-8384-4a3c-a781-1a6f1960df73"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="705e2849-0125-487e-8495-9066c0100161"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a4984d90-7e0a-42d8-b467-fad8bd70e463"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="85ebb12e-6f2b-45de-816a-841df9fa8856"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7d362893-6f71-44a5-8f11-984cb6ab9cd9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="441ea52d-b00d-4c70-9413-d6b0ee1d5dce"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a9b755b2-e95b-4bd4-9c1f-e3603df243bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="efc9f06a-d503-4b8c-acb8-c61f6fa85348"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eeadd273-6cf0-490f-a7d5-cd575922249c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0b0c8980-83d3-4f60-86a6-a0baa697938a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b721a8be-7961-4fb3-b45f-6023663138fb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7b591960-8cf8-4593-bc5e-38261ca3b664"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c9ea2439-8309-46f0-87f5-efe2ac3aef22"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf4ab78f-d379-463d-987f-3478a46772ae"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ab84fdfe-26a3-41a8-833e-426110ff07f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d7582216-534b-46c2-aa33-f2072e29129e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0c014f19-db46-45d4-ae67-2a341a72b916"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="436efd17-3251-4e4e-a740-f48359fa4a6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49f8937c-0ff6-4e80-a980-769c30b38cd2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="55a15023-651d-4f8b-9cd8-3e3340103318"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0148a488-29b4-4d83-b21f-c8b90133473f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e6a343c7-ac82-4381-9a2b-9c24773fdfdb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a97886db-e403-4e43-881f-ceebb901db3f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="660d744a-f43c-409b-9558-82ce9a8a6909"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="23792618-44b8-4567-96f0-280c9c5a3f48"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="79ffee73-6a06-4b72-b194-f8fae10aced0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="21f66281-5e6a-417a-b64b-e1cac637af25"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e4cb92cf-32c2-42e6-b91a-a40274b93ac2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c20b5a5-eff5-4f3c-b578-63ef4211177b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
        </div>
    </div>
    



<p class="footer">
    Generated by junit2html
</p>
</body>
</html>