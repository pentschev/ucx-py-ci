[1705734380.721132] [dgx13:94374:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:94374:0:94374]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  94374) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7ff9d096d07d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7ff9d096ac21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7ff9d096adbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7ff9d0a159f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7ff9d09ecd8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7ff9d0a28afd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7ff9d0a2d9ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7ff9d0a2e72f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7ff9d0adc6f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55f8e274404c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55f8e272a3f6]
11  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55f8e2724fb4]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f8e2736469]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55f8e2727042]
14  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55f8e2724fb4]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f8e2736469]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55f8e2727042]
17  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55f8e27d96d2]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55f8e272bc10]
19  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55f8e27d96d2]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55f8e272bc10]
21  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55f8e27d96d2]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55f8e272bc10]
23  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55f8e27d96d2]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55f8e272bc10]
25  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55f8e27d96d2]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55f8e272bc10]
27  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55f8e27d96d2]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7ffa59fc51e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7ffa59fc5aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55f8e272e6ac]
31  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x55f8e26e93ff]
32  /opt/conda/envs/gdf/bin/python(+0x136723) [0x55f8e272d723]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x55f8e272b929]
34  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55f8e2736712]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f8e27264e6]
36  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55f8e2736712]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f8e27264e6]
38  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55f8e2736712]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f8e27264e6]
40  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55f8e2736712]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f8e27264e6]
42  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55f8e2724fb4]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f8e2736469]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55f8e2727042]
45  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55f8e2724fb4]
46  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x55f8e27438cb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55f8e274404c]
48  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x55f8e280780e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55f8e272e6ac]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55f8e272a3f6]
51  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55f8e2736712]
52  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x55f8e27439ac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55f8e272a3f6]
54  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55f8e2736712]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f8e27264e6]
56  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55f8e2724fb4]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f8e2736469]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f8e27264e6]
59  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55f8e2736712]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55f8e2726232]
61  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55f8e2724fb4]
=================================
2024-01-20 07:06:22,829 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38293
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7f5c1c306100, tag: 0x2509515785e7e6ad, nbytes: 800000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7f5c1c306100, tag: 0x2509515785e7e6ad, nbytes: 800000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
[1705734383.261138] [dgx13:94351:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_0: LRU push returned Unsupported operation
[dgx13:94351:0:94351]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  94351) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f5c1f21c07d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f5c1f219c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f5c1f219dbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7f5c1f2c49f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f5c1f29bd8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f5c1f2d7afd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f5c1f2dc9ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f5c1f2dd72f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7f5c1f38b6f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x557470bde04c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x557470bc43f6]
11  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x557470bbefb4]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x557470bd0469]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x557470bc1042]
14  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x557470bbefb4]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x557470bd0469]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x557470bc1042]
17  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x557470c736d2]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x557470bc5c10]
19  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x557470c736d2]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x557470bc5c10]
21  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x557470c736d2]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x557470bc5c10]
23  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x557470c736d2]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x557470bc5c10]
25  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x557470c736d2]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x557470bc5c10]
27  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x557470c736d2]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f5cc685f1e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f5cc685faa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x557470bc86ac]
31  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x557470b833ff]
32  /opt/conda/envs/gdf/bin/python(+0x136723) [0x557470bc7723]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x557470bc5929]
34  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x557470bd0712]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x557470bc04e6]
36  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x557470bd0712]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x557470bc04e6]
38  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x557470bd0712]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x557470bc04e6]
40  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x557470bd0712]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x557470bc04e6]
42  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x557470bbefb4]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x557470bd0469]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x557470bc1042]
45  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x557470bbefb4]
46  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x557470bdd8cb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x557470bde04c]
48  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x557470ca180e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x557470bc86ac]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x557470bc43f6]
51  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x557470bd0712]
52  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x557470bdd9ac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x557470bc43f6]
54  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x557470bd0712]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x557470bc04e6]
56  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x557470bbefb4]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x557470bd0469]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x557470bc04e6]
59  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x557470bd0712]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x557470bc0232]
61  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x557470bbefb4]
=================================
2024-01-20 07:06:25,369 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60370
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7f5ab19cc100, tag: 0xecdd379ea95f07e, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7f5ab19cc100, tag: 0xecdd379ea95f07e, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2024-01-20 07:06:25,370 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60370
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f6861b74100, tag: 0x57b134e69d96e8e8, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f6861b74100, tag: 0x57b134e69d96e8e8, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2024-01-20 07:06:25,370 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60370
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7ff71c671100, tag: 0x42239b07b379366b, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7ff71c671100, tag: 0x42239b07b379366b, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-20 07:06:25,371 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60370
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f33358b4100, tag: 0x2dc8cdd2d6a2540e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f33358b4100, tag: 0x2dc8cdd2d6a2540e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-20 07:06:25,388 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60370
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2024-01-20 07:06:25,388 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60370
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
[1705734387.500453] [dgx13:94367:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_1: LRU push returned Unsupported operation
[dgx13:94367:0:94367]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  94367) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7ff71f59307d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7ff71f590c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7ff71f590dbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7ff71f63b9f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7ff71f612d8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7ff71f64eafd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7ff71f6539ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7ff71f65472f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7ff71f7026f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55e9d442d04c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55e9d44133f6]
11  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e9d440dfb4]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55e9d441f469]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55e9d4410042]
14  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e9d440dfb4]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55e9d441f469]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55e9d4410042]
17  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55e9d44c26d2]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55e9d4414c10]
19  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55e9d44c26d2]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55e9d4414c10]
21  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55e9d44c26d2]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55e9d4414c10]
23  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55e9d44c26d2]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55e9d4414c10]
25  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55e9d44c26d2]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55e9d4414c10]
27  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55e9d44c26d2]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7ff7c6bdf1e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7ff7c6bdfaa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55e9d44176ac]
31  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x55e9d43d23ff]
32  /opt/conda/envs/gdf/bin/python(+0x136723) [0x55e9d4416723]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x55e9d4414929]
34  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e9d441f712]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e9d440f4e6]
36  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e9d441f712]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e9d440f4e6]
38  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e9d441f712]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e9d440f4e6]
40  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e9d441f712]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e9d440f4e6]
42  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e9d440dfb4]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55e9d441f469]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55e9d4410042]
45  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e9d440dfb4]
46  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x55e9d442c8cb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55e9d442d04c]
48  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x55e9d44f080e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55e9d44176ac]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55e9d44133f6]
51  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e9d441f712]
52  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x55e9d442c9ac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55e9d44133f6]
54  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e9d441f712]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e9d440f4e6]
56  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e9d440dfb4]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55e9d441f469]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e9d440f4e6]
59  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e9d441f712]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55e9d440f232]
61  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e9d440dfb4]
=================================
2024-01-20 07:06:27,904 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b9e75a656c00804c86f03e519074f660', 5)
Function:  _concat
args:      ([                key   payload  _partitions
112333    604804184  97603651            5
2753      816513075  83300320            5
41636     818901971  70260504            5
2773      812908881  25442108            5
112335    864316264  48849421            5
...             ...       ...          ...
99998989  831090627  53854693            5
99998993  824482102  55578690            5
99998998  212312790  11635464            5
99999003  814224945  35177185            5
99999005  842201393  17791475            5

[12501172 rows x 3 columns],                 key   payload  _partitions
52354     618569608  53121560            5
52356     119515767  65816641            5
52365     953925328  16743116            5
52383     963710134  90764403            5
31906     953277924  49548919            5
...             ...       ...          ...
99988812  520391387  27703316            5
99988813  926854837  45466034            5
99988816  951710838  26708082            5
99988817  901442681  5
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded')"

2024-01-20 07:06:29,632 - distributed.nanny - WARNING - Restarting worker
2024-01-20 07:06:29,745 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #047] ep: 0x7f5ab19cc1c0, tag: 0xc3285795cb809b17, nbytes: 799821936, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #047] ep: 0x7f5ab19cc1c0, tag: 0xc3285795cb809b17, nbytes: 799821936, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
[1705734391.718889] [dgx13:94357:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_1: LRU push returned Unsupported operation
[dgx13:94357:0:94357]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  94357) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f6878ab007d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f6878aadc21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f6878aaddbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7f6878b589f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f6878b2fd8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f6878b6bafd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f6878b709ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f6878b7172f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7f6878c1f6f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x56182d6d404c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56182d6ba3f6]
11  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56182d6b4fb4]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56182d6c6469]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x56182d6b7042]
14  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56182d6b4fb4]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56182d6c6469]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x56182d6b7042]
17  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56182d7696d2]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x56182d6bbc10]
19  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56182d7696d2]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x56182d6bbc10]
21  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56182d7696d2]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x56182d6bbc10]
23  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56182d7696d2]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x56182d6bbc10]
25  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56182d7696d2]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x56182d6bbc10]
27  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56182d7696d2]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f69020df1e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f69020dfaa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56182d6be6ac]
31  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x56182d6793ff]
32  /opt/conda/envs/gdf/bin/python(+0x136723) [0x56182d6bd723]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x56182d6bb929]
34  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56182d6c6712]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56182d6b64e6]
36  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56182d6c6712]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56182d6b64e6]
38  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56182d6c6712]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56182d6b64e6]
40  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56182d6c6712]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56182d6b64e6]
42  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56182d6b4fb4]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56182d6c6469]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x56182d6b7042]
45  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56182d6b4fb4]
46  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x56182d6d38cb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x56182d6d404c]
48  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x56182d79780e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56182d6be6ac]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56182d6ba3f6]
51  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56182d6c6712]
52  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x56182d6d39ac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56182d6ba3f6]
54  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56182d6c6712]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56182d6b64e6]
56  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56182d6b4fb4]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56182d6c6469]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56182d6b64e6]
59  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56182d6c6712]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x56182d6b6232]
61  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56182d6b4fb4]
=================================
2024-01-20 07:06:33,280 - distributed.nanny - WARNING - Restarting worker
2024-01-20 07:06:33,896 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50004
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #067] ep: 0x7f5ab19cc140, tag: 0xaf03dd3c96c5d235, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #067] ep: 0x7f5ab19cc140, tag: 0xaf03dd3c96c5d235, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-20 07:06:33,896 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50004
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #075] ep: 0x7fda6d0621c0, tag: 0x68ccecdb70fad38b, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #075] ep: 0x7fda6d0621c0, tag: 0x68ccecdb70fad38b, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-20 07:06:33,896 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50004
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #064] ep: 0x7f5c65017240, tag: 0xa0d1eeeb238b3558, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #064] ep: 0x7f5c65017240, tag: 0xa0d1eeeb238b3558, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2024-01-20 07:06:33,898 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50004
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #060] ep: 0x7f33358b41c0, tag: 0xc7c3141a0741f343, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #060] ep: 0x7f33358b41c0, tag: 0xc7c3141a0741f343, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2024-01-20 07:06:38,090 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b9e75a656c00804c86f03e519074f660', 3)
Function:  _concat
args:      ([                key   payload  _partitions
11436     804834137  15614818            3
11442     510819889  52929828            3
267938    824691464    119445            3
11446     303323426  23567619            3
140838    821904469  75038283            3
...             ...       ...          ...
99985895  509199705  77144117            3
99985902  300472728  78124105            3
99985905  815423988  41752644            3
99985906  103631842  81929017            3
99985917  861846151  71774644            3

[12504123 rows x 3 columns],                 key   payload  _partitions
123440    218223689  96254375            3
123441    624634377  95492354            3
123453    915669220  30871013            3
21124     115277645  64716362            3
114401    915562266  27405257            3
...             ...       ...          ...
99988897  317494351  49901536            3
99988918  116602680  22349792            3
99988922  917144031  72539419            3
99988923  912455200  9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded')"

2024-01-20 07:06:38,246 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b9e75a656c00804c86f03e519074f660', 6)
Function:  _concat
args:      ([                key   payload  _partitions
11428     867387233  55924324            6
238272    205191889  76203646            6
11452     802111240  65344956            6
238277    823641952  10529057            6
267960    824657649  33445549            6
...             ...       ...          ...
99985840  864233964  54652593            6
99985845  862611615  54678046            6
99985889  812809326  40516933            6
99985899  832170422  29249330            6
99985914  804639578  74975711            6

[12495842 rows x 3 columns],                 key   payload  _partitions
123433    522799317  33850893            6
123434    940706197  34081258            6
123435    953448644  48308010            6
21128     421098821  66522321            6
123448    415490858  61304705            6
...             ...       ...          ...
99988991  316305402  36913089            6
99988901  963727387  45147384            6
99988903  714894632  71309864            6
99988910  929729040  2
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded')"

2024-01-20 07:06:38,294 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b9e75a656c00804c86f03e519074f660', 5)
Function:  _concat
args:      ([                key   payload  _partitions
11426     706431177  34416834            5
238282    863909069  87574993            5
11429     813559065  87859800            5
238285    820193197  24155524            5
267937    868552355  36992715            5
...             ...       ...          ...
99985828  866096331  25011556            5
99985888  807853626  94760074            5
99985894  702669211  43716273            5
99985900  802833398  34836229            5
99985904  829491040  18130989            5

[12501172 rows x 3 columns],                 key   payload  _partitions
123427    916318446  27311438            5
123428    935604497  39442371            5
123437    900029156  65449322            5
21120     929420103   8262669            5
123445    952192775  19254896            5
...             ...       ...          ...
99988987  955857119  63667796            5
99988896  917117052  33207055            5
99988904  418529082   2351418            5
99988908  900167687  7
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded')"

2024-01-20 07:06:38,295 - distributed.nanny - WARNING - Restarting worker
2024-01-20 07:06:40,889 - distributed.nanny - WARNING - Restarting worker
2024-01-20 07:06:40,975 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-54efe4e1c1ff02b405ca9dd1c57e206a', 2)
Function:  _concat
args:      ([               key   payload  _partitions
shuffle                                  
0           629906  53421103            2
0           403290  10603999            2
0           321286  63321947            2
0           347141  10089585            2
0           358052  45844737            2
...            ...       ...          ...
0        799780559  50337650            2
0        799835431  92838833            2
0        799821208  61861374            2
0        799780484  44185552            2
0        799868299    819795            2

[12499717 rows x 3 columns],                key   payload  _partitions
shuffle                                  
1           473119  35598930            2
1           566281  57204352            2
1           369456   3262213            2
1           900419  45623855            2
1           468480  71375318            2
...            ...       ...          ...
1        799863531  95448592            2
1        799971052  19717784            2
1 
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded')"

2024-01-20 07:06:41,025 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-54efe4e1c1ff02b405ca9dd1c57e206a', 7)
Function:  _concat
args:      ([               key   payload  _partitions
shuffle                                  
0           409546  50840789            7
0           558181  70375561            7
0           416425  88942410            7
0           615483  18614614            7
0           355905  56695631            7
...            ...       ...          ...
0        799821196  43284036            7
0        799778869  43603915            7
0        799778501   8780111            7
0        799765626  89034634            7
0        799889206  31087603            7

[12497064 rows x 3 columns],                key   payload  _partitions
shuffle                                  
1           481848  84777162            7
1           921538  53456639            7
1           952702  47112814            7
1           995635  52605272            7
1          1029233  95665843            7
...            ...       ...          ...
1        799924448  78768037            7
1        799973715  50967036            7
1 
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded')"

2024-01-20 07:06:41,078 - distributed.comm.ucx - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 374, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 167, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded
2024-01-20 07:06:41,078 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 374, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 167, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:320: Maximum pool size exceeded
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
